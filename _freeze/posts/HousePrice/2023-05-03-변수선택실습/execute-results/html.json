{
  "hash": "7c3d8b7946f75ab131bab9cc3eb6d4e3",
  "result": {
    "markdown": "---\ntitle: 변수선택 실습\nauthor: JiyunLim\ndate: \"05/03/2023\"\n---\n\n\n# 변수선택\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndt <- data.frame(\n x1 = c(7,1,11,11,7,11,3,1,2,21,1,11,10),\n x2 = c(26,29,56,31,52,55,71,31,54,47,40,66,68),\n x3 = c(6,15,8,8,6,9,17,22,18,4,23,9,8),\n x4 = c(60,52,20,47,33,22,6,44,22,26,34,12,12),\n y = c(78.5,74.3,104.3,87.6,95.9,109.2,102.7,72.5,93.1,115.9,83.8,113.3,109.4)\n)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\npairs(dt, pch=16)\n```\n\n::: {.cell-output-display}\n![](2023-05-03-변수선택실습_files/figure-html/unnamed-chunk-2-1.png){width=672}\n:::\n:::\n\n\n-   $x2$와 $x3$ 의 선형관계가 크게 나타난다.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncor(dt)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n           x1         x2         x3         x4          y\nx1  1.0000000  0.2285795 -0.8241338 -0.2454451  0.7307175\nx2  0.2285795  1.0000000 -0.1392424 -0.9729550  0.8162526\nx3 -0.8241338 -0.1392424  1.0000000  0.0295370 -0.5346707\nx4 -0.2454451 -0.9729550  0.0295370  1.0000000 -0.8213050\ny   0.7307175  0.8162526 -0.5346707 -0.8213050  1.0000000\n```\n:::\n:::\n\n\n### Full Model: $y=\\beta_0 + \\beta_1x_1 + \\beta_2x_2 + \\beta_3x_3+\\beta_4x_4 + \\epsilon$\n\n\n::: {.cell}\n\n```{.r .cell-code}\nm <- lm(y~., dt)  ## FM\nsummary(m)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = y ~ ., data = dt)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-3.1750 -1.6709  0.2508  1.3783  3.9254 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)  \n(Intercept)  62.4054    70.0710   0.891   0.3991  \nx1            1.5511     0.7448   2.083   0.0708 .\nx2            0.5102     0.7238   0.705   0.5009  \nx3            0.1019     0.7547   0.135   0.8959  \nx4           -0.1441     0.7091  -0.203   0.8441  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 2.446 on 8 degrees of freedom\nMultiple R-squared:  0.9824,\tAdjusted R-squared:  0.9736 \nF-statistic: 111.5 on 4 and 8 DF,  p-value: 4.756e-07\n```\n:::\n:::\n\n\n-   모형은 매우 유의하고 $R^2_{Adj}$ 도 매우 높지만 개별 회귀계수가 유의한 것은 하나도 없다. 이러한 문제가 발생하는 이유는 ***\"다중공선성\"*** 때문이다. 다중공선성이 있기 때문에 위의 모델을 그대로 사용할 수 없다.\n\n-   변수선택 시도!\n\n## 후진제거법\n\n> 가장 유의하지 않을 것을 부분 F-test를 통해 찾는다.\n\n$H_0: \\beta_1 = 0$\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(m)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = y ~ ., data = dt)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-3.1750 -1.6709  0.2508  1.3783  3.9254 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)  \n(Intercept)  62.4054    70.0710   0.891   0.3991  \nx1            1.5511     0.7448   2.083   0.0708 .\nx2            0.5102     0.7238   0.705   0.5009  \nx3            0.1019     0.7547   0.135   0.8959  \nx4           -0.1441     0.7091  -0.203   0.8441  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 2.446 on 8 degrees of freedom\nMultiple R-squared:  0.9824,\tAdjusted R-squared:  0.9736 \nF-statistic: 111.5 on 4 and 8 DF,  p-value: 4.756e-07\n```\n:::\n:::\n\n\n![](%EC%82%AC%EC%A7%84/%EB%B3%80%EC%88%98%EC%84%A0%ED%83%9D(%ED%9B%84%EC%A7%84%EC%A0%9C%EA%B1%B0).png){fig-align=\"center\"}\n\n### drop1\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndrop1(m, test='F')  # x3제거\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nSingle term deletions\n\nModel:\ny ~ x1 + x2 + x3 + x4\n       Df Sum of Sq    RSS    AIC F value  Pr(>F)  \n<none>              47.864 26.944                  \nx1      1   25.9509 73.815 30.576  4.3375 0.07082 .\nx2      1    2.9725 50.836 25.728  0.4968 0.50090  \nx3      1    0.1091 47.973 24.974  0.0182 0.89592  \nx4      1    0.2470 48.111 25.011  0.0413 0.84407  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n:::\n:::\n\n\n-   $x1$ 을 제거했을때, $x2$를 제거했을 때, $x3$ 를 제거했을 때, $x4$ 를 제거했을 때의 결과이다.\n\n-   F통계량 값이 작으면 작을수록 의미가 없다는 뜻. ($x3$ 제거)\n\n\n::: {.cell}\n\n```{.r .cell-code}\nm1 <- update(m, ~. -x3)\nsummary(m1) \n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = y ~ x1 + x2 + x4, data = dt)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-3.0919 -1.8016  0.2562  1.2818  3.8982 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  71.6483    14.1424   5.066 0.000675 ***\nx1            1.4519     0.1170  12.410 5.78e-07 ***\nx2            0.4161     0.1856   2.242 0.051687 .  \nx4           -0.2365     0.1733  -1.365 0.205395    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 2.309 on 9 degrees of freedom\nMultiple R-squared:  0.9823,\tAdjusted R-squared:  0.9764 \nF-statistic: 166.8 on 3 and 9 DF,  p-value: 3.323e-08\n```\n:::\n:::\n\n\n-   $x3$ 가 빠지게 되면서 $x1$ 입장에서 다중공선성 문제가 어느정도 해결되었다.\n\n### drop2\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndrop1(m1, test='F')\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nSingle term deletions\n\nModel:\ny ~ x1 + x2 + x4\n       Df Sum of Sq    RSS    AIC  F value    Pr(>F)    \n<none>               47.97 24.974                       \nx1      1    820.91 868.88 60.629 154.0076 5.781e-07 ***\nx2      1     26.79  74.76 28.742   5.0259   0.05169 .  \nx4      1      9.93  57.90 25.420   1.8633   0.20540    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nm2 <- update(m1, ~. -x4)\nsummary(m2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = y ~ x1 + x2, data = dt)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-2.893 -1.574 -1.302  1.363  4.048 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept) 52.57735    2.28617   23.00 5.46e-10 ***\nx1           1.46831    0.12130   12.11 2.69e-07 ***\nx2           0.66225    0.04585   14.44 5.03e-08 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 2.406 on 10 degrees of freedom\nMultiple R-squared:  0.9787,\tAdjusted R-squared:  0.9744 \nF-statistic: 229.5 on 2 and 10 DF,  p-value: 4.407e-09\n```\n:::\n:::\n\n\n### STOP!\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndrop1(m2, test='F')\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nSingle term deletions\n\nModel:\ny ~ x1 + x2\n       Df Sum of Sq     RSS    AIC F value    Pr(>F)    \n<none>                57.90 25.420                      \nx1      1    848.43  906.34 59.178  146.52 2.692e-07 ***\nx2      1   1207.78 1265.69 63.519  208.58 5.029e-08 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n:::\n:::\n\n\n-   $x1, x2$ 모두 통계적으로 유의하므로 제거하면 안된다.\n\n## 전진선택법\n\n> 절편만 있는 모형부터 시작!\n\nStart model: $y=\\beta_0 + \\epsilon$\n\n\n::: {.cell}\n\n```{.r .cell-code}\nm0 = lm(y ~ 1, data=dt) ## start model\n```\n:::\n\n\n### add1\n\n\n::: {.cell}\n\n```{.r .cell-code}\nadd1(m0,\n     scope = y~ x1 + x2 + x3 + x4,\n     test= 'F')\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nSingle term additions\n\nModel:\ny ~ 1\n       Df Sum of Sq     RSS    AIC F value    Pr(>F)    \n<none>              2715.76 71.444                      \nx1      1   1450.08 1265.69 63.519 12.6025 0.0045520 ** \nx2      1   1809.43  906.34 59.178 21.9606 0.0006648 ***\nx3      1    776.36 1939.40 69.067  4.4034 0.0597623 .  \nx4      1   1831.90  883.87 58.852 22.7985 0.0005762 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nm1 <- update(m0, ~ . + x4)\nsummary(m1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = y ~ x4, data = dt)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-12.589  -8.228   1.495   4.726  17.524 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept) 117.5679     5.2622  22.342 1.62e-10 ***\nx4           -0.7382     0.1546  -4.775 0.000576 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 8.964 on 11 degrees of freedom\nMultiple R-squared:  0.6745,\tAdjusted R-squared:  0.645 \nF-statistic:  22.8 on 1 and 11 DF,  p-value: 0.0005762\n```\n:::\n:::\n\n\n### add2\n\n\n::: {.cell}\n\n```{.r .cell-code}\nadd1(m1,\n     scope = y~ x1+x2+x3+x4,\n     test= 'F') ## x1 추가\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nSingle term additions\n\nModel:\ny ~ x4\n       Df Sum of Sq    RSS    AIC  F value    Pr(>F)    \n<none>              883.87 58.852                       \nx1      1    809.10  74.76 28.742 108.2239 1.105e-06 ***\nx2      1     14.99 868.88 60.629   0.1725    0.6867    \nx3      1    708.13 175.74 39.853  40.2946 8.375e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nm2 <- update(m1, ~ . +x1)\nsummary(m2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = y ~ x4 + x1, data = dt)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-5.0234 -1.4737  0.1371  1.7305  3.7701 \n\nCoefficients:\n             Estimate Std. Error t value Pr(>|t|)    \n(Intercept) 103.09738    2.12398   48.54 3.32e-13 ***\nx4           -0.61395    0.04864  -12.62 1.81e-07 ***\nx1            1.43996    0.13842   10.40 1.11e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 2.734 on 10 degrees of freedom\nMultiple R-squared:  0.9725,\tAdjusted R-squared:  0.967 \nF-statistic: 176.6 on 2 and 10 DF,  p-value: 1.581e-08\n```\n:::\n:::\n\n\n### STOP\n\n\n::: {.cell}\n\n```{.r .cell-code}\nadd1(m2,\n     scope=y~ x1 + x2 + x3 + x4,\n     test = \"F\") ## stop\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nSingle term additions\n\nModel:\ny ~ x4 + x1\n       Df Sum of Sq    RSS    AIC F value  Pr(>F)  \n<none>              74.762 28.742                  \nx2      1    26.789 47.973 24.974  5.0259 0.05169 .\nx3      1    23.926 50.836 25.728  4.2358 0.06969 .\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n:::\n:::\n\n\n-   기준을 $0.05$ 로 잡았을 때 $x2$ 는 모형에 포함될 수 없다.\n\n-   STOP! 최종모형은 $x1, x4$ 를 선택한 모형이 된다.\n\n-   유의수준을 \\$0.01\\$로 한다면 $x3$ 을 포함시키면 된다.\n\n## 단계적 선택법\n\n> add, drop을 번갈아 가면서 하는 것.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nm0 = lm(y~1, data=dt) ## start model (절편)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nadd1(m0,\n     scope = y ~ x1 + x2 + x3 + x4,\n     test= \"F\") ## x4추가\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nSingle term additions\n\nModel:\ny ~ 1\n       Df Sum of Sq     RSS    AIC F value    Pr(>F)    \n<none>              2715.76 71.444                      \nx1      1   1450.08 1265.69 63.519 12.6025 0.0045520 ** \nx2      1   1809.43  906.34 59.178 21.9606 0.0006648 ***\nx3      1    776.36 1939.40 69.067  4.4034 0.0597623 .  \nx4      1   1831.90  883.87 58.852 22.7985 0.0005762 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nm1 <- update(m0, ~. + x4)\nsummary(m1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = y ~ x4, data = dt)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-12.589  -8.228   1.495   4.726  17.524 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept) 117.5679     5.2622  22.342 1.62e-10 ***\nx4           -0.7382     0.1546  -4.775 0.000576 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 8.964 on 11 degrees of freedom\nMultiple R-squared:  0.6745,\tAdjusted R-squared:  0.645 \nF-statistic:  22.8 on 1 and 11 DF,  p-value: 0.0005762\n```\n:::\n:::\n\n\n### $x4$ 가 선택된 모형부터 시작!\n\n### add1\n\n\n::: {.cell}\n\n```{.r .cell-code}\nadd1(m1,\n     scope= y~ x1 + x2 + x3 + x4,\n     test = \"F\") ## x1 추가\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nSingle term additions\n\nModel:\ny ~ x4\n       Df Sum of Sq    RSS    AIC  F value    Pr(>F)    \n<none>              883.87 58.852                       \nx1      1    809.10  74.76 28.742 108.2239 1.105e-06 ***\nx2      1     14.99 868.88 60.629   0.1725    0.6867    \nx3      1    708.13 175.74 39.853  40.2946 8.375e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n:::\n:::\n\n\n-   F값이 제일 크면서 유의한 $x1$ 추가.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nm2 <- update(m1,~. + x1)\n```\n:::\n\n\n### drop1\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndrop1(m2, test = 'F') ## 제거없음.\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nSingle term deletions\n\nModel:\ny ~ x4 + x1\n       Df Sum of Sq     RSS    AIC F value    Pr(>F)    \n<none>                74.76 28.742                      \nx4      1    1190.9 1265.69 63.519  159.30 1.815e-07 ***\nx1      1     809.1  883.87 58.852  108.22 1.105e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n:::\n:::\n\n\n### add2\n\n\n::: {.cell}\n\n```{.r .cell-code}\n## 유의수준 = 0.1\nadd1(m2,\n     scope = y ~ x1 + x2 + x3 + x4,\n     test=  \"F\") ## x2 추가\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nSingle term additions\n\nModel:\ny ~ x4 + x1\n       Df Sum of Sq    RSS    AIC F value  Pr(>F)  \n<none>              74.762 28.742                  \nx2      1    26.789 47.973 24.974  5.0259 0.05169 .\nx3      1    23.926 50.836 25.728  4.2358 0.06969 .\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nm3 <- update(m2, ~. +x2)\nsummary(m3)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = y ~ x4 + x1 + x2, data = dt)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-3.0919 -1.8016  0.2562  1.2818  3.8982 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  71.6483    14.1424   5.066 0.000675 ***\nx4           -0.2365     0.1733  -1.365 0.205395    \nx1            1.4519     0.1170  12.410 5.78e-07 ***\nx2            0.4161     0.1856   2.242 0.051687 .  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 2.309 on 9 degrees of freedom\nMultiple R-squared:  0.9823,\tAdjusted R-squared:  0.9764 \nF-statistic: 166.8 on 3 and 9 DF,  p-value: 3.323e-08\n```\n:::\n:::\n\n\n### drop2\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndrop1(m3, test='F') ## x4제거\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nSingle term deletions\n\nModel:\ny ~ x4 + x1 + x2\n       Df Sum of Sq    RSS    AIC  F value    Pr(>F)    \n<none>               47.97 24.974                       \nx4      1      9.93  57.90 25.420   1.8633   0.20540    \nx1      1    820.91 868.88 60.629 154.0076 5.781e-07 ***\nx2      1     26.79  74.76 28.742   5.0259   0.05169 .  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n:::\n:::\n\n\n-   이전에 추가됐던 $x2$ 는 보지 않고 $x1, x4$ 만 보면된다.\n\n-   F값이 작고 유의확률이 큰 $x4$ 제거.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nm4 <- update(m3, ~. -x4)\nsummary(m4)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = y ~ x1 + x2, data = dt)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-2.893 -1.574 -1.302  1.363  4.048 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept) 52.57735    2.28617   23.00 5.46e-10 ***\nx1           1.46831    0.12130   12.11 2.69e-07 ***\nx2           0.66225    0.04585   14.44 5.03e-08 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 2.406 on 10 degrees of freedom\nMultiple R-squared:  0.9787,\tAdjusted R-squared:  0.9744 \nF-statistic: 229.5 on 2 and 10 DF,  p-value: 4.407e-09\n```\n:::\n:::\n\n\n### STOP!\n\n\n::: {.cell}\n\n```{.r .cell-code}\nadd1(m4,\n     scope = y~ x1 + x2 + x3 + x4,\n     test = 'F') # stop\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nSingle term additions\n\nModel:\ny ~ x1 + x2\n       Df Sum of Sq    RSS    AIC F value Pr(>F)\n<none>              57.904 25.420               \nx3      1    9.7939 48.111 25.011  1.8321 0.2089\nx4      1    9.9318 47.973 24.974  1.8633 0.2054\n```\n:::\n:::\n\n\n# AIC를 이용한 변수 선택법\n\n## Backward - AIC\n\n> AIC, BIC는 작을수록 좋음.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel_back = stats::step(m, direction = 'backward')\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nStart:  AIC=26.94\ny ~ x1 + x2 + x3 + x4\n\n       Df Sum of Sq    RSS    AIC\n- x3    1    0.1091 47.973 24.974\n- x4    1    0.2470 48.111 25.011\n- x2    1    2.9725 50.836 25.728\n<none>              47.864 26.944\n- x1    1   25.9509 73.815 30.576\n\nStep:  AIC=24.97\ny ~ x1 + x2 + x4\n\n       Df Sum of Sq    RSS    AIC\n<none>               47.97 24.974\n- x4    1      9.93  57.90 25.420\n- x2    1     26.79  74.76 28.742\n- x1    1    820.91 868.88 60.629\n```\n:::\n\n```{.r .cell-code}\nsummary(model_back)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = y ~ x1 + x2 + x4, data = dt)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-3.0919 -1.8016  0.2562  1.2818  3.8982 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  71.6483    14.1424   5.066 0.000675 ***\nx1            1.4519     0.1170  12.410 5.78e-07 ***\nx2            0.4161     0.1856   2.242 0.051687 .  \nx4           -0.2365     0.1733  -1.365 0.205395    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 2.309 on 9 degrees of freedom\nMultiple R-squared:  0.9823,\tAdjusted R-squared:  0.9764 \nF-statistic: 166.8 on 3 and 9 DF,  p-value: 3.323e-08\n```\n:::\n:::\n\n\n-   최종적으로 $x1,x2,x4$ 가 뽑힌 모형이 된다.\n\n-   모형 자체는 유의하지만 개별 회귀계수의 p-value 를 보면 에매하게 유의하다. ($x2$ 는 에매하고, $x4$ 는 유의하지 않다.)\n\n::: {.callout-warning appearance=\"simple\"}\n## Error in length(obj): class name too long in 'length'\n\n`step` 함수 사용시 위와 같은 에러메세지가 난다면,\n\nstats::step() 이런식으로 지정해주면 된다. ( package conflict )\n:::\n\n## Forward - AIC\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel_forward = stats::step(\n  m0,\n  scope = y~ x1+x2+x3+x4,\n  direction = 'forward')\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nStart:  AIC=71.44\ny ~ 1\n\n       Df Sum of Sq     RSS    AIC\n+ x4    1   1831.90  883.87 58.852\n+ x2    1   1809.43  906.34 59.178\n+ x1    1   1450.08 1265.69 63.519\n+ x3    1    776.36 1939.40 69.067\n<none>              2715.76 71.444\n\nStep:  AIC=58.85\ny ~ x4\n\n       Df Sum of Sq    RSS    AIC\n+ x1    1    809.10  74.76 28.742\n+ x3    1    708.13 175.74 39.853\n<none>              883.87 58.852\n+ x2    1     14.99 868.88 60.629\n\nStep:  AIC=28.74\ny ~ x4 + x1\n\n       Df Sum of Sq    RSS    AIC\n+ x2    1    26.789 47.973 24.974\n+ x3    1    23.926 50.836 25.728\n<none>              74.762 28.742\n\nStep:  AIC=24.97\ny ~ x4 + x1 + x2\n\n       Df Sum of Sq    RSS    AIC\n<none>              47.973 24.974\n+ x3    1   0.10909 47.864 26.944\n```\n:::\n\n```{.r .cell-code}\nsummary(model_forward)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = y ~ x4 + x1 + x2, data = dt)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-3.0919 -1.8016  0.2562  1.2818  3.8982 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  71.6483    14.1424   5.066 0.000675 ***\nx4           -0.2365     0.1733  -1.365 0.205395    \nx1            1.4519     0.1170  12.410 5.78e-07 ***\nx2            0.4161     0.1856   2.242 0.051687 .  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 2.309 on 9 degrees of freedom\nMultiple R-squared:  0.9823,\tAdjusted R-squared:  0.9764 \nF-statistic: 166.8 on 3 and 9 DF,  p-value: 3.323e-08\n```\n:::\n:::\n\n\n-   절편만 포함된 모형이 start model! ($AIC=71.44$)\n\n-   $x4$ 를 추가했을 때 AIC가 가장 작아졌으므로 $x4$ 추가.\n\n-   $x4$ 가 추가된 상태에서 나머지 변수들 추가해보기\n\n-   $x1$ 을 추가했을 때, AIC가 가장작아지므로 $x1$ 추가.\n\n-   $x1, x4$ 가 있는 상태에서 $x2, x3$ 를 추가해본다.\n\n-   $x2$ 를 넣었을 때 AIC가 가장 작아지므로 $x2$ 추가.\n\n-   $x3$ 를 넣어도 좋아지지 않으므로 최종적으로 $x1,x2, x4$ 선택.\n\n## Step-AIC\n\n> direction = 'both'\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel_step = stats::step(\n  m0,\n  scope = y ~ x1 + x2 + x3 + x4,\n  direction = 'both')\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nStart:  AIC=71.44\ny ~ 1\n\n       Df Sum of Sq     RSS    AIC\n+ x4    1   1831.90  883.87 58.852\n+ x2    1   1809.43  906.34 59.178\n+ x1    1   1450.08 1265.69 63.519\n+ x3    1    776.36 1939.40 69.067\n<none>              2715.76 71.444\n\nStep:  AIC=58.85\ny ~ x4\n\n       Df Sum of Sq     RSS    AIC\n+ x1    1    809.10   74.76 28.742\n+ x3    1    708.13  175.74 39.853\n<none>               883.87 58.852\n+ x2    1     14.99  868.88 60.629\n- x4    1   1831.90 2715.76 71.444\n\nStep:  AIC=28.74\ny ~ x4 + x1\n\n       Df Sum of Sq     RSS    AIC\n+ x2    1     26.79   47.97 24.974\n+ x3    1     23.93   50.84 25.728\n<none>                74.76 28.742\n- x1    1    809.10  883.87 58.852\n- x4    1   1190.92 1265.69 63.519\n\nStep:  AIC=24.97\ny ~ x4 + x1 + x2\n\n       Df Sum of Sq    RSS    AIC\n<none>               47.97 24.974\n- x4    1      9.93  57.90 25.420\n+ x3    1      0.11  47.86 26.944\n- x2    1     26.79  74.76 28.742\n- x1    1    820.91 868.88 60.629\n```\n:::\n\n```{.r .cell-code}\nsummary(model_step)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = y ~ x4 + x1 + x2, data = dt)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-3.0919 -1.8016  0.2562  1.2818  3.8982 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  71.6483    14.1424   5.066 0.000675 ***\nx4           -0.2365     0.1733  -1.365 0.205395    \nx1            1.4519     0.1170  12.410 5.78e-07 ***\nx2            0.4161     0.1856   2.242 0.051687 .  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 2.309 on 9 degrees of freedom\nMultiple R-squared:  0.9823,\tAdjusted R-squared:  0.9764 \nF-statistic: 166.8 on 3 and 9 DF,  p-value: 3.323e-08\n```\n:::\n:::\n\n\n-   최종모형으로는 $x1,x2,x4$ 가 뽑히게 된다.\n\n# 자동차 연비 분석\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmcor <- round(cor(mtcars),2)\nmcor\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n       mpg   cyl  disp    hp  drat    wt  qsec    vs    am  gear  carb\nmpg   1.00 -0.85 -0.85 -0.78  0.68 -0.87  0.42  0.66  0.60  0.48 -0.55\ncyl  -0.85  1.00  0.90  0.83 -0.70  0.78 -0.59 -0.81 -0.52 -0.49  0.53\ndisp -0.85  0.90  1.00  0.79 -0.71  0.89 -0.43 -0.71 -0.59 -0.56  0.39\nhp   -0.78  0.83  0.79  1.00 -0.45  0.66 -0.71 -0.72 -0.24 -0.13  0.75\ndrat  0.68 -0.70 -0.71 -0.45  1.00 -0.71  0.09  0.44  0.71  0.70 -0.09\nwt   -0.87  0.78  0.89  0.66 -0.71  1.00 -0.17 -0.55 -0.69 -0.58  0.43\nqsec  0.42 -0.59 -0.43 -0.71  0.09 -0.17  1.00  0.74 -0.23 -0.21 -0.66\nvs    0.66 -0.81 -0.71 -0.72  0.44 -0.55  0.74  1.00  0.17  0.21 -0.57\nam    0.60 -0.52 -0.59 -0.24  0.71 -0.69 -0.23  0.17  1.00  0.79  0.06\ngear  0.48 -0.49 -0.56 -0.13  0.70 -0.58 -0.21  0.21  0.79  1.00  0.27\ncarb -0.55  0.53  0.39  0.75 -0.09  0.43 -0.66 -0.57  0.06  0.27  1.00\n```\n:::\n:::\n\n\n$y$와 상관관계가 높은 애들도 많지만 설명변수들끼리 상관관계가 높은 애들도 많다. (다중공선성)\\\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfit <- lm(mpg~., data=mtcars)\nsummary(fit)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = mpg ~ ., data = mtcars)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-3.4506 -1.6044 -0.1196  1.2193  4.6271 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)  \n(Intercept) 12.30337   18.71788   0.657   0.5181  \ncyl         -0.11144    1.04502  -0.107   0.9161  \ndisp         0.01334    0.01786   0.747   0.4635  \nhp          -0.02148    0.02177  -0.987   0.3350  \ndrat         0.78711    1.63537   0.481   0.6353  \nwt          -3.71530    1.89441  -1.961   0.0633 .\nqsec         0.82104    0.73084   1.123   0.2739  \nvs           0.31776    2.10451   0.151   0.8814  \nam           2.52023    2.05665   1.225   0.2340  \ngear         0.65541    1.49326   0.439   0.6652  \ncarb        -0.19942    0.82875  -0.241   0.8122  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 2.65 on 21 degrees of freedom\nMultiple R-squared:  0.869,\tAdjusted R-squared:  0.8066 \nF-statistic: 13.93 on 10 and 21 DF,  p-value: 3.793e-07\n```\n:::\n:::\n\n\n-   모형자체는 유의하게 나왔지만 개별 회귀계수는 모두 유의하지 않게 나왔다. $\\to$ 다중공선성 때문!\n-   그럼 앞에서 배웠던 drop, add 이용해서 계속 해야할까? $\\to$ 이것은 수동적인 방법\n-   보통 2가지 사용하는데 1. `step` 함수이용 2. `regsubsets` 보통 2번째 방법을 많이 사용한다.\n-   `regsubsets` : regression subset들을 가지고 보겠다라고 생각.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(leaps)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nfit <- regsubsets(mpg ~., data=mtcars, nbest=1, nvmax=9,\n                  # method = c('exhuastive', 'backward', 'forward', 'seqrep')\n                  method = 'exhaustive'\n                  )\n```\n:::\n\n\n::: {.callout-note appearance=\"simple\"}\n## regsubsets\n\n    method=c(\"exhaustive\",\"backward\", \"forward\", \"seqrep\")\n\n    순서대로 1. 모든 가능한 회귀, 2.후진제거, 3. 전진선택, 4. stepwise\n:::\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(fit)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nSubset selection object\nCall: regsubsets.formula(mpg ~ ., data = mtcars, nbest = 1, nvmax = 9, \n    method = \"exhaustive\")\n10 Variables  (and intercept)\n     Forced in Forced out\ncyl      FALSE      FALSE\ndisp     FALSE      FALSE\nhp       FALSE      FALSE\ndrat     FALSE      FALSE\nwt       FALSE      FALSE\nqsec     FALSE      FALSE\nvs       FALSE      FALSE\nam       FALSE      FALSE\ngear     FALSE      FALSE\ncarb     FALSE      FALSE\n1 subsets of each size up to 9\nSelection Algorithm: exhaustive\n         cyl disp hp  drat wt  qsec vs  am  gear carb\n1  ( 1 ) \" \" \" \"  \" \" \" \"  \"*\" \" \"  \" \" \" \" \" \"  \" \" \n2  ( 1 ) \"*\" \" \"  \" \" \" \"  \"*\" \" \"  \" \" \" \" \" \"  \" \" \n3  ( 1 ) \" \" \" \"  \" \" \" \"  \"*\" \"*\"  \" \" \"*\" \" \"  \" \" \n4  ( 1 ) \" \" \" \"  \"*\" \" \"  \"*\" \"*\"  \" \" \"*\" \" \"  \" \" \n5  ( 1 ) \" \" \"*\"  \"*\" \" \"  \"*\" \"*\"  \" \" \"*\" \" \"  \" \" \n6  ( 1 ) \" \" \"*\"  \"*\" \"*\"  \"*\" \"*\"  \" \" \"*\" \" \"  \" \" \n7  ( 1 ) \" \" \"*\"  \"*\" \"*\"  \"*\" \"*\"  \" \" \"*\" \"*\"  \" \" \n8  ( 1 ) \" \" \"*\"  \"*\" \"*\"  \"*\" \"*\"  \" \" \"*\" \"*\"  \"*\" \n9  ( 1 ) \" \" \"*\"  \"*\" \"*\"  \"*\" \"*\"  \"*\" \"*\" \"*\"  \"*\" \n```\n:::\n:::\n\n\n-   꼭 넣고 싶은 변수가 있다 Forced in , 꼭 빼고 싶은 변수가 있다 Forced out\n\n-   우리는 옵션을 준 것이 하나도 없기때문에 다 FALSE로 되어있음.\n\n-   \"\\*\" 의 의미?\n\n    -   예를 들어, 2번째 `cyl` 와 `wt` 에 \"\\*\" 표시가 되어있다. 이 말은\n\n    -   $_{10}C_2 = \\frac{10\\times 9}{2}=45$ 개의 조합으로 lm을 다 돌린 후 $R^2$ 를 비교하여 제일 좋은 $R^2$ 모형을 찾아준다. 즉, 변수가 2개인 모형 중에서는 `cyl` 과 `wt` 가 들어간 모델이 제일 좋은 모델이라는 것!\n\n    -   변수를 1개를 쓴 모델 중에는 `wt` 를 쓴 모델이 제일 좋았다.\n\n    -   3개를 쓴 모델 중에는 `wt`, `qsec` , `am` 이 들어간 모델이 제일 좋았다.\n\n그렇다면 10개 중에서는 어떤 모델이 가장 좋은가?\n\n\n::: {.cell}\n\n```{.r .cell-code}\nwith(summary(fit),\n     round(cbind(which, rss, rsq, adjr2, cp, bic), 3))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n  (Intercept) cyl disp hp drat wt qsec vs am gear carb     rss   rsq adjr2\n1           1   0    0  0    0  1    0  0  0    0    0 278.322 0.753 0.745\n2           1   1    0  0    0  1    0  0  0    0    0 191.172 0.830 0.819\n3           1   0    0  0    0  1    1  0  1    0    0 169.286 0.850 0.834\n4           1   0    0  1    0  1    1  0  1    0    0 160.066 0.858 0.837\n5           1   0    1  1    0  1    1  0  1    0    0 153.438 0.864 0.838\n6           1   0    1  1    1  1    1  0  1    0    0 150.093 0.867 0.835\n7           1   0    1  1    1  1    1  0  1    1    0 148.528 0.868 0.830\n8           1   0    1  1    1  1    1  0  1    1    1 147.843 0.869 0.823\n9           1   0    1  1    1  1    1  1  1    1    1 147.574 0.869 0.815\n      cp     bic\n1 11.627 -37.795\n2  1.219 -46.348\n3  0.103 -46.773\n4  0.790 -45.099\n5  1.846 -42.987\n6  3.370 -40.227\n7  5.147 -37.096\n8  7.050 -33.779\n9  9.011 -30.371\n```\n:::\n:::\n\n\n-   각 각 어떤 변수를 썼을 때 좋은지 나타나고, measure가 나옴.\n\n-   SSE는 복잡한 모델일수록 작아진다. $\\to$ 감소하는데 둔화되는 지점을 찾자.\n\n![](%EC%82%AC%EC%A7%84/%EB%B3%80%EC%88%98%EC%84%A0%ED%83%9D(%EA%B2%B0%EA%B3%BC%EB%B9%84%EA%B5%90).png)\n\n-   변수를 3개정도 선택하면 좋을 것 같다.\n\n-   다른 책의 경우 종합적으로 판단해서 4개를 골랐다. 판단을 했을 때 결과는 주관적이다.\n\n-   똑같은 표라도 사람마다 다른 결과를 내릴 수 있다. (3개정도 쓰면 적당할듯?)\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfit_4 <- lm(mpg~hp + wt + qsec + am, mtcars)\nsummary(fit_4)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = mpg ~ hp + wt + qsec + am, data = mtcars)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-3.4975 -1.5902 -0.1122  1.1795  4.5404 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)   \n(Intercept) 17.44019    9.31887   1.871  0.07215 . \nhp          -0.01765    0.01415  -1.247  0.22309   \nwt          -3.23810    0.88990  -3.639  0.00114 **\nqsec         0.81060    0.43887   1.847  0.07573 . \nam           2.92550    1.39715   2.094  0.04579 * \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 2.435 on 27 degrees of freedom\nMultiple R-squared:  0.8579,\tAdjusted R-squared:  0.8368 \nF-statistic: 40.74 on 4 and 27 DF,  p-value: 4.589e-11\n```\n:::\n:::\n\n\n-   `hp` 는 빼는 게 나을 것 같은데?\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfit_5 <- lm(mpg~ wt + qsec + am, mtcars)\nsummary(fit_5)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = mpg ~ wt + qsec + am, data = mtcars)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-3.4811 -1.5555 -0.7257  1.4110  4.6610 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)   9.6178     6.9596   1.382 0.177915    \nwt           -3.9165     0.7112  -5.507 6.95e-06 ***\nqsec          1.2259     0.2887   4.247 0.000216 ***\nam            2.9358     1.4109   2.081 0.046716 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 2.459 on 28 degrees of freedom\nMultiple R-squared:  0.8497,\tAdjusted R-squared:  0.8336 \nF-statistic: 52.75 on 3 and 28 DF,  p-value: 1.21e-11\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nfit <- regsubsets(mpg~., data=mtcars, nbest=1, nvmax=9,\n                  # method =c('exhaustive','backward', 'forward','seqrep')\n                  method = 'backward'\n                  )\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(fit)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nSubset selection object\nCall: regsubsets.formula(mpg ~ ., data = mtcars, nbest = 1, nvmax = 9, \n    method = \"backward\")\n10 Variables  (and intercept)\n     Forced in Forced out\ncyl      FALSE      FALSE\ndisp     FALSE      FALSE\nhp       FALSE      FALSE\ndrat     FALSE      FALSE\nwt       FALSE      FALSE\nqsec     FALSE      FALSE\nvs       FALSE      FALSE\nam       FALSE      FALSE\ngear     FALSE      FALSE\ncarb     FALSE      FALSE\n1 subsets of each size up to 9\nSelection Algorithm: backward\n         cyl disp hp  drat wt  qsec vs  am  gear carb\n1  ( 1 ) \" \" \" \"  \" \" \" \"  \"*\" \" \"  \" \" \" \" \" \"  \" \" \n2  ( 1 ) \" \" \" \"  \" \" \" \"  \"*\" \"*\"  \" \" \" \" \" \"  \" \" \n3  ( 1 ) \" \" \" \"  \" \" \" \"  \"*\" \"*\"  \" \" \"*\" \" \"  \" \" \n4  ( 1 ) \" \" \" \"  \"*\" \" \"  \"*\" \"*\"  \" \" \"*\" \" \"  \" \" \n5  ( 1 ) \" \" \"*\"  \"*\" \" \"  \"*\" \"*\"  \" \" \"*\" \" \"  \" \" \n6  ( 1 ) \" \" \"*\"  \"*\" \"*\"  \"*\" \"*\"  \" \" \"*\" \" \"  \" \" \n7  ( 1 ) \" \" \"*\"  \"*\" \"*\"  \"*\" \"*\"  \" \" \"*\" \"*\"  \" \" \n8  ( 1 ) \" \" \"*\"  \"*\" \"*\"  \"*\" \"*\"  \" \" \"*\" \"*\"  \"*\" \n9  ( 1 ) \" \" \"*\"  \"*\" \"*\"  \"*\" \"*\"  \"*\" \"*\" \"*\"  \"*\" \n```\n:::\n:::\n\n\n-   후진제거법은 10번째부터 시작해서 거꾸로 올라가는 것.\n\n-   9: `cyl` 라는 변수가 빠지고 9개 사용.\n\n-   8: `cyl` , `vs` 라는 변수가 빠지고 8개 사용.\n\n-   이런식으로 순차적으로 찾아나가는 것이므로, 모든 가능한 회귀와는 결과과 좀 다르게 나온다.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nwith(summary(fit),\n     round(cbind(which, rss, rsq, adjr2, cp, bic),3))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n  (Intercept) cyl disp hp drat wt qsec vs am gear carb     rss   rsq adjr2\n1           1   0    0  0    0  1    0  0  0    0    0 278.322 0.753 0.745\n2           1   0    0  0    0  1    1  0  0    0    0 195.464 0.826 0.814\n3           1   0    0  0    0  1    1  0  1    0    0 169.286 0.850 0.834\n4           1   0    0  1    0  1    1  0  1    0    0 160.066 0.858 0.837\n5           1   0    1  1    0  1    1  0  1    0    0 153.438 0.864 0.838\n6           1   0    1  1    1  1    1  0  1    0    0 150.093 0.867 0.835\n7           1   0    1  1    1  1    1  0  1    1    0 148.528 0.868 0.830\n8           1   0    1  1    1  1    1  0  1    1    1 147.843 0.869 0.823\n9           1   0    1  1    1  1    1  1  1    1    1 147.574 0.869 0.815\n      cp     bic\n1 11.627 -37.795\n2  1.830 -45.638\n3  0.103 -46.773\n4  0.790 -45.099\n5  1.846 -42.987\n6  3.370 -40.227\n7  5.147 -37.096\n8  7.050 -33.779\n9  9.011 -30.371\n```\n:::\n:::\n",
    "supporting": [
      "2023-05-03-변수선택실습_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}