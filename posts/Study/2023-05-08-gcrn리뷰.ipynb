{
 "cells": [
  {
   "cell_type": "raw",
   "id": "8cebf181-f21a-4d1a-a214-765755e1f029",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"GCRN\" \n",
    "author: \"JiyunLim\"\n",
    "date: \"05/08/2023\"\n",
    "categories:\n",
    "  - Research\n",
    "  - STGCN\n",
    "  - PAPER REVIEW\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32013e35-db0f-4abb-92da-667a37fb10e5",
   "metadata": {},
   "source": [
    "> STRUCTURED SEQUENCE MODELING WITH GRAPH CONVOLUTIONAL RECURRENT NETWORKS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5544e9dc-80d5-488a-a9c3-f12b54bc054d",
   "metadata": {},
   "source": [
    "# GCRN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42d866a2-f677-4644-a351-e7af1990b8af",
   "metadata": {},
   "source": [
    "> Seo, Youngjoo, et al. \"Structured sequence modeling with graph convolutional recurrent networks.\" Neural Information Processing: 25th International Conference, ICONIP 2018, Siem Reap, Cambodia, December 13-16, 2018, Proceedings, Part I 25. Springer International Publishing, 2018."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6f9a78a-3a2d-4020-8306-48aa23743fe3",
   "metadata": {},
   "source": [
    "- [arXiv](https://arxiv.org/abs/1612.07659)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e96fb4c-33f9-42cf-90a8-1ae1d6bddfc7",
   "metadata": {},
   "source": [
    "This paper introduces Graph Convolutional Recurrent Network (GCRN), a deep learning model able to predict structured sequences of data. Precisely, GCRN is a generalization of classical recurrent neural networks (RNN) to data structured by an arbitrary graph. Such structured sequences can represent series of frames in videos, spatio-temporal measurements on a network of sensors, or random walks on a vocabulary graph for natural language modeling. The proposed model combines convolutional neural networks (CNN) on graphs to identify spatial structures and RNN to find dynamic patterns. We study two possible architectures of GCRN, and apply the models to two practical problems: predicting moving MNIST data, and modeling natural language with the Penn Treebank dataset. Experiments show that exploiting simultaneously graph spatial and dynamic information about data can improve both precision and learning speed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "071dfa7c-204e-4741-bb5c-ed522b0bc91b",
   "metadata": {},
   "source": [
    "본 논문은 구조화된 데이터 시퀀스를 예측할 수 있는 딥러닝 모델인 Graph Convolutional Recurrent Network (GCRN)에 대해 소개한다. GCRN은 임의의 그래프로 구조화된 데이터에 대한 고전적인 recurrnet neural network(RNN)의 일반화 버전이다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23a24801-2198-45af-8953-23f939f7e85a",
   "metadata": {},
   "source": [
    "제안된 모델은 convolutional neural networks(CNN)을 결합하여 공간 구조를 식별하고 동적 패턴을 찾는 RNN을 결합한다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70e5fddc-7fed-4d94-b9e6-a0ba35c5070b",
   "metadata": {},
   "source": [
    "본 논문에서는 GCRN의 두 가지 가능한 아키텍처를 연구하고 모델을 두 가지 실제 문제에 적용해본다. (moving-MNIST 데이터 예측, 펜트리뱅크 데이터 셋을 이용한 자연어 모델링)\n",
    "\n",
    "실험에 따르면 데이터에 대한 그래프 공간 정보와 동적 정보를 동시에 활용하면 정밀도와 학습속도를 모두 향상시킬 수 있다고 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6476fdf-ed40-45fa-9a75-c0c175ae1a95",
   "metadata": {},
   "source": [
    "## INTRODUCTION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53dd77b1-b107-4a24-a78f-e266be820e74",
   "metadata": {},
   "source": [
    "Many real-world data can be cast as structured sequences, with spatio-temporal sequences being a special case. A well-studied example of spatio-temporal data are videos, where succeeding frames share temporal and spatial structures. Many works, such as Donahue et al. (2015); Karpathy & FeiFei (2015); Vinyals et al. (2015), leveraged a combination of CNN and RNN to exploit such spatial and temporal regularities. Their models are able to process possibly time-varying visual inputs for variable-length prediction. These neural network architectures consist of combining a CNN for visual feature extraction followed by a RNN for sequence learning. Such architectures have been successfully used for video activity recognition, image captioning and video description.\n",
    "More recently, interest has grown in properly fusing the CNN and RNN models for spatio-temporal sequence modeling. Inspired by language modeling, Ranzato et al. (2014) proposed a model to represent complex deformations and motion patterns by discovering both spatial and temporal correlations. They showed that prediction of the next video frame and interpolation of intermediate frames can be achieved by building a RNN-based language model on the visual words obtained by quantizing the image patches. Their highest-performing model, recursive CNN (rCNN), uses convolutions for both inputs and states. Shi et al. (2015) then proposed the convolutional LSTM network (convLSTM), a recurrent model for spatio-temporal sequence modeling which uses 2D-grid convolution to leverage the spatial correlations in input data. They successfully applied their model to the\n",
    "prediction of the evolution of radar echo maps for precipitation nowcasting.\n",
    "The spatial structure of many important problems may however not be as simple as regular grids.\n",
    "\n",
    "\n",
    "For instance, the data measured from meteorological stations lie on a irregular grid, i.e. a network of heterogeneous spatial distribution of stations. More challenging, the spatial structure of data may not even be spatial, as it is the case for social or biological networks. Eventually, the interpretation that\n",
    "sentences can be regarded as random walks on vocabulary graphs, a view popularized by Mikolov et al. (2013), allows us to cast language analysis problems as graph-structured sequence models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d4271fa-20d5-4968-99be-694efbd07c1e",
   "metadata": {},
   "source": [
    "## PROPOSED GCRN MODELS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90552247-93fe-49d3-8976-2ebf03311216",
   "metadata": {},
   "source": [
    "```python\n",
    "import torch\n",
    "from torch_geometric.nn import ChebConv\n",
    "\n",
    "\n",
    "[docs]class GConvGRU(torch.nn.Module):\n",
    "    r\"\"\"An implementation of the Chebyshev Graph Convolutional Gated Recurrent Unit\n",
    "    Cell. For details see this paper: `\"Structured Sequence Modeling with Graph\n",
    "    Convolutional Recurrent Networks.\" <https://arxiv.org/abs/1612.07659>`_\n",
    "\n",
    "    Args:\n",
    "        in_channels (int): Number of input features.\n",
    "        out_channels (int): Number of output features.\n",
    "        K (int): Chebyshev filter size :math:`K`.\n",
    "        normalization (str, optional): The normalization scheme for the graph\n",
    "            Laplacian (default: :obj:`\"sym\"`):\n",
    "\n",
    "            1. :obj:`None`: No normalization\n",
    "            :math:`\\mathbf{L} = \\mathbf{D} - \\mathbf{A}`\n",
    "\n",
    "            2. :obj:`\"sym\"`: Symmetric normalization\n",
    "            :math:`\\mathbf{L} = \\mathbf{I} - \\mathbf{D}^{-1/2} \\mathbf{A}\n",
    "            \\mathbf{D}^{-1/2}`\n",
    "\n",
    "            3. :obj:`\"rw\"`: Random-walk normalization\n",
    "            :math:`\\mathbf{L} = \\mathbf{I} - \\mathbf{D}^{-1} \\mathbf{A}`\n",
    "\n",
    "            You need to pass :obj:`lambda_max` to the :meth:`forward` method of\n",
    "            this operator in case the normalization is non-symmetric.\n",
    "            :obj:`\\lambda_max` should be a :class:`torch.Tensor` of size\n",
    "            :obj:`[num_graphs]` in a mini-batch scenario and a\n",
    "            scalar/zero-dimensional tensor when operating on single graphs.\n",
    "            You can pre-compute :obj:`lambda_max` via the\n",
    "            :class:`torch_geometric.transforms.LaplacianLambdaMax` transform.\n",
    "        bias (bool, optional): If set to :obj:`False`, the layer will not learn\n",
    "            an additive bias. (default: :obj:`True`)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels: int,\n",
    "        out_channels: int,\n",
    "        K: int,\n",
    "        normalization: str = \"sym\",\n",
    "        bias: bool = True,\n",
    "    ):\n",
    "        super(GConvGRU, self).__init__()\n",
    "\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.K = K\n",
    "        self.normalization = normalization\n",
    "        self.bias = bias\n",
    "        self._create_parameters_and_layers()\n",
    "\n",
    "    def _create_update_gate_parameters_and_layers(self):\n",
    "\n",
    "        self.conv_x_z = ChebConv(\n",
    "            in_channels=self.in_channels,\n",
    "            out_channels=self.out_channels,\n",
    "            K=self.K,\n",
    "            normalization=self.normalization,\n",
    "            bias=self.bias,\n",
    "        )\n",
    "\n",
    "        self.conv_h_z = ChebConv(\n",
    "            in_channels=self.out_channels,\n",
    "            out_channels=self.out_channels,\n",
    "            K=self.K,\n",
    "            normalization=self.normalization,\n",
    "            bias=self.bias,\n",
    "        )\n",
    "\n",
    "    def _create_reset_gate_parameters_and_layers(self):\n",
    "\n",
    "        self.conv_x_r = ChebConv(\n",
    "            in_channels=self.in_channels,\n",
    "            out_channels=self.out_channels,\n",
    "            K=self.K,\n",
    "            normalization=self.normalization,\n",
    "            bias=self.bias,\n",
    "        )\n",
    "\n",
    "        self.conv_h_r = ChebConv(\n",
    "            in_channels=self.out_channels,\n",
    "            out_channels=self.out_channels,\n",
    "            K=self.K,\n",
    "            normalization=self.normalization,\n",
    "            bias=self.bias,\n",
    "        )\n",
    "\n",
    "    def _create_candidate_state_parameters_and_layers(self):\n",
    "\n",
    "        self.conv_x_h = ChebConv(\n",
    "            in_channels=self.in_channels,\n",
    "            out_channels=self.out_channels,\n",
    "            K=self.K,\n",
    "            normalization=self.normalization,\n",
    "            bias=self.bias,\n",
    "        )\n",
    "\n",
    "        self.conv_h_h = ChebConv(\n",
    "            in_channels=self.out_channels,\n",
    "            out_channels=self.out_channels,\n",
    "            K=self.K,\n",
    "            normalization=self.normalization,\n",
    "            bias=self.bias,\n",
    "        )\n",
    "\n",
    "    def _create_parameters_and_layers(self):\n",
    "        self._create_update_gate_parameters_and_layers()\n",
    "        self._create_reset_gate_parameters_and_layers()\n",
    "        self._create_candidate_state_parameters_and_layers()\n",
    "\n",
    "    def _set_hidden_state(self, X, H):\n",
    "        if H is None:\n",
    "            H = torch.zeros(X.shape[0], self.out_channels).to(X.device)\n",
    "        return H\n",
    "\n",
    "    def _calculate_update_gate(self, X, edge_index, edge_weight, H, lambda_max):\n",
    "        Z = self.conv_x_z(X, edge_index, edge_weight, lambda_max=lambda_max)\n",
    "        Z = Z + self.conv_h_z(H, edge_index, edge_weight, lambda_max=lambda_max)\n",
    "        Z = torch.sigmoid(Z)\n",
    "        return Z\n",
    "\n",
    "    def _calculate_reset_gate(self, X, edge_index, edge_weight, H, lambda_max):\n",
    "        R = self.conv_x_r(X, edge_index, edge_weight, lambda_max=lambda_max)\n",
    "        R = R + self.conv_h_r(H, edge_index, edge_weight, lambda_max=lambda_max)\n",
    "        R = torch.sigmoid(R)\n",
    "        return R\n",
    "\n",
    "    def _calculate_candidate_state(self, X, edge_index, edge_weight, H, R, lambda_max):\n",
    "        H_tilde = self.conv_x_h(X, edge_index, edge_weight, lambda_max=lambda_max)\n",
    "        H_tilde = H_tilde + self.conv_h_h(H * R, edge_index, edge_weight, lambda_max=lambda_max)\n",
    "        H_tilde = torch.tanh(H_tilde)\n",
    "        return H_tilde\n",
    "\n",
    "    def _calculate_hidden_state(self, Z, H, H_tilde):\n",
    "        H = Z * H + (1 - Z) * H_tilde\n",
    "        return H\n",
    "\n",
    "[docs]    def forward(\n",
    "        self,\n",
    "        X: torch.FloatTensor,\n",
    "        edge_index: torch.LongTensor,\n",
    "        edge_weight: torch.FloatTensor = None,\n",
    "        H: torch.FloatTensor = None,\n",
    "        lambda_max: torch.Tensor = None,\n",
    "    ) -> torch.FloatTensor:\n",
    "        \"\"\"\n",
    "        Making a forward pass. If edge weights are not present the forward pass\n",
    "        defaults to an unweighted graph. If the hidden state matrix is not present\n",
    "        when the forward pass is called it is initialized with zeros.\n",
    "\n",
    "        Arg types:\n",
    "            * **X** *(PyTorch Float Tensor)* - Node features.\n",
    "            * **edge_index** *(PyTorch Long Tensor)* - Graph edge indices.\n",
    "            * **edge_weight** *(PyTorch Long Tensor, optional)* - Edge weight vector.\n",
    "            * **H** *(PyTorch Float Tensor, optional)* - Hidden state matrix for all nodes.\n",
    "            * **lambda_max** *(PyTorch Tensor, optional but mandatory if normalization is not sym)* - Largest eigenvalue of Laplacian.\n",
    "\n",
    "\n",
    "        Return types:\n",
    "            * **H** *(PyTorch Float Tensor)* - Hidden state matrix for all nodes.\n",
    "        \"\"\"\n",
    "        H = self._set_hidden_state(X, H)\n",
    "        Z = self._calculate_update_gate(X, edge_index, edge_weight, H, lambda_max)\n",
    "        R = self._calculate_reset_gate(X, edge_index, edge_weight, H, lambda_max)\n",
    "        H_tilde = self._calculate_candidate_state(X, edge_index, edge_weight, H, R, lambda_max)\n",
    "        H = self._calculate_hidden_state(Z, H, H_tilde)\n",
    "        return H\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e360e4f6-397a-49d0-9090-af31e0248be7",
   "metadata": {},
   "source": [
    "# Spatio-Temporal Graph Structure Learning for Traffic Forecasting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "402bf2ce-f647-441a-84ae-e39a2a25ab1c",
   "metadata": {},
   "source": [
    "- [download](https://ojs.aaai.org/index.php/AAAI/article/view/5470/5326)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c669cea8-46e4-4305-b98a-9156752d2e9b",
   "metadata": {},
   "source": [
    ">Zhang, Qi, et al. \"Spatio-temporal graph structure learning for traffic forecasting.\" Proceedings of the AAAI conference on artificial intelligence. Vol. 34. No. 01. 2020."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
