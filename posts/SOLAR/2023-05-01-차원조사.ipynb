{
 "cells": [
  {
   "cell_type": "raw",
   "id": "cf4a5937-6946-43b0-99b9-73cb93bbacba",
   "metadata": {},
   "source": [
    "---\n",
    "title: \" **[SOLAR]** 차원조사\" \n",
    "author: \"JiyunLim\"\n",
    "date: \"04/29/2023\"\n",
    "categories:\n",
    "  - Research\n",
    "  - STGCN\n",
    "  - SOLAR\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2ed78ef-ccda-4aca-8bb7-69c50b238bb3",
   "metadata": {},
   "source": [
    "# STGCN 튜토리얼"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feef2d6b-fbb3-4e8d-838b-2448d38c3abe",
   "metadata": {},
   "source": [
    "- ref: <https://miruetoto.github.io/yechan3/posts/3_Researches/ITSTGCN/2022-12-29-STGCN-tutorial.html>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bc8bd68-9be0-403b-ad55-b2c793f8f0a7",
   "metadata": {},
   "source": [
    "# import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b8604e7-5c59-4da3-80d0-e657ccb1f4c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 일반적인 모듈 \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import networkx as nx \n",
    "from tqdm import tqdm \n",
    "\n",
    "# 파이토치 관련 \n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# PyG 관련 \n",
    "from torch_geometric.data import Data\n",
    "\n",
    "# STGCN 관련 \n",
    "import torch_geometric_temporal\n",
    "from torch_geometric_temporal.nn.recurrent import GConvGRU\n",
    "from torch_geometric_temporal.signal import temporal_signal_split \n",
    "import eptstgcn\n",
    "import eptstgcn.planner\n",
    "\n",
    "# 경고메세지 무시\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cf56cc6-4381-4416-8542-b6bb95bfc4da",
   "metadata": {},
   "source": [
    "- `tdqm`: for문의 진행상태를 확인하기 위한 패키지\n",
    "- `networkx`: 그래프 시그널 시각화를 위한 모듈\n",
    "- `torch`: 파이토치 (STGCN은 파이토치 기반으로 만들어짐) 모듈\n",
    "- `torch.nn.functional`: relu 등의 활성화함수를 불러오기 위한 모듈\n",
    "- `Data`: 그래프자료를 만들기 위한 클래스\n",
    "- `GConvGRU`: STGCN layer를 만드는 클래스\n",
    "- `temporal_signal_split`: STGCN dataset 을 train/test 형태로 분리하는 기능이 있는 “함수”"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bdd2038-c22c-4a76-b3f4-c865e2ccc97e",
   "metadata": {},
   "source": [
    "# (방법1) StaticGraphTemporalSignal 를 이용하여 데이터 셋 만들기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "181b95a9-b650-4d33-8454-a241c6f387e1",
   "metadata": {},
   "source": [
    "`StaticGraphTemporalSignal` 는 시간에 따라서 그래프 구조가 일정한 경우, 즉 ${\\cal G}_t=\\{{\\cal V},{\\cal E}\\}$와 같은 구조를 의미한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21ffbb52-40c3-45a3-9686-89ca332161ef",
   "metadata": {},
   "source": [
    "A data iterator object to contain a static graph with a dynamically\n",
    "    changing constant time difference temporal feature set (multiple signals).\n",
    "    The node labels (target) are also temporal. The iterator returns a single\n",
    "    constant time difference temporal snapshot for a time period (e.g. day or week).\n",
    "    This single temporal snapshot is a Pytorch Geometric Data object. Between two\n",
    "    temporal snapshots the features and optionally passed attributes might change.\n",
    "    However, the underlying graph is the same.\n",
    "\n",
    "\n",
    "-        edge_index (Numpy array): Index tensor of edges.\n",
    "-        edge_weight (Numpy array): Edge weight tensor.\n",
    "-        features (Sequence of Numpy arrays): Sequence of node feature tensors.\n",
    "-        targets (Sequence of Numpy arrays): Sequence of node label (target) tensors.\n",
    "-        **kwargs (optional Sequence of Numpy arrays): Sequence of additional attributes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b634e8d6-f644-4d35-9408-56cb7a6b151e",
   "metadata": {},
   "source": [
    "`-` json data $\\to$ dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dede8866-9637-4676-978c-418cedd1976a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import urllib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ab6585b-296d-42af-b374-b61fb6247cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://raw.githubusercontent.com/pinkocto/noteda/main/posts/SOLAR/data2/stgcn_data1.json\"\n",
    "data_dict = json.loads(urllib.request.urlopen(url).read())\n",
    "# data_dict 출력이 김"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ba6c212c-1935-4a69-82d0-eeb0edfed36b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['edges', 'node_ids', 'weights', 'FX'])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dict.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b53c1d48-caff-4f2c-8bec-7b514145039f",
   "metadata": {},
   "source": [
    "`-` 살펴보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1746d887-c0cd-4ae2-bace-dacb923d2f4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  0,  0, ..., 43, 43, 43],\n",
       "       [ 1,  2,  3, ..., 40, 41, 42]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(data_dict['edges']).T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f388307f-5369-49da-beb2-e657e70e3ba2",
   "metadata": {},
   "source": [
    "- ${\\cal E} = \\{(0,1),(0,2), \\dots, (43,42)\\}$\n",
    "- 혹은 ${\\cal E} = \\{(\\tt{북춘천},\\tt{철원}), ({\\tt 북춘천},{\\tt 대관령}), \\dots, (\\tt{경주시},\\tt{청송군})\\}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "82044c34-5dca-4ad7-90b2-1cf86ad31b19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'북춘천': 0, '철원': 1, '대관령': 2, '춘천': 3, '백령도': 4, '북강릉': 5, '강릉': 6, '서울': 7, '인천': 8, '원주': 9, '울릉도': 10, '수원': 11, '서산': 12, '청주': 13, '대전': 14, '추풍령': 15, '안동': 16, '포항': 17, '대구': 18, '전주': 19, '창원': 20, '광주': 21, '부산': 22, '목포': 23, '여수': 24, '흑산도': 25, '고창': 26, '홍성': 27, '제주': 28, '고산': 29, '진주': 30, '고창군': 31, '영광군': 32, '김해시': 33, '순창군': 34, '북창원': 35, '양산시': 36, '보성군': 37, '강진군': 38, '의령군': 39, '함양군': 40, '광양시': 41, '청송군': 42, '경주시': 43}\n"
     ]
    }
   ],
   "source": [
    "print(data_dict['node_ids'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f10723d8-36d1-42fc-817a-4126a4b4c163",
   "metadata": {},
   "source": [
    "- ${\\cal V}=\\{\\tt{북춘천},\\tt{철원} \\dots, \\tt{경주시}\\}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "921ca3d8-9950-4d37-8f75-6b9d142236a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]]),\n",
       " (2568, 44))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(data_dict['FX']), np.array(data_dict['FX']).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9ea73715-0868-4cbf-90d1-37dec4dcded5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(data_dict['FX'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "586be38f-12c9-43a3-9065-ea6ebd15f709",
   "metadata": {},
   "source": [
    "- ${\\bf f}=\\begin{bmatrix} {\\bf f}_1\\\\ {\\bf f}_2\\\\ \\dots \\\\ {\\bf f}_{2568} \\end{bmatrix}=\\begin{bmatrix} f(t=1,v=\\tt{북춘천}) & \\dots & f(t=1,v=\\tt{경주시}) \\\\ f(t=2,v=\\tt{북춘천}) & \\dots & f(t=2,v=\\tt{경주시}) \\\\ \\dots & \\dots & \\dots \\\\ f(t=2568,v=\\tt{북춘천}) & \\dots & f(t=2568,v=\\tt{경주시}) \\end{bmatrix}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c7d1b5b-99d3-4065-8998-3e65b81f9fe8",
   "metadata": {},
   "source": [
    "`-` 즉, `data_dict`는 아래와 같이 구성되어 있음."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21a7a844-e4ba-483a-bf85-88479548c745",
   "metadata": {},
   "source": [
    "| **수학기호** | **코드에 저장된 변수** | **자료형** | **차원** | **설명** |\n",
    "|--------------|----------------------|------------|----------|---------|\n",
    "|${\\cal V}$|`data_dict['node_ids']`|dict|44|44개의 노드에 대한 설명이 있음|\n",
    "|${\\cal E}$|`data_dict['edges']`|list(double list)|(1892, 2)|노드들에 대한 1892개의 연결을 정의함|\n",
    "|${\\mathbf f}$|`data_dict['FX']`|list(double list)|(2568,44)|$v \\in {\\cal V}$ for $v\\in{\\cal V}$and $t=1,\\dots,T$|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90235bce-eaf2-4cc7-9759-7e9cf37282af",
   "metadata": {},
   "source": [
    "`-` 주어진 자료를 정리하여 그래프 신호 $\\big(\\{{\\cal V},{\\cal E},{\\bf W}\\},{\\bf f}\\big)$를 만들면 아래와 같다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "53f9cf1f-167f-4c8f-beb7-c9157a1936e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "edges = np.array(data_dict[\"edges\"]).T\n",
    "edge_weight = np.array(data_dict['weights'])\n",
    "f = np.array(data_dict[\"FX\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b751e84-7f28-41b9-874c-201c1e5e3b40",
   "metadata": {},
   "source": [
    "- 여기에서 `edges`는 ${\\cal E}$에 대한 정보를\n",
    "- `edges_weight`는 $bf W$에 대한 정보를\n",
    "- `f`는 $\\bf f$에 대한 정보를 저장한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d95351fe-3362-4cda-aa73-6c58a1893e96",
   "metadata": {},
   "source": [
    "`-` `data_dict` $\\to$ `dl`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c3fd3a38-853a-4b2e-8897-6dfa41aa423e",
   "metadata": {},
   "outputs": [],
   "source": [
    "lags = 4\n",
    "features = [f[i:i + lags, :].T for i in range(f.shape[0] - lags)]\n",
    "targets = [f[i + lags, :].T for i in range(f.shape[0] - lags)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "84bd183c-ce7a-4cdb-946d-53afb51eeef3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2564, 44, 4), (2564, 44))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(features).shape, np.array(targets).shape # lag만큼 row 수가 줄었음."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79a83dd9-0533-4c02-9519-95a18dc437a4",
   "metadata": {},
   "source": [
    "| **설명변수** | **반응변수** |\n",
    "|:------:|:-------|\n",
    "|$${\\bf X} = {\\tt features} = \\begin{bmatrix} {\\bf f}_1 & {\\bf f}_2 & {\\bf f}_3 & {\\bf f}_4 \\\\ {\\bf f}_2 & {\\bf f}_3 & {\\bf f}_4 & {\\bf f}_5 \\\\ \\dots & \\dots & \\dots & \\dots \\\\ {\\bf f}_{2564} & {\\bf f}_{2565} & {\\bf f}_{2566} & {\\bf f}_{2567} \\end{bmatrix}$$|$${\\bf y}= {\\tt targets} = \\begin{bmatrix} {\\bf f}_5 \\\\ {\\bf f}_6 \\\\ \\dots \\\\ {\\bf f}_{2568} \\end{bmatrix}$$|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d16a286f-4a8f-4d87-a9fc-04b5ac764827",
   "metadata": {},
   "source": [
    "- AR느낌으로 표현하면 AR(4)!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ae0ec49d-3220-4806-83bc-683470129e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = torch_geometric_temporal.signal.StaticGraphTemporalSignal(\n",
    "    edge_index= edges,\n",
    "    edge_weight = edge_weight,\n",
    "    features = features,\n",
    "    targets = targets\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "194dc3e6-73b7-4642-9932-c346f943459e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch_geometric_temporal.signal.static_graph_temporal_signal.StaticGraphTemporalSignal at 0x7f24d07cbd30>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20ad4fb8-78fc-4fbe-ac0f-3e3f604f21f4",
   "metadata": {},
   "source": [
    "`-` 그런데 이 과정을 아래와 같이 할 수도 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca9d606f-b52c-4a55-add3-1e6d847a2131",
   "metadata": {},
   "source": [
    "# (방법2) PyTorch Geometric Temporal 공식홈페이지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0cc0717e-24d1-41e6-b99a-03f1f349c3c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PyTorch Geometric Temporal 공식홈페이지에 소개된 코드\n",
    "loader = eptstgcn.DatasetLoader(url)\n",
    "dataset = loader.get_dataset(lags=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "832c70c9-a80d-4309-9d1d-d778c826716c",
   "metadata": {},
   "source": [
    "`-` dataset은 `dataset[0]`, $\\dots$ , `dataset[2563]`과 같은 방식으로 각 시점별 자료에 접근가능."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "67915530-d189-4d1d-b524-18480f30f403",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Data(x=[44, 4], edge_index=[2, 1892], edge_attr=[1892], y=[44]),\n",
       " Data(x=[44, 4], edge_index=[2, 1892], edge_attr=[1892], y=[44]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0], dataset[2563]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e5694862-fae2-467f-81c1-0307ed80f430",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch_geometric.data.data.Data"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(dataset[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68144da5-bd4b-4dab-9fe2-8f01dec68e61",
   "metadata": {},
   "source": [
    "- 각 시점에 대한 자료형은 PyG의 Data자료형과 같음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9e45933-972f-4911-942c-da1a4d5fb9e0",
   "metadata": {},
   "source": [
    "`-` 첫번째 시점의 자료 $(T=1)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c90eee0a-4416-4f05-9213-bc1153f7f1a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([44, 4]),\n",
       " tensor([[0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.]]))"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0].x.shape, dataset[0].x[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae19848e-a048-43ba-b0b0-2630b97169aa",
   "metadata": {},
   "source": [
    "이 값들은 `features[0]`의 값들과 같음. 즉, $[{\\bf f}_1~ {\\bf f}_2~ {\\bf f}_3~ {\\bf f}_4]$를 의미함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "74ab3156-03d5-4c14-b2c0-fc4a200b8340",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 확인\n",
    "features[0][:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "556afc56-8667-4b33-a751-e9f2a0cd78e3",
   "metadata": {},
   "source": [
    "`-` 101번째 시점의 자료 $(T=101)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "efb70a23-5001-4d7e-9662-fdb41dff067b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([44, 4]),\n",
       " tensor([[0.0000, 0.0000, 0.0500, 0.2400],\n",
       "         [0.0000, 0.0000, 0.0300, 0.2200],\n",
       "         [0.0000, 0.0000, 0.0400, 0.1700],\n",
       "         [0.0000, 0.0000, 0.0500, 0.2100],\n",
       "         [0.0000, 0.0000, 0.0100, 0.2000]]))"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[100].x.shape, dataset[100].x[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f78c9fc-be0f-42a9-ab0e-4d1468e4293b",
   "metadata": {},
   "source": [
    "이 값들은 `features[100]`의 값들과 같음. 즉, $[{\\bf f}_{101}~ {\\bf f}_{102}~ {\\bf f}_{103}~ {\\bf f}_{104}]$를 의미함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "21f31c41-fc9b-4fb2-b1f5-88eccfc27abc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.  , 0.  , 0.05, 0.24],\n",
       "       [0.  , 0.  , 0.03, 0.22],\n",
       "       [0.  , 0.  , 0.04, 0.17],\n",
       "       [0.  , 0.  , 0.05, 0.21],\n",
       "       [0.  , 0.  , 0.01, 0.2 ]])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 확인\n",
    "features[100][:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79801377-3c5e-4d2f-913a-0ab5b65c3453",
   "metadata": {},
   "source": [
    "`-` target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "0f6715c2-2316-49e9-8b6a-224bc29c3d23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0].y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a599e6f-6b9a-4a34-b636-6a52cffbe93a",
   "metadata": {},
   "source": [
    "- 이 값들은 `targets[0]`의 값들과 같음. 즉 ${\\bf f}_5$를 의미함."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23961ced-1a7e-4110-8c9c-933abfa238cb",
   "metadata": {},
   "source": [
    "다 $0$이라 잘 모르겠으니까 다른 시점의 데이터로 다시 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "edde04de-9e91-4167-9cd7-82108fa402da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.7400, 1.8500, 1.1600, 1.4100, 1.1200, 1.9200, 1.7400, 1.6100, 1.6100,\n",
       "        0.3300, 0.6400, 1.2200, 1.1400, 0.9500, 0.7400, 0.4100, 0.6000, 0.4200,\n",
       "        0.6000, 0.3800, 0.6800, 0.7100, 0.3200, 1.2400, 0.3500, 0.6200, 0.5500,\n",
       "        0.8800, 0.7400, 0.4900, 0.5100, 0.6300, 0.6200, 0.2400, 0.6800, 0.5700,\n",
       "        0.3500, 0.5700, 0.3700, 0.6900, 0.7100, 0.4800, 0.6900, 0.4000])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[104].y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "296856c0-afc2-4c5e-9126-d37b35d3eaa7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.74, 1.85, 1.16, 1.41, 1.12, 1.92, 1.74, 1.61, 1.61, 0.33, 0.64,\n",
       "       1.22, 1.14, 0.95, 0.74, 0.41, 0.6 , 0.42, 0.6 , 0.38, 0.68, 0.71,\n",
       "       0.32, 1.24, 0.35, 0.62, 0.55, 0.88, 0.74, 0.49, 0.51, 0.63, 0.62,\n",
       "       0.24, 0.68, 0.57, 0.35, 0.57, 0.37, 0.69, 0.71, 0.48, 0.69, 0.4 ])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets[104]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0347c9b3-1ffa-4fde-86fe-5713545658de",
   "metadata": {},
   "source": [
    "## Time Lag"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b28f1d4-f73b-4db7-809e-db3ff7cbf277",
   "metadata": {},
   "source": [
    "| **설명변수** | **반응변수** |\n",
    "|:------:|:-------|\n",
    "|$${\\bf X} = {\\tt features} = \\begin{bmatrix} {\\bf f}_1 & {\\bf f}_2 & {\\bf f}_3 & {\\bf f}_4 \\\\ {\\bf f}_2 & {\\bf f}_3 & {\\bf f}_4 & {\\bf f}_5 \\\\ \\dots & \\dots & \\dots & \\dots \\\\ {\\bf f}_{2564} & {\\bf f}_{2565} & {\\bf f}_{2566} & {\\bf f}_{2567} \\end{bmatrix}$$|$${\\bf y}= {\\tt targets} = \\begin{bmatrix} {\\bf f}_5 \\\\ {\\bf f}_6 \\\\ \\dots \\\\ {\\bf f}_{2568} \\end{bmatrix}$$|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "eb4c46fb-1c16-45e7-9958-04ac826ee7bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2564, 44, 4), (2564, 44))"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(dataset.features).shape, np.array(dataset.targets).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73ac97ae-4a6a-43da-9daa-24c19557a61c",
   "metadata": {},
   "source": [
    "### $\\bf X_{101 \\cdot} = [\\bf f_{101}, \\bf f_{102}, \\bf f_{103}, \\bf f_{104}]$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4b54701-3318-4988-a92a-27b520ca50af",
   "metadata": {},
   "source": [
    "`-` $\\bf f_{101}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "c3d81282-59ba-4b30-a966-2853997b3120",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.  , 0.  , 0.05, 0.24],\n",
       "        [0.  , 0.  , 0.03, 0.22],\n",
       "        [0.  , 0.  , 0.04, 0.17],\n",
       "        [0.  , 0.  , 0.05, 0.21],\n",
       "        [0.  , 0.  , 0.01, 0.2 ]]),\n",
       " (44, 4))"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(dataset.features)[100][:5], np.array(train_dataset.features)[100].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7b87592-d9d9-4941-a102-5e5b7838f754",
   "metadata": {},
   "source": [
    "`-` $\\bf f_{102}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "87231d37-b4c5-4137-9513-ebd3778454c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.  , 0.05, 0.24, 0.38],\n",
       "        [0.  , 0.03, 0.22, 0.64],\n",
       "        [0.  , 0.04, 0.17, 0.5 ],\n",
       "        [0.  , 0.05, 0.21, 0.32],\n",
       "        [0.  , 0.01, 0.2 , 0.63]]),\n",
       " (44, 4))"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(dataset.features)[101][:5], np.array(train_dataset.features)[101].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19b50d6e-6657-404d-b54c-50f86f9aaf1d",
   "metadata": {},
   "source": [
    "`-` $\\bf f_{103}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "f757b9f6-00b0-4c8f-8146-91eef4e92a0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.05, 0.24, 0.38, 0.57],\n",
       "        [0.03, 0.22, 0.64, 1.36],\n",
       "        [0.04, 0.17, 0.5 , 0.81],\n",
       "        [0.05, 0.21, 0.32, 0.45],\n",
       "        [0.01, 0.2 , 0.63, 1.03]]),\n",
       " (44, 4))"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(dataset.features)[102][:5], np.array(train_dataset.features)[102].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "236b71cf-cd4b-44d9-9eca-aa70abcbca91",
   "metadata": {},
   "source": [
    "`-` $\\bf f_{104}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "c18bddd8-343e-49f9-a5c4-68f56ac30ca8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.24, 0.38, 0.57, 1.12],\n",
       "        [0.22, 0.64, 1.36, 1.7 ],\n",
       "        [0.17, 0.5 , 0.81, 1.5 ],\n",
       "        [0.21, 0.32, 0.45, 1.15],\n",
       "        [0.2 , 0.63, 1.03, 1.63]]),\n",
       " (44, 4))"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(dataset.features)[103][:5], np.array(train_dataset.features)[103].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "346f5b13-8777-4dcd-b12a-c02620ed8051",
   "metadata": {},
   "source": [
    "### $\\bf y_{101} = \\bf f_{105}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c58ec36f-97bf-40d5-87a7-3683159118fe",
   "metadata": {},
   "source": [
    "`-` $\\bf f_{105}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "c42259ec-3b16-4387-b9e1-5bad92480813",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.38, 0.57, 1.12, 1.78],\n",
       "        [0.64, 1.36, 1.7 , 1.81],\n",
       "        [0.5 , 0.81, 1.5 , 2.41],\n",
       "        [0.32, 0.45, 1.15, 1.69],\n",
       "        [0.63, 1.03, 1.63, 1.56]]),\n",
       " (44, 4))"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(dataset.features)[104][:5], np.array(train_dataset.features)[104].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c298967-c34e-4951-93b5-6dcfd7e73ace",
   "metadata": {},
   "source": [
    "`-` $\\bf y_{101} $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "4f6e1332-3284-4b67-bae5-4d8d3f45cc78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.38, 0.64, 0.5 , 0.32, 0.63, 0.5 , 0.5 , 0.25, 0.16, 0.16, 0.17,\n",
       "       0.38, 0.4 , 0.24, 0.21, 0.18, 0.11, 0.19, 0.28, 0.27, 0.32, 0.19,\n",
       "       0.23, 0.14, 0.07, 0.11, 0.12, 0.34, 0.03, 0.23, 0.17, 0.24, 0.05,\n",
       "       0.23, 0.17, 0.41, 0.28, 0.07, 0.06, 0.3 , 0.35, 0.08, 0.17, 0.32])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(train_dataset.targets)[100]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58618d6b-d562-40d6-b0d4-e352f1689cca",
   "metadata": {
    "tags": []
   },
   "source": [
    "# (추가) Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "848f358f-f637-4ec6-9099-9209b7061e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = eptstgcn.DatasetLoader(url)\n",
    "dataset = loader.get_dataset(lags=4)\n",
    "train_dataset, test_dataset = eptstgcn.utils.temporal_signal_split(dataset, train_ratio = 0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e4cc1be9-ba7a-4fc7-b07f-1ce432b712b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1794, 44, 4) (1794, 44)\n",
      "(770, 44, 4) (770, 44)\n"
     ]
    }
   ],
   "source": [
    "print(np.array(train_dataset.features).shape, np.array(train_dataset.targets).shape)\n",
    "print(np.array(test_dataset.features).shape, np.array(test_dataset.targets).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9be1c8db-9b68-4fc7-a4f6-dac1b08b7c3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.05, 0.24, 0.38, 0.57],\n",
       "        [0.03, 0.22, 0.64, 1.36],\n",
       "        [0.04, 0.17, 0.5 , 0.81],\n",
       "        [0.05, 0.21, 0.32, 0.45],\n",
       "        [0.01, 0.2 , 0.63, 1.03]]),\n",
       " (44, 4))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## before normalization\n",
    "np.array(train_dataset.features)[102][:5], np.array(train_dataset.features)[102].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "82f056b5-1e9f-4cd6-8065-744cc3fe0dd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1794, 44, 4)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stacked_target = np.array(train_dataset.features)\n",
    "standardized_target = (stacked_target - np.mean(stacked_target, axis=0)) / (\n",
    "        np.std(stacked_target, axis=0) + 10 ** -10\n",
    "    )\n",
    "standardized_target.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dea474f9-14c3-4d0c-9104-9a6434a042c7",
   "metadata": {},
   "source": [
    "```python\n",
    "def _get_targets_and_features(self):\n",
    "    # stacked_target = np.stack(self._dataset[\"FX\"])\n",
    "    stacked_target = np.stack(self.features)\n",
    "    standardized_target = (stacked_target - np.mean(stacked_target, axis=0)) / (\n",
    "        np.std(stacked_target, axis=0) + 10 ** -10\n",
    "    )\n",
    "    self.features = [\n",
    "        standardized_target[i : i + self.lags, :].T\n",
    "        for i in range(standardized_target.shape[0] - self.lags)\n",
    "    ]\n",
    "    self.targets = [\n",
    "        standardized_target[i + self.lags, :].T\n",
    "        for i in range(standardized_target.shape[0] - self.lags)\n",
    "    ]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f1f4ef53-778c-4b30-a0aa-9c2e864b1c28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]]),\n",
       " (2568, 44))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(data_dict['FX']), np.array(data_dict['FX']).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "37dd2894-50ce-4162-ba6e-e481e212c6d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2564, 44, 4), (2568, 44), 1797.6)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(dataset.features).shape, np.array(data_dict['FX']).shape, np.array(data_dict['FX']).shape[0]*0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cb92d8a6-4de4-4250-8d03-347ae2084eb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1798, 44) (770, 44)\n"
     ]
    }
   ],
   "source": [
    "X_train = np.array(data_dict['FX'])[:1798]\n",
    "X_test = np.array(data_dict['FX'])[1798:]\n",
    "print(X_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6da227b0-81d7-46cf-be57-51447ca5d41d",
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_train = np.stack(X_train)\n",
    "stacked_test = np.stack(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1d6f9925-8511-4d77-bbf9-ffe22148594c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.69638487, 0.69291991, 0.71728587, 0.67663515, 0.72013904,\n",
       "       0.68520578, 0.67242492, 0.6165406 , 0.70714127, 0.68873192,\n",
       "       0.75573415, 0.65022247, 0.69432703, 0.73623471, 0.72322581,\n",
       "       0.7477475 , 0.77799778, 0.73844271, 0.76658509, 0.68938265,\n",
       "       0.74851502, 0.74797553, 0.796802  , 0.77722469, 0.78023359,\n",
       "       0.66378754, 0.77681869, 0.6920634 , 0.85137375, 0.7665406 ,\n",
       "       0.77932703, 0.72912681, 0.76936596, 0.74153504, 0.7364238 ,\n",
       "       0.72896552, 0.72090656, 0.7813515 , 0.73452725, 0.76474416,\n",
       "       0.79341491, 0.74067297, 0.75582314, 0.75042269])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(stacked_train, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b8da39ab-1103-483d-8ac9-60a1e3c18ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "standardized_train = (stacked_train - np.mean(stacked_train, axis=0)) / (\n",
    "    np.std(stacked_train, axis=0) + 10 ** -10\n",
    ")\n",
    "\n",
    "standardized_test = (stacked_test - np.mean(stacked_train, axis=0)) / (\n",
    "    np.std(stacked_train, axis=0) + 10 ** -10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "723b37c0-0700-4097-a77d-0b8fef8e5c51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1798, 44), (770, 44))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "standardized_train.shape, standardized_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "8f1a51b7-c5db-4fdc-9b11-a74ef362afaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "lags = 4\n",
    "train_features = [\n",
    "    standardized_train[i : i + lags, :].T\n",
    "    for i in range(standardized_train.shape[0] - lags)\n",
    "]\n",
    "\n",
    "train_targets = [\n",
    "    standardized_train[i + lags, :].T\n",
    "    for i in range(standardized_train.shape[0] - lags)\n",
    "]\n",
    "\n",
    "test_features = [\n",
    "    standardized_test[i : i + lags, :].T\n",
    "    for i in range(standardized_test.shape[0] - lags)\n",
    "]\n",
    "\n",
    "test_targets = [\n",
    "    standardized_test[i + lags, :].T\n",
    "    for i in range(standardized_test.shape[0] - lags)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "99447ad5-3481-4a1e-b330-4057018c6f3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((766, 44, 4), (766, 44))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(np.array(train_features).shape, np.array(train_targets).shape )\n",
    "print(np.array(test_features).shape, np.array(test_targets).shape )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4bad7bbf-e8c2-459d-a9b6-b851d6613ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "edges = np.array(data_dict[\"edges\"]).T\n",
    "edge_weight = np.array(data_dict['weights'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2ed1bda8-e311-4306-b2f3-bd59693ca720",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_train_dataset = torch_geometric_temporal.signal.StaticGraphTemporalSignal(\n",
    "    edge_index= edges,\n",
    "    edge_weight = edge_weight,\n",
    "    features = train_features,\n",
    "    targets = train_targets\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0a75c81b-78a6-4b6b-8fd1-b1de71e3b91d",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_test_dataset = torch_geometric_temporal.signal.StaticGraphTemporalSignal(\n",
    "    edge_index= edges,\n",
    "    edge_weight = edge_weight,\n",
    "    features = test_features,\n",
    "    targets = test_targets\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6ffe54f5-6b06-46b8-ba47-e0a6c94933f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1794, 44, 4), (766, 44, 4))"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(my_train_dataset.features).shape, np.array(my_test_dataset.features).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9d00f45c-a0c1-42da-9053-7586749eaa06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# eptstgcn.save_data(my_train_dataset, './normal_data/ver1/train_dataset.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "72cd56c0-793c-4b45-87ed-92beacbfdcc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# eptstgcn.save_data(my_test_dataset, './normal_data/ver1/test_dataset.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ef101ece-cdcd-4f33-85f1-acbf23c4b2c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = eptstgcn.load_data('./normal_data/ver1/train_dataset.pickle')\n",
    "test_dataset = eptstgcn.load_data('./normal_data/ver1/test_dataset.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c3203756-9941-4814-a55a-8650f21f5f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "plans_stgcn = {\n",
    "    'max_iteration': 1,   # 30, \n",
    "    'method': ['EPT-STGCN'], \n",
    "    'lags': [4],  # [4, 8, 12]\n",
    "    'nof_filters': [16], # [16, 32, 64]\n",
    "    'epoch': [1] # [50, 100, 150]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a9715010-d3cd-4ce1-993f-55c3f649dbf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plnr = eptstgcn.planner.NORMAL_PLNR_STGCN(plans_stgcn,train_dataset, test_dataset, dataset_name='data2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0f851a12-75ac-449e-bbd4-192982dd77b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 is done\n",
      "All results are stored in ./simulation_results/2023-05-02_10-03-07.csv\n"
     ]
    }
   ],
   "source": [
    "plnr.simulate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "78054bc9-292b-4ff8-b936-412dfeaa32a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>method</th>\n",
       "      <th>normal</th>\n",
       "      <th>lags</th>\n",
       "      <th>nof_filters</th>\n",
       "      <th>epoch</th>\n",
       "      <th>mse(train)</th>\n",
       "      <th>mse(test)</th>\n",
       "      <th>calculation_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>data2</td>\n",
       "      <td>EPT-STGCN</td>\n",
       "      <td>O</td>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0.198832</td>\n",
       "      <td>0.199054</td>\n",
       "      <td>8.110707</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  dataset     method normal lags nof_filters epoch mse(train) mse(test)  \\\n",
       "0   data2  EPT-STGCN      O    4          16     1   0.198832  0.199054   \n",
       "\n",
       "  calculation_time  \n",
       "0         8.110707  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plnr.simulation_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfd1d5dd-02f8-49e5-bf78-296a9f0dd170",
   "metadata": {},
   "source": [
    "- test완료!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "b390e0e6-55af-46c3-90ad-205b1369e79d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RecurrentGCN(torch.nn.Module):\n",
    "    def __init__(self, node_features, filters):\n",
    "        super(RecurrentGCN, self).__init__()\n",
    "        self.recurrent = GConvGRU(node_features, filters, 2)\n",
    "        self.linear = torch.nn.Linear(filters, 1)\n",
    "\n",
    "    def forward(self, x, edge_index, edge_weight):\n",
    "        h = self.recurrent(x, edge_index, edge_weight)\n",
    "        h = F.relu(h)\n",
    "        h = self.linear(h)\n",
    "        return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "6843af13-12bf-4ef8-86ca-ac94fe3d8e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NormalStgcnLearner:\n",
    "    def __init__(self,train_dataset,dataset_name = None):\n",
    "        self.train_dataset = train_dataset\n",
    "        self.lags = torch.tensor(train_dataset.features).shape[-1]\n",
    "        self.dataset_name = str(train_dataset) if dataset_name is None else dataset_name\n",
    "        self.method = 'STGCN'\n",
    "    def learn(self,filters=32,epoch=50):\n",
    "        self.model = RecurrentGCN(node_features=self.lags, filters=filters)\n",
    "        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=0.01)\n",
    "        self.model.train()\n",
    "        for e in range(epoch):\n",
    "            for t, snapshot in enumerate(self.train_dataset):\n",
    "                yt_hat = self.model(snapshot.x, snapshot.edge_index, snapshot.edge_attr)\n",
    "                cost = torch.mean((yt_hat-snapshot.y)**2)\n",
    "                cost.backward()\n",
    "                self.optimizer.step()\n",
    "                self.optimizer.zero_grad()\n",
    "            print('{}/{}'.format(e+1,epoch),end='\\r')\n",
    "        # recording HP\n",
    "        self.nof_filters = filters\n",
    "        # self.epochs = epoch+1\n",
    "        self.epochs = epoch\n",
    "    def __call__(self,dataset):\n",
    "        X = torch.tensor(dataset.features).float()\n",
    "        y = torch.tensor(dataset.targets).float()\n",
    "        yhat = torch.stack([self.model(snapshot.x, snapshot.edge_index, snapshot.edge_attr) for snapshot in dataset]).detach().squeeze().float()\n",
    "        return {'X':X, 'y':y, 'yhat':yhat} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "86ad568a-9779-4dc3-b700-66d6084a28af",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Evaluator():\n",
    "    def __init__(self,learner,train_dataset,test_dataset):\n",
    "        self.learner = learner\n",
    "        # self.learner.model.eval()\n",
    "        try:self.learner.model.eval()\n",
    "        except:pass\n",
    "        self.train_dataset = train_dataset\n",
    "        self.test_dataset = test_dataset\n",
    "        self.lags = self.learner.lags\n",
    "        rslt_tr = self.learner(self.train_dataset) \n",
    "        rslt_test = self.learner(self.test_dataset)\n",
    "        self.X_tr = rslt_tr['X']\n",
    "        self.y_tr = rslt_tr['y']\n",
    "        self.f_tr = torch.concat([self.train_dataset[0].x.T,self.y_tr],axis=0).float()\n",
    "        self.yhat_tr = rslt_tr['yhat']\n",
    "        self.fhat_tr = torch.concat([self.train_dataset[0].x.T,self.yhat_tr],axis=0).float()\n",
    "        self.X_test = rslt_test['X']\n",
    "        self.y_test = rslt_test['y']\n",
    "        self.f_test = self.y_test \n",
    "        self.yhat_test = rslt_test['yhat']\n",
    "        self.fhat_test = self.yhat_test\n",
    "        self.f = torch.concat([self.f_tr,self.f_test],axis=0)\n",
    "        self.fhat = torch.concat([self.fhat_tr,self.fhat_test],axis=0)\n",
    "    def calculate_mse(self):\n",
    "        test_base_mse_eachnode = ((self.y_test - self.y_test.mean(axis=0).reshape(-1,self.y_test.shape[-1]))**2).mean(axis=0).tolist()\n",
    "        test_base_mse_total = ((self.y_test - self.y_test.mean(axis=0).reshape(-1,self.y_test.shape[-1]))**2).mean().item()\n",
    "        train_mse_eachnode = ((self.y_tr-self.yhat_tr)**2).mean(axis=0).tolist()\n",
    "        train_mse_total = ((self.y_tr-self.yhat_tr)**2).mean().item()\n",
    "        test_mse_eachnode = ((self.y_test-self.yhat_test)**2).mean(axis=0).tolist()\n",
    "        test_mse_total = ((self.y_test-self.yhat_test)**2).mean().item()\n",
    "        self.mse = {'train': {'each_node': train_mse_eachnode, 'total': train_mse_total},\n",
    "                    'test': {'each_node': test_mse_eachnode, 'total': test_mse_total},\n",
    "                    'test(base)': {'each_node': test_base_mse_eachnode, 'total': test_base_mse_total},\n",
    "                   }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "12d12b11-650e-4697-a8ad-605dd929dd91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def minmaxscaler(arr):\n",
    "    arr = arr - arr.min()\n",
    "    arr = arr/arr.max()\n",
    "    return arr "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "ee111103-8a7f-429d-b70a-871fcd853025",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PLNR2():\n",
    "    def __init__(self,plans,data_dict ,dataset_name=None,simulation_results=None):\n",
    "        self.plans = plans\n",
    "        col = ['dataset', 'method', 'normal','lags', 'nof_filters', 'epoch', 'mse(train)','mse(test)','calculation_time']\n",
    "        #self.train_dataset = train_dataset\n",
    "        #self.test_dataset = test_dataset\n",
    "        self.dataset_name = dataset_name\n",
    "        self.simulation_results = pd.DataFrame(columns=col) if simulation_results is None else simulation_results \n",
    "    def record(self,method,lags,nof_filters,epoch,mse_tr, mse_test, calculation_time):\n",
    "        dct = {'dataset': self.dataset_name,\n",
    "               'method': method, \n",
    "               'normal': 'O',\n",
    "               'lags': lags,\n",
    "               'nof_filters': nof_filters,\n",
    "               'epoch': epoch,\n",
    "               'mse(train)': mse_tr,\n",
    "               'mse(test)': mse_test,\n",
    "               'calculation_time': calculation_time\n",
    "              }\n",
    "        simulation_result_new = pd.Series(dct).to_frame().transpose()\n",
    "        self.simulation_results = pd.concat([self.simulation_results,simulation_result_new]).reset_index(drop=True)\n",
    "    def save(self):\n",
    "        if 'simulation_results' not in os.listdir(): \n",
    "            os.mkdir('simulation_results')\n",
    "        fname = datetime.datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S.csv\")\n",
    "        self.simulation_results.to_csv('./simulation_results/'+fname,index=False)    \n",
    "        print(\"All results are stored in ./simulation_results/\"+fname)\n",
    "        \n",
    "        \n",
    "class NORMAL_PLNR_STGCN(PLNR2):\n",
    "    def simulate(self):\n",
    "        for _ in range(self.plans['max_iteration']):  \n",
    "            product_iterator = itertools.product(\n",
    "                self.plans['method'], \n",
    "                self.plans['lags'], \n",
    "                self.plans['nof_filters'], \n",
    "                self.plans['epoch']\n",
    "            )\n",
    "            for prod_iter in product_iterator:\n",
    "                method,lags,nof_filters,epoch = prod_iter\n",
    "                \"\"\"\n",
    "                self.dataset = self.loader.get_dataset(lags=lags)\n",
    "                train_dataset, test_dataset = torch_geometric_temporal.signal.temporal_signal_split(self.dataset, train_ratio=0.7)\n",
    "                \"\"\"\n",
    "                edges = np.array(data_dict[\"edges\"]).T\n",
    "                edge_weights = np.array(data_dict['weights'])\n",
    "                scaled_edge_weights = minmaxscaler(edge_weights)\n",
    "                edge_weight = scaled_edge_weights\n",
    "                \n",
    "                X_train = np.array(data_dict['FX'])[:1798]\n",
    "                X_test = np.array(data_dict['FX'])[1798:]\n",
    "                stacked_train = np.stack(X_train)\n",
    "                stacked_test = np.stack(X_test)\n",
    "                standardized_train = (stacked_train - np.mean(stacked_train, axis=0)) / (np.std(stacked_train, axis=0) + 10 ** -10)\n",
    "                standardized_test = (stacked_test - np.mean(stacked_train, axis=0)) / (np.std(stacked_train, axis=0) + 10 ** -10)\n",
    "                train_features = [standardized_train[i : i + lags, :].T for i in range(standardized_train.shape[0] - lags)]\n",
    "                train_targets = [standardized_train[i + lags, :].T for i in range(standardized_train.shape[0] - lags)]\n",
    "                test_features = [standardized_test[i : i + lags, :].T for i in range(standardized_test.shape[0] - lags)]\n",
    "                test_targets = [standardized_test[i + lags, :].T for i in range(standardized_test.shape[0] - lags)]\n",
    "                train_dataset = torch_geometric_temporal.signal.StaticGraphTemporalSignal(edge_index= edges,\n",
    "                                                                                            edge_weight = edge_weight,\n",
    "                                                                                            features = train_features,\n",
    "                                                                                            targets = train_targets)\n",
    "                test_dataset = torch_geometric_temporal.signal.StaticGraphTemporalSignal(edge_index= edges,\n",
    "                                                                                            edge_weight = edge_weight,\n",
    "                                                                                            features = test_features,\n",
    "                                                                                            targets = test_targets)\n",
    "                \n",
    "                lrnr = NormalStgcnLearner(train_dataset,dataset_name=self.dataset_name)\n",
    "                t1 = time.time()\n",
    "                lrnr.learn(filters=nof_filters,epoch=epoch)\n",
    "                t2 = time.time()\n",
    "                evtor = Evaluator(lrnr,train_dataset,test_dataset)\n",
    "                evtor.calculate_mse()\n",
    "                # mse = evtor.mse['test']['total']\n",
    "                mse_tr = evtor.mse['train']['total']\n",
    "                mse_test = evtor.mse['test']['total']\n",
    "                calculation_time = t2-t1\n",
    "                self.record(method, lags, nof_filters, epoch, mse_tr, mse_test, calculation_time)\n",
    "            print('{}/{} is done'.format(_+1,self.plans['max_iteration']))\n",
    "        self.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "edd8448a-4b48-4d87-a2d1-35eb61e1aa12",
   "metadata": {},
   "outputs": [],
   "source": [
    "plans_stgcn = {\n",
    "    'max_iteration': 1,   # 30, \n",
    "    'method': ['EPT-STGCN'], \n",
    "    'lags': [0, 2, 4],  # [4, 8, 12]\n",
    "    'nof_filters': [16], # [16, 32, 64]\n",
    "    'epoch': [1] # [50, 100, 150]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "3d8a71ff-a102-42bd-9a67-3de0afacb1e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import itertools\n",
    "import time\n",
    "import os\n",
    "from torch_geometric_temporal.nn.recurrent import GConvGRU\n",
    "\n",
    "import datetime\n",
    "import torch_geometric_temporal \n",
    "\n",
    "\n",
    "plnr_ = NORMAL_PLNR_STGCN(plans_stgcn,data_dict, dataset_name='data2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "f687a23c-3c33-4a47-ae63-3519667a1dbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 is done\n",
      "All results are stored in ./simulation_results/2023-05-02_14-50-31.csv\n"
     ]
    }
   ],
   "source": [
    "plnr_.simulate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "2382c900-6ebb-48bc-aa46-6324f71626db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>method</th>\n",
       "      <th>normal</th>\n",
       "      <th>lags</th>\n",
       "      <th>nof_filters</th>\n",
       "      <th>epoch</th>\n",
       "      <th>mse(train)</th>\n",
       "      <th>mse(test)</th>\n",
       "      <th>calculation_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>data2</td>\n",
       "      <td>EPT-STGCN</td>\n",
       "      <td>O</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>1.018119</td>\n",
       "      <td>0.848976</td>\n",
       "      <td>5.398019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>data2</td>\n",
       "      <td>EPT-STGCN</td>\n",
       "      <td>O</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0.207399</td>\n",
       "      <td>0.196737</td>\n",
       "      <td>5.854818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>data2</td>\n",
       "      <td>EPT-STGCN</td>\n",
       "      <td>O</td>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0.312694</td>\n",
       "      <td>0.288329</td>\n",
       "      <td>5.940862</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  dataset     method normal lags nof_filters epoch mse(train) mse(test)  \\\n",
       "0   data2  EPT-STGCN      O    0          16     1   1.018119  0.848976   \n",
       "1   data2  EPT-STGCN      O    2          16     1   0.207399  0.196737   \n",
       "2   data2  EPT-STGCN      O    4          16     1   0.312694  0.288329   \n",
       "\n",
       "  calculation_time  \n",
       "0         5.398019  \n",
       "1         5.854818  \n",
       "2         5.940862  "
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plnr_.simulation_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "610dadcf-6ae8-4925-a15d-54cfa7743217",
   "metadata": {},
   "source": [
    "### NORMAL STGCN Tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aaf431c4-a676-4511-94ab-7ac6124c0cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 일반적인 모듈 \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import networkx as nx \n",
    "from tqdm import tqdm \n",
    "\n",
    "# 파이토치 관련 \n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# PyG 관련 \n",
    "from torch_geometric.data import Data\n",
    "\n",
    "# STGCN 관련 \n",
    "import torch_geometric_temporal\n",
    "from torch_geometric_temporal.nn.recurrent import GConvGRU\n",
    "from torch_geometric_temporal.signal import temporal_signal_split \n",
    "import eptstgcn\n",
    "import eptstgcn.planner\n",
    "\n",
    "# 경고메세지 무시\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "97e6f394-955a-4d1d-b588-dcc42aba67f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import urllib\n",
    "\n",
    "url = \"https://raw.githubusercontent.com/pinkocto/noteda/main/posts/SOLAR/data2/stgcn_data1.json\"\n",
    "data_dict = json.loads(urllib.request.urlopen(url).read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f2ea898b-9a37-4b6f-9294-39b77bde769b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plans_stgcn = {\n",
    "    'max_iteration': 1,   # 30, \n",
    "    'method': ['EPT-STGCN'], \n",
    "    'lags': [0, 2, 4],  # [4, 8, 12]\n",
    "    'nof_filters': [16], # [16, 32, 64]\n",
    "    'epoch': [1] # [50, 100, 150]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "101cbff9-2c0a-4626-ba63-6172fc5d56f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plnr_test = eptstgcn.planner.NORMAL_PLNR_STGCN(plans_stgcn, data_dict, dataset_name='data2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5cfa0e7f-20cd-434e-beb6-141f70f1f169",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 is done\n",
      "All results are stored in ./simulation_results/2023-05-02_15-02-35.csv\n"
     ]
    }
   ],
   "source": [
    "plnr_test.simulate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "54a1bf35-4301-4658-8016-d5048e43e42c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>method</th>\n",
       "      <th>normal</th>\n",
       "      <th>lags</th>\n",
       "      <th>nof_filters</th>\n",
       "      <th>epoch</th>\n",
       "      <th>mse(train)</th>\n",
       "      <th>mse(test)</th>\n",
       "      <th>calculation_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>data2</td>\n",
       "      <td>EPT-STGCN</td>\n",
       "      <td>O</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>1.018115</td>\n",
       "      <td>0.848976</td>\n",
       "      <td>5.363684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>data2</td>\n",
       "      <td>EPT-STGCN</td>\n",
       "      <td>O</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0.195851</td>\n",
       "      <td>0.185911</td>\n",
       "      <td>5.768746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>data2</td>\n",
       "      <td>EPT-STGCN</td>\n",
       "      <td>O</td>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0.221883</td>\n",
       "      <td>0.206726</td>\n",
       "      <td>5.851692</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  dataset     method normal lags nof_filters epoch mse(train) mse(test)  \\\n",
       "0   data2  EPT-STGCN      O    0          16     1   1.018115  0.848976   \n",
       "1   data2  EPT-STGCN      O    2          16     1   0.195851  0.185911   \n",
       "2   data2  EPT-STGCN      O    4          16     1   0.221883  0.206726   \n",
       "\n",
       "  calculation_time  \n",
       "0         5.363684  \n",
       "1         5.768746  \n",
       "2         5.851692  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plnr_test.simulation_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c720fce2-3df1-48ba-be3b-aebefdd0d09d",
   "metadata": {},
   "source": [
    "- 수정완료!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
