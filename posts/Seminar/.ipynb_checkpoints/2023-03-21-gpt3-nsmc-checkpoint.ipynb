{
 "cells": [
  {
   "cell_type": "raw",
   "id": "bbd9e435-14be-47a3-afd4-b7e55e46c236",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Few-shot learning using GPT3\"\n",
    "author: \"jiyunLim\"\n",
    "date: \"03/21/2023\"\n",
    "categories:\n",
    "  - seminar\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66eeee79-1a4b-4cb2-8c57-3d83f1d8ebe5",
   "metadata": {},
   "source": [
    "# NSMC - NAVER Sentiment Movie Corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f837a16-708e-4e6c-a2f8-c9eec5795299",
   "metadata": {},
   "source": [
    "> gpt3 백본모델로 KoAlpaca를 활용하여 인컨텍스트 퓨삿러닝을 통해 네이버 영화 리뷰 데이터(NSMC - NAVER Sentiment Movie Corpus) 분류문제를 풀어보자."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b085ff3e-3af1-41c3-8372-1d712dd9809d",
   "metadata": {},
   "source": [
    "참고로 `KoAlpaca` 는 한국어로 인스트럭션 데이터를 한국어 오픈소스 gpt3 모델인 polyglot-ko에 파인튜닝한 모델입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3b3441dc-c802-4d04-a0c3-43b14c15d56f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install transformers\n",
    "# !pip install accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "438d423c-2093-4465-8fec-74c9b52f3efe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-04-02 21:25:32--  https://raw.githubusercontent.com/NLP-kr/tensorflow-ml-nlp-tf2/master/7.PRETRAIN_METHOD/data_in/KOR/naver_movie/ratings_train.txt\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.110.133, 185.199.108.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 14628807 (14M) [text/plain]\n",
      "Saving to: ‘data_in/KOR/naver_movie/ratings_train.txt’\n",
      "\n",
      "data_in/KOR/naver_m 100%[===================>]  13.95M  --.-KB/s    in 0.1s    \n",
      "\n",
      "2023-04-02 21:25:34 (97.0 MB/s) - ‘data_in/KOR/naver_movie/ratings_train.txt’ saved [14628807/14628807]\n",
      "\n",
      "--2023-04-02 21:25:34--  https://raw.githubusercontent.com/NLP-kr/tensorflow-ml-nlp-tf2/master/7.PRETRAIN_METHOD/data_in/KOR/naver_movie/ratings_test.txt\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.111.133, 185.199.109.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 4893335 (4.7M) [text/plain]\n",
      "Saving to: ‘data_in/KOR/naver_movie/ratings_test.txt’\n",
      "\n",
      "data_in/KOR/naver_m 100%[===================>]   4.67M  --.-KB/s    in 0.06s   \n",
      "\n",
      "2023-04-02 21:25:34 (78.6 MB/s) - ‘data_in/KOR/naver_movie/ratings_test.txt’ saved [4893335/4893335]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!mkdir -p data_in/KOR/naver_movie\n",
    "!wget https://raw.githubusercontent.com/NLP-kr/tensorflow-ml-nlp-tf2/master/7.PRETRAIN_METHOD/data_in/KOR/naver_movie/ratings_train.txt \\\n",
    "              -O data_in/KOR/naver_movie/ratings_train.txt\n",
    "!wget https://raw.githubusercontent.com/NLP-kr/tensorflow-ml-nlp-tf2/master/7.PRETRAIN_METHOD/data_in/KOR/naver_movie/ratings_test.txt \\\n",
    "              -O data_in/KOR/naver_movie/ratings_test.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "141ec966-c9cd-4656-bd28-251fde82355b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import re\n",
    "\n",
    "import random\n",
    "from random import sample\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "47825f33-c044-4fd4-8e7b-97ee1f222872",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.cuda.is_available()\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "02191bac-e084-4701-99c8-0fb12e73720e",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED_NUM = 1234\n",
    "random.seed(SEED_NUM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5e6c0d33-6031-46f0-b341-8288d2311e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"EleutherAI/polyglot-ko-5.8b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2d1fe450-0b01-430d-87aa-4ba8cdf0d3d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████████████████████████████████████████████████████████████████████| 3/3 [00:08<00:00,  2.69s/it]\n"
     ]
    }
   ],
   "source": [
    "cls_model = AutoModelForCausalLM.from_pretrained(\"beomi/KoAlpaca-Polyglot\",\n",
    "                                                 torch_dtype=torch.float16,\n",
    "                                                 device_map='sequential',\n",
    "                                                 low_cpu_mem_usage=True).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bcb1b85a-1557-402a-a073-e73f8a055f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "cls_model.config.max_length = 2048\n",
    "cls_model.config.pad_token_id = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2cd06616-f1b6-4916-ab0e-2beab1d30f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 전처리 준비\n",
    "DATA_IN_PATH = './data_in/KOR'\n",
    "DATA_OUT_PATH = './data_out/KOR'\n",
    "\n",
    "DATA_TRAIN_PATH = os.path.join(DATA_IN_PATH, 'naver_movie', 'ratings_train.txt')\n",
    "DATA_TEST_PATH = os.path.join(DATA_IN_PATH, 'naver_movie', 'ratings_test.txt')\n",
    "\n",
    "train_data = pd.read_csv(DATA_TRAIN_PATH, header = 0, delimiter = '\\t', quoting = 3)\n",
    "train_data = train_data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ff1022ca-8c44-45f0-add4-a08c32be27e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터 positive 라벨:  긍정\n",
      "데이터 negative 라벨:  부정\n"
     ]
    }
   ],
   "source": [
    "print('데이터 positive 라벨: ', '긍정')\n",
    "print('데이터 negative 라벨: ', '부정')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e4e840f6-8b33-4f64-9a2c-afe8c743cd2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습 예시 케이스 구조:  문장: 오늘 기분이 좋아\n",
      "감정: 긍정\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('학습 예시 케이스 구조: ', '문장: 오늘 기분이 좋아\\n감정: 긍정\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "036ac570-1031-46f0-b2b1-54e2220c31e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpt3 최대 토큰 길이:  2048\n"
     ]
    }
   ],
   "source": [
    "print('gpt3 최대 토큰 길이: ', cls_model.config.max_position_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "17140df1-6817-436f-919a-ea69ada88ab6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████| 149995/149995 [00:07<00:00, 21048.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Few shot 케이스 토큰 평균 길이:  20.22912763758792\n",
      "Few shot 케이스 토큰 최대 길이:  280\n",
      "Few shot 케이스 토큰 길이 표준편차:  16.48828728915166\n",
      "Few shot 케이스 토큰 길이 80 퍼센타일:  27.0\n"
     ]
    }
   ],
   "source": [
    "sent_lens = [len(tokenizer(s).input_ids) for s in tqdm(train_data['document'])]\n",
    "\n",
    "print('Few shot 케이스 토큰 평균 길이: ', np.mean(sent_lens))\n",
    "print('Few shot 케이스 토큰 최대 길이: ', np.max(sent_lens))\n",
    "print('Few shot 케이스 토큰 길이 표준편차: ',np.std(sent_lens))\n",
    "print('Few shot 케이스 토큰 길이 80 퍼센타일: ',np.percentile(sent_lens, 80))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "31801f58-6cbb-4f54-9bc3-1f72ba16348d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████| 149995/149995 [00:07<00:00, 20502.42it/s]\n"
     ]
    }
   ],
   "source": [
    "train_fewshot_data = []\n",
    "\n",
    "for train_sent, train_label in tqdm(train_data[['document', 'label']].values):\n",
    "    tokens = tokenizer(train_sent).input_ids\n",
    "\n",
    "    if len(tokens) <= 25:\n",
    "        train_fewshot_data.append((train_sent, train_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "90708f40-d4c3-467b-8993-b0f9d25be359",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>document</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6270596</td>\n",
       "      <td>굳 ㅋ</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9274899</td>\n",
       "      <td>GDNTOPCLASSINTHECLUB</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8544678</td>\n",
       "      <td>뭐야 이 평점들은.... 나쁘진 않지만 10점 짜리는 더더욱 아니잖아</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6825595</td>\n",
       "      <td>지루하지는 않은데 완전 막장임... 돈주고 보기에는....</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6723715</td>\n",
       "      <td>3D만 아니었어도 별 다섯 개 줬을텐데.. 왜 3D로 나와서 제 심기를 불편하게 하죠??</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                           document  label\n",
       "0  6270596                                                굳 ㅋ      1\n",
       "1  9274899                               GDNTOPCLASSINTHECLUB      0\n",
       "2  8544678             뭐야 이 평점들은.... 나쁘진 않지만 10점 짜리는 더더욱 아니잖아      0\n",
       "3  6825595                   지루하지는 않은데 완전 막장임... 돈주고 보기에는....      0\n",
       "4  6723715  3D만 아니었어도 별 다섯 개 줬을텐데.. 왜 3D로 나와서 제 심기를 불편하게 하죠??      0"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = pd.read_csv(DATA_TEST_PATH, header=0, delimiter='\\t', quoting=3)\n",
    "test_data = test_data.dropna()\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "1f3d05e8-f1f0-4928-b615-671ad28e9c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 평가 데이터 수\n",
    "sample_size = 500\n",
    "\n",
    "# 평가에서 활용할 few-shot 예제를 묶음으로 저장\n",
    "train_fewshot_samples = []\n",
    "\n",
    "for _ in range(sample_size):\n",
    "    # few-shot 예제를 10개씩 묶음\n",
    "    fewshot_examples = sample(train_fewshot_data, 10)\n",
    "    train_fewshot_samples.append(fewshot_examples)\n",
    "\n",
    "if sample_size < len(test_data['id']):\n",
    "    test_data = test_data.sample(sample_size, random_state=SEED_NUM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "93ddeaa6-4067-4e84-806a-49df7d105da9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('레전드.', 1),\n",
       " ('보고 있으면 어느새 영화에 빠져들어 있다. 마지막 장면을 생각하면 아직도 가슴이 찡하다.', 1),\n",
       " ('오즈의 영역을 넘어 마술의 경지에 이르는 허우.', 1),\n",
       " (\"'스트레스 해소용 영화' 로써만 강추..\", 0),\n",
       " ('볼만햇다 액션영화가 아닌데 아쉽다', 1),\n",
       " ('귀여운 기니피그가 나오는... 디즈니 영화. 디즈니 디즈니 디즈니', 0),\n",
       " ('햄릿! 돈은 있는데.. 정말 매너리즘에 빠진 최악의 중국 영화', 0),\n",
       " ('영화도 좋지만 책도 꼭 읽어보세요ㅎㅎ', 1),\n",
       " ('많은 생각이 떠돌게 되는 영화...', 1),\n",
       " ('개봉일을 잡았다는게 신기한 싸구려 영화.. 싼맛에 수입한거겠지?', 0)]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_fewshot_samples[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "28b62eb7-0fdf-4e5f-b89f-d1132d909133",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_prompt_text(sent):\n",
    "    return \"문장: \" + sent + '\\n감정:'\n",
    "\n",
    "def clean_text(sent):\n",
    "    sent_clean = re.sub(\"[^가-힣ㄱ-ㅎㅏ-ㅣ\\\\s]\", \"\", sent)\n",
    "    return sent_clean\n",
    "\n",
    "def generate_fewshot_example(data, with_label=True):\n",
    "    example_text, example_label = data\n",
    "    # 텍스트 전처리\n",
    "    cleaned_example_text = clean_text(example_text)\n",
    "    # Prompt 형식 구성\n",
    "    fewshot_example_text = build_prompt_text(cleaned_example_text)\n",
    "    # Label 추가\n",
    "    if with_label:\n",
    "      fewshot_example_text += ' 긍정' if example_label == 1 else ' 부정' + '\\n'\n",
    "    \n",
    "    return fewshot_example_text\n",
    "\n",
    "def predict_by_generation(prompt_text):\n",
    "    # 토큰화 및 인덱싱\n",
    "    tokens = tokenizer(prompt_text, return_tensors=\"pt\")\n",
    "    token_ids, attn_mask = tokens.input_ids.cuda(), tokens.attention_mask.cuda()\n",
    "    # 텍스트 생성\n",
    "    gen_tokens = cls_model.generate(input_ids=token_ids, attention_mask=attn_mask,\n",
    "                                    max_new_tokens=1, pad_token_id=0)\n",
    "    # 인덱스 복호화\n",
    "    pred = tokenizer.batch_decode(gen_tokens[:, -1])[0].strip()\n",
    "    \n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "6d2209c8-0e71-4abf-b794-5336fe5dc07b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>document</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6270596</td>\n",
       "      <td>굳 ㅋ</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9274899</td>\n",
       "      <td>GDNTOPCLASSINTHECLUB</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8544678</td>\n",
       "      <td>뭐야 이 평점들은.... 나쁘진 않지만 10점 짜리는 더더욱 아니잖아</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6825595</td>\n",
       "      <td>지루하지는 않은데 완전 막장임... 돈주고 보기에는....</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6723715</td>\n",
       "      <td>3D만 아니었어도 별 다섯 개 줬을텐데.. 왜 3D로 나와서 제 심기를 불편하게 하죠??</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>4608761</td>\n",
       "      <td>오랜만에 평점 로긴했네ㅋㅋ 킹왕짱 쌈뽕한 영화를 만났습니다 강렬하게 육쾌함</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>5308387</td>\n",
       "      <td>의지 박약들이나 하는거다 탈영은 일단 주인공 김대희 닮았고 이등병 찐따 OOOO</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>9072549</td>\n",
       "      <td>그림도 좋고 완성도도 높았지만... 보는 내내 불안하게 만든다</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>5802125</td>\n",
       "      <td>절대 봐서는 안 될 영화.. 재미도 없고 기분만 잡치고.. 한 세트장에서 다 해먹네</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>6070594</td>\n",
       "      <td>마무리는 또 왜이래</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>49997 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id                                           document  label\n",
       "0      6270596                                                굳 ㅋ      1\n",
       "1      9274899                               GDNTOPCLASSINTHECLUB      0\n",
       "2      8544678             뭐야 이 평점들은.... 나쁘진 않지만 10점 짜리는 더더욱 아니잖아      0\n",
       "3      6825595                   지루하지는 않은데 완전 막장임... 돈주고 보기에는....      0\n",
       "4      6723715  3D만 아니었어도 별 다섯 개 줬을텐데.. 왜 3D로 나와서 제 심기를 불편하게 하죠??      0\n",
       "...        ...                                                ...    ...\n",
       "49995  4608761          오랜만에 평점 로긴했네ㅋㅋ 킹왕짱 쌈뽕한 영화를 만났습니다 강렬하게 육쾌함      1\n",
       "49996  5308387       의지 박약들이나 하는거다 탈영은 일단 주인공 김대희 닮았고 이등병 찐따 OOOO      0\n",
       "49997  9072549                 그림도 좋고 완성도도 높았지만... 보는 내내 불안하게 만든다      0\n",
       "49998  5802125     절대 봐서는 안 될 영화.. 재미도 없고 기분만 잡치고.. 한 세트장에서 다 해먹네      0\n",
       "49999  6070594                                         마무리는 또 왜이래      0\n",
       "\n",
       "[49997 rows x 3 columns]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "9c9c746c-793b-4dfd-a41a-bf4c201cf307",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [00:30<00:00, 16.16it/s]\n"
     ]
    }
   ],
   "source": [
    "real_labels = []\n",
    "pred_tokens = []\n",
    "\n",
    "total_len = len(test_data[['document','label']].values)\n",
    "\n",
    "for i, row in tqdm(enumerate(test_data[['document','label']].values), total=total_len):\n",
    "    prompt_text = ''\n",
    "\n",
    "    for ex in train_fewshot_samples[i]:\n",
    "        prompt_text += generate_fewshot_example(ex)\n",
    "\n",
    "    prompt_text += generate_fewshot_example(row, with_label=False)\n",
    "\n",
    "    pred = predict_by_generation(prompt_text)\n",
    "\n",
    "    pred_tokens.append(pred)\n",
    "    real_labels.append('긍정' if row[1] == 1 else '부정')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "69d7dce0-3c85-43b6-a9c9-96afbc88bbf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.762\n"
     ]
    }
   ],
   "source": [
    "accuracy_match = [p == t for p, t in zip(pred_tokens, real_labels)]\n",
    "accuracy = len([m for m in accuracy_match if m]) / len(real_labels)\n",
    "\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "da6d9510-25de-472d-859f-b5bd4ab2568b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [00:39<00:00, 12.80it/s]\n"
     ]
    }
   ],
   "source": [
    "def build_prompt_text(sent):\n",
    "    return '다음 문장은 긍정일까요 부정일까요?\\n' + sent + '\\n정답:'\n",
    "\n",
    "real_labels = []\n",
    "pred_tokens = []\n",
    "\n",
    "total_len = len(test_data[['document','label']].values)\n",
    "\n",
    "for i, row in tqdm(enumerate(test_data[['document','label']].values), total=total_len):\n",
    "    prompt_text = ''\n",
    "\n",
    "    for ex in train_fewshot_samples[i]:\n",
    "        prompt_text += generate_fewshot_example(ex)\n",
    "\n",
    "    prompt_text += generate_fewshot_example(row, with_label=False)\n",
    "\n",
    "    pred = predict_by_generation(prompt_text)\n",
    "\n",
    "    pred_tokens.append(pred)\n",
    "    real_labels.append('긍정' if row[1] == 1 else '부정')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "8253b749-f605-4339-b6b0-b70cbed0f296",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.744\n"
     ]
    }
   ],
   "source": [
    "accuracy_match = [p == t for p, t in zip(pred_tokens, real_labels)]\n",
    "accuracy = len([m for m in accuracy_match if m]) / len(real_labels)\n",
    "\n",
    "print(accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
