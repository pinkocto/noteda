[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this blog\nThis blog was created for my personal research, study.\n\nSome links that help me\n\nhttps://miruetoto.github.io/yechan3/\nhttps://github.com/guebin\nhttps://wandb.ai/authors/One-Shot-3D-Photography/reports/-Machine-Learning-With-Graphs---Vmlldzo0MTY1MzY\n\n2023-1\n\nAP2023"
  },
  {
    "objectID": "posts/etc/2023-03-21-scorecard.html",
    "href": "posts/etc/2023-03-21-scorecard.html",
    "title": "Scorecard",
    "section": "",
    "text": "import pandas as pd\n\n\ncol = ['Model', 'scaling', 'Oversampling', 'Undersampling','hyper tunning', 'train(macro F1)','test(macro F1)', 'sub score']\n\n\ndf_row = pd.DataFrame(columns = col)\ndf_row['Model'] = ['DT','et']\n# df_row['missing'] = ['X'] # 해당 데이터는 결측치 없음.\ndf_row['scaling'] = ['X', 'O']\ndf_row['Oversampling'] = ['X', 'SMOTE']\ndf_row['Undersampling'] = ['X', 'X']\ndf_row['hyper tunning'] = ['X', 'O']\ndf_row['train(macro F1)'] = [1.0, 1.0]\ndf_row['test(macro F1)'] = [0.69, 0.76]\ndf_row['sub score'] = [0.73807, 0.76054]\n\n\ndf_row\n\n\n\n\n\n  \n    \n      \n      Model\n      scaling\n      Oversampling\n      Undersampling\n      hyper tunning\n      train(macro F1)\n      test(macro F1)\n      sub score\n    \n  \n  \n    \n      0\n      DT\n      X\n      X\n      X\n      X\n      1.0\n      0.69\n      0.73807\n    \n    \n      1\n      et\n      O\n      SMOTE\n      X\n      O\n      1.0\n      0.76\n      0.76054"
  },
  {
    "objectID": "posts/etc/2023-03-21-scorecard.html#r버전",
    "href": "posts/etc/2023-03-21-scorecard.html#r버전",
    "title": "Scorecard",
    "section": "R버전",
    "text": "R버전\n\nimport rpy2\n\n\n%load_ext rpy2.ipython\n\n\nrpy2.__version__\n\n'3.5.1'\n\n\n\n# !pip install rpy2==3.5.1\n\n\n%%R\nscore <- matrix(0, ncol=6, nrow=6, byrow=T)\ncolnames(score) <- c('변수','스케일링','변수변환','이상치제거','변동사항', 'R2')\n\n\n%%R\nscore[1,] <- c('집값, 실거주면적','X','X','X','단순선형회귀(절편O)',0.5021)\nscore[2,] <- c('집값, 실거주면적','X','X','X','단순선형회귀(절편X)',0.9186)\nscore[3,] <- c('집값, 실거주면적','X','X','O','단순선형회귀(절편O) + 이상치제거',0.5402)\nscore[4,] <- c('집값, 실거주면적','X','X','O','단순선형회귀(절편X) + 이상치제거',0.9255)\nscore[5,] <- c('집값, 실거주면적','X','O','O','단순선형회귀(절편X) + 이상치제거',0.5259)\nscore[6,] <- c('집값, 실거주면적','X','O','O','단순선형회귀(절편X) + 이상치제거',0.9120)\n\n\n%%R\ndata.frame(score)\n\n              변수 스케일링 변수변환 이상치제거\n1 집값, 실거주면적        X        X          X\n2 집값, 실거주면적        X        X          X\n3 집값, 실거주면적        X        X          O\n4 집값, 실거주면적        X        X          O\n5 집값, 실거주면적        X        O          O\n6 집값, 실거주면적        X        O          O\n                          변동사항     R2\n1              단순선형회귀(절편O) 0.5021\n2              단순선형회귀(절편X) 0.9186\n3 단순선형회귀(절편O) + 이상치제거 0.5402\n4 단순선형회귀(절편X) + 이상치제거 0.9255\n5 단순선형회귀(절편X) + 이상치제거 0.5259\n6 단순선형회귀(절편X) + 이상치제거  0.912\n\n\n\nref: r,python 둘다쓰는법\nref: 패키지특정버전업데이트\nref: rpy2에러해결"
  },
  {
    "objectID": "posts/etc/2023-04-20-학회.html",
    "href": "posts/etc/2023-04-20-학회.html",
    "title": "학회",
    "section": "",
    "text": "https://sejong-kr.libguides.com/c.php?g=936487&p=6772760\n자료분석학회, 데이터마이닝학회\n\n통계학회(4/20), 한국빅데이터학회(4/17), 한국데이터정보과학회(4/21),정보처리학회(4/19) \\(\\to\\) “마감”\n자료분석학회(5/29 발표신청, 5/31 초록/논문제출)\n데이터마이닝학회(5/5 초록제출, 5/12 논문선정통보, 6/16 발표논문제출)"
  },
  {
    "objectID": "posts/etc/2023-04-20-학회.html#통계학회-마감-6월29일7월1일",
    "href": "posts/etc/2023-04-20-학회.html#통계학회-마감-6월29일7월1일",
    "title": "학회",
    "section": "통계학회 (마감) (6월29일~7월1일)",
    "text": "통계학회 (마감) (6월29일~7월1일)\n\n학술대회 모집공고\n\n4/20일까지 초록(1페이지)과 발표요약본(A4 5장내외) 제출필요\n￭ 일 시 : 2023년 6월 29일(목)-7월 1일(토)\n￭ 장 소 : 부경대학교\n￭ 주 최 : (사)한국통계학회\n￭ 주 관 : (사)한국통계학회, 부경대학교 통계·데이터사이언스전공\n\n발표논문초록템플릿\n초록분량 1페이지 이내\n석사생의 경우 별도로 발표요약본을 추가로 제출해야함.(A4 5장 내외)\n\n\n\n\n일정\n\n\n\n논문발표신청 일정\n\n\n\n논문발표신청일정\n\n\n\n\n초록양식 및 제출방법\n\n\n\nimage.png\n\n\n\n\n초록 탬플릿 예시\n\n\n\n초록템플릿"
  },
  {
    "objectID": "posts/etc/2023-04-20-학회.html#한국데이터마이닝학회-6월23일-24일",
    "href": "posts/etc/2023-04-20-학회.html#한국데이터마이닝학회-6월23일-24일",
    "title": "학회",
    "section": "한국데이터마이닝학회 (6월23일-24일)",
    "text": "한국데이터마이닝학회 (6월23일-24일)\n\n하계학술대회 모집공고\n\nKDMS 2023 하계학술대회가 “챗GPT AI 시대 속에서 데이터마이닝의 역할”이라는 주제로 강릉원주대학교에서 6월 23일(금)-24(토) 양일에 걸쳐 개최됩니다.\n\n논문발표신청 및 등록일정\n\n▣ 일반 논문 발표신청\n\n사전 등록: 5월 22일(월) ~ 6월 22일(목) - 학생 7만, 일반 14만\n초록 제출: 5월 5일 (금)\n선정 통보: 5월 7일 (금)\n논문 제출: 6월 16일 (금)\n일정: 6월 23일(금) ~ 6월 24일(토)\n제출처: https://forms.gle/5CRQhxUqwAmbo5iu7\n\n\n\n\n논문모집분야\n\n일반논문, SAS학생논문 모집중.\n\n\n\n\nimage.png"
  },
  {
    "objectID": "posts/etc/2023-04-20-학회.html#자료분석학회-7월6일7월7일",
    "href": "posts/etc/2023-04-20-학회.html#자료분석학회-7월6일7월7일",
    "title": "학회",
    "section": "자료분석학회 (7월6일~7월7일)",
    "text": "자료분석학회 (7월6일~7월7일)\n\n일시: 2023년 7월 6일 (목) ~ 7월 7일 (금)\n장소: 고려대학교 (서울특별시 성북구안암로 145)\n발표신청 : 2023년 5월 29일 (월) 까지\n초록/논문제출: 2023년 5월 31일(수) 까지\n\n초록 1페이지, 논문 4쪽이내\n\n사전등록기간: 2023년 4월 1일(토) ~ 2023년 5월 31일(수)\n등록비(사전등록): 일반회원 50000원, 학생회원 30000원\n\n\n\n\n자료분석학회 타임라인\n\n\n\n\n\n일정"
  },
  {
    "objectID": "posts/etc/2023-04-05-ppt.html",
    "href": "posts/etc/2023-04-05-ppt.html",
    "title": "ppt 폰트",
    "section": "",
    "text": "https://m.blog.naver.com/yeeeeeei/220672713797"
  },
  {
    "objectID": "posts/etc/2023-03-21-lib.html",
    "href": "posts/etc/2023-03-21-lib.html",
    "title": "Libraries for DA",
    "section": "",
    "text": "Library\nDescription\n\n\n\n\n1.Numpy (Numeric + Python)\n과학/수학과 관련된 연산, 계산을 수행하는 함수의 집합\n\n\n2. Pandas (Panel + Data Set)\n정형데이터 분석 및 통계 연산을 수행하는 함수들의 집합\n\n\n3. Matplotlib (Matlab + Python)\n수치형 자료에 대한 시각화 함수들의 집합\n\n\n4. Seaborn\n정형데이터의 통계적 연산 및 시각화\n\n\n5. Scipy\n응용통계연산 (가설검정 / 회귀 분석 / 시계열) 함수들의 집합\n\n\n6. Scikit Learn\n정형데이터의 기계학습 기법에 관련한 함수들의 집합\n\n\n7. Missingno\n결측값을 시각화하는 함수들의 집합\n\n\n8. Plotly\n정형데이터 시각화 (동적시각화) 함수들의 집합\n\n\n9. Tensorflow\n비정형 데이터의 기계학습(신경망, 딥러닝) 함수들의 집합\n\n\n10. Keras\n신경망 알고리즘을 간단하게 사용할 수 있는 함수들의 집합\n\n\n11. NLTK\n영어 자연어 처리를 수행하는 함수들의 집합\n\n\n12. KoNLPy\n한국어 자연어 처리를 수행하는 함수들의 집합\n\n\n13. OpenCV\n컴퓨터 비전 (이미지 또는 영상처리) 함수들의 집합\n\n\n14. Gym\n강화학습과 관련한 함수들의 집합 (Chat GPT)"
  },
  {
    "objectID": "posts/etc/2023-04-02-abstract.html",
    "href": "posts/etc/2023-04-02-abstract.html",
    "title": "초록 작성법",
    "section": "",
    "text": "https://blog.essayreview.co.kr/difference-between-the-abstract-and-the-introduction-of-a-thesis/"
  },
  {
    "objectID": "posts/etc/2023-04-02-abstract.html#논문-초록과-서론의-차이점",
    "href": "posts/etc/2023-04-02-abstract.html#논문-초록과-서론의-차이점",
    "title": "초록 작성법",
    "section": "논문 초록과 서론의 차이점",
    "text": "논문 초록과 서론의 차이점\n초록(Abstract)은 논문 전체 내용을 요약하여 연구배경, 연구목표, 연구방법, 결과, 결론 이 구조를 따라 작성되기 때문에 서론+본론+결론 모든 내용이 포함됩니다. 대부분의 학술지에서는 보통 200-300단어로 제한하기 때문에 최대한 함축하여 핵심만 담아내야 하며, 독자들이 누구든 읽기 쉽고 명확하게 작성돼야 합니다\n서론(Introduction)은 연구 배경에 대해 자세한 정보를 제공하는 것이 목적입니다. 일부 저자들은 용어나 개념을 정의하거나 논문 순서를 설명하기도 합니다.\n\n\n\n논문 초록과 서론의 차이점"
  },
  {
    "objectID": "posts/etc/2023-04-02-abstract.html#논문-초록abstract이란",
    "href": "posts/etc/2023-04-02-abstract.html#논문-초록abstract이란",
    "title": "초록 작성법",
    "section": "논문 초록(abstract)이란?",
    "text": "논문 초록(abstract)이란?\n초록(abstract)은 저널 에디터와 연구원에게 논문을 간결하게 설명하고 자신의 논문을 읽도록 하는데 중요한 역할을 합니다. 온라인 데이터베이스 내의 수많은 논문 중에서, 자신의 논문을 읽도록 독자의 시선을 사로잡는 초록을 쓰는 일이 오늘날 더욱 중요해졌습니다."
  },
  {
    "objectID": "posts/etc/2023-04-02-abstract.html#논문-초록-작성-전-체크리스트",
    "href": "posts/etc/2023-04-02-abstract.html#논문-초록-작성-전-체크리스트",
    "title": "초록 작성법",
    "section": "논문 초록 작성 전 체크리스트",
    "text": "논문 초록 작성 전 체크리스트\n\n1. 초록 유형 정하기\n모든 초록은 연구를 요약합니다. 초록은 크게 두 가지 유형으로 구분될 수 있습니다: 서술형 (descriptive) 및 정보형 (informative). 다음은 이 두 가지 초록에 대한 간략한 설명입니다:\n\n서술형 초록 (Descriptive abstract): 100-200 단어; 논문의 목적 및 방법 설명하지만 결과와 결론은 생략합니다\n정보형 초록 (Informative abstract): 한 문단에서 1 페이지; 결과를 포함하여 연구의 모든 내용을 요약하는 연구 요약문\n\n두 가지 유형 중 정보형 초록 (informative abstract)이 더 많이 사용되며 저널 및 컨퍼런스에 제출할 때 사용됩니다. 정보형 초록은 더 길고 전문적인 연구에 적용되는 반면, 서술형 초록은 더 짧은 논문과 글에 더 적합합니다. 어느 초록을 사용해야 하는지 결정하는데 있어 가장 좋은 방법은 저널 투고 지침을 따르고 저널 논문을 가능한 한 많이 읽는 것입니다.\n\n\n2. 가이드라인과 요구사항 확인하기\n명시된 특정 지침과 요구 사항을 항상 철저히 준수해야 합니다. 일반적으로 저널 가이드라인에 포함된 질문은 아래와 같습니다:\n최대 또는 최소 단어/글자 수 제한이 있는가? 스타일 및 포맷팅 요구사항이 있는가? 적합한 초록 유형은? 특정 내용이나 구성이 포함되어야 하는가?\n\n\n3. 잠재 독자 생각하기\n초록의 주요 연구원들을 자신의 논문을 읽도록 연구원들을 사로잡는 것입니다. 학술 저널에서 초록은 독자가 연구가 자신의 관심 분야 또는 연구와 관련이 있는지를 알게 합니다. 초록은 독자로 하여금 자신의 연구의 논증을 빨리 이해할 수 있게 도와줍니다. 초록을 작성할 때 다음 질문을 고려합니다:\n자신의 분야에 있는 다른 학자들이 논문의 타겟 독자인가? 자신의 연구가 일반 대중에게 유용할 것인가? 연구 결과가 더 광범위한 영향을 가지고 있는가?"
  },
  {
    "objectID": "posts/etc/2023-04-02-abstract.html#논문-초록-구성방법",
    "href": "posts/etc/2023-04-02-abstract.html#논문-초록-구성방법",
    "title": "초록 작성법",
    "section": "논문 초록 구성방법",
    "text": "논문 초록 구성방법\n\n목적과 동기를 확인합니다. 왜 자신의 연구가 중요한가요 독자가 이 연구에 관심을 가져야 하는 이유를 설명하여 초록을 시작합니다—왜 자신의 분야에서 그리고 더 넓은 시각에서 자신의 연구가 중요한가요? 연구의 목적이 무엇인가요? 연구를 통해 성취하고자 하는 것이 무엇인가요? 아래 질문에 대답하여 시작합니다:\n해당 연구가 다루는 문제를 설명합니다. 해당 연구가 다루는 문제를 언급하는 것은 왜 자신의 연구가 중요하고 필요한지를 설명하는데 있어 빼먹지 말아야 할 요소입니다. 아래는 다루어야 할 질문을 보여줍니다:\n접근 방식에 대해 논의합니다 (Methods and Materials). 연구의 중요성, 연구를 하게 된 동기, 논문에서 다루는 구체적인 주제를 정한 후 해당 문제를 어떻게 해결했는지, 즉 연구를 수행한 방법에 대해 다루어야 합니다. 분석 모델, 시뮬레이션, 혹은 이중 맹검법을 사용했나요? 아래 사항을 명심하세요:\n결과를 요약합니다. 해당 연구 결과를 설명합니다. 애매한 질적인 용어를 사용하지 않고 (예: “very,” “small,” “tremendous”) 양적 용어를 사용합니다 (예: 백분율, 수치). 아래와 같은 질문에 답합니다:\n결론을 언급합니다. 초록의 마지막 부분에서 연구의 영향에 관해 언급합니다. 이를 연구 결과와 연결하여 설명합니다. 하지만 연구 결과에 대해 너무 과장해서 말해서는 안됩니다. 아래 질문 중 하나에 대답합니다:"
  },
  {
    "objectID": "posts/etc/2023-03-21-resumetable.html",
    "href": "posts/etc/2023-03-21-resumetable.html",
    "title": "resumetable",
    "section": "",
    "text": "def resumetable(df):\n    print(f'데이터셋 형상: {df.shape}')\n    summary = pd.DataFrame(df.dtypes, columns = ['데이터 타입'])\n    summary = summary.reset_index()\n    summary = summary.rename(columns = {'index':'피처'})\n    summary['결측값 개수'] = df.isnull().sum().values\n    summary['고윳값 개수'] = df.nunique().values\n    summary['첫 번째 값'] = df.loc[0].values\n    summary['두 번째 값'] = df.loc[1].values\n    summary['세 번째 값'] = df.loc[2].values\n            \n    return summary\nsummary = resumetable(train) \nsummary"
  },
  {
    "objectID": "posts/etc/2023-04-11-git-error.html",
    "href": "posts/etc/2023-04-11-git-error.html",
    "title": "Github remote: error: this exceeds GitHub’s file size limit of 100.00 MB",
    "section": "",
    "text": "- 에러내용\nremote: error: File <file path+name> is 618.76 MB; this exceeds GitHub's file size limit of 100.00 MB\nremote: error: GH001: Large files detected. You may want to try Git Large File Storage - https://git-lfs.github.com.\n- 해결방법\ngit -lfs 적용\n\n단, 이미 큰 용량의 파일을 커밋한 이력이 있으면 적용이 되지 않는다\nlfs리포지토리 용량이 1gb가 넘으면 유료버전으로 가입해야한다\n\nbatch response: This repository is over its data quota. Account responsible for LFS bandwidth should purchase more data packs to restore access.\nlfs 용량초과로 위와 같은 에러가 남. 용량이 큰 파일은 올릴 수 없을 듯하다..\n어쩔수 없이 이미 push한 파일들에 대해서 취소를 해야한다."
  },
  {
    "objectID": "posts/etc/2023-04-11-git-error.html#git-push-취소",
    "href": "posts/etc/2023-04-11-git-error.html#git-push-취소",
    "title": "Github remote: error: this exceeds GitHub’s file size limit of 100.00 MB",
    "section": "Git push 취소",
    "text": "Git push 취소\n문제가 되는 파일을 먼저 따로 빼놔야 한다.\ngit push를 취소하기 위해 먼저 가장 최근의 commit을 취소하고 워킹 디렉터리를 되돌려야한다.\n$ git reset HEAD^\n위의 명령어를 실행해 최근 커밋을 취소한다.\n$ git reflog\ngit reflog 명령어를 사용하여 브랜치와 HEAD가 가리켰던 커밋 목록을 확인하여 내가 어떤 시점으로 되돌아갈 것인지 확인\n$ git reset HEAD@{number}   #원하는 시점으로 되돌아가기\n$ git commit -m \"commit messages\"   #돌아간 시점에서 커밋하기\n$ git push origin main   #되돌린 시점을 원격에 강제 push\n이렇게 원하는 시점으로 돌아가면 로컬, 원격 모두 원하는 시점 이전의 상태로 돌아간다.\n이전의 상태로 돌아갔다면 커밋 후 강제 push를 해주면 된다.\n\n\nref: lfs 할당량 에러\nref: push 취소\nref: lfs사용하여 대용량 파일 업로드"
  },
  {
    "objectID": "posts/etc/2023-02-24-tips.html",
    "href": "posts/etc/2023-02-24-tips.html",
    "title": "Julia 설치 및 실행",
    "section": "",
    "text": "Julia 설치\n설치된 Julia를 열어 Command창에 using Pkg 입력 + 엔터\nPkg.add(\"IJulia\") 입력 + 엔터\nJupyter notebook/lab 들어가서 확인\n\n결과\n\n\n\nimage.png"
  },
  {
    "objectID": "posts/etc/2023-02-24-tips.html#linux",
    "href": "posts/etc/2023-02-24-tips.html#linux",
    "title": "Julia 설치 및 실행",
    "section": "Linux",
    "text": "Linux\n\n1. 줄리아 설치\n## 설치\n>> sudo apt install wget ## wget 설치가 안되어 있다면\n>> wget https://julialang-s3.julialang.org/bin/linux/x64/1.8/julia-1.8.5-linux-x86_64.tar.gz\n\n\n\njulia 설치되고 있는 화면 캡처\n\n\n## 압축풀기\n>> tar zxvf julia-1.8.5-linux-x86_64.tar.gz\n## 심볼릭 링크 만들기\n>> sudo ln -s /home/[유저이름]/julia-1.3.1/bin/julia /usr/bin/julia\n\n\n2. 주피터와 연결\n## julia 실행\n>> julia\n>> using Pkg\n>> Pkg.add(\"IJulia\")\n\n\n3. 플루토 키는 방법\nimport Pluto\nPluto.run(host=\"0.0.0.0\",port=1234,launch_browser=false,require_secret_for_open_links=false,require_secret_for_access=false,threads=\"8\")\n\nref: https://miruetoto.github.io/yechan3/posts/4_Notes/2000-01-07-%EC%A4%84%EB%A6%AC%EC%95%84%20%EC%84%A4%EC%B9%98%20%EB%B0%8F%20%EC%8B%A4%ED%96%89.html\nref: https://freshrimpsushi.github.io/posts/how-to-install-the-latest-version-julia-in-linux/"
  },
  {
    "objectID": "posts/etc/2023-04-01-연구생신규등록.html",
    "href": "posts/etc/2023-04-01-연구생신규등록.html",
    "title": "연구참여 확약서",
    "section": "",
    "text": "연구지원부\n학생연구비 통합관리: 063-270-4904"
  },
  {
    "objectID": "posts/etc/2023-04-01-연구생신규등록.html#학생용",
    "href": "posts/etc/2023-04-01-연구생신규등록.html#학생용",
    "title": "연구참여 확약서",
    "section": "학생용",
    "text": "학생용\n\n국가연구자번호 필요\niris, KRI 회원가입 진행\n[오아시스]-[연구원기본정보] - 국가연구자번호 입력 및 풀링제 개인정보 동의\n연구자 윤리교육 수료증 필요 (졸업 전까지 들어야 한다는데 모호함..)\n\n[오아시스] - [연구원기본정보등록] - 수료번호, 수료증 업로드"
  },
  {
    "objectID": "posts/etc/2023-04-01-연구생신규등록.html#신규연구생-등록-절차-교수님",
    "href": "posts/etc/2023-04-01-연구생신규등록.html#신규연구생-등록-절차-교수님",
    "title": "연구참여 확약서",
    "section": "신규연구생 등록 절차 (교수님)",
    "text": "신규연구생 등록 절차 (교수님)\n\n오아시스3.0 > 연구책임자계정인원(변경)신청 > 추가 옆에 뭔가 탭이 있었는데 그거 클릭하고 추가누르면 추가가됨\n학생인건비 통합관리 동의(학생 동의필요) 후 승인이 떨어지면 아래의 과정 진행\n학생인건비 참여연구원 변경 신청 결의서는 교수님 작성/업로드\n오아시스3.0 > 상단 연구정보 탭 > 사이드바에 학생인건비 통합관리(학생) > 하단에 연구참여 확약서(돋보기 클릭) > 연구참여 확약서 양식 출력해서 교수 님, 학생 승인 후 학생이 업로드 > 교수님이 신청"
  },
  {
    "objectID": "posts/etc/2023-04-23-r-python-same-jupyter.html",
    "href": "posts/etc/2023-04-23-r-python-same-jupyter.html",
    "title": "R/Python jupyter",
    "section": "",
    "text": "import numpy as np\nimport pandas as pd"
  },
  {
    "objectID": "posts/etc/2023-04-23-r-python-same-jupyter.html#using-python",
    "href": "posts/etc/2023-04-23-r-python-same-jupyter.html#using-python",
    "title": "R/Python jupyter",
    "section": "- using Python",
    "text": "- using Python\n\nn=100\nt=np.linspace(0,0.99,n)\nf_true =3+ 1.5*np.sin(2*np.pi*t)+2*np.sin(10*np.pi*t)\nϵ=np.random.normal(scale=0.2,size=n)\nf = f_true + ϵ\n\n\n# t=np.linspace(0,0.99,n)\nx1 = np.sin(2*np.pi*t)\nx2 = np.sin(10*np.pi*t)\n\n\n# n=100\n# f = f_true + ϵ\nX=np.ones((n,3))\nX[:,1] = x1\nX[:,2] = x2\nX = np.matrix(X)\ny = np.matrix(f).T # y는 col-vec로 선언\nβhat = (X.T*X).I*X.T*y\nβhat\n\nmatrix([[2.99321226],\n        [1.49335619],\n        [1.99914477]])"
  },
  {
    "objectID": "posts/etc/2023-04-23-r-python-same-jupyter.html#using-r",
    "href": "posts/etc/2023-04-23-r-python-same-jupyter.html#using-r",
    "title": "R/Python jupyter",
    "section": "- using R",
    "text": "- using R\n\n%R -i f,x1,x2\n\n\n%%R \nlm(f~x1+x2)\n\n\nCall:\nlm(formula = f ~ x1 + x2)\n\nCoefficients:\n(Intercept)           x1           x2  \n      2.993        1.493        1.999"
  },
  {
    "objectID": "posts/etc/2023-03-21-downcasting.html",
    "href": "posts/etc/2023-03-21-downcasting.html",
    "title": "downcasting",
    "section": "",
    "text": "def downcast(df, verbose=True):\n    start_mem = df.memory_usage().sum() / 1024**2\n    for col in df.columns:\n        dtype_name = df[col].dtype.name\n        if dtype_name == 'object':\n            pass\n        elif dtype_name == 'bool':\n            df[col] = df[col].astype('int8')\n        elif dtype_name.startswith('int') or (df[col].round() == df[col]).all():\n            df[col] = pd.to_numeric(df[col], downcast='integer')\n        else:\n            df[col] = pd.to_numeric(df[col], downcast='float')\n    end_mem = df.memory_usage().sum() / 1024**2\n    if verbose:\n        print('{:.1f}% 압축됨'.format(100 * (start_mem - end_mem) / start_mem))\n    \n    return df\nall_df = [sales_train, shops, items, item_categories, test]\nfor df in all_df:\n    df = downcast(df)\n\nint8 (Byte) : -128~127\nint16 (integer) : -32768~32768\nint32 (integer) : -2147483648~2147483647\nint64 (integer) : very very big\nuint8 (unsigned integer) : 0~255\nuint16 (unsigned integer) : 0~65535\nuint32 (unsigned integer) : 0~4294967295\nuint64 (unsigned integer) :0~very very big\nfloat (shortand for float64)\nfloat16 (Half precision float)\nfloat32 (Single precision float)\nfloat64"
  },
  {
    "objectID": "posts/etc/2023-03-21-dv.html",
    "href": "posts/etc/2023-03-21-dv.html",
    "title": "data visualization",
    "section": "",
    "text": "import numpy as np\nimport missingno as msno\nmsno.matrix(df, figsize=(13,6)) ## 결측값을 매트릭스 형태로 시각화\n# msno.bar(df, figsize=(13, 6)) ## bar 형태"
  },
  {
    "objectID": "posts/etc/2023-03-21-dv.html#target-distribution-비율",
    "href": "posts/etc/2023-03-21-dv.html#target-distribution-비율",
    "title": "data visualization",
    "section": "target Distribution (+비율)",
    "text": "target Distribution (+비율)\nimport seaborn as sns\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\n\nimport matplotlib.pyplot as plt\nplt.rcParams['font.family'] = 'Malgun Gothic'  ## 한글깨짐 방지\ndef write_percent(ax, total_size):\n    for patch in ax.patches:\n        height = patch.get_height() # 도형 높이 (데이터 개수)\n        width = patch.get_width()\n        left_coord = patch.get_x()\n        percent = height/total_size*100 # target ratio\n        \n        ax.text(left_coord + width/2.0,\n                height + total_size*0.001,\n                '{:1.1f}%'.format(percent),\n                ha = 'center')\n   \nmpl.rc('font', size=15)\nplt.figure(figsize=(7,6))\n\nax = sns.countplot(x='target', data=train)\nwrite_percent(ax, len(train))\nax.set_title('Target Distribution')"
  },
  {
    "objectID": "posts/etc/2023-03-21-dv.html#그룹별-요약통계량-분포-시각화",
    "href": "posts/etc/2023-03-21-dv.html#그룹별-요약통계량-분포-시각화",
    "title": "data visualization",
    "section": "그룹별 요약통계량 분포 시각화",
    "text": "그룹별 요약통계량 분포 시각화\nfigure, ax = plt.subplots()\nfigure.set_size_inches(11, 5)\n\n# 상품분류별 총 상품 판매량\ngroup_cat_sum = train.groupby('item_category_id').agg({'item_cnt_day':'sum'})\ngroup_cat_sum = group_cat_sum.reset_index()\n\n# 월간 판매량이 10,000개를 초과하는 상품분류만 추출\ngroup_cat_sum2 = group_cat_sum[group_cat_sum['item_cnt_day'] > 10000].sort_values(by='item_cnt_day', ascending=False)\n\n# 상품분류별 총 상품 판매량 막대 그래프\nsns.barplot(x='item_category_id', y='item_cnt_day', data=group_cat_sum2, order=group_cat_sum2['item_category_id'])\nax.set(title='Distribution of total item counts by item category id',\n       xlabel='Data block number',\n       ylabel='Total item counts')\nax.tick_params(axis='x', labelrotation=90) # x축 라벨 회전\n\n\n\n예시 그림"
  },
  {
    "objectID": "posts/etc/2023-05-08-에러모음.html",
    "href": "posts/etc/2023-05-08-에러모음.html",
    "title": "에러 모음",
    "section": "",
    "text": "에러메세지 내용\n\n\n\nhttps://tex.stackexchange.com/questions/256920/package-amsmath-error-beginaligned-allowed-only-in-math-mode\n\n두줄 이상은 {aligned} 사용해야함. (align*, align이런 것들 안됨, equation, split 이런것들도 안됐음.)\n패키지 amsmath 오류: \\begin{aligned}는 수학 모드에서만 허용됩니다.\nLaTeX는 수학 표현식에 대한 두 가지 쓰기 모드인 인라인 수학 모드와 디스플레이 수학 모드를 허용합니다.\n인라인 수학 모드는 단락의 일부인 수식을 작성하는 데 사용됩니다. 디스플레이 수학 모드는 단락의 일부가 아닌 식을 작성하는 데 사용되므로 별도의 줄에 표시됩니다. 인라인 수학 모드 구분 기호\n\\(...\\)\n$...$\n\\begin{math}...\\end{math}\n수학 모드 구분 기호 표시\n\\[...\\]\n\\begin{displaymath}...\\end{displaymath}\n\\begin{equation}...\\end{equation}\n한마디로 \\begin{aligned}이러한 수학 모드 구분 기호 중 하나에 작성해야 합니다."
  },
  {
    "objectID": "posts/DataHandling/2023-04-06-pivot-wider-error.html",
    "href": "posts/DataHandling/2023-04-06-pivot-wider-error.html",
    "title": "[R] pivot_wider Error",
    "section": "",
    "text": "SOLAR 데이터 재구조화 과정에서 발생한 오류였음.\n\n\n\n\nError Message 캡처\n\n\n\nvalue가 유니크하지 않아서 발생하는 에러이다. 각 region별 임의로 유니크한 식별 로우를 만들어 주면 에러를 해결할 수 있음."
  },
  {
    "objectID": "posts/DataHandling/2023-04-06-pivot-wider-error.html#solution",
    "href": "posts/DataHandling/2023-04-06-pivot-wider-error.html#solution",
    "title": "[R] pivot_wider Error",
    "section": "Solution",
    "text": "Solution\ndf %>%\n  group_by(region) %>%\n  mutate(row = row_number()) %>%\n  tidyr::pivot_wider(names_from = region, values_from = solar_radiation) %>%\n  select(-row)\n\nref: https://stackoverflow.com/questions/58837773/pivot-wider-issue-values-in-values-from-are-not-uniquely-identified-output-w"
  },
  {
    "objectID": "posts/DataHandling/2023-04-02-assign.html",
    "href": "posts/DataHandling/2023-04-02-assign.html",
    "title": "[Python] 새로운 열 할당(.assign) 및 특정 열 선택",
    "section": "",
    "text": "DV2022 7wk-1 Lecture\n\n\n\n판다스로 새로운 열 할당하는 방법에는 여러 방법들이 있지만 그 중 assign으로 할당하는 것은 확장성이 있고 다양한 상황에 사용하기 좋음.\n\nimport pandas as pd\n\n\ndf = pd.DataFrame({'a':[1,2,3],'b':[2,3,4]})\ndf\n\n\n\n\n\n  \n    \n      \n      a\n      b\n    \n  \n  \n    \n      0\n      1\n      2\n    \n    \n      1\n      2\n      3\n    \n    \n      2\n      3\n      4\n    \n  \n\n\n\n\n\ndf.assign(c=[3,4,5])\n\n\n\n\n\n  \n    \n      \n      a\n      b\n      c\n    \n  \n  \n    \n      0\n      1\n      2\n      3\n    \n    \n      1\n      2\n      3\n      4\n    \n    \n      2\n      3\n      4\n      5\n    \n  \n\n\n\n\n\ndf.assign(c=[3,4,5],d=[4,5,6])\n\n\n\n\n\n  \n    \n      \n      a\n      b\n      c\n      d\n    \n  \n  \n    \n      0\n      1\n      2\n      3\n      4\n    \n    \n      1\n      2\n      3\n      4\n      5\n    \n    \n      2\n      3\n      4\n      5\n      6\n    \n  \n\n\n\n\n\ndf.assign(c=[3,4,5]).assign(d=[4,5,6])\n\n\n\n\n\n  \n    \n      \n      a\n      b\n      c\n      d\n    \n  \n  \n    \n      0\n      1\n      2\n      3\n      4\n    \n    \n      1\n      2\n      3\n      4\n      5\n    \n    \n      2\n      3\n      4\n      5\n      6\n    \n  \n\n\n\n\n\n\n\ndf.assign(c=[3,4,5]).assign(d=[4,5,6])\n\n\n\n\n\n  \n    \n      \n      a\n      b\n      c\n      d\n    \n  \n  \n    \n      0\n      1\n      2\n      3\n      4\n    \n    \n      1\n      2\n      3\n      4\n      5\n    \n    \n      2\n      3\n      4\n      5\n      6\n    \n  \n\n\n\n\n\ndf # 원래 데이터 프레임은 그대로 유지된다.\n\n\n\n\n\n  \n    \n      \n      a\n      b\n    \n  \n  \n    \n      0\n      1\n      2\n    \n    \n      1\n      2\n      3\n    \n    \n      2\n      3\n      4\n    \n  \n\n\n\n\n\n\n\n\ndf.assign(c=[3,4,5]).assign(d=[4,5,6]) # 1->2, 2->3 으로 가는 과정이 메모리 공간안에 모두 저장되어 있다.\n\n\n\n\n\n  \n    \n      \n      a\n      b\n      c\n      d\n    \n  \n  \n    \n      0\n      1\n      2\n      3\n      4\n    \n    \n      1\n      2\n      3\n      4\n      5\n    \n    \n      2\n      3\n      4\n      5\n      6\n    \n  \n\n\n\n\n\ndf ## step1\n\n\n\n\n\n  \n    \n      \n      a\n      b\n    \n  \n  \n    \n      0\n      1\n      2\n    \n    \n      1\n      2\n      3\n    \n    \n      2\n      3\n      4\n    \n  \n\n\n\n\n\ndf.assign(c=[3,4,5]) ## step2\n\n\n\n\n\n  \n    \n      \n      a\n      b\n      c\n    \n  \n  \n    \n      0\n      1\n      2\n      3\n    \n    \n      1\n      2\n      3\n      4\n    \n    \n      2\n      3\n      4\n      5\n    \n  \n\n\n\n\n\ndf.assign(c=[3,4,5]).assign(d=[4,5,6]) ## step3\n\n\n\n\n\n  \n    \n      \n      a\n      b\n      c\n      d\n    \n  \n  \n    \n      0\n      1\n      2\n      3\n      4\n    \n    \n      1\n      2\n      3\n      4\n      5\n    \n    \n      2\n      3\n      4\n      5\n      6\n    \n  \n\n\n\n\n\n## d=[4,5,6] >> d = [4,-5,6]으로 변환.\ndf.assign(c=[3,4,5]).assign(d=[4,-5,6]) \n\n\n\n\n\n  \n    \n      \n      a\n      b\n      c\n      d\n    \n  \n  \n    \n      0\n      1\n      2\n      3\n      4\n    \n    \n      1\n      2\n      3\n      4\n      -5\n    \n    \n      2\n      3\n      4\n      5\n      6"
  },
  {
    "objectID": "posts/DataHandling/2023-04-02-assign.html#예시1",
    "href": "posts/DataHandling/2023-04-02-assign.html#예시1",
    "title": "[Python] 새로운 열 할당(.assign) 및 특정 열 선택",
    "section": "예시1",
    "text": "예시1\ncolor ~ num_voted_user를 뽑고 + aspect_ratio도 추가적으로 뽑으시오.\n\n- 안되는 예\n\ndf.loc[:,['color':'num_voted_users','aspect_ratio']] # 이건 안됨.\n\nSyntaxError: invalid syntax (<ipython-input-21-b5b8957e5ac9>, line 1)\n\n\n\n\n- 해결 (iloc 이용)\nTip! : 복잡한 조건은 iloc으로 쓰는게 편할때가 있다. \\(\\to\\) 그런데 df.columns 변수들이 몇번인지 알아보기 힘듬 \\(\\to\\) 아래와 같이 하면 열의 이름을 인덱스와 함께 출력할 수 있음\n\npd.Series(df.columns) # 매우 편함.\n\n0                         color\n1                 director_name\n2        num_critic_for_reviews\n3                      duration\n4       director_facebook_likes\n5        actor_3_facebook_likes\n6                  actor_2_name\n7        actor_1_facebook_likes\n8                         gross\n9                        genres\n10                 actor_1_name\n11                  movie_title\n12              num_voted_users\n13    cast_total_facebook_likes\n14                 actor_3_name\n15         facenumber_in_poster\n16                plot_keywords\n17              movie_imdb_link\n18         num_user_for_reviews\n19                     language\n20                      country\n21               content_rating\n22                       budget\n23                   title_year\n24       actor_2_facebook_likes\n25                   imdb_score\n26                 aspect_ratio\n27         movie_facebook_likes\ndtype: object\n\n\n\n해당 열의 인덱스와 컬럼명이 같이 출력된다. 일일이 세지 않아도 된다.\n\n\nlist(range(13))+[26]\n\n[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 26]\n\n\n\ndf.iloc[:,list(range(13))+[26]].head(2)\n\n\n\n\n\n  \n    \n      \n      color\n      director_name\n      num_critic_for_reviews\n      duration\n      director_facebook_likes\n      actor_3_facebook_likes\n      actor_2_name\n      actor_1_facebook_likes\n      gross\n      genres\n      actor_1_name\n      movie_title\n      num_voted_users\n      aspect_ratio\n    \n  \n  \n    \n      0\n      Color\n      James Cameron\n      723.0\n      178.0\n      0.0\n      855.0\n      Joel David Moore\n      1000.0\n      760505847.0\n      Action|Adventure|Fantasy|Sci-Fi\n      CCH Pounder\n      Avatar\n      886204\n      1.78\n    \n    \n      1\n      Color\n      Gore Verbinski\n      302.0\n      169.0\n      563.0\n      1000.0\n      Orlando Bloom\n      40000.0\n      309404152.0\n      Action|Adventure|Fantasy\n      Johnny Depp\n      Pirates of the Caribbean: At World's End\n      471220\n      2.35"
  },
  {
    "objectID": "posts/DataHandling/2023-04-02-hanling-index.html",
    "href": "posts/DataHandling/2023-04-02-hanling-index.html",
    "title": "[Python] 중첩인덱스 깨는 법",
    "section": "",
    "text": "중첩인덱스 깨는 법\n\nDV2022 10wk-2 Lecture 심슨의 역설\n\n\nstack 이 답이다.\n\n\nimport pandas as pd\nimport numpy as np\nfrom plotnine import *\n\n\n# 중첩인덱스로 되어있는 dataframe\ndf=pd.read_csv(\"https://raw.githubusercontent.com/guebin/DV2022/master/posts/Simpson.csv\",index_col=0,header=[0,1])\ndf\n\n\n\n\n\n  \n    \n      \n      male\n      female\n    \n    \n      \n      fail\n      pass\n      fail\n      pass\n    \n  \n  \n    \n      A\n      314\n      511\n      19\n      89\n    \n    \n      B\n      208\n      352\n      7\n      18\n    \n    \n      C\n      204\n      121\n      391\n      202\n    \n    \n      D\n      279\n      138\n      244\n      131\n    \n    \n      E\n      137\n      54\n      299\n      94\n    \n    \n      F\n      149\n      224\n      103\n      238\n    \n  \n\n\n\n\n\n# stack 1번 적용\ndf=pd.read_csv(\"https://raw.githubusercontent.com/guebin/DV2022/master/posts/Simpson.csv\",index_col=0,header=[0,1])\\\n.stack()\ndf\n\n\n\n\n\n  \n    \n      \n      \n      female\n      male\n    \n  \n  \n    \n      A\n      fail\n      19\n      314\n    \n    \n      pass\n      89\n      511\n    \n    \n      B\n      fail\n      7\n      208\n    \n    \n      pass\n      18\n      352\n    \n    \n      C\n      fail\n      391\n      204\n    \n    \n      pass\n      202\n      121\n    \n    \n      D\n      fail\n      244\n      279\n    \n    \n      pass\n      131\n      138\n    \n    \n      E\n      fail\n      299\n      137\n    \n    \n      pass\n      94\n      54\n    \n    \n      F\n      fail\n      103\n      149\n    \n    \n      pass\n      238\n      224\n    \n  \n\n\n\n\n\n# stack 2번 적용\ndf=pd.read_csv(\"https://raw.githubusercontent.com/guebin/DV2022/master/posts/Simpson.csv\",index_col=0,header=[0,1])\\\n.stack().stack()\ndf\n\nA  fail  female     19\n         male      314\n   pass  female     89\n         male      511\nB  fail  female      7\n         male      208\n   pass  female     18\n         male      352\nC  fail  female    391\n         male      204\n   pass  female    202\n         male      121\nD  fail  female    244\n         male      279\n   pass  female    131\n         male      138\nE  fail  female    299\n         male      137\n   pass  female     94\n         male       54\nF  fail  female    103\n         male      149\n   pass  female    238\n         male      224\ndtype: int64\n\n\n\n# stack2번 + 인덱스 리셋\ndf=pd.read_csv(\"https://raw.githubusercontent.com/guebin/DV2022/master/posts/Simpson.csv\",index_col=0,header=[0,1])\\\n.stack().stack().reset_index()\ndf\n\n\n\n\n\n  \n    \n      \n      level_0\n      level_1\n      level_2\n      0\n    \n  \n  \n    \n      0\n      A\n      fail\n      female\n      19\n    \n    \n      1\n      A\n      fail\n      male\n      314\n    \n    \n      2\n      A\n      pass\n      female\n      89\n    \n    \n      3\n      A\n      pass\n      male\n      511\n    \n    \n      4\n      B\n      fail\n      female\n      7\n    \n    \n      5\n      B\n      fail\n      male\n      208\n    \n    \n      6\n      B\n      pass\n      female\n      18\n    \n    \n      7\n      B\n      pass\n      male\n      352\n    \n    \n      8\n      C\n      fail\n      female\n      391\n    \n    \n      9\n      C\n      fail\n      male\n      204\n    \n    \n      10\n      C\n      pass\n      female\n      202\n    \n    \n      11\n      C\n      pass\n      male\n      121\n    \n    \n      12\n      D\n      fail\n      female\n      244\n    \n    \n      13\n      D\n      fail\n      male\n      279\n    \n    \n      14\n      D\n      pass\n      female\n      131\n    \n    \n      15\n      D\n      pass\n      male\n      138\n    \n    \n      16\n      E\n      fail\n      female\n      299\n    \n    \n      17\n      E\n      fail\n      male\n      137\n    \n    \n      18\n      E\n      pass\n      female\n      94\n    \n    \n      19\n      E\n      pass\n      male\n      54\n    \n    \n      20\n      F\n      fail\n      female\n      103\n    \n    \n      21\n      F\n      fail\n      male\n      149\n    \n    \n      22\n      F\n      pass\n      female\n      238\n    \n    \n      23\n      F\n      pass\n      male\n      224\n    \n  \n\n\n\n\n\ndf=pd.read_csv(\"https://raw.githubusercontent.com/guebin/DV2022/master/posts/Simpson.csv\",index_col=0,header=[0,1])\\\n.stack().stack().reset_index()\\\n.rename({'level_0':'department','level_1':'result','level_2':'gender',0:'count'},axis=1)\ndf.head()\n\n\n\n\n\n  \n    \n      \n      department\n      result\n      gender\n      count\n    \n  \n  \n    \n      0\n      A\n      fail\n      female\n      19\n    \n    \n      1\n      A\n      fail\n      male\n      314\n    \n    \n      2\n      A\n      pass\n      female\n      89\n    \n    \n      3\n      A\n      pass\n      male\n      511\n    \n    \n      4\n      B\n      fail\n      female\n      7"
  },
  {
    "objectID": "posts/DataHandling/2023-04-06-assign-r.html",
    "href": "posts/DataHandling/2023-04-06-assign-r.html",
    "title": "[R] 문자열을 변수명으로 & assign",
    "section": "",
    "text": "ref: assign함수 이용하여 값을 변수에 넣기\nref: R문자열을 볂수명으로 사용하는 방법"
  },
  {
    "objectID": "posts/DataHandling/2023-04-06-assign-r.html#예제",
    "href": "posts/DataHandling/2023-04-06-assign-r.html#예제",
    "title": "[R] 문자열을 변수명으로 & assign",
    "section": "예제",
    "text": "예제\n\n- 문자열을 변수명으로\n\na = 3\neval(parse(text = 'a'))\n\n3\n\n\n\n\n- assign으로 값을 변수에 할당\n## 변수명은 반드시 문자형으로 들어가야한다.\nassign(변수명, 값)\n(예제1) x1이라는 변수에 c(1,2,3,4,5)를 할당하기\n\nassign(\"x1\", c(1,2,3,4,5)) \n\n\nx1\n\n\n12345\n\n\n(예제2) 변수를 한번에 많이 생성할 경우\n\nfor(x in 1:100){\n    assign(paste0('var',1:100)[x],x)\n}\n\n\nvar1\n\n1\n\n\n\nvar2\n\n2\n\n\n\nvar100\n\n100"
  },
  {
    "objectID": "posts/DataHandling/2023-04-06-assign-r.html#활용-solar-data",
    "href": "posts/DataHandling/2023-04-06-assign-r.html#활용-solar-data",
    "title": "[R] 문자열을 변수명으로 & assign",
    "section": "활용 (SOLAR DATA)",
    "text": "활용 (SOLAR DATA)\n\nlibrary(tidyverse)\nlibrary(lubridate)\nlibrary(EPT)\n\n── Attaching packages ─────────────────────────────────────── tidyverse 1.3.1 ──\n\n✔ ggplot2 3.4.1     ✔ purrr   1.0.1\n✔ tibble  3.2.0     ✔ dplyr   1.1.0\n✔ tidyr   1.3.0     ✔ stringr 1.5.0\n✔ readr   2.1.4     ✔ forcats 1.0.0\n\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\n\n\nAttaching package: ‘lubridate’\n\n\nThe following objects are masked from ‘package:base’:\n\n    date, intersect, setdiff, union\n\n\n\n\n\nurl = 'https://raw.githubusercontent.com/pinkocto/mm/main/posts/2_Research/SOLAR/solar_radiation.csv'\ndf = read_csv(url)\n\nRows: 803000 Columns: 3\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (2): region, date\ndbl (1): solar_radiation\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\nfor (i in 1:44){\n     assign(paste0('data',1:44)[i],df |> filter(region == unique(df$region)[i]))\n     assign(paste0('data',1:44)[i],eval(parse(text=paste0('data',i)))[order(eval(parse(text=paste0('data',i)))$date),])\n     assign(paste0('y',1:44)[i], eval(parse(text=paste0('data',i)))$solar_radiation)\n}\n\n\nfor (i in 1:44){\n    plot(eval(parse(text=paste0('y',i)))[1:500], ann=FALSE)\n    lines(eval(parse(text=paste0('y',i))),lty=2)\n    title(main = as.character(unique(df$region)[i]), xlab='time', ylab='solar radiation')\n    }"
  },
  {
    "objectID": "posts/2023-03-23-read-list.html",
    "href": "posts/2023-03-23-read-list.html",
    "title": "Lists to read",
    "section": "",
    "text": "0. For Research\n\n시간별 기상 변화를 고려한 LSTM 기반 일사량 예측에 관한 연구\nEMD\n\n\n\n1. GNN\n\nGraph Representation Learning Book\nscGCN is a graph convolutional networks algorithm for knowledge transfer in single cell omics\nhttps://wandb.ai/yashkotadia/gatedgcn-pattern/reportlist\nCt Image Denoising With Encoder-Decoder Based Graph Convolutional Networks\n\nhttps://paperswithcode.com/sota/point-cloud-segmentation-on-pointcloud-c\n\n\n2. RNN\n\nLearning Phrase Representations using RNN Encoder-Decoder for Statistical Machine Translation\nLight Gated Recurrent Units for Speech Recognition\n\n\n\n참고링크\n시계열 : https://machinelearningmastery.com/arima-for-time-series-forecasting-with-python/"
  },
  {
    "objectID": "posts/welcome/index.html",
    "href": "posts/welcome/index.html",
    "title": "Welcome To My Blog",
    "section": "",
    "text": "This is the first post in a Quarto blog. Welcome!\n\nSince this post doesn’t specify an explicit image, the first image in the post will be used in the listing page of posts.\n\nSave model\nmodule and package"
  },
  {
    "objectID": "posts/Study/2023-04-10-arima-ex-day.html",
    "href": "posts/Study/2023-04-10-arima-ex-day.html",
    "title": "ARIMA (Day)",
    "section": "",
    "text": "import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\n\nmpl.rc('font', family='NanumGothic')"
  },
  {
    "objectID": "posts/Study/2023-04-10-arima-ex-day.html#visualization",
    "href": "posts/Study/2023-04-10-arima-ex-day.html#visualization",
    "title": "ARIMA (Day)",
    "section": "Visualization",
    "text": "Visualization\n\n# 전체\nsns.lineplot(data=df, x='date', y='북춘천')\nplt.xticks(rotation=45)\nplt.show()\n\n\n\n\n\n# 2021-01-01 부터 한달간.\nsns.lineplot(data=df[:760], x='date', y='북춘천')\nplt.xticks(rotation=45)\nplt.show()\n\n\n\n\n\n# 최근 10일간\nsns.lineplot(data=df[df.shape[0]-250:], x='date', y='북춘천')\nplt.xticks(rotation=45)\nplt.show()"
  },
  {
    "objectID": "posts/Study/2023-04-10-arima-ex-day.html#arima",
    "href": "posts/Study/2023-04-10-arima-ex-day.html#arima",
    "title": "ARIMA (Day)",
    "section": "ARIMA",
    "text": "ARIMA\n\nimport statsmodels.tsa.api as tsa\n\n\ndf.index\n\nRangeIndex(start=0, stop=18250, step=1)\n\n\n\nfrom pylab import rcParams\n\nrcParams['figure.figsize'] = 15, 10\n\n\n## 그림그리기용\ny1 = df_time['북춘천'].resample('1D').mean()\n\n\n# 시계열 모델 생성\nmodel_series = tsa.seasonal_decompose(y1, model = 'additive')\n# 모델 시각화\nfig = model_series.plot()\nplt.show()\n\n/home/jy/anaconda3/envs/torch/lib/python3.8/site-packages/statsmodels/tsa/seasonal.py:338: UserWarning: Glyph 8722 (\\N{MINUS SIGN}) missing from current font.\n  fig.tight_layout()\n/home/jy/anaconda3/envs/torch/lib/python3.8/site-packages/IPython/core/pylabtools.py:152: UserWarning: Glyph 8722 (\\N{MINUS SIGN}) missing from current font.\n  fig.canvas.print_figure(bytes_io, **kw)\n\n\n\n\n\n\nFig1: 트렌드 O\nFig2: 계절성 O\nFig3: 잔차\n\n\ny1.shape , 365*2\n\n((730,), 730)\n\n\n\ntsa.seasonal_decompose(y1[:90], model = 'additive').plot()\nplt.show()"
  },
  {
    "objectID": "posts/Study/2023-04-10-arima-ex-day.html#에러",
    "href": "posts/Study/2023-04-10-arima-ex-day.html#에러",
    "title": "ARIMA (Day)",
    "section": "–에러",
    "text": "–에러\n/home/jy/anaconda3/envs/torch/lib/python3.8/site-packages/statsmodels/tsa/base/tsa_model.py:471: ValueWarning: A date index has been provided, but it is not monotonic and so will be ignored when e.g. forecasting.\n\nidx = len(df)*0.7\ntrain = df.loc[0:idx].set_index('date').to_period('H')\ntest = df.loc[idx:].set_index('date').to_period('H')\n\n\nimport itertools\n\n\np = d = q = range(0, 2)\npdq = list(itertools.product(p, d, q))\nseasonal_pdq = [ (x[0], x[1], x[2], 12) for x in list(itertools.product(p, d, q))] \n\n\nparam_list = []\nparam_seasonal_list = []\nresults_AIC_list = []\nresults_MSE_list = []\n\n\ny = train['북춘천']\ny.index\n\nPeriodIndex(['2021-01-01 00:00', '2021-01-01 01:00', '2021-01-01 02:00',\n             '2021-01-01 03:00', '2021-01-01 04:00', '2021-01-01 05:00',\n             '2021-01-01 06:00', '2021-01-01 07:00', '2021-01-01 08:00',\n             '2021-01-01 09:00',\n             ...\n             '2022-05-26 16:00', '2022-05-26 17:00', '2022-05-26 18:00',\n             '2022-05-26 19:00', '2022-05-26 07:00', '2022-05-26 20:00',\n             '2022-05-26 06:00', '2022-05-26 21:00', '2022-05-26 05:00',\n             '2022-05-27 00:00'],\n            dtype='period[H]', name='date', length=12776)\n\n\n\n### 에러.. (시간빠진부분 있어서 그런듯)\nfor param in pdq:\n    for param_seasonal in seasonal_pdq:\n        try:\n            mod = tsa.statespace.SARIMAX(y, order=param,\n                                            seasonal_order=param_seasonal,\n                                            enforce_stationarity=False,\n                                            enforce_invertibility=False)\n            results = mod.fit()\n            param_list.append(param)\n            param_seasonal_list.append(param_seasonal)\n            results_AIC_list.append(results.aic)\n            results_MSE_list.append(results.mse)\n        except:\n            continue\n\n\nprint(len(param_list), len(param_seasonal_list), len(results_AIC_list))\n\n64 64 64\n\n\n\nARIMA_list = pd.DataFrame({'Parameter':param_list, 'Seasonal':param_seasonal_list, 'AIC':results_AIC_list})\n\n\nARIMA_list.sort_values(by='AIC')\n\n\n\n\n\n  \n    \n      \n      Parameter\n      Seasonal\n      AIC\n    \n  \n  \n    \n      56\n      (1, 1, 1)\n      (0, 0, 0, 12)\n      -27.919333\n    \n    \n      57\n      (1, 1, 1)\n      (0, 0, 1, 12)\n      -17.887908\n    \n    \n      60\n      (1, 1, 1)\n      (1, 0, 0, 12)\n      -17.191112\n    \n    \n      61\n      (1, 1, 1)\n      (1, 0, 1, 12)\n      -16.236937\n    \n    \n      24\n      (0, 1, 1)\n      (0, 0, 0, 12)\n      2.108300\n    \n    \n      ...\n      ...\n      ...\n      ...\n    \n    \n      50\n      (1, 1, 0)\n      (0, 1, 0, 12)\n      729.258196\n    \n    \n      18\n      (0, 1, 0)\n      (0, 1, 0, 12)\n      819.565003\n    \n    \n      8\n      (0, 0, 1)\n      (0, 0, 0, 12)\n      930.795162\n    \n    \n      1\n      (0, 0, 0)\n      (0, 0, 1, 12)\n      1035.717831\n    \n    \n      0\n      (0, 0, 0)\n      (0, 0, 0, 12)\n      1470.861058\n    \n  \n\n64 rows × 3 columns\n\n\n\n\nmod = tsa.statespace.SARIMAX(y1, order=(1,1,1),\n                                            seasonal_order=(0,0,0,12),\n                                            enforce_stationarity=False,\n                                            enforce_invertibility=False)\n\nresults = mod.fit()\nprint(results.summary().tables[1])\n\n==============================================================================\n                 coef    std err          z      P>|z|      [0.025      0.975]\n------------------------------------------------------------------------------\nar.L1          0.2286      0.035      6.544      0.000       0.160       0.297\nma.L1         -1.0822      0.017    -64.958      0.000      -1.115      -1.050\nsigma2         0.0476      0.003     18.244      0.000       0.043       0.053\n==============================================================================\n\n\n\nprint(results.summary())\n\n                               SARIMAX Results                                \n==============================================================================\nDep. Variable:                    북춘천   No. Observations:                  730\nModel:               SARIMAX(1, 1, 1)   Log Likelihood                  16.960\nDate:                Mon, 10 Apr 2023   AIC                            -27.919\nTime:                        17:29:21   BIC                            -14.153\nSample:                    01-01-2021   HQIC                           -22.607\n                         - 12-31-2022                                         \nCovariance Type:                  opg                                         \n==============================================================================\n                 coef    std err          z      P>|z|      [0.025      0.975]\n------------------------------------------------------------------------------\nar.L1          0.2286      0.035      6.544      0.000       0.160       0.297\nma.L1         -1.0822      0.017    -64.958      0.000      -1.115      -1.050\nsigma2         0.0476      0.003     18.244      0.000       0.043       0.053\n===================================================================================\nLjung-Box (L1) (Q):                   0.40   Jarque-Bera (JB):                41.71\nProb(Q):                              0.53   Prob(JB):                         0.00\nHeteroskedasticity (H):               0.90   Skew:                            -0.58\nProb(H) (two-sided):                  0.43   Kurtosis:                         3.20\n===================================================================================\n\nWarnings:\n[1] Covariance matrix calculated using the outer product of gradients (complex-step)."
  },
  {
    "objectID": "posts/Study/2023-04-10-arima-ex-day.html#section",
    "href": "posts/Study/2023-04-10-arima-ex-day.html#section",
    "title": "ARIMA (Day)",
    "section": "–",
    "text": "–\n\n## MSE\ndef mse_(real, pred):\n    diff = real - pred\n    return mean(diff^2)\n\n\n## fitting\n\n\nfrom sklearn.metrics import mean_squared_error as MSE\n\n\npred_y = results.predict(start = '2022-05-27 00:00:00', end='2022-12-31 05:00:00')\n\n\npred_y\n\n2022-05-27    0.960337\n2022-05-28    0.882472\n2022-05-29    0.982962\n2022-05-30    0.985353\n2022-05-31    0.756740\n                ...   \n2022-12-28    0.337356\n2022-12-29    0.383494\n2022-12-30    0.388694\n2022-12-31    0.375957\n2023-01-01    0.356190\nFreq: D, Name: predicted_mean, Length: 220, dtype: float64\n\n\n\nref: How to interpret Negative AIC Vluaes"
  },
  {
    "objectID": "posts/Study/2023-04-10-arima-ex.html",
    "href": "posts/Study/2023-04-10-arima-ex.html",
    "title": "ARIMA (시간별 예측안됨, 에러)",
    "section": "",
    "text": "import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\n\nmpl.rc('font', family='NanumGothic')"
  },
  {
    "objectID": "posts/Study/2023-04-10-arima-ex.html#arima",
    "href": "posts/Study/2023-04-10-arima-ex.html#arima",
    "title": "ARIMA (시간별 예측안됨, 에러)",
    "section": "ARIMA",
    "text": "ARIMA\n\nimport statsmodels.tsa.api as tsa\n\n\ndf.index\n\nRangeIndex(start=0, stop=18250, step=1)\n\n\n\nfrom pylab import rcParams\n\nrcParams['figure.figsize'] = 15, 10\n\n\n## 그림 그리기용\ny1 = df_time['북춘천'].resample('1D').mean()\n\n\n# 시계열 모델 생성\nmodel_series = tsa.seasonal_decompose(y1, model = 'additive')\n# 모델 시각화\nfig = model_series.plot()\nplt.show()\n\n/home/jy/anaconda3/envs/torch/lib/python3.8/site-packages/statsmodels/tsa/seasonal.py:338: UserWarning: Glyph 8722 (\\N{MINUS SIGN}) missing from current font.\n  fig.tight_layout()\n/home/jy/anaconda3/envs/torch/lib/python3.8/site-packages/IPython/core/pylabtools.py:152: UserWarning: Glyph 8722 (\\N{MINUS SIGN}) missing from current font.\n  fig.canvas.print_figure(bytes_io, **kw)\n\n\n\n\n\n\nFig1: 트렌드 O\nFig2: 계절성 O\nFig3: 잔차\n\n\ny1.shape , 365*2\n\n((730,), 730)\n\n\n\ntsa.seasonal_decompose(y1[:90], model = 'additive').plot()\nplt.show()"
  },
  {
    "objectID": "posts/Study/2023-04-10-arima-ex.html#에러",
    "href": "posts/Study/2023-04-10-arima-ex.html#에러",
    "title": "ARIMA (시간별 예측안됨, 에러)",
    "section": "–에러",
    "text": "–에러\n/home/jy/anaconda3/envs/torch/lib/python3.8/site-packages/statsmodels/tsa/base/tsa_model.py:471: ValueWarning: A date index has been provided, but it is not monotonic and so will be ignored when e.g. forecasting.\n\nidx = len(df)*0.7\ntrain = df.loc[0:idx].set_index('date').to_period('H')\ntest = df.loc[idx:].set_index('date').to_period('H')\n\n\ntrain.index()\n\nPeriodIndex(['2021-01-01 00:00', '2021-01-01 01:00', '2021-01-01 02:00',\n             '2021-01-01 03:00', '2021-01-01 04:00', '2021-01-01 05:00',\n             '2021-01-01 06:00', '2021-01-01 07:00', '2021-01-01 08:00',\n             '2021-01-01 09:00',\n             ...\n             '2022-05-26 16:00', '2022-05-26 17:00', '2022-05-26 18:00',\n             '2022-05-26 19:00', '2022-05-26 07:00', '2022-05-26 20:00',\n             '2022-05-26 06:00', '2022-05-26 21:00', '2022-05-26 05:00',\n             '2022-05-27 00:00'],\n            dtype='period[H]', name='date', length=12776)\n\n\n\nimport itertools\n\n\np = d = q = range(0, 2)\npdq = list(itertools.product(p, d, q))\nseasonal_pdq = [ (x[0], x[1], x[2], 12) for x in list(itertools.product(p, d, q))] \n\n\nparam_list = []\nparam_seasonal_list = []\nresults_AIC_list = []\nresults_MSE_list = []\n\n\ny = train['북춘천']\ny.index\n\nPeriodIndex(['2021-01-01 00:00', '2021-01-01 01:00', '2021-01-01 02:00',\n             '2021-01-01 03:00', '2021-01-01 04:00', '2021-01-01 05:00',\n             '2021-01-01 06:00', '2021-01-01 07:00', '2021-01-01 08:00',\n             '2021-01-01 09:00',\n             ...\n             '2022-05-26 16:00', '2022-05-26 17:00', '2022-05-26 18:00',\n             '2022-05-26 19:00', '2022-05-26 07:00', '2022-05-26 20:00',\n             '2022-05-26 06:00', '2022-05-26 21:00', '2022-05-26 05:00',\n             '2022-05-27 00:00'],\n            dtype='period[H]', name='date', length=12776)\n\n\n\n### 에러.. (시간빠진부분 있어서 그런듯)\nfor param in pdq:\n    for param_seasonal in seasonal_pdq:\n        try:\n            mod = tsa.statespace.SARIMAX(y, order=param,\n                                            seasonal_order=param_seasonal,\n                                            enforce_stationarity=False,\n                                            enforce_invertibility=False)\n            results = mod.fit()\n            param_list.append(param)\n            param_seasonal_list.append(param_seasonal)\n            results_AIC_list.append(results.aic)\n            results_MSE_list.append(results.mse)\n        except:\n            continue\n\n\nprint(len(param_list), len(param_seasonal_list), len(results_AIC_list))\n\n64 64 64\n\n\n\nARIMA_list = pd.DataFrame({'Parameter':param_list, 'Seasonal':param_seasonal_list, 'AIC':results_AIC_list})\n\n\nARIMA_list.sort_values(by='AIC')\n\n\n\n\n\n  \n    \n      \n      Parameter\n      Seasonal\n      AIC\n    \n  \n  \n    \n      56\n      (1, 1, 1)\n      (0, 0, 0, 12)\n      -27.919333\n    \n    \n      57\n      (1, 1, 1)\n      (0, 0, 1, 12)\n      -17.887908\n    \n    \n      60\n      (1, 1, 1)\n      (1, 0, 0, 12)\n      -17.191112\n    \n    \n      61\n      (1, 1, 1)\n      (1, 0, 1, 12)\n      -16.236937\n    \n    \n      24\n      (0, 1, 1)\n      (0, 0, 0, 12)\n      2.108300\n    \n    \n      ...\n      ...\n      ...\n      ...\n    \n    \n      50\n      (1, 1, 0)\n      (0, 1, 0, 12)\n      729.258196\n    \n    \n      18\n      (0, 1, 0)\n      (0, 1, 0, 12)\n      819.565003\n    \n    \n      8\n      (0, 0, 1)\n      (0, 0, 0, 12)\n      930.795162\n    \n    \n      1\n      (0, 0, 0)\n      (0, 0, 1, 12)\n      1035.717831\n    \n    \n      0\n      (0, 0, 0)\n      (0, 0, 0, 12)\n      1470.861058\n    \n  \n\n64 rows × 3 columns\n\n\n\n\nmod = tsa.statespace.SARIMAX(y1, order=(1,1,1),\n                                            seasonal_order=(0,0,0,12),\n                                            enforce_stationarity=False,\n                                            enforce_invertibility=False)\n\nresults = mod.fit()\nprint(results.summary().tables[1])\n\n==============================================================================\n                 coef    std err          z      P>|z|      [0.025      0.975]\n------------------------------------------------------------------------------\nar.L1          0.2286      0.035      6.544      0.000       0.160       0.297\nma.L1         -1.0822      0.017    -64.958      0.000      -1.115      -1.050\nsigma2         0.0476      0.003     18.244      0.000       0.043       0.053\n==============================================================================\n\n\n\nprint(results.summary())\n\n                               SARIMAX Results                                \n==============================================================================\nDep. Variable:                    북춘천   No. Observations:                  730\nModel:               SARIMAX(1, 1, 1)   Log Likelihood                  16.960\nDate:                Mon, 10 Apr 2023   AIC                            -27.919\nTime:                        17:29:21   BIC                            -14.153\nSample:                    01-01-2021   HQIC                           -22.607\n                         - 12-31-2022                                         \nCovariance Type:                  opg                                         \n==============================================================================\n                 coef    std err          z      P>|z|      [0.025      0.975]\n------------------------------------------------------------------------------\nar.L1          0.2286      0.035      6.544      0.000       0.160       0.297\nma.L1         -1.0822      0.017    -64.958      0.000      -1.115      -1.050\nsigma2         0.0476      0.003     18.244      0.000       0.043       0.053\n===================================================================================\nLjung-Box (L1) (Q):                   0.40   Jarque-Bera (JB):                41.71\nProb(Q):                              0.53   Prob(JB):                         0.00\nHeteroskedasticity (H):               0.90   Skew:                            -0.58\nProb(H) (two-sided):                  0.43   Kurtosis:                         3.20\n===================================================================================\n\nWarnings:\n[1] Covariance matrix calculated using the outer product of gradients (complex-step)."
  },
  {
    "objectID": "posts/Study/2023-04-10-arima-ex.html#section",
    "href": "posts/Study/2023-04-10-arima-ex.html#section",
    "title": "ARIMA (시간별 예측안됨, 에러)",
    "section": "–",
    "text": "–\n\n## MSE\ndef mse_(real, pred):\n    diff = real - pred\n    return mean(diff^2)\n\n\n## fitting\n\n\nfrom sklearn.metrics import mean_squared_error as MSE\n\n\npred_y = results.predict(start = '2022-05-27 00:00:00', end='2022-12-31 05:00:00')\n\n\npred_y\n\n2022-05-27    0.960337\n2022-05-28    0.882472\n2022-05-29    0.982962\n2022-05-30    0.985353\n2022-05-31    0.756740\n                ...   \n2022-12-28    0.337356\n2022-12-29    0.383494\n2022-12-30    0.388694\n2022-12-31    0.375957\n2023-01-01    0.356190\nFreq: D, Name: predicted_mean, Length: 220, dtype: float64\n\n\n\nref: How to interpret Negative AIC Vluaes"
  },
  {
    "objectID": "posts/Study/2023-04-13-windmill-스몰버전.html",
    "href": "posts/Study/2023-04-13-windmill-스몰버전.html",
    "title": "WindmillOutput (Small)",
    "section": "",
    "text": "ref: https://pytorch-geometric.readthedocs.io/en/latest/notes/introduction.html#\nref: <>\n\nHourly energy output of windmills from a European country for more than 2 years. Vertices represent 11 windmills and weighted edges describe the strength of relationships. The target variable allows for regression tasks.\n\nimport torch\nfrom torch_geometric_temporal.dataset import WindmillOutputSmallDatasetLoader\n\n\nloader =  WindmillOutputSmallDatasetLoader()\ndataset = loader.get_dataset()\n\n\ndataset.edge_index.shape\n\n(2, 121)"
  },
  {
    "objectID": "posts/Study/python-midterm.html",
    "href": "posts/Study/python-midterm.html",
    "title": "noteda",
    "section": "",
    "text": "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport yfinance as yf\n\n\ndf=pd.read_csv('https://raw.githubusercontent.com/guebin/DV2022/master/posts/FIFA23_official_data.csv').drop(columns=['Loaned From', 'Best Overall Rating']).dropna().reset_index(drop=True)\ndf.head()\n\n\n\n\n\n  \n    \n      \n      ID\n      Name\n      Age\n      Photo\n      Nationality\n      Flag\n      Overall\n      Potential\n      Club\n      Club Logo\n      ...\n      Work Rate\n      Body Type\n      Real Face\n      Position\n      Joined\n      Contract Valid Until\n      Height\n      Weight\n      Release Clause\n      Kit Number\n    \n  \n  \n    \n      0\n      209658\n      L. Goretzka\n      27\n      https://cdn.sofifa.net/players/209/658/23_60.png\n      Germany\n      https://cdn.sofifa.net/flags/de.png\n      87\n      88\n      FC Bayern München\n      https://cdn.sofifa.net/teams/21/30.png\n      ...\n      High/ Medium\n      Unique\n      Yes\n      <span class=\"pos pos28\">SUB\n      Jul 1, 2018\n      2026\n      189cm\n      82kg\n      €157M\n      8.0\n    \n    \n      1\n      212198\n      Bruno Fernandes\n      27\n      https://cdn.sofifa.net/players/212/198/23_60.png\n      Portugal\n      https://cdn.sofifa.net/flags/pt.png\n      86\n      87\n      Manchester United\n      https://cdn.sofifa.net/teams/11/30.png\n      ...\n      High/ High\n      Unique\n      Yes\n      <span class=\"pos pos15\">LCM\n      Jan 30, 2020\n      2026\n      179cm\n      69kg\n      €155M\n      8.0\n    \n    \n      2\n      224334\n      M. Acuña\n      30\n      https://cdn.sofifa.net/players/224/334/23_60.png\n      Argentina\n      https://cdn.sofifa.net/flags/ar.png\n      85\n      85\n      Sevilla FC\n      https://cdn.sofifa.net/teams/481/30.png\n      ...\n      High/ High\n      Stocky (170-185)\n      No\n      <span class=\"pos pos7\">LB\n      Sep 14, 2020\n      2024\n      172cm\n      69kg\n      €97.7M\n      19.0\n    \n    \n      3\n      192985\n      K. De Bruyne\n      31\n      https://cdn.sofifa.net/players/192/985/23_60.png\n      Belgium\n      https://cdn.sofifa.net/flags/be.png\n      91\n      91\n      Manchester City\n      https://cdn.sofifa.net/teams/10/30.png\n      ...\n      High/ High\n      Unique\n      Yes\n      <span class=\"pos pos13\">RCM\n      Aug 30, 2015\n      2025\n      181cm\n      70kg\n      €198.9M\n      17.0\n    \n    \n      4\n      224232\n      N. Barella\n      25\n      https://cdn.sofifa.net/players/224/232/23_60.png\n      Italy\n      https://cdn.sofifa.net/flags/it.png\n      86\n      89\n      Inter\n      https://cdn.sofifa.net/teams/44/30.png\n      ...\n      High/ High\n      Normal (170-)\n      Yes\n      <span class=\"pos pos13\">RCM\n      Sep 1, 2020\n      2026\n      172cm\n      68kg\n      €154.4M\n      23.0\n    \n  \n\n5 rows × 27 columns\n\n\n\n\ndf.columns\n\nIndex(['ID', 'Name', 'Age', 'Photo', 'Nationality', 'Flag', 'Overall',\n       'Potential', 'Club', 'Club Logo', 'Value', 'Wage', 'Special',\n       'Preferred Foot', 'International Reputation', 'Weak Foot',\n       'Skill Moves', 'Work Rate', 'Body Type', 'Real Face', 'Position',\n       'Joined', 'Contract Valid Until', 'Height', 'Weight', 'Release Clause',\n       'Kit Number'],\n      dtype='object')\n\n\n\nlen(df.columns)\n\n27\n\n\n\na = 0\nfor i in df.columns:\n    a += ' ' in i\nprint(a)\n\n11"
  },
  {
    "objectID": "posts/Study/2023-04-10-ex.html",
    "href": "posts/Study/2023-04-10-ex.html",
    "title": "연습장",
    "section": "",
    "text": "Data"
  },
  {
    "objectID": "posts/Study/2023-04-10-ex.html#import",
    "href": "posts/Study/2023-04-10-ex.html#import",
    "title": "연습장",
    "section": "import",
    "text": "import\n\nimport os\nimport time\nimport gc\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import TensorDataset, DataLoader\nfrom torch.autograd import Variable\nfrom tqdm import tqdm_notebook\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler\nfrom sklearn.model_selection import train_test_split  \n\ndevice = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n\n\ndevice\n\ndevice(type='cuda', index=0)\n\n\n\nurl = 'https://raw.githubusercontent.com/pinkocto/noteda/main/posts/SOLAR/data/df_new.csv'\ndata = pd.read_csv(url)\n\n\nprint(data.dtypes)\n\ndate     object\n북춘천     float64\n철원      float64\n대관령     float64\n춘천      float64\n백령도     float64\n북강릉     float64\n강릉      float64\n서울      float64\n인천      float64\n원주      float64\n울릉도     float64\n수원      float64\n서산      float64\n청주      float64\n대전      float64\n추풍령     float64\n안동      float64\n포항      float64\n대구      float64\n전주      float64\n창원      float64\n광주      float64\n부산      float64\n목포      float64\n여수      float64\n흑산도     float64\n고창      float64\n홍성      float64\n제주      float64\n고산      float64\n진주      float64\n고창군     float64\n영광군     float64\n김해시     float64\n순창군     float64\n북창원     float64\n양산시     float64\n보성군     float64\n강진군     float64\n의령군     float64\n함양군     float64\n광양시     float64\n청송군     float64\n경주시     float64\ndtype: object\n\n\n\ndata['date'] = pd.to_datetime(data['date'])\ndata.set_index('date', inplace=True)\n\n\ndata.columns\n\nIndex(['북춘천', '철원', '대관령', '춘천', '백령도', '북강릉', '강릉', '서울', '인천', '원주', '울릉도',\n       '수원', '서산', '청주', '대전', '추풍령', '안동', '포항', '대구', '전주', '창원', '광주', '부산',\n       '목포', '여수', '흑산도', '고창', '홍성', '제주', '고산', '진주', '고창군', '영광군', '김해시',\n       '순창군', '북창원', '양산시', '보성군', '강진군', '의령군', '함양군', '광양시', '청송군', '경주시'],\n      dtype='object')\n\n\n\nX=data.iloc[:,:-1] # 마지막 칼럼을 제외한 모든 컬럼\ny=data.iloc[:,5:6] # 마지막 Volumn을 레이블로 사용\nprint(X)\nprint(y)\n\n<Axes: >"
  },
  {
    "objectID": "posts/Study/2023-05-07-stgcn논문리뷰.html",
    "href": "posts/Study/2023-05-07-stgcn논문리뷰.html",
    "title": "[PAPER] Spatio-Temporal Graph Convolutional Networks (+++)",
    "section": "",
    "text": "arxiv"
  },
  {
    "objectID": "posts/Study/2023-05-07-stgcn논문리뷰.html#introduction",
    "href": "posts/Study/2023-05-07-stgcn논문리뷰.html#introduction",
    "title": "[PAPER] Spatio-Temporal Graph Convolutional Networks (+++)",
    "section": "Introduction",
    "text": "Introduction\n\n교통예측은 현재 상황을 모니터링 하는 task이며, 속도, 차량의양, 밀도 등을 지표로 활용\n단기예측 뿐만 아니라 장기예측도 중요한 task.\n물리적 동적모델링: 시뮬레이션을 통한 예측은 교통모델을 공식화하여 계산하나 비용적 측면과 정교하지 못한 문제를 야기함.\n데이터 기반접근: ARIMA, SVM과 같은 기존 접근 방법론들은 장기예측에 약점을 보임.\n교통예측 Task: 주요 교통 지점에서의 traffic flow/speed와 같은 정량적 지표를 예측하는 것\n특징1: 도로 교통망의 수집되는 지점은 각 지점마다 공간적 특징을 기반으로 상호관련성이 존재함. (예: 어떤 도로에서의 교통량증가/정체는 특정 도로지점에 더 영향력을 많이 줄 수 있음.)\n특징2: 해당 task 자체가 미래를 예측하는 시간적 정보를 기반으로 진행됨. (예: 30분전의 정보를 바탕으로 미래의 10분 교통량을 예측함)\n이전연구의 한계점: 시공간적 특징을 동시에 반영하는 모델구조가 필요함.\n시간적 특징만 반영하는 모델의 한계: LSTM에 각 수집지점의 정보를 Flatten하게 input으로 사용 \\(\\to\\) 공간적 상관성 무시\n공간적 특징을 반영하는 모델의 한계: 2D-CNN을 이용하여 local 영역의 정보를 취합함 \\(\\to\\) 실제 연결여부의 특징을 모두 반영하지 못함.\n\n\n\n\nGraph Convolutional Network\n\n\n\n2D CNN: GRID를 통해 Locality 정보를 취함 \\(\\to\\) 거리의 정의가 단위로 설정됨.\nGCN: 거리 단위가 아닌 연결여부를 통해 정보를 취합함 \\(\\to\\) 학습과정에서 message passing flow 개념으로 정보가 전달되며, degree가 영향을 줌\n실제 도로교통망은 grid가 아닌 graph 구조로 되어있음.\n\n\n\n\nGraph Convolutional Network"
  },
  {
    "objectID": "posts/Study/2023-05-07-stgcn논문리뷰.html#dataset",
    "href": "posts/Study/2023-05-07-stgcn논문리뷰.html#dataset",
    "title": "[PAPER] Spatio-Temporal Graph Convolutional Networks (+++)",
    "section": "Dataset",
    "text": "Dataset\n\n\n\nTraffic Prediction Data"
  },
  {
    "objectID": "posts/Study/2023-05-07-stgcn논문리뷰.html#stgcn",
    "href": "posts/Study/2023-05-07-stgcn논문리뷰.html#stgcn",
    "title": "[PAPER] Spatio-Temporal Graph Convolutional Networks (+++)",
    "section": "STGCN",
    "text": "STGCN\n\nFramework\n\n\n\nFigure 2: Architecture of spatio-temporal graph convolutional networks. The framework STGCN consists of two spatio-temporal convolutional blocks (ST-Conv blocks) and a fully-connected output layer in the end. Each ST-Conv block contains two temporal gated convolution layers and one spatial graph convolution layer in the middle. The residual connection and bottleneck strategy are applied inside each block. The input \\(v_{t−M+1}, \\cdots, v_t\\) is uniformly processed by ST-Conv blocks to explore spatial and temporal dependencies coherently. Comprehensive features are integrated by an output layer to generate the final prediction \\(\\hat{v}\\).\n\n\n본 논문에서는 2개의 ST-Conv Block으로 구성되어있다. [가운데 그림] 각 ST-Conv Block은 2개의 Temporal Gated-Conv와 그 사이에 Spatial Graph-Conv을 포함하고 있다. 여기서 Spatial Graph-Conv는 GCN1이고, [오른쪽 그림] Temporal Gated-Conv는 오른쪽 그림과 같음.\n\n\nFramework: Temporal Gated-Conv\n\n\n\nFramework: Temporal Feature Extract1\n\n\n\n\n\nFramework: Temporal Feature Extract2\n\n\n\n\n\nFramework: Temporal Feature Extract3\n\n\n\n\n\nFramework: Temporal Feature Extract4\n\n\n\n\n\nFramework: Temporal Feature Extract5\n\n\n\n\nFramework: Ouput layer\n\n\n\nFramwork: Output layer"
  },
  {
    "objectID": "posts/Study/2023-05-07-stgcn논문리뷰.html#experiments-and-dataset-description",
    "href": "posts/Study/2023-05-07-stgcn논문리뷰.html#experiments-and-dataset-description",
    "title": "[PAPER] Spatio-Temporal Graph Convolutional Networks (+++)",
    "section": "Experiments and Dataset Description",
    "text": "Experiments and Dataset Description\n\n\n\nimage.png\n\n\n\n각 지점의 센서에서의 교통량\n해당 지점간의 인접 weight 정보: weight는 실제 거리를 반영하여 생성\\(\\to\\) 즉, 일정거리 이상이면 edge 생성X\nTime 정보는 5분단위로 갱신: 하루기준 288(12*24) data 생성\n\n원래 인접행렬은 1 혹은 0으로 구성되어 있는데 거리 기반으로 weight를 다시 줌. 거리가 가까울 수록 weight을 더 주고, 멀수록 작은 weight. 많이 멀어질수록 값을 아예 \\(0\\)으로 바꿔 weight을 주는 adjacency matrix를 생성.\n\n\n데이터 갱신은 5분마다 이루어지기 때문에 하루에 12*24=288개의 row가 생성되는 데이터셋으로 진행함.\n총 60분을 통해 다음 15분/30분/45분 후의 지점을 개별적으로 예측하도록 함. (세가지를 따로 따로 예측)\n\n\n\n\nTable1: Performance Comparison of diffent approaches on the dataset BJER4.\n\n\n\nSTGGCN을 사용한 마지막 두 모델이 우리가 알고있는 locality에 대한 edge가 실제 그래프의 지도와 유사한 방법론이기 때문에 locality가 더 정확하다. 연결성에 대한 정보가 geometric하게 일치한다는 것을 직관적으로 알 수 있다.\n\n\n모델 비교\n\n\n\nFigure 5:\n\n\n\nSTGCN: Cheb conv 기반으로 layer를 구성함. (kernel:3) – \\(k-1\\) approximation\nSTGCN(\\(1^{st}\\)): Cheb conv kernel 1\nGCGRU: GCN + GRU 순차적으로 학습하는 구조 (GCN을 통해 결과값을 뽑아둔 후 나온 값들을 다시한번 GRU에 태워서 순차적으로 뽑아내 output을 만들어냄(Conv-LSTM과 비슷)\nRush Hour 구간을 제안한 방법론이 GRU를 사용하는 것보다 더 대응을 잘함.\nGRU를 사용하는 방법론은 특성상 학습 및 추론에 시간이 더 오래걸림.\n\nGRU 특성상 정보를 순차적으로 받아오기 때문에 정보가 변하는 것을 캐치하는 것이 조금 느리다."
  },
  {
    "objectID": "posts/Study/2023-02-21-gcn-이해용정리.html",
    "href": "posts/Study/2023-02-21-gcn-이해용정리.html",
    "title": "Graph Convolutional Network (이해용)",
    "section": "",
    "text": "Many important real-world datasets come in the form of graphs or networks: social networks, knowledge graphs, protein-interaction networks, the World Wide Web, etc. (just to name a few).\n\n대부분의 머신러닝 알고리즘은 입력 데이터가 유클리디안 공간 (Euclidean space)에 존재함을 가정하고 있다. 즉, 통계 데이터나 이미지처럼 입력 데이터가 벡터의 형태로 표현될 수 있어야 한다. 그러나 소셜 네트워크, 관계형 데이터베이스, 분자 구조 등과 같이 객체들과 그 객체들 간의 관계로 표현되는 데이터는 기본적으로 위와 같은 그래프로 표현된다.\n또한, 만약 사용자나 원자의 속성, 연결의 종류 등을 고려해야하는 경우에는 단순히 node와 edge로 이루어진 그래프가 아니라, node feature matrix와 edge feature matrix가 추가된 속성 그래프 (attributed graph)로 데이터를 표현해야 한다. 이러한 형태의 그래프 데이터는 유클리드 공간에 존재하지 않으며, 직접적인 방식으로 벡터의 형태로 변환하는 것 또한 불가능하다. 따라서, 벡터 형태의 입력 데이터를 가정하는 기존의 인공신경망 (Artificial Neural Network, ANN)으로는 분자 구조와 같은 그래프 형태의 데이터를 처리할 수 없다는 문제점이 존재한다.\n(+) 행동 인식 분야에서 가장 핫하게 등장하는 네트워크가 바로 GCN(Graph Convolutional Networks)이다. GCN은 쉽게 설명하자면, 어떤 그래프 구조를 이미지 convolution과 유사한 방식으로 연산해서 특징점을 추출하는 네트워크라고 보면 될 것 같다. 사람의 몸도 어떻게 보면 각 관절과 그 관절들이 연결되어있는 구조로 그래프 구조라고 볼 수 있다. 그렇기 때문에 GCN을 사용한 논문들에서도 좋은 성능을 보이고 있다.\n\nref: (AAAI-2018) Spatial Temporal Graph Convolutional Networks for Skeleton-Based Action Recognition\n\n\n\n\n\n\nGraph는 vertex(node)와 edge로 이루어져있다. 이 때 node는 한 input data를 의미하고 edge는 두 데이터 간의 relationship을 의미한다. (어차피 같은 의미이지만 앞으로는 vertex 대신 node라는 표현을 많이 사용할 것이다.)\n\n소셜 그래프에서 node는 사람, edge는 두 사람 사이의 관계를 의미한다.\nWeighted Grapgh vs. Unweighted Graph\nDirected Graph vs. Undirected Graph\n(참고) 위의 그래프의 경우 방향성이 존재하지 않는 undirected Graph이다.\n\n\n\n\n모든 노드간의 relationship 정보를 담고있도록 data를 표현해야하므로 이 정보들은 1. Adgacency matrix로 나타낼 수 있다. 또한 노드간의 relationship정보 말고도 node 자체가 가지고 있는 feature 정보가 있으므로 이는 2. Feature matrix로 나타낸다.\n\n1 Network(Graph data) \\(\\to\\) Adjacency matrix\n\n\\(n\\) 개의 노드가 있다면 Adjacency matrix는 \\(n\\times n\\) 크기를 갖게 된다.\n\n5개의 노드가 있으므로 \\(5\\times 5\\) Adjacency matrix\n\n\\(\\bf{A}_{ij}\\) : Adjacency matrix의 \\(i\\)번째 row와 \\(j\\)번째 컬럼에 있는 값을 나타내며, \\(i\\)번째 노드와 \\(j\\)번째 노드가 서로 연결이 되어 있는지를 나타낸다.\n\n노드 사이에 엣지가 있는지? (있으면 \\(1\\), 없으면 \\(0\\))\n\n\n2 Feature matrix\n\nFeature matirx로 각 노드의 정보를 나타낸다.\n\nFeature matrix의 크기는 \\(n(\\text{노드의 수}) \\times f(\\text{feature 개수})\\) 이며, \\(f\\)는 설정함에 따라서 많아질 수도 있고 적어질 수도 있는 값이다.\nfeature matrix를 \\(\\bf{X}\\) 라고 하자, 이 때 \\(\\bf{X}_{ij}\\) 가 의미하는 것은 i번째 노드에 j번째 feature가 무엇인지 나타내는 것이다.\n\n\n\n\n\n\n\n데이터의 구조를 고려해야 한다는 점은 이미지뿐만 아니라 그래프 데이터에서도 매우 중요하기 때문에 이미지에 대한 convolution을 일반화하여 그래프 데이터에 적용하기 위한 연구가 머신러닝 분야에서 활발히 진행되었다. 그래프 합성곱 신경망 (Graph Convolutional Network, GCN)은 이미지에 대한 convolution을 그래프 데이터로 확장한 머신러닝 알고리즘이다.\n이부분에 대해 이해를 하려면 먼저 CNN에 이해가 필요할 것 같다.\n\n\n\n\n\nStanford, cs231n 2017\n\n\n\n\n\nReduce the number of parameters \\(\\to\\) less overfitting, low computational cost\nLearn local features\nTranslation invariance\n\n\n\n\n\n어쨌든 얘도 convolutional network니까 CNN을 보고 이것을 이미지가 아닌 그래프에 적용시켜본다면 구조를 어떻게 바꿔야 할지지 생각해보자.\n\nCNN updates values in activation map in each layer. Values of activation map determine the state of image.\nValues of each node feature determine the state of graph. \\(\\to\\) Make each layer of network update values of each node feature\n\n그래프의 정보를 결정하는 것은 무엇일까? 이미지는 activation map에 있는 value들이 그 이미지에 담긴 상태가 뭔지, 이미지에 담긴 정보가 뭔지를 결정을 하는 값들이었는데 그래프 같은 경우에는 각 노드에 담긴 value 즉, node feature matrix 안에 담긴 정보가 업데이트 되도록 하면 되겠다.\n결국 중요한 것은 Graph Convolutional Layer를 거치게 되면 노드 피처에 담긴 값이 업데이트가 되어야 한다는 것을 convolutional network를 통해 알 수 있었다.\n그렇다면 어떤 방식으로 업데이트를 해야 타당할까?\n어쨌든 이것도 컨볼루션이니까 컨볼루션은 어떤 작은 웨이트를 쭉 이동시키는 연산이었는데 중요한 특성은 Weight sharing을 한다는 것이었고, 어떤 로컬한 이 값 근처에 있는 값들만 weight에 들어가서 로컬한 피처를 배운다는 것이 또 하나의 특징이었다. 그래서 그 뉴런이 receptive field를 갖게 된다. (어떤 전체의 데이터에 정보를 하나의 뉴런이 다 받는게 아니라 어떤 로컬한 부분에 있는 정보를 이제 뉴런이 받게 되고 이를 receptive field 라고 한다.)\n그런 특성을 그럼 그래프에는 어떻게 적용시켜야 될까? 노드의 피처를 계속 업데이트 한다는 것은 각 노드의 정보를 업데이트 하는 것 그래서 노드 피처 매트릭스를 다시 그려보면 \\(n\\)개의 노드가 있는 그래프일 때 \\(n\\times f\\text{(feature 개수)}\\)의 shape을 갖고 이 matrix의 i번째 row가 의미하는 것은 i번째 노드의 피처/상태/정보를 담고있다고 앞에서 배웠다.\n아까 말했듯이 layer를 하나 거쳐서 이 node feature matrix를 업데이트 한다는 것은 이 각각의 row를 즉, 각각의 노드의 정보를 업데이트 해주면 될 것 같다.\n그럼 어떤 방식으로 업데이트를 할 거냐? convolution network 같이 그 주변에 있는 애들의 정보만 받아서 업데이트를 하자 이런식으로 생각해 볼 수 있을 것 같다.\n\n\n\n\n\n\nimage.png\n\n\n\\[H_1^{(l+1)} = \\sigma(H_1^{(l)}W^{(l)} + H_2^{(l)}W^{(l)} + H_3^{(l)}W^{(l)} + H_4^{(l)}W^{(l)} + b^{(l)})\\]\n\\[\\Rightarrow H_i^{(l+1)} = \\sigma\\Big(\\sum_{j\\in N(i)} H_j^{(l)}W^{(l)} + b^{(l)} \\Big)\\]\n\\[W: \\text{weight},\\quad W^{(l)}: l\\text{번째 layer의 weight},\\quad H:\\text{hidden state}, \\quad \\sigma: \\text{activation function}\\]\n(참고) 여기서는 node feature matrix를 hidden state라고 부를 것임\n위의 그림과 같은 그래프가 있다고 가정해보자. 그래프의 번호가 1번, 2번, 3번, 4번 이런식으로 붙여졌다고 할 때 \\(H_1^{(l+1)}\\), 즉 하나의 \\((l+1)\\)번 째 layer를 통과하게 되면 \\(H_1\\)의 정보는 자기 자신의 웨이트를 더하고, 그 다음에 연결되어 있는 \\(H_2\\)의 hidden state에 weight를 곱하고, \\(H_3\\)의 hidden state에 weight를 곱하고 \\(H_4\\)의 hidden state에 weight를 곱하고 bias를 더해서 activation을 거쳐서 다음 layer의 값을 업데이트 하면 되겠다.\n이렇게 되면 이제 convolutional layer처럼 어떤 local한 feature를 뽑아낼 수 있고, 그럼 이 다음 노드가 받은 것은 1번, 2번, 3번, 4번 노드의 정보만 받아서 다음 뉴런에 전달을 해주는 것이고, 연결되지 않은 5번, 6번, 7번에 대해서는 들어가지 않았으니까 1번 노드의 정보는 1번 노드의 근처에 있는 로컬한 정보를 뽑아냈다라고 볼 수 있다.\n또한 이 weight가 다 똑같기 때문에 weight sharing을 한다. 즉, 전체가 다 연결되어 있는게 아니라 어쨌든 얘도 어떤 노드의 정보는 그 구조가 다 비슷할 것이다. 왜냐하면 처음에 같은 이 feature의 순서가 똑같았으니까 거기에 어차피 애들도 다 비슷한 애들이니까 같은 weight를 곱해서 general한 정보를 뽑아낼 수 있게 마치 LSTM에서 각각의 워드에 다 똑같은 weight를 곱해줬던 것 처럼(왜냐하면 이 word는 다 비슷한 특성을 가지고 있기 때문에) 얘들도 각각의 노드 피처가 비슷한 성격을 띄고 있을 거니까 같은 weight를 sharing해서 곱해줘서 computational cost도 낮추고 efficiency도 높일 수 있겠다.\n그래서 이런식으로 업데이트 하면 아까 convolutional layer의 두 가지 특성이였던 weight sharing과 local feature를 뽑아낸다는 것 둘 다 가지고 있게 됐다.\n실질적으로 구현할 때 1번 노드에 연결되었는지 다 보고, 1번노드와 연결되어 있는 애들을 weight 타고 다 더한다음에 2번노드로 가서 2번노드에 뭐가 연결되어있는지 다 보고, 그 다음에 종합해서 업데이트 하고, 3번노드 뭐랑 연결되어있는지 다 보고,,이렇게 할 수는 없겠죠.(for문을 엄청나게 많이 사용해서 속도가 느려질 것이다.)\n그러면 우리가 graph structure를 adjacency matrix로 나타내는데 그럼 이 adjacency matrix가 결국은 connectivity를 담고있는 매트릭스이다. 그럼 이것을 어떻게 잘 활용하면 한번에 행렬연산으로 할 수 있을 것 같다. (행렬 연산은 gpu가 빠르게 잘함)\n- 예제\n자기자신과 연결되어있다고 가정, feature의 개수도 임의로 10으로 지정\n보기 쉽게 node feature matrix를 H라고 놓자. (오른쪽 matrix가 H임)\n\n\n\nimage.png\n\n\n\n\n\nimage.png\n\n\n그 새로운 값은 각각의 노드의 근처에 있는 값들만 받아들여서 convolution 연산을 한 효과를 냈고, 그리고 그 weight들은 다 똑같다. 그 weight를 곱할때 filter마다는 다르지만 동일한 하나의 필터 내에서는 같은 weight들이 서로 다른 노드에 곱해진다.\n그래서 이런식으로 하면 weight sharing을 하고, local feature를 뽑아내는 convolutional layer의 특성을 가지면서도 for문을 돌고 하는게 아니라 행렬연산을 통해 이것을 구현 함으로써 GPU에 넣었을 때 훨씬 빠르고 gradient 계산하는 것도 병렬화되서 훨씬 빠르게 할 수 있기 때문에 이렇게 구현하면 쓸 수 있겠다고 생각해볼 수 있다.\n타당한 structure인 것 같다.\n\\[H^{(l+1)} = \\sigma(AH^{(l)}W^{(l)}+b^{(l)})\\]\n다음 layer의 hidden state는 이전 layer의 hidden stat에 weight를 곱하고 여기에 adjacency matrix를 곱하면 그 connectivity에 들어가는 정보가 들어가서 각각의 노드가 연결되어 있는 애들의 정보만 받게되고, 이것도 어쨌든 컨볼루션을 했으니까 activation을 씌워주면 update된 값을 얻을 수 있다.\n\n\n\n\nPermutation invariance는 adjency matrix의 순서가 바뀌더라도 그 output이 변하지 않는 함수의 특성을 말한다.\n\n\\[f(PAP^{T}) = f(A)\\]\n(참고) 위 식에서 \\(\\bf{A}\\)는 adjacency matrix, \\(\\bf{P}\\)는 행과 열의 순서를 바꾸는 permutation matrix이다. 위 식은 위에서 설명한 것처럼 adjacency matrix 내의 노드의 순서가 바뀌어도 함수의 결과는 바뀌지 않는다.\n\n\n\nimage.png\n\n\n그래프를 adjacency matrix와 node feature matrix로 표현을 했는데 node feature matrix에 순서가 있다. 노드의 순서가 바뀐다고 해서 그래프가 달라지지는 않는다. 노드의 배치만 바뀌었을 뿐 노드의 특성과 엣지는 다 똑같이 연결되어 있으니까 같은 그래프이다.그런데 우리가 표현하는 node feature matrix는 바뀌게 될것이다. (row의 순서가 뒤죽박죽..)근데 결국 얘네들은 같은 그래프이니까 feature를 뽑아낼 때 같은 값이 나와야 된다. (순서가 다르게되어 있다고 다른값이 나오면 안되겠죠) 따라서 이걸 하기 위해서 Readout layer를 거치게 된다.\n이 Readout layer의 역할은 permutation invariance를 준다. 즉, permutation이 어떻게 되어있든 관계없이 invariance하게 하는 역할을 수행해준다. 다양한 방법이 있지만 가장 간단한 방법은 위와 같다.\n\n\n\n\n\n\n\nimage.png\n\n\nGCN을 거친 후 마지막에 Readout layer를 통해 최종적으로 classification 혹은 value를 regression한다. CNN에서 Conv-pool layer들을 거친 후 마지막에 모든 node들 정보를 취합하기 위해 FC-layer를 거친 후 softmax를 통해 classification작업을 수행한다.\n마찬가지로 Graph Neural Network에서도 graph convolution layer들을 거친 후 MLP로 모든 node 정보를 취합하고 최종적으로 regression 혹은 classification을 위해 어떤 값을 결정짓는 작업이 필요하다. 이를 GCN에서 readout-layer라고 한다\n\n\n\nimage.png\n\n\n\n\n\nGCN을 비롯한 graph neural network (GNN)을 직접 구현하는 것은 인접 행렬과 node feature matrix를 추출하는 것부터 여러 그래프의 batch를 만드는 것 까지 많은 어려움이 따른다. PyTorch를 기준으로는 Deep Graph Library (DGL)와 PyTorch Geometric이라는 라이브러리가 GNN과 이를 이용한 딥 러닝에 관한 여러 구현을 제공하고 있다.\n\n\n\n\nhttps://tkipf.github.io/graph-convolutional-networks/\nhttps://untitledtblog.tistory.com/152"
  },
  {
    "objectID": "posts/Study/2023-02-21-STGCN-tutorial1.html",
    "href": "posts/Study/2023-02-21-STGCN-tutorial1.html",
    "title": "튜토리얼 따라가기1",
    "section": "",
    "text": "https://miruetoto.github.io/yechan3/posts/3_Researches/STGCN/2022-12-29-STGCN-tutorial.html\nhttps://pytorch-geometric-temporal.readthedocs.io/en/latest/"
  },
  {
    "objectID": "posts/Study/2023-02-21-STGCN-tutorial1.html#imports",
    "href": "posts/Study/2023-02-21-STGCN-tutorial1.html#imports",
    "title": "튜토리얼 따라가기1",
    "section": "imports",
    "text": "imports\n\n# 일반적인 모듈\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport networkx as nx # 그래프 시그널 시각화를 위한 모듈\nfrom tqdm import tqdm # for문의 진행 상태 확인\n\n# 파이토치 관련\nimport torch\nimport torch.nn.functional as F\n\n\n# PyG 관련\nfrom torch_geometric.data import Data # 그래프 자료를 만들기 위한 클래스\n\n\n# STGCN 관련\nimport torch_geometric_temporal\nfrom torch_geometric_temporal.nn.recurrent import GConvGRU\nfrom torch_geometric_temporal.signal import temporal_signal_split # STGCN dataset을 train/test set으로 분리\n\n- STGCN의 학습을 위한 클래스 선언\n\n# define recurrent GCN architecture\nclass RecurrentGCN(torch.nn.Module):\n    def __init__(self, node_features, filters):\n        super(RecurrentGCN, self).__init__()\n        self.recurrent = GConvGRU(node_features, filters, 2)\n        self.linear = torch.nn.Linear(filters, 1)\n\n    def forward(self, x, edge_index, edge_weight):\n        h = self.recurrent(x, edge_index, edge_weight)\n        h = F.relu(h)\n        h = self.linear(h)\n        return h"
  },
  {
    "objectID": "posts/Study/2023-02-21-STGCN-tutorial1.html#notations-of-stgcn",
    "href": "posts/Study/2023-02-21-STGCN-tutorial1.html#notations-of-stgcn",
    "title": "튜토리얼 따라가기1",
    "section": "notations of STGCN",
    "text": "notations of STGCN\n- 시계열: each \\(t\\) 에에 대한 observation이 하나의 값 (혹은 벡터)\n\n자료: \\(X(t) \\quad \\text{for} \\quad t = 1,2,\\dots,T\\)\n\n- STGCN setting에서는 each \\(t\\) 에 대한 observation이 graph\n\n자료: \\(X(v,t) \\quad \\text{for} \\quad t = 1,2,\\dots,T \\quad \\text{and} \\quad v\\in V\\)\n주의: 이 포스트에서는 \\(X(v,t)\\)를 \\(f(v,t)\\)로 표현할 때가 있음"
  },
  {
    "objectID": "posts/Study/2023-02-21-STGCN-tutorial1.html#dataset-dataloaders",
    "href": "posts/Study/2023-02-21-STGCN-tutorial1.html#dataset-dataloaders",
    "title": "튜토리얼 따라가기1",
    "section": "dataset, dataloaders",
    "text": "dataset, dataloaders\n\nPyG의 Data 자료형\n(예제) 아래와 같은 그래프 자료를 고려하자.\nWe show a simple example of an unweighted and undirected graph with three nodes and four edges. Each node contains exactly one feature\n\n이러한 자료형은 아래와 같은 형식으로 저장한다.\n\nedge_index = torch.tensor([[0, 1, 1, 2],\n                           [1, 0, 2, 1]], dtype = torch.long)  # 4 edges\nx  = torch.tensor([[-1], [0], [1]], dtype = torch.float) # 3 nodes\ndata = Data(x=x, edge_index=edge_index) # Data는 그래프자료형을 만드는 클래스\n\n\ndata\n\nData(x=[3, 1], edge_index=[2, 4])\n\n\n\nx : \\(3\\times1\\) 크기의 행렬 \\(\\to\\) 3개의 노드와 각 노드는 단일 값을 가진다.\nedge_index : \\(2 \\times 4\\) 크기의 행렬 \\(\\to\\) \\(4\\)개의 엣지들 (양방향 그래프)\n\n\ntype(data)\n\ntorch_geometric.data.data.Data\n\n\n\ndata.x # 노드의 특징 행렬\n\ntensor([[-1.],\n        [ 0.],\n        [ 1.]])\n\n\n\ndata.edge_index # 그래프 연결성\n\ntensor([[0, 1, 1, 2],\n        [1, 0, 2, 1]])\n\n\n\ndata.num_edges # edge 총 갯수\n\n4\n\n\n\ndata.is_directed() # 그래프 방향성 여부 확인\n\nFalse"
  },
  {
    "objectID": "posts/Study/2023-02-21-STGCN-tutorial1.html#pytorch-geometric-temporal-의-자료형",
    "href": "posts/Study/2023-02-21-STGCN-tutorial1.html#pytorch-geometric-temporal-의-자료형",
    "title": "튜토리얼 따라가기1",
    "section": "PyTorch Geometric Temporal 의 자료형",
    "text": "PyTorch Geometric Temporal 의 자료형\n\nref: PyTorch Geomatric Temporal Signal\n\n아래의 클래스들 중 하나를 이용하여 만든다.\n\n## Temporal Signal Iterators\ntorch_geometric_temporal.signal.StaticGraphTemporalSignal\ntorch_geometric_temporal.signal.DynamicGraphTemporalSignal\ntorch_geometric_temporal.signal.DynamicGraphStaticSignal\n\n## Heterogeneous Temporal Signal Iterators\ntorch_geometric_temporal.signal.StaticHeteroGraphTemporalSignal\ntorch_geometric_temporal.signal.DynamicHeteroGraphTemporalSignal\ntorch_geometric_temporal.signal.DynamicHeteroGraphStaticSignal\n\ntorch_geometric_temporal.signal.dynamic_hetero_graph_static_signal.DynamicHeteroGraphStaticSignal\n\n\n이 중 “Heterogeneous Temporal Signal”은 우리가 관심이 있는 신호가 아님로 사실상 아래 3가지만 고려하면 된다.\n\ntorch_geometric_temporal.signal.StaticGraphTemporalSignal\ntorch_geometric_temporal.signal.DynamicGraphTemporalSignal\ntorch_geometric_temporal.signal.DynamicGraphStaticSignal\n\n여기에서 StaticGraphTemporalSignal 는 시간에 따라서 그래프 구조가 일정한 경우, 즉 \\({\\cal G}_t=\\{{\\cal V},{\\cal E}\\}\\) 와 같은 구조를 의미한다.\n\n(예제1) StaticGraphTemporalSignal을 이용하여 데이터 셋 만들기\n- json data \\(\\to\\) dict\n\nimport json\nimport urllib\n\n\nurl = \"https://raw.githubusercontent.com/benedekrozemberczki/pytorch_geometric_temporal/master/dataset/chickenpox.json\"\ndata_dict = json.loads(urllib.request.urlopen(url).read())\n# data_dict 출력이 김\n\n\ndata_dict.keys()\n\ndict_keys(['edges', 'node_ids', 'FX'])\n\n\n- 살펴보기\n\nnp.array(data_dict['edges']).T\n\narray([[ 0,  0,  0,  0,  0,  0,  0,  1,  1,  1,  1,  2,  2,  2,  2,  3,\n         3,  3,  3,  3,  3,  4,  4,  5,  5,  5,  5,  6,  6,  6,  6,  6,\n         6,  6,  7,  7,  7,  7,  8,  8,  8,  8,  8,  9,  9,  9,  9,  9,\n        10, 10, 10, 10, 10, 10, 10, 10, 11, 11, 11, 11, 11, 12, 12, 12,\n        12, 13, 13, 13, 13, 13, 13, 13, 13, 14, 14, 14, 14, 14, 14, 15,\n        15, 15, 16, 16, 16, 16, 16, 17, 17, 17, 17, 18, 18, 18, 18, 18,\n        18, 18, 19, 19, 19, 19],\n       [10,  6, 13,  1,  0,  5, 16,  0, 16,  1, 14, 10,  8,  2,  5,  8,\n        15, 12,  9, 10,  3,  4, 13,  0, 10,  2,  5,  0, 16,  6, 14, 13,\n        11, 18,  7, 17, 11, 18,  3,  2, 15,  8, 10,  9, 13,  3, 12, 10,\n         5,  9,  8,  3, 10,  2, 13,  0,  6, 11,  7, 13, 18,  3,  9, 13,\n        12, 13,  9,  6,  4, 12,  0, 11, 10, 18, 19,  1, 14,  6, 16,  3,\n        15,  8, 16, 14,  1,  0,  6,  7, 19, 17, 18, 14, 18, 17,  7,  6,\n        19, 11, 18, 14, 19, 17]])\n\n\n\n\\({\\cal E} = \\{(0,10),(0,6), \\dots, (19,17)\\}\\)\n혹은 \\({\\cal E} = \\{(\\tt{BACS},\\tt{JASZ}), ({\\tt BACS},{\\tt FEJER}), \\dots, (\\tt{ZALA},\\tt{VAS})\\}\\)\n\n\ndata_dict['node_ids']\n\n{'BACS': 0,\n 'BARANYA': 1,\n 'BEKES': 2,\n 'BORSOD': 3,\n 'BUDAPEST': 4,\n 'CSONGRAD': 5,\n 'FEJER': 6,\n 'GYOR': 7,\n 'HAJDU': 8,\n 'HEVES': 9,\n 'JASZ': 10,\n 'KOMAROM': 11,\n 'NOGRAD': 12,\n 'PEST': 13,\n 'SOMOGY': 14,\n 'SZABOLCS': 15,\n 'TOLNA': 16,\n 'VAS': 17,\n 'VESZPREM': 18,\n 'ZALA': 19}\n\n\n\nlen(data_dict['node_ids']) # node 개수는 20개\n\n20\n\n\n\n\\({\\cal V}=\\{\\tt{BACS},\\tt{BARANYA} \\dots, \\tt{ZALA}\\}\\)\n\n\nlen(data_dict['edges']) # edge의 개수 102개\n\n102\n\n\n\ndata_dict.keys()\n\ndict_keys(['edges', 'node_ids', 'FX'])\n\n\n\nnp.array(data_dict['FX']), np.array(data_dict['FX']).shape\n\n(array([[-1.08135724e-03, -7.11136085e-01, -3.22808515e+00, ...,\n          1.09445310e+00, -7.08747750e-01, -1.82280792e+00],\n        [ 2.85705967e-02, -5.98430173e-01, -2.29097341e-01, ...,\n         -1.59220988e+00, -2.24597623e-01,  7.86330575e-01],\n        [ 3.54742090e-01,  1.90511208e-01,  1.61028185e+00, ...,\n          1.38183225e-01, -7.08747750e-01, -5.61724314e-01],\n        ...,\n        [-4.75512620e-01, -1.19952837e+00, -3.89043358e-01, ...,\n         -1.00023329e+00, -1.71429032e+00,  4.70746677e-02],\n        [-2.08645035e-01,  6.03766218e-01,  1.08216835e-02, ...,\n          4.71099041e-02,  2.45684924e+00, -3.44296107e-01],\n        [ 1.21464875e+00,  7.16472130e-01,  1.29038982e+00, ...,\n          4.56939849e-01,  7.43702632e-01,  1.00375878e+00]]),\n (521, 20))\n\n\n\n\\({\\bf f}=\\begin{bmatrix} {\\bf f}_1\\\\ {\\bf f}_2\\\\ \\dots \\\\ {\\bf f}_{521} \\end{bmatrix}=\\begin{bmatrix} f(t=1,v=\\tt{BACS}) & \\dots & f(t=1,v=\\tt{ZALA}) \\\\ f(t=2,v=\\tt{BACS}) & \\dots & f(t=2,v=\\tt{ZALA}) \\\\ \\dots & \\dots & \\dots \\\\ f(t=521,v=\\tt{BACS}) & \\dots & f(t=521,v=\\tt{ZALA}) \\end{bmatrix}\\)\n\n즉, data_dict는 아래와 같이 구성되어 있음\n\n\n\n\n\n\n\n\n\n\n수학 기호\n코드에 저장된 변수\n자료형\n차원\n설명\n\n\n\n\n\\({\\cal V}\\)\ndata_dict['node_ids']\ndict\n20\n20개의 노드에 대한 설명이 있음\n\n\n\\({\\cal E}\\)\ndata_dict['edges']\nlist (double list)\n(102,2)\n노드들에 대한 102개의 연결을 정의함\n\n\n\\({\\bf f}\\)\ndata_dict['node_ids']\ndict\n(521,20)\n\\(f(t,v)\\) for \\(v \\in {\\cal V}\\) and \\(t = 1,\\dots, T\\)\n\n\n\n- 주어진 자료를 정리하여 그래프신호 \\(\\big(\\{{\\cal V},{\\cal E},{\\bf W}\\},{\\bf f}\\big)\\)를 만들면 아래와 같다.\n\nedges = np.array(data_dict['edges']).T\nedge_weight = np.ones(edges.shape[1])\nf =  np.array(data_dict['FX'])\n\n\n여기에서 edges는 \\(\\cal{E}\\) 에 대한 정보들\nedges_weight는 \\(\\bf{W}\\)에 대한 정보들\nf는 \\(\\bf{f}\\)에 대한 정보를 저장한다.\n\n\nNote: 이때 \\(\\bf{W} = \\bf{E}\\)로 정의한다.\n\n- data_dict \\(\\to\\) dl\n\nlags = 4\nfeatures = [f[i : i + lags, :].T for i in range(f.shape[0] - lags)]\ntargets = [f[i + lags, :].T for i in range(f.shape[0] - lags)]\n\n\nnp.array(features).shape, np.array(targets).shape\n\n((517, 20, 4), (517, 20))\n\n\n\n\n\n\n\n\n\n설명변수\n반응변수\n\n\n\n\n\\({\\bf X} = {\\tt features} = \\begin{bmatrix} {\\bf f}_1 & {\\bf f}_2 & {\\bf f}_3 & {\\bf f}_4 \\\\ {\\bf f}_2 & {\\bf f}_3 & {\\bf f}_4 & {\\bf f}_5 \\\\ \\dots & \\dots & \\dots & \\dots \\\\ {\\bf f}_{517} & {\\bf f}_{518} & {\\bf f}_{519} & {\\bf f}_{520} \\end{bmatrix}\\)\n\\({\\bf y}= {\\tt targets} = \\begin{bmatrix} {\\bf f}_5 \\\\ {\\bf f}_6 \\\\ \\dots \\\\ {\\bf f}_{521} \\end{bmatrix}\\)\n\n\n\n\nAR 느낌으로 표현하면 AR(4) 이다.\n\n\ndataset = torch_geometric_temporal.signal.StaticGraphTemporalSignal(\n    edge_index = edges,\n    edge_weight = edge_weight,\n    features = features,\n    targets = targets)\n\n\ndataset\n\n<torch_geometric_temporal.signal.static_graph_temporal_signal.StaticGraphTemporalSignal at 0x7fc4bee0a250>\n\n\n- 그런데 이 과정을 아래와 같이 할 수도있음\n\n# Pytorch Geometric Temporal 공식홈페이지에 소개된 콛,ㅡ\nloader = torch_geometric_temporal.dataset.ChickenpoxDatasetLoader()\ndataset = loader.get_dataset(lags = 4)\n\n- dataset은 dataset[0],\\(\\dots\\)dataset[516]과 같은 방식으로 각 시점별 자료에 접근 가능\n\ndataset[0]\n\nData(x=[20, 4], edge_index=[2, 102], edge_attr=[102], y=[20])\n\n\n각 시점에 대한 자료형은 아까 살펴보았던 PyG의 Data 자료형과 같음\n\ntype(dataset[0])\n\ntorch_geometric.data.data.Data\n\n\n\ndataset[0].x\n\ntensor([[-1.0814e-03,  2.8571e-02,  3.5474e-01,  2.9544e-01],\n        [-7.1114e-01, -5.9843e-01,  1.9051e-01,  1.0922e+00],\n        [-3.2281e+00, -2.2910e-01,  1.6103e+00, -1.5487e+00],\n        [ 6.4750e-01, -2.2117e+00, -9.6858e-01,  1.1862e+00],\n        [-1.7302e-01, -9.4717e-01,  1.0347e+00, -6.3751e-01],\n        [ 3.6345e-01, -7.5468e-01,  2.9768e-01, -1.6273e-01],\n        [-3.4174e+00,  1.7031e+00, -1.6434e+00,  1.7434e+00],\n        [-1.9641e+00,  5.5208e-01,  1.1811e+00,  6.7002e-01],\n        [-2.2133e+00,  3.0492e+00, -2.3839e+00,  1.8545e+00],\n        [-3.3141e-01,  9.5218e-01, -3.7281e-01, -8.2971e-02],\n        [-1.8380e+00, -5.8728e-01, -3.5514e-02, -7.2298e-02],\n        [-3.4669e-01, -1.9827e-01,  3.9540e-01, -2.4774e-01],\n        [ 1.4219e+00, -1.3266e+00,  5.2338e-01, -1.6374e-01],\n        [-7.7044e-01,  3.2872e-01, -1.0400e+00,  3.4945e-01],\n        [-7.8061e-01, -6.5022e-01,  1.4361e+00, -1.2864e-01],\n        [-1.0993e+00,  1.2732e-01,  5.3621e-01,  1.9023e-01],\n        [ 2.4583e+00, -1.7811e+00,  5.0732e-02, -9.4371e-01],\n        [ 1.0945e+00, -1.5922e+00,  1.3818e-01,  1.1855e+00],\n        [-7.0875e-01, -2.2460e-01, -7.0875e-01,  1.5630e+00],\n        [-1.8228e+00,  7.8633e-01, -5.6172e-01,  1.2647e+00]])\n\n\n\n이 값들은 features[0]의 값들과 같음. 즉 \\([\\bf{f}_1, \\bf{f}_2, \\bf{f}_3, \\bf{f}_4]\\)를 의미함\n\n\ndataset[0].y\n\ntensor([ 0.7106, -0.0725,  2.6099,  1.7870,  0.8024, -0.2614, -0.8370,  1.9674,\n        -0.4212,  0.1655,  1.2519,  2.3743,  0.7877,  0.4531, -0.1721, -0.0614,\n         1.0452,  0.3203, -1.3791,  0.0036])\n\n\n\n이 값들은 targets[0]이 값들과 같음. 즉 \\(\\bf{f}_5\\)를 의미함"
  },
  {
    "objectID": "posts/Study/2023-02-21-STGCN-tutorial1.html#summary-of-data",
    "href": "posts/Study/2023-02-21-STGCN-tutorial1.html#summary-of-data",
    "title": "튜토리얼 따라가기1",
    "section": "Summary of data",
    "text": "Summary of data\n\n\\(T = 519\\)\n\\(N=20\\) # number of nodes\n\\(|\\cal{E}|=102\\) # edges\n\\(f(t,v)\\)의 차원? \\((1,)\\) # edges\n시간에 따라서 Number of nods가 변하는지? \\(\\to\\) False\n\\(\\bf{X}: (20, 4)\\)\n\\(\\bf{y}: (20, )\\)\n예제코드적용가능 여부 : Yes\n\n- Nodes : 20 - vertices are counties\n- Edges: 102 - edges are neighbourhoods\n- Time: 519 - between 2004 and 2014 - per weeks\n\nloader = torch_geometric_temporal.dataset.ChickenpoxDatasetLoader()\ndataset = loader.get_dataset(lags = 4)\ntrain_dataset, test_dataset = temporal_signal_split(dataset, train_ratio = 0.8)"
  },
  {
    "objectID": "posts/Study/2023-02-21-STGCN-tutorial1.html#learn",
    "href": "posts/Study/2023-02-21-STGCN-tutorial1.html#learn",
    "title": "튜토리얼 따라가기1",
    "section": "Learn",
    "text": "Learn\n\nmodel = RecurrentGCN(node_features = 4, filters = 32)\noptimizer = torch.optim.Adam(model.parameters(), lr = 0.01)\nmodel.train()\n\nfor epoch in tqdm(range(50)):\n    for t, snapshot in enumerate(train_dataset):\n        yt_hat = model(snapshot.x, snapshot.edge_index, snapshot.edge_attr)\n        cost = torch.mean((yt_hat - snapshot.y)**2)\n        cost.backward()\n        optimizer.step()\n        optimizer.zero_grad()\n\n100%|██████████| 50/50 [01:08<00:00,  1.37s/it]"
  },
  {
    "objectID": "posts/Study/2023-02-21-STGCN-tutorial1.html#visualization",
    "href": "posts/Study/2023-02-21-STGCN-tutorial1.html#visualization",
    "title": "튜토리얼 따라가기1",
    "section": "Visualization",
    "text": "Visualization\n\nmodel.eval()\n\nRecurrentGCN(\n  (recurrent): GConvGRU(\n    (conv_x_z): ChebConv(4, 32, K=2, normalization=sym)\n    (conv_h_z): ChebConv(32, 32, K=2, normalization=sym)\n    (conv_x_r): ChebConv(4, 32, K=2, normalization=sym)\n    (conv_h_r): ChebConv(32, 32, K=2, normalization=sym)\n    (conv_x_h): ChebConv(4, 32, K=2, normalization=sym)\n    (conv_h_h): ChebConv(32, 32, K=2, normalization=sym)\n  )\n  (linear): Linear(in_features=32, out_features=1, bias=True)\n)\n\n\n\nyhat_train = torch.stack([model(snapshot.x,snapshot.edge_index, snapshot.edge_attr) for snapshot in train_dataset]).detach().numpy()\nyhat_test = torch.stack([model(snapshot.x,snapshot.edge_index, snapshot.edge_attr) for snapshot in test_dataset]).detach().numpy()\n\n\nV = list(data_dict['node_ids'].keys())\nV\n\n['BACS',\n 'BARANYA',\n 'BEKES',\n 'BORSOD',\n 'BUDAPEST',\n 'CSONGRAD',\n 'FEJER',\n 'GYOR',\n 'HAJDU',\n 'HEVES',\n 'JASZ',\n 'KOMAROM',\n 'NOGRAD',\n 'PEST',\n 'SOMOGY',\n 'SZABOLCS',\n 'TOLNA',\n 'VAS',\n 'VESZPREM',\n 'ZALA']\n\n\n\nfig,ax = plt.subplots(20,1,figsize=(10,50))\nfor k in range(20):\n    ax[k].plot(f[:,k],'--',alpha=0.5,label='observed')\n    ax[k].set_title('node: {}'.format(V[k]))\n    ax[k].plot(yhat_train[:,k],label='predicted (tr)')\n    ax[k].plot(range(yhat_train.shape[0],yhat_train.shape[0]+yhat_test.shape[0]),yhat_test[:,k],label='predicted (test)')\n    ax[k].legend()\nfig.tight_layout()"
  },
  {
    "objectID": "posts/Study/python_7장.html",
    "href": "posts/Study/python_7장.html",
    "title": "스타벅스 주가예측",
    "section": "",
    "text": "import os\nimport time\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import TensorDataset, DataLoader\nfrom torch.autograd import Variable\nfrom tqdm import tqdm_notebook\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler\nfrom sklearn.model_selection import train_test_split  \n\ndevice = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n\n\ndevice\n\ndevice(type='cuda', index=0)\n\n\n\ndata=pd.read_csv('https://raw.githubusercontent.com/gilbutITbook/080289/main/chap07/data/SBUX.csv')\nprint(data.dtypes)\n\nDate          object\nOpen         float64\nHigh         float64\nLow          float64\nClose        float64\nAdj Close    float64\nVolume         int64\ndtype: object\n\n\n\ndata['Date'] = pd.to_datetime(data['Date'])\ndata.set_index('Date', inplace=True)\n\n\ndata['Volume'] = data['Volume'].astype(float) # 추후 텐서로 변환시 용이\n\n\nX=data.iloc[:,:-1] # 마지막 칼럼을 제외한 모든 컬럼\ny=data.iloc[:,5:6] # 마지막 Volumn을 레이블로 사용\nprint(X)\nprint(y)\n\n                  Open        High         Low       Close   Adj Close\nDate                                                                  \n2019-12-11   86.260002   86.870003   85.849998   86.589996   84.145752\n2019-12-12   88.000000   88.889999   87.540001   88.209999   85.720032\n2019-12-13   88.019997   88.790001   87.580002   88.669998   86.167046\n2019-12-16   89.139999   89.300003   88.430000   88.779999   86.273941\n2019-12-17   88.870003   88.970001   87.470001   88.129997   85.642288\n...                ...         ...         ...         ...         ...\n2020-12-04  101.349998  102.940002  101.070000  102.279999  101.442787\n2020-12-07  102.010002  102.220001  100.690002  101.410004  100.579918\n2020-12-08  100.370003  101.570000  100.010002  101.209999  100.381554\n2020-12-09  101.940002  102.209999  100.099998  100.400002   99.578186\n2020-12-10  103.510002  106.089996  102.750000  105.389999  104.527336\n\n[253 rows x 5 columns]\n                Volume\nDate                  \n2019-12-11   4921900.0\n2019-12-12  10282100.0\n2019-12-13   6714100.0\n2019-12-16   6705600.0\n2019-12-17   7296900.0\n...                ...\n2020-12-04   6952700.0\n2020-12-07   4514800.0\n2020-12-08   3911300.0\n2020-12-09   6629900.0\n2020-12-10  12939200.0\n\n[253 rows x 1 columns]\n\n\n\n200/253\n\n0.7905138339920948\n\n\n\nms = MinMaxScaler()\nss = StandardScaler()\n\nX_ss = ss.fit_transform(X)\ny_ms = ms.fit_transform(y) \n\nX_train = X_ss[:200, :]\nX_test = X_ss[200:, :]\n\ny_train = y_ms[:200, :]\ny_test = y_ms[200:, :] \n\nprint(\"Training Shape\", X_train.shape, y_train.shape)\nprint(\"Testing Shape\", X_test.shape, y_test.shape) \n\nTraining Shape (200, 5) (200, 1)\nTesting Shape (53, 5) (53, 1)\n\n\n\n## X\nX_train_tensors = Variable(torch.Tensor(X_train))\nX_test_tensors = Variable(torch.Tensor(X_test))\n\n## y\ny_train_tensors = Variable(torch.Tensor(y_train))\ny_test_tensors = Variable(torch.Tensor(y_test))\n\n## reshape X (200 x 1 x 5)\nX_train_tensors_f = torch.reshape(X_train_tensors,   (X_train_tensors.shape[0], 1, X_train_tensors.shape[1]))\nX_test_tensors_f = torch.reshape(X_test_tensors,  (X_test_tensors.shape[0], 1, X_test_tensors.shape[1])) \n\nprint(\"Training Shape\", X_train_tensors_f.shape, y_train_tensors.shape)\nprint(\"Testing Shape\", X_test_tensors_f.shape, y_test_tensors.shape) \n\nTraining Shape torch.Size([200, 1, 5]) torch.Size([200, 1])\nTesting Shape torch.Size([53, 1, 5]) torch.Size([53, 1])\n\n\n\nVariable로 감싸진 텐서는 .backward()가 호출될 때 자동으로 기울기 계산.\n이와같이 데이터셋의 형태를 변경하는 이유는 LSTM 네트워크의 입력 형태와 맞추기 위해서이다.\n\n\n\n\n\nclass LSTM(nn.Module):\n    def __init__(self, num_classes, input_size, hidden_size, num_layers, seq_length):\n        super(LSTM, self).__init__()\n        self.num_classes = num_classes # 클래스 개수\n        self.num_layers = num_layers # LSTM 계층 개수\n        self.input_size = input_size  #입력크기 (훈련 데이터셋의 칼럼 수)\n        self.hidden_size = hidden_size  # 은닉층 뉴런개수\n        self.seq_length = seq_length  # sequence 길이\n\n        self.lstm = nn.LSTM(input_size=input_size, hidden_size=hidden_size,\n                          num_layers=num_layers, batch_first=True) \n        self.fc_1 =  nn.Linear(hidden_size, 128) \n        self.fc = nn.Linear(128, num_classes) \n\n        self.relu = nn.ReLU()\n    \n    def forward(self,x):\n        h_0 = Variable(torch.zeros(self.num_layers, x.size(0), self.hidden_size))  # 은닉상태 0으로 초기화\n        c_0 = Variable(torch.zeros(self.num_layers, x.size(0), self.hidden_size))  # 셀 상태 0으로 초기화\n        \n        output, (hn, cn) = self.lstm(x, (h_0, c_0))  # LSTM 계층에 은닉상태, 셀상태 적용\n        hn = hn.view(-1, self.hidden_size)  # 완전연결층 적용을 위해 데이터의 형태 1차원으로 조정.\n        out = self.relu(hn)\n        out = self.fc_1(out) \n        out = self.relu(out) \n        out = self.fc(out)\n        return out\n\n\n\n\n\n## 모델 학습을 위해 필요한 변수값 설정.\nnum_epochs = 1000 \nlearning_rate = 0.0001 \n\ninput_size = 5 \nhidden_size = 2 \nnum_layers = 1 \n\nnum_classes = 1 \nmodel = LSTM(num_classes, input_size, hidden_size, num_layers, X_train_tensors_f.shape[1]) \n\ncriterion = torch.nn.MSELoss()    \noptimizer = torch.optim.Adam(model.parameters(), lr=learning_rate) \n\n\nfor epoch in range(num_epochs):\n    outputs = model.forward(X_train_tensors_f) \n    optimizer.zero_grad()  \n    loss = criterion(outputs, y_train_tensors)  # 손실함수를 이용한 오차 계산. \n    loss.backward()  # 기울기 계산\n    optimizer.step() # 오차 업데이트\n    if epoch % 100 == 0:\n        print(\"Epoch: %d, loss: %1.5f\" % (epoch, loss.item())) \n\nEpoch: 0, loss: 0.25400\nEpoch: 100, loss: 0.08501\nEpoch: 200, loss: 0.04538\nEpoch: 300, loss: 0.04002\nEpoch: 400, loss: 0.03854\nEpoch: 500, loss: 0.03714\nEpoch: 600, loss: 0.03550\nEpoch: 700, loss: 0.03339\nEpoch: 800, loss: 0.02975\nEpoch: 900, loss: 0.02508\n\n\n\n\n\n모델 예측결과를 출력하기 위한 데이터 크기 재구성\n\ndf_x_ss = ss.transform(data.iloc[:, :-1])  ## ss: StandardScaler()\ndf_y_ms = ms.transform(data.iloc[:, -1:])  ## ms: MinMaxScaler()\n\ndf_x_ss = Variable(torch.Tensor(df_x_ss)) \ndf_y_ms = Variable(torch.Tensor(df_y_ms))\ndf_x_ss = torch.reshape(df_x_ss, (df_x_ss.shape[0], 1, df_x_ss.shape[1])) \n\n\nnp.array(df_x_ss).shape, np.array(df_y_ms).shape\n\n((253, 1, 5), (253, 1))\n\n\n\ntrain_predict = model(df_x_ss)\npredicted = train_predict.data.numpy() \nlabel_y = df_y_ms.data.numpy()\n\npredicted= ms.inverse_transform(predicted) \nlabel_y = ms.inverse_transform(label_y)\nplt.figure(figsize=(10,6)) \nplt.axvline(x=200, c='r', linestyle='--') \n\nplt.plot(label_y, label='Actual Data') \nplt.plot(predicted, label='Predicted Data') \nplt.title('Time-Series Prediction')\nplt.legend()\nplt.show()"
  },
  {
    "objectID": "posts/Study/2023-05-06-ept-논문리뷰.html",
    "href": "posts/Study/2023-05-06-ept-논문리뷰.html",
    "title": "[PAPER] Ensemble patch transformation",
    "section": "",
    "text": "ref : https://www.sciencedirect.com/science/article/pii/S2352711021000492\n\nThe primary focus of multiscale analysis is to interpret the temporal characteristics of one-dimensional signals and local spatial patterns of two-dimensional images according to the scale variability. There have been numerous studies for multiscale analysis in the literature, including spectral analysis, wavelet analysis, empirical mode decomposition, synchrosqueezed wavelet transforms, and variational mode decomposition. These methodologies have been widely applied in various areas and can be easily implemented by Matlab and R packages. Recently, ensemble patch transform has been developed for multiscale analysis of one-dimensional signals and two-dimensional images. For researchers and practitioners of multidisciplinary areas, we provide the R package EPT for an efficient implementation of the ensemble patch transform. This package flexibly designs various types of filters for identifying local characteristics and scale patterns hidden in a signal and the spatial characteristics of an image. The R package EPT also provides an effective tool for visualization and decomposition of signals and images."
  },
  {
    "objectID": "posts/Study/2023-04-11-arima-hour-data-fill.html",
    "href": "posts/Study/2023-04-11-arima-hour-data-fill.html",
    "title": "[SOLAR] SARIMA (MSE: 0.478)",
    "section": "",
    "text": "import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\nimport rpy2\n%load_ext rpy2.ipython \n\nimport matplotlib.pyplot as plt\nplt.rcParams['font.family'] = 'NanumGothic'\n\nThe rpy2.ipython extension is already loaded. To reload it, use:\n  %reload_ext rpy2.ipython\n\n\n\nurl = 'https://raw.githubusercontent.com/pinkocto/noteda/main/posts/SOLAR/data/solar_radiation2.csv'\ndf = pd.read_csv(url)"
  },
  {
    "objectID": "posts/Study/2023-04-11-arima-hour-data-fill.html#mse",
    "href": "posts/Study/2023-04-11-arima-hour-data-fill.html#mse",
    "title": "[SOLAR] SARIMA (MSE: 0.478)",
    "section": "MSE",
    "text": "MSE\n\n## MSE\ndef mse_(real, pred):\n    diff = real - pred\n    return mean(diff^2)\n\n\ntest\n\n\n\n\n\n  \n    \n      \n      북춘천\n      철원\n      대관령\n      춘천\n      백령도\n      북강릉\n      강릉\n      서울\n      인천\n      원주\n      ...\n      순창군\n      북창원\n      양산시\n      보성군\n      강진군\n      의령군\n      함양군\n      광양시\n      청송군\n      경주시\n    \n    \n      date\n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n    \n  \n  \n    \n      2022-05-27 00:00\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      ...\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n    \n    \n      2022-05-27 01:00\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      ...\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n    \n    \n      2022-05-27 02:00\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      ...\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n    \n    \n      2022-05-27 03:00\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      ...\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n    \n    \n      2022-05-27 04:00\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      ...\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      2022-12-31 19:00\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      ...\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n    \n    \n      2022-12-31 20:00\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      ...\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n    \n    \n      2022-12-31 21:00\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      ...\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n    \n    \n      2022-12-31 22:00\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      ...\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n    \n    \n      2022-12-31 23:00\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      ...\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n    \n  \n\n5256 rows × 44 columns\n\n\n\n\ntrain['북춘천'].index[0], train['북춘천'].index[-1]\n\n(Period('2021-01-01 00:00', 'H'), Period('2022-05-26 23:00', 'H'))\n\n\n\ntrain_pred = results.predict(start = train['북춘천'].index[0], end = train['북춘천'].index[-1]).values\n\n\nfig = plt.figure(figsize = (80,30))\nplt.plot(train['북춘천'].values[:500], \"b-\", label = \"Actual\", alpha = 0.9, lw=3)\nplt.plot(train_pred[:500], \"r-\", label = \"Prediction\", alpha = 0.9, lw=3)\nplt.legend()\nplt.show()\n\n\n\n\n\n## fitting\nsteps = len(test)\ntest_pred = results.forecast(steps).values\n\n\nfig = plt.figure(figsize = (80,30))\nplt.plot(test['북춘천'].values[:500], \"b-\", label = \"Actual\", alpha = 0.9, lw=3)\nplt.plot(results.forecast(steps).values[:500], \"r-\", label = \"Prediction\", alpha = 0.9, lw=3)\nplt.legend()\nplt.show()\n\n\n\n\n\n…\n\n\nfrom sklearn.metrics import mean_squared_error as MSE\n\n\nprint(MSE(train['북춘천'].values, train_pred))\nprint(MSE(test['북춘천'].values, test_pred))\n\n0.047077332895820334\n0.47824005920354684\n\n\n\n완전 과적합..\nref: How to interpret Negative AIC Vluaes\nref: https://direction-f.tistory.com/71 (시계열 관련)\nref: https://stackoverflow.com/questions/38033570/seasonal-decompose-raises-error-typeerror-periodindex-given-check-the-freq (freq: 에러)"
  },
  {
    "objectID": "posts/Study/2023-04-24-베르누이.html",
    "href": "posts/Study/2023-04-24-베르누이.html",
    "title": "[SC2022] 포아송분포, 지수분포",
    "section": "",
    "text": "using Plots, Distributions, PlutoUI"
  },
  {
    "objectID": "posts/Study/2023-04-24-베르누이.html#how-to-generate-it",
    "href": "posts/Study/2023-04-24-베르누이.html#how-to-generate-it",
    "title": "[SC2022] 포아송분포, 지수분포",
    "section": "How to generate it?",
    "text": "How to generate it?\n\n평균이 3인 포아송분포에서 100개의 샘플을 뽑는 방법\n(방법1)\n\nrand(Poisson(3), 100)\n\n100-element Vector{Int64}:\n 3\n 4\n 6\n 1\n 4\n 3\n 2\n 1\n 4\n 3\n 3\n 3\n 3\n ⋮\n 1\n 1\n 3\n 2\n 3\n 3\n 3\n 8\n 4\n 2\n 2\n 0\n\n\n(방법2) 이항분포의 포아송근사를 이용\n\n이론: 이항분포에서 (1) \\(n\\to \\infty\\) (2) \\(p\\to 0\\) (3) \\(np=\\lambda\\) 이면 이것은 평균이 \\(\\lambda\\)인 포아송분포로 근사함.\n평균이 \\(\\lambda\\)인 포아송분포는 \\(B(n,\\frac{\\lambda}{n})\\)로 근 로 근사할 수 있다. 이때 \\(n\\)이 커질수록 더 정확해짐.\n\n\nlet\n    N = 10000\n    λ = 3\n    n = 10000\n    p = λ/n\n    X = rand(Binomial(n,p),N)\n    Y = rand(Poisson(λ),N)\n    p1 = histogram(X)\n    p2 = histogram(Y)\n    plot(p1,p2,layout=(2,1))\nend\n\n    \n    \n\n\n\n\\(n=10000\\) 정도이면 꽤 비슷함.\n방법2는 근사방법이므로 엄밀히 말하면 분포를 뽑는 기법이라고 볼 수는 없음.\n\n(방법3) 균등분포 \\(\\to\\) 베르누이 \\(\\to\\) 이항분포 \\(\\approx\\) 포아송\n\n1분동안 맥도날드에 평균 3명온다고 생각\n이건 사실 1초에 성공확률이 \\(0.05\\)인 베르누이 시행을 1번 시행하여 1분동안 총 60회 반복한 것으로 이해할 수 있음.\n좀 더 세밀하게는 0.001 초에 성공확률이 5.0e-5 인 베르누이 시행을 1번 시행하여 1분동안 총 60000 회 반복한 것으도 이해할수 있음. (무한반복가능)\n느낌: 하여튼 (1) “엄청 작은 시간”에 (2) “엄청 작은 확률”의 베르누이 시행이 (3) “엄청 많이 독립적으로 반복”되는 느낌을 기억하세요!\n\n\nlet \nλ=3\nn=60000\np=λ/n\nΔt = (60/n) # 단위가 60초니까 60\n\nN = 10000\nX = [(rand(n) .< p) |> sum for k in 1:N]\np1= histogram(X)\np2= rand(Poisson(λ),N) |> histogram\n_p = plot(p1,p2,layout=(2,1)) \n\n    \n    \n\n\n\n위: 유니폼 \\(\\to\\) 베르누이 \\(\\to\\) 이항분포 \\(\\approx\\) 포아송\n아래: 포아송\n\n(방법4) 균등분포 \\(\\to\\) inverse cdf method를 이용해서 생성할 수 있음.\n- 포아송분포의 합은 다시 포아송분포가 된다.\n\n이론: \\(X\\sim Poi(\\lambda_1), Y\\sim Poi(\\lambda_2), X\\perp Y \\Rightarrow X+Y\\sim Poi(\\lambda_1+\\lambda_2)\\)\n의미? (1) 1분동안 맥도날드 매장에 들어오는 남자의 수는 평균이 5인 포아송 분포를 따름 (2) 1분동안 맥도날드 매장에 들어오는 여자의 수는 평균이 4.5인 포아송분포를 따름 (3) 남자와 여자가 매장에 오는 사건은 독립 => 1분동안 맥도날드 매장에 오는 사람은 평균이 9.5인 포아송 분포를 따른다는 의미.\n\n(실습)\n\nlet \n    N= 1000\n    X = rand(Poisson(5),N)\n    Y = rand(Poisson(4.5),N)\n    p1 = X.+Y |> histogram \n    p2 = rand(Poisson(9.5),N) |> histogram\n    plot(p1,p2,layout=(2,1))\nend"
  },
  {
    "objectID": "posts/Study/2023-04-24-베르누이.html#평균과-분산의-추정",
    "href": "posts/Study/2023-04-24-베르누이.html#평균과-분산의-추정",
    "title": "[SC2022] 포아송분포, 지수분포",
    "section": "평균과 분산의 추정",
    "text": "평균과 분산의 추정\n\n평균: 5\n평균의 추정치: 5.062\n분산: 5\n분산의 추정치: 5.039195195195196\n\n\nlet\n    N=1000\n    λ=5 \n    X = rand(Poisson(λ),N) \nend\n\n1000-element Vector{Int64}:\n 7\n 6\n 5\n 6\n 2\n 4\n 6\n 2\n 7\n 8\n 1\n 5\n 3\n ⋮\n 5\n 4\n 4\n 4\n 5\n 7\n 4\n 1\n 9\n 4\n 9\n 5\n\n\n\n생각해보니까 왜 평균추정값과 분산추정값이 달라야하나?\nmean(X), var(X)로 \\(\\lambda\\) 추정\n\nlet \n    N = 10000\n    λ = 5 \n    p1=[mean(rand(Poisson(λ),N)) for k in 1:100] |> histogram\n    p2=[var(rand(Poisson(λ),N)) for k in 1:100] |> histogram\n    #p3=[(mean(rand(Poisson(λ),n))+var(rand(Poisson(λ),n)))/2  for k in 1:100] |> histogram\n    _p=plot(p1,p2,layout=(2,1),xlim=(4.8,5.2))\nend \n\n    \n    \n\n\n\n히스토그램을 그려보니까 누가봐도 mean(X)로 λ를 추정하는것이 var(X)로 λ를 추정하는것 보다 좋아 보인다.\n그냥 mean(X)=평균추정량=분산추정량 이라고 주장하면 안되나? => 됩니다! 이게 바로 MLE에요!"
  },
  {
    "objectID": "posts/Study/2023-04-03-일사량.html",
    "href": "posts/Study/2023-04-03-일사량.html",
    "title": "일사량자료정리(수정 for ARIMA)",
    "section": "",
    "text": "import pandas as pd\nimport numpy as np\nimport itertools\n\n\ndf0 = pd.read_csv('https://raw.githubusercontent.com/pinkocto/noteda/main/posts/SOLAR/data/OBS_ASOS_TIM_data0.csv', encoding='cp949') # 2021-01-01 ~ 2021-12-31\ndf1 = pd.read_csv('https://raw.githubusercontent.com/pinkocto/noteda/main/posts/SOLAR/data/OBS_ASOS_TIM_data1.csv') # 2022-01-01 ~ 2023-12-31\ndf2 = pd.read_csv('https://raw.githubusercontent.com/pinkocto/noteda/main/posts/SOLAR/data/test_raw.csv', encoding='cp949') # 2023-01-01 ~ 2023-01-15\n\n- df_raw\n\ndf_raw = pd.concat([df0, df1])\ndf_raw\n\n\n\n\n\n  \n    \n      \n      지점\n      지점명\n      일시\n      일사(MJ/m2)\n    \n  \n  \n    \n      0\n      93\n      북춘천\n      2021-01-01 08:00\n      0.00\n    \n    \n      1\n      93\n      북춘천\n      2021-01-01 09:00\n      0.37\n    \n    \n      2\n      93\n      북춘천\n      2021-01-01 10:00\n      0.96\n    \n    \n      3\n      93\n      북춘천\n      2021-01-01 11:00\n      1.40\n    \n    \n      4\n      93\n      북춘천\n      2021-01-01 12:00\n      1.72\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      229672\n      283\n      경주시\n      2022-12-31 14:00:00\n      1.82\n    \n    \n      229673\n      283\n      경주시\n      2022-12-31 15:00:00\n      1.52\n    \n    \n      229674\n      283\n      경주시\n      2022-12-31 16:00:00\n      0.96\n    \n    \n      229675\n      283\n      경주시\n      2022-12-31 17:00:00\n      0.35\n    \n    \n      229676\n      283\n      경주시\n      2022-12-31 18:00:00\n      0.01\n    \n  \n\n444720 rows × 4 columns\n\n\n\n- 지점칼럼 삭제 // 일시 \\(\\to\\) 날짜, 시간으로 분리\n\ndf_temp = df_raw.assign(날짜= list(map(lambda x: x[:10],df_raw['일시'])))\\\n.assign(시간 = list(map(lambda x: x[11:16], df_raw['일시'])))\\\n.drop(['일시','지점'], axis=1).rename({'일사(MJ/m2)':'일사'},axis=1).reset_index(drop=True)\ndf_temp\n\n\n\n\n\n  \n    \n      \n      지점명\n      일사\n      날짜\n      시간\n    \n  \n  \n    \n      0\n      북춘천\n      0.00\n      2021-01-01\n      08:00\n    \n    \n      1\n      북춘천\n      0.37\n      2021-01-01\n      09:00\n    \n    \n      2\n      북춘천\n      0.96\n      2021-01-01\n      10:00\n    \n    \n      3\n      북춘천\n      1.40\n      2021-01-01\n      11:00\n    \n    \n      4\n      북춘천\n      1.72\n      2021-01-01\n      12:00\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      444715\n      경주시\n      1.82\n      2022-12-31\n      14:00\n    \n    \n      444716\n      경주시\n      1.52\n      2022-12-31\n      15:00\n    \n    \n      444717\n      경주시\n      0.96\n      2022-12-31\n      16:00\n    \n    \n      444718\n      경주시\n      0.35\n      2022-12-31\n      17:00\n    \n    \n      444719\n      경주시\n      0.01\n      2022-12-31\n      18:00\n    \n  \n\n444720 rows × 4 columns\n\n\n\n- 파주, 상주, 동두천, 충주, 제천은 삭제\n\ndf_temp = df_temp.query(\"지점명 not in ['파주','상주','동두천','충주','제천']\").reset_index(drop=True)\ndf_temp\n\n\n\n\n\n  \n    \n      \n      지점명\n      일사\n      날짜\n      시간\n    \n  \n  \n    \n      0\n      북춘천\n      0.00\n      2021-01-01\n      08:00\n    \n    \n      1\n      북춘천\n      0.37\n      2021-01-01\n      09:00\n    \n    \n      2\n      북춘천\n      0.96\n      2021-01-01\n      10:00\n    \n    \n      3\n      북춘천\n      1.40\n      2021-01-01\n      11:00\n    \n    \n      4\n      북춘천\n      1.72\n      2021-01-01\n      12:00\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      420955\n      경주시\n      1.82\n      2022-12-31\n      14:00\n    \n    \n      420956\n      경주시\n      1.52\n      2022-12-31\n      15:00\n    \n    \n      420957\n      경주시\n      0.96\n      2022-12-31\n      16:00\n    \n    \n      420958\n      경주시\n      0.35\n      2022-12-31\n      17:00\n    \n    \n      420959\n      경주시\n      0.01\n      2022-12-31\n      18:00\n    \n  \n\n420960 rows × 4 columns\n\n\n\n\n–수정\n- 시간이 비어있지 않도록…\n\nreg = df_temp['지점명'].unique().tolist() \nday = df_temp['날짜'].unique().tolist() \n# time = list(df_temp['시간'].unique())\n# time = ['0{}:00'.format(i) for i in range(0,8)] + time\ntime = ['0{}:00'.format(i) for i in range(0,10)] + ['{}:00'.format(i) for i in range(10,24)]\n\n\ndf_temp2 = pd.DataFrame(itertools.product(reg,day,time)).rename({0:'지점명',1:'날짜',2:'시간'},axis=1).merge(df_temp,how='left').fillna(0)\ndf_temp2\n\n\n\n\n\n  \n    \n      \n      지점명\n      날짜\n      시간\n      일사\n    \n  \n  \n    \n      0\n      북춘천\n      2021-01-01\n      00:00\n      0.0\n    \n    \n      1\n      북춘천\n      2021-01-01\n      01:00\n      0.0\n    \n    \n      2\n      북춘천\n      2021-01-01\n      02:00\n      0.0\n    \n    \n      3\n      북춘천\n      2021-01-01\n      03:00\n      0.0\n    \n    \n      4\n      북춘천\n      2021-01-01\n      04:00\n      0.0\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      770875\n      경주시\n      2022-12-31\n      19:00\n      0.0\n    \n    \n      770876\n      경주시\n      2022-12-31\n      20:00\n      0.0\n    \n    \n      770877\n      경주시\n      2022-12-31\n      21:00\n      0.0\n    \n    \n      770878\n      경주시\n      2022-12-31\n      22:00\n      0.0\n    \n    \n      770879\n      경주시\n      2022-12-31\n      23:00\n      0.0\n    \n  \n\n770880 rows × 4 columns\n\n\n\n\ndf_temp2[:10]\n\n\n\n\n\n  \n    \n      \n      지점명\n      날짜\n      시간\n      일사\n    \n  \n  \n    \n      0\n      북춘천\n      2021-01-01\n      00:00\n      0.00\n    \n    \n      1\n      북춘천\n      2021-01-01\n      01:00\n      0.00\n    \n    \n      2\n      북춘천\n      2021-01-01\n      02:00\n      0.00\n    \n    \n      3\n      북춘천\n      2021-01-01\n      03:00\n      0.00\n    \n    \n      4\n      북춘천\n      2021-01-01\n      04:00\n      0.00\n    \n    \n      5\n      북춘천\n      2021-01-01\n      05:00\n      0.00\n    \n    \n      6\n      북춘천\n      2021-01-01\n      06:00\n      0.00\n    \n    \n      7\n      북춘천\n      2021-01-01\n      07:00\n      0.00\n    \n    \n      8\n      북춘천\n      2021-01-01\n      08:00\n      0.00\n    \n    \n      9\n      북춘천\n      2021-01-01\n      09:00\n      0.37\n    \n  \n\n\n\n\n\ndf_temp2[:-10]\n\n\n\n\n\n  \n    \n      \n      지점명\n      날짜\n      시간\n      일사\n    \n  \n  \n    \n      0\n      북춘천\n      2021-01-01\n      00:00\n      0.00\n    \n    \n      1\n      북춘천\n      2021-01-01\n      01:00\n      0.00\n    \n    \n      2\n      북춘천\n      2021-01-01\n      02:00\n      0.00\n    \n    \n      3\n      북춘천\n      2021-01-01\n      03:00\n      0.00\n    \n    \n      4\n      북춘천\n      2021-01-01\n      04:00\n      0.00\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      770865\n      경주시\n      2022-12-31\n      09:00\n      0.41\n    \n    \n      770866\n      경주시\n      2022-12-31\n      10:00\n      1.05\n    \n    \n      770867\n      경주시\n      2022-12-31\n      11:00\n      1.52\n    \n    \n      770868\n      경주시\n      2022-12-31\n      12:00\n      1.86\n    \n    \n      770869\n      경주시\n      2022-12-31\n      13:00\n      1.93\n    \n  \n\n770870 rows × 4 columns\n\n\n\n- 시간,날짜 \\(\\to\\) 일시\n\ndf_temp3=df_temp2.assign(일시 = list(map(lambda x,y: x+'-'+y,df_temp2['날짜'],df_temp2['시간'])))\\\n.drop(['날짜','시간'],axis=1)\ndf_temp3\n\n\n\n\n\n  \n    \n      \n      지점명\n      일사\n      일시\n    \n  \n  \n    \n      0\n      북춘천\n      0.0\n      2021-01-01-00:00\n    \n    \n      1\n      북춘천\n      0.0\n      2021-01-01-01:00\n    \n    \n      2\n      북춘천\n      0.0\n      2021-01-01-02:00\n    \n    \n      3\n      북춘천\n      0.0\n      2021-01-01-03:00\n    \n    \n      4\n      북춘천\n      0.0\n      2021-01-01-04:00\n    \n    \n      ...\n      ...\n      ...\n      ...\n    \n    \n      770875\n      경주시\n      0.0\n      2022-12-31-19:00\n    \n    \n      770876\n      경주시\n      0.0\n      2022-12-31-20:00\n    \n    \n      770877\n      경주시\n      0.0\n      2022-12-31-21:00\n    \n    \n      770878\n      경주시\n      0.0\n      2022-12-31-22:00\n    \n    \n      770879\n      경주시\n      0.0\n      2022-12-31-23:00\n    \n  \n\n770880 rows × 3 columns\n\n\n\n- 저장\n\ndf_temp3.rename({'지점명':'region','일사':'solar_radiation','일시':'date'},axis=1)\n\n\n\n\n\n  \n    \n      \n      region\n      solar_radiation\n      date\n    \n  \n  \n    \n      0\n      북춘천\n      0.0\n      2021-01-01-00:00\n    \n    \n      1\n      북춘천\n      0.0\n      2021-01-01-01:00\n    \n    \n      2\n      북춘천\n      0.0\n      2021-01-01-02:00\n    \n    \n      3\n      북춘천\n      0.0\n      2021-01-01-03:00\n    \n    \n      4\n      북춘천\n      0.0\n      2021-01-01-04:00\n    \n    \n      ...\n      ...\n      ...\n      ...\n    \n    \n      770875\n      경주시\n      0.0\n      2022-12-31-19:00\n    \n    \n      770876\n      경주시\n      0.0\n      2022-12-31-20:00\n    \n    \n      770877\n      경주시\n      0.0\n      2022-12-31-21:00\n    \n    \n      770878\n      경주시\n      0.0\n      2022-12-31-22:00\n    \n    \n      770879\n      경주시\n      0.0\n      2022-12-31-23:00\n    \n  \n\n770880 rows × 3 columns\n\n\n\n\ndf = df_temp3.rename({'지점명':'region','일사':'solar_radiation','일시':'date'},axis=1)\ndf.to_csv(\"solar_radiation2.csv\",index=False)\n!git add .\n!git commit -m .\n!git push \n\n[main 2af59d2] .\n 13 files changed, 780980 insertions(+), 2928 deletions(-)\n create mode 100644 \"posts/Study/.ipynb_checkpoints/2023-04-03-\\354\\235\\274\\354\\202\\254\\353\\237\\211-checkpoint.ipynb\"\n create mode 100644 posts/Study/.ipynb_checkpoints/2023-04-10-arima-ex-checkpoint.ipynb\n create mode 100644 posts/Study/.ipynb_checkpoints/2023-04-10-arima-ex-day-checkpoint.ipynb\n create mode 100644 posts/Study/.ipynb_checkpoints/2023-04-11-arima-hour-data-fill-checkpoint.ipynb\n create mode 100644 \"posts/Study/2023-04-03-\\354\\235\\274\\354\\202\\254\\353\\237\\211.ipynb\"\n create mode 100644 posts/Study/2023-04-10-arima-ex-day.ipynb\n create mode 100644 posts/Study/2023-04-10-arima-ex.ipynb\n create mode 100644 posts/Study/2023-04-11-arima-hour-data-fill.ipynb\n create mode 100644 posts/Study/solar_radiation2.csv\nEnumerating objects: 17, done.\nCounting objects: 100% (17/17), done.\nDelta compression using up to 16 threads\nCompressing objects: 100% (13/13), done.\nWriting objects: 100% (13/13), 3.21 MiB | 1.27 MiB/s, done.\nTotal 13 (delta 6), reused 0 (delta 0), pack-reused 0\nremote: Resolving deltas: 100% (6/6), completed with 2 local objects.\nTo https://github.com/pinkocto/noteda\n   0bb5fb7..2af59d2  main -> main\n\n\n- 불러오기\n\n# df = pd.read_csv(\"https://raw.githubusercontent.com/pinkocto/noteda/main/posts/SOLAR/data/solar_radiation2.csv\")\n# df\n\n- 다운로드\n\n# !wget https://raw.githubusercontent.com/miruetoto/yechan3/main/posts/3_Researches/SOLAR/solar_radiation.csv"
  },
  {
    "objectID": "posts/Study/2023-05-08-gcrn리뷰.html",
    "href": "posts/Study/2023-05-08-gcrn리뷰.html",
    "title": "GCRN",
    "section": "",
    "text": "STRUCTURED SEQUENCE MODELING WITH GRAPH CONVOLUTIONAL RECURRENT NETWORKS\nThis paper introduces Graph Convolutional Recurrent Network (GCRN), a deep learning model able to predict structured sequences of data. Precisely, GCRN is a generalization of classical recurrent neural networks (RNN) to data structured by an arbitrary graph. Such structured sequences can represent series of frames in videos, spatio-temporal measurements on a network of sensors, or random walks on a vocabulary graph for natural language modeling. The proposed model combines convolutional neural networks (CNN) on graphs to identify spatial structures and RNN to find dynamic patterns. We study two possible architectures of GCRN, and apply the models to two practical problems: predicting moving MNIST data, and modeling natural language with the Penn Treebank dataset. Experiments show that exploiting simultaneously graph spatial and dynamic information about data can improve both precision and learning speed.\n본 논문은 구조화된 데이터 시퀀스를 예측할 수 있는 딥러닝 모델인 Graph Convolutional Recurrent Network (GCRN)에 대해 소개한다. GCRN은 임의의 그래프로 구조화된 데이터에 대한 고전적인 recurrnet neural network(RNN)의 일반화 버전이다.\n제안된 모델은 convolutional neural networks(CNN)을 결합하여 공간 구조를 식별하고 동적 패턴을 찾는 RNN을 결합한다.\n본 논문에서는 GCRN의 두 가지 가능한 아키텍처를 연구하고 모델을 두 가지 실제 문제에 적용해본다. (moving-MNIST 데이터 예측, 펜트리뱅크 데이터 셋을 이용한 자연어 모델링)\n실험에 따르면 데이터에 대한 그래프 공간 정보와 동적 정보를 동시에 활용하면 정밀도와 학습속도를 모두 향상시킬 수 있다고 한다."
  },
  {
    "objectID": "posts/Study/2023-05-08-gcrn리뷰.html#introduction",
    "href": "posts/Study/2023-05-08-gcrn리뷰.html#introduction",
    "title": "GCRN",
    "section": "INTRODUCTION",
    "text": "INTRODUCTION\nMany real-world data can be cast as structured sequences, with spatio-temporal sequences being a special case. A well-studied example of spatio-temporal data are videos, where succeeding frames share temporal and spatial structures. Many works, such as Donahue et al. (2015); Karpathy & FeiFei (2015); Vinyals et al. (2015), leveraged a combination of CNN and RNN to exploit such spatial and temporal regularities. Their models are able to process possibly time-varying visual inputs for variable-length prediction. These neural network architectures consist of combining a CNN for visual feature extraction followed by a RNN for sequence learning. Such architectures have been successfully used for video activity recognition, image captioning and video description. More recently, interest has grown in properly fusing the CNN and RNN models for spatio-temporal sequence modeling. Inspired by language modeling, Ranzato et al. (2014) proposed a model to represent complex deformations and motion patterns by discovering both spatial and temporal correlations. They showed that prediction of the next video frame and interpolation of intermediate frames can be achieved by building a RNN-based language model on the visual words obtained by quantizing the image patches. Their highest-performing model, recursive CNN (rCNN), uses convolutions for both inputs and states. Shi et al. (2015) then proposed the convolutional LSTM network (convLSTM), a recurrent model for spatio-temporal sequence modeling which uses 2D-grid convolution to leverage the spatial correlations in input data. They successfully applied their model to the prediction of the evolution of radar echo maps for precipitation nowcasting. The spatial structure of many important problems may however not be as simple as regular grids.\nFor instance, the data measured from meteorological stations lie on a irregular grid, i.e. a network of heterogeneous spatial distribution of stations. More challenging, the spatial structure of data may not even be spatial, as it is the case for social or biological networks. Eventually, the interpretation that sentences can be regarded as random walks on vocabulary graphs, a view popularized by Mikolov et al. (2013), allows us to cast language analysis problems as graph-structured sequence models."
  },
  {
    "objectID": "posts/Study/2023-05-08-gcrn리뷰.html#proposed-gcrn-models",
    "href": "posts/Study/2023-05-08-gcrn리뷰.html#proposed-gcrn-models",
    "title": "GCRN",
    "section": "PROPOSED GCRN MODELS",
    "text": "PROPOSED GCRN MODELS\nimport torch\nfrom torch_geometric.nn import ChebConv\n\n\n[docs]class GConvGRU(torch.nn.Module):\n    r\"\"\"An implementation of the Chebyshev Graph Convolutional Gated Recurrent Unit\n    Cell. For details see this paper: `\"Structured Sequence Modeling with Graph\n    Convolutional Recurrent Networks.\" <https://arxiv.org/abs/1612.07659>`_\n\n    Args:\n        in_channels (int): Number of input features.\n        out_channels (int): Number of output features.\n        K (int): Chebyshev filter size :math:`K`.\n        normalization (str, optional): The normalization scheme for the graph\n            Laplacian (default: :obj:`\"sym\"`):\n\n            1. :obj:`None`: No normalization\n            :math:`\\mathbf{L} = \\mathbf{D} - \\mathbf{A}`\n\n            2. :obj:`\"sym\"`: Symmetric normalization\n            :math:`\\mathbf{L} = \\mathbf{I} - \\mathbf{D}^{-1/2} \\mathbf{A}\n            \\mathbf{D}^{-1/2}`\n\n            3. :obj:`\"rw\"`: Random-walk normalization\n            :math:`\\mathbf{L} = \\mathbf{I} - \\mathbf{D}^{-1} \\mathbf{A}`\n\n            You need to pass :obj:`lambda_max` to the :meth:`forward` method of\n            this operator in case the normalization is non-symmetric.\n            :obj:`\\lambda_max` should be a :class:`torch.Tensor` of size\n            :obj:`[num_graphs]` in a mini-batch scenario and a\n            scalar/zero-dimensional tensor when operating on single graphs.\n            You can pre-compute :obj:`lambda_max` via the\n            :class:`torch_geometric.transforms.LaplacianLambdaMax` transform.\n        bias (bool, optional): If set to :obj:`False`, the layer will not learn\n            an additive bias. (default: :obj:`True`)\n    \"\"\"\n\n    def __init__(\n        self,\n        in_channels: int,\n        out_channels: int,\n        K: int,\n        normalization: str = \"sym\",\n        bias: bool = True,\n    ):\n        super(GConvGRU, self).__init__()\n\n        self.in_channels = in_channels\n        self.out_channels = out_channels\n        self.K = K\n        self.normalization = normalization\n        self.bias = bias\n        self._create_parameters_and_layers()\n\n    def _create_update_gate_parameters_and_layers(self):\n\n        self.conv_x_z = ChebConv(\n            in_channels=self.in_channels,\n            out_channels=self.out_channels,\n            K=self.K,\n            normalization=self.normalization,\n            bias=self.bias,\n        )\n\n        self.conv_h_z = ChebConv(\n            in_channels=self.out_channels,\n            out_channels=self.out_channels,\n            K=self.K,\n            normalization=self.normalization,\n            bias=self.bias,\n        )\n\n    def _create_reset_gate_parameters_and_layers(self):\n\n        self.conv_x_r = ChebConv(\n            in_channels=self.in_channels,\n            out_channels=self.out_channels,\n            K=self.K,\n            normalization=self.normalization,\n            bias=self.bias,\n        )\n\n        self.conv_h_r = ChebConv(\n            in_channels=self.out_channels,\n            out_channels=self.out_channels,\n            K=self.K,\n            normalization=self.normalization,\n            bias=self.bias,\n        )\n\n    def _create_candidate_state_parameters_and_layers(self):\n\n        self.conv_x_h = ChebConv(\n            in_channels=self.in_channels,\n            out_channels=self.out_channels,\n            K=self.K,\n            normalization=self.normalization,\n            bias=self.bias,\n        )\n\n        self.conv_h_h = ChebConv(\n            in_channels=self.out_channels,\n            out_channels=self.out_channels,\n            K=self.K,\n            normalization=self.normalization,\n            bias=self.bias,\n        )\n\n    def _create_parameters_and_layers(self):\n        self._create_update_gate_parameters_and_layers()\n        self._create_reset_gate_parameters_and_layers()\n        self._create_candidate_state_parameters_and_layers()\n\n    def _set_hidden_state(self, X, H):\n        if H is None:\n            H = torch.zeros(X.shape[0], self.out_channels).to(X.device)\n        return H\n\n    def _calculate_update_gate(self, X, edge_index, edge_weight, H, lambda_max):\n        Z = self.conv_x_z(X, edge_index, edge_weight, lambda_max=lambda_max)\n        Z = Z + self.conv_h_z(H, edge_index, edge_weight, lambda_max=lambda_max)\n        Z = torch.sigmoid(Z)\n        return Z\n\n    def _calculate_reset_gate(self, X, edge_index, edge_weight, H, lambda_max):\n        R = self.conv_x_r(X, edge_index, edge_weight, lambda_max=lambda_max)\n        R = R + self.conv_h_r(H, edge_index, edge_weight, lambda_max=lambda_max)\n        R = torch.sigmoid(R)\n        return R\n\n    def _calculate_candidate_state(self, X, edge_index, edge_weight, H, R, lambda_max):\n        H_tilde = self.conv_x_h(X, edge_index, edge_weight, lambda_max=lambda_max)\n        H_tilde = H_tilde + self.conv_h_h(H * R, edge_index, edge_weight, lambda_max=lambda_max)\n        H_tilde = torch.tanh(H_tilde)\n        return H_tilde\n\n    def _calculate_hidden_state(self, Z, H, H_tilde):\n        H = Z * H + (1 - Z) * H_tilde\n        return H\n\n[docs]    def forward(\n        self,\n        X: torch.FloatTensor,\n        edge_index: torch.LongTensor,\n        edge_weight: torch.FloatTensor = None,\n        H: torch.FloatTensor = None,\n        lambda_max: torch.Tensor = None,\n    ) -> torch.FloatTensor:\n        \"\"\"\n        Making a forward pass. If edge weights are not present the forward pass\n        defaults to an unweighted graph. If the hidden state matrix is not present\n        when the forward pass is called it is initialized with zeros.\n\n        Arg types:\n            * **X** *(PyTorch Float Tensor)* - Node features.\n            * **edge_index** *(PyTorch Long Tensor)* - Graph edge indices.\n            * **edge_weight** *(PyTorch Long Tensor, optional)* - Edge weight vector.\n            * **H** *(PyTorch Float Tensor, optional)* - Hidden state matrix for all nodes.\n            * **lambda_max** *(PyTorch Tensor, optional but mandatory if normalization is not sym)* - Largest eigenvalue of Laplacian.\n\n\n        Return types:\n            * **H** *(PyTorch Float Tensor)* - Hidden state matrix for all nodes.\n        \"\"\"\n        H = self._set_hidden_state(X, H)\n        Z = self._calculate_update_gate(X, edge_index, edge_weight, H, lambda_max)\n        R = self._calculate_reset_gate(X, edge_index, edge_weight, H, lambda_max)\n        H_tilde = self._calculate_candidate_state(X, edge_index, edge_weight, H, R, lambda_max)\n        H = self._calculate_hidden_state(Z, H, H_tilde)\n        return H"
  },
  {
    "objectID": "posts/Study/2023-03-05-기하학적딥러닝-survey-review.html",
    "href": "posts/Study/2023-03-05-기하학적딥러닝-survey-review.html",
    "title": "[PAPER] A Comprehensive Survey on Geometric Deep Learning (+++)",
    "section": "",
    "text": "# !pip install torch-geometric\n# !pip install torch-geometric-temporal\nconda install pyg -c pyg"
  },
  {
    "objectID": "posts/Study/2023-03-05-기하학적딥러닝-survey-review.html#i.-introduction",
    "href": "posts/Study/2023-03-05-기하학적딥러닝-survey-review.html#i.-introduction",
    "title": "[PAPER] A Comprehensive Survey on Geometric Deep Learning (+++)",
    "section": "I. INTRODUCTION",
    "text": "I. INTRODUCTION\nWith the emergence of larger data scale and more powerful GPU computing ability, people begin to be more and more interested in processing data in non-Euclidean domain, such as graphs and manifolds. This type of data is ubiquitous in real life. It is of great significance to study deep learning techniques in non-Euclidean domains. This is called geometric deep learning.\n\nminifold data?\n\nThe geometric deep learning mainly study graph and man\u0002ifold data. The graph is composed of nodes and edges of the network structure data. For instance, in social network, each node represent a person’s information and the edge represent the relationship between people. The edges can be directed or undirected depending on the relationship of the connecting vertices. The Manifold data are usually used to describe geometric shapes, such as surface of objects returned by radar scanning. These geometric data are irregularly arranged and randomly distributed, which makes it difficult for people to find out the underlying pattern. Specifically, it is difficult to find the neighbor nodes of a certain point in the data, or the number of a node’s neighbor is different in [9]. This makes it difficult to define convolution operations like those on images. On the other hand, data like images in the Euclidean domain can be regarded as a special graph data, with vertices arranged in a regular way. Another issue is that non-Euclidean data usually has extraordinarily large scale. For example, molecular graph can have hundreds of millions of nodes. For this case, it is unlikely to use the traditional deep learning technology to carry out analysis and prediction tasks. This is why deep learning is so important in the field of geometric data.\nThe purpose of this survey is to review and summarize the geometric deep learning frameworks and algorithms developed on graphs and manifolds data, and to introduce the practical difficulties and development directions in this new rising field\nBRIEF HISTORY\nThe history of geometric deep learning filed is not very long. Although it seems that this area is in its infancy, the deep learning behind its development has a long history. The rapid development of deep learning technologies such as convolutional neural network greatly pushes the progress of geometric deep learning. After all, studying geometric deep learning is to study how to define the non-Euclidean world mathematically, and how to transplant the existing frameworks and algorithms of deep learning to handle graphs and manifolds data effectively. In general, geometric deep learning can be mainly divided into two major research directions, one is for processing graph data (i.e. graph networks or grid-like data); the other is for processing manifold data (i.e. generally for processing 3D point cloud data). Among them, graph data processing is more popular, and people aim to extend the deep learning technologies to non-Euclidean structural data.\nAs early as in 2005, M. Gori et al. first proposed a graph neural network (GNN) to process graph data [10] such as directed graphs, undirected graphs, labeled graphs, and recurrent graphs. The work of [11] published by Scarselli et al. in 2009 brought back the graph neural network model to the public’s horizon, defined a function that can map graph and any node to a dimensional Euclidean space, and proposed an algorithm to estimate the neural network model parameter with supervised learning.\nIn the work of [12] proposed spectral convolutional neural networks on graphs. Work of [13] extended the spectral network by combining a graph estimation process. diffusion convolutional neural network (DCNN) was next proposed in [14] to learning diffusion based representation from graph data for node classification. The work of [9], similar to image based convolutional network operating on the input locally connected region, proposed a general method to extract the locally connected region from the graph.\nIn 2016, M. Defferrard et al. proposed ChebNet[15], and then a simplified version GCN (graph convolutional network) was proposed [16]. One year later, CayleyNet was proposed by Levie et al. [17]. All the above research results were based on the idea of convolutional network. Besides graph convolution model, there are other similar studies conducted in parallel, such as graph attention networks, graph generative networks, and graph auto-encoders that will be seen in section III.\nAt the same time, research of deep learning theory on manifold data are also carried out. There have been two traditional research methods on manifolds, one is to fill 3D shapes with many voxel grids (cube blocks), and each"
  },
  {
    "objectID": "posts/Study/2023-03-05-기하학적딥러닝-survey-review.html#ii.-background",
    "href": "posts/Study/2023-03-05-기하학적딥러닝-survey-review.html#ii.-background",
    "title": "[PAPER] A Comprehensive Survey on Geometric Deep Learning (+++)",
    "section": "II. BACKGROUND",
    "text": "II. BACKGROUND\nIn this section, we give a basic background introduction on graph and manifold theories. voxel can be processed by 3D CNN opreation, called 3D volumetric CNN.\n\nA. Graph and Laplacian Matrix\n\nref: https://pinkocto.github.io/mm/posts/GNN/2023-03-13-chap2.html#graph-theory\n\n\\[ \\bf{G} = (\\bf{V},\\bf{E})\\]\nLet \\(v_i \\in \\bf{V}\\) represent a node and \\(e_{ij} = (v_i, v_j) \\in \\bf{E}\\) to represent an edge between \\(v_i\\) and \\(v_j\\) .\n\n\\(\\bf{V}\\): the set of vertices or nodes.\n\\(\\bf{E}\\): the set of edges.\n\\(M = |\\bf{E}|\\) : total number of edges\n\\(\\bf{A}\\) : \\(N \\times N\\) matrix of edge weights where:\n\n\\[\\begin{cases}\n& \\bf{A}_{ij} = a_{ij} > 0 &&  \\text{if } e_{ij}  \\in \\bf{E} \\\\\n& \\bf{A}_{ij} = 0 &&  \\text{if } e_{ij} \\notin \\bf{E}\n\\end{cases}\\]\nThe edges in an undirected graph are all undirected, i.e. an undirected graph’s edges are all undirected, any two nodes are just connected without direction. - For an undirected graph, \\(\\bf{A}_{ij}=\\bf{A}_{ji} = 1\\).\ndirected graph has edges going from one node to another. - For a directed graph, \\(\\bf{A}_{ij} \\neq \\bf{A}_{ji}\\)\nThe Laplacian matrix of a graph is defined as - \\(\\bf{L} = \\bf{D} - \\bf{A}\\) - \\(\\bf{D}\\): degree matrix, which is diagonal.\nthe diagonal elements are the degrees of nodes, which is defined as the number of connecting edges, namely, \\(\\bf{D}_{ii} = \\sum_j \\bf{A}_{ij}\\)\nThe common Laplacian matrix usually has the following three forms, Combinatorial Laplacian:\n\n- Combinatorial Laplacian: (가장 기초적인 라플라시안)\n\\[ \\bf{L} = \\bf{D} - \\bf{A}\\]\nPositive semi-definite 행렬이고, \\(N\\)개의 음이 아닌 고윳값을 갖는다.\n\n\n- Symmetric Nomalized Laplacian:\n\\[ \\bf{L}^{sym}  = \\bf{D}^{-\\frac{1}{2}}\\bf{L}\\bf{D}^{-\\frac{1}{2}} = \\bf{I} - \\bf{D}^{-\\frac{1}{2}}\\bf{A}\\bf{D}^{-\\frac{1}{2}}\\]\n\n\n- Random Walk Nomalized Laplacian:\n\\[\\bf{L}^{rw} = \\bf{D}^{-1}\\bf{L} = \\bf{I} - \\bf{D}^{-1}\\bf{A}\\]\nFor an undirected graph \\(G\\), the Laplacian matrix \\(\\bf{L}\\) is symmetric and positive-semidefinite. The dimension of the eigenspace is \\(N\\).\n\n참고: Definite matrix\npositive-definite?\n\n영벡터가 아닌 임의의 열벡터 \\(\\bf{x}\\)와 대칭행렬 \\(\\bf{A}\\)에 대해 다음이 성립한다면 \\(\\bf{A}\\)는 양의 정부호(positive definite) 행렬이다.\n\\(\\text{M positive-definite} \\Leftrightarrow \\bf{x}^\\top \\bf{A} \\bf{x} > 0 \\text{ for all } \\bf{x} \\in \\mathbb{R}^n \\text{ \\ } \\{0\\}\\)\n\npositive-semidefinite?\n\nsemi-definite은 \\(0\\)을 포함한 양수\n$ \\bf{x} ^n {0}$\n\n\n\n\n\nB. Fourier Transformation on Graphs\nThe key of graph convolutional network based on spectral method is the eigen-decomposition of Laplacian matrix, so Laplacian matrix plays a very important role. The normalized Laplacian matrix is a semi-positive definite symmetric matrix, it has \\(N\\) linearly independent and mutually orthogonal eigenvectors, and N non-negative eigenvalues. Therefore, Laplacian matrix can be decomposed into the following formula:\n\\[\\bf{L} = \\bf{U}\\Lambda\\bf{U}^{-1}\\]\n여기서 \\(\\bf{U} = [u_0, u_1, \\dots, u_{N-1}] \\in \\mathbb{R}^{N\\times N}\\)\n\\(\\bf{U}\\)는 orthogonal matrix. \\((\\bf{U}^{-1} = \\bf{U}^\\top)\\)\n\n\nC. Convolution on Graphs\nThe convolution theorem states that the Fourier transform of convolution is the product of Fourier transforms, by analogy to the graph and puts in the definition of the Fourier transform on graph. Now the graph convolution of the input signal \\(\\bf{x}\\) with a filter \\(g \\in \\mathbb{R}^N\\) is defined as\n\\[ \\bf{x}_G^*g = \\bf{U}\\big(\\big(\\bf{U}^\\top \\bf{x}\\big) \\odot \\big(\\bf{U}^\\top g\\big)\\big)\\]\n\n\\(\\odot\\) : Hadamard product, in which the two elements from the sample location are multiplied."
  },
  {
    "objectID": "posts/Study/2023-03-05-기하학적딥러닝-survey-review.html#iii.-methods",
    "href": "posts/Study/2023-03-05-기하학적딥러닝-survey-review.html#iii.-methods",
    "title": "[PAPER] A Comprehensive Survey on Geometric Deep Learning (+++)",
    "section": "III. METHODS",
    "text": "III. METHODS\nWith the background knowledge introduced, we now come to focus on the questions of constructing CNNs on non-Euclidean domains. At present, the two typical non-Euclidean geometric data in research are graphs and manifolds. Graphs refer to network structure data composed of nodes and edges, such as social network.\nmanifolds are often used to describe 3D geometric shapes, such as spatial coordinates on the surface of an object returned by a LiDAR scan.\n\n\n\nimage.png\n\n\n\nA. Methods of Graphs\n그래프 사용 예시: the graphs, such as social network, protein structure network, traffic network, and knowledge graph, and even some regular data like grid structural data (such as images, video, etc.)\n기존 딥러닝 알고리즘으로는 한계가 있다.\nt is important to note that graph data are different from images due to its irregularity. Each node in the graph may have different number of neighbors."
  },
  {
    "objectID": "posts/Study/2023-03-05-기하학적딥러닝-survey-review.html#iv.-applications",
    "href": "posts/Study/2023-03-05-기하학적딥러닝-survey-review.html#iv.-applications",
    "title": "[PAPER] A Comprehensive Survey on Geometric Deep Learning (+++)",
    "section": "IV. APPLICATIONS",
    "text": "IV. APPLICATIONS"
  },
  {
    "objectID": "posts/Study/2023-03-05-기하학적딥러닝-survey-review.html#v.-future-work-and-open-problems",
    "href": "posts/Study/2023-03-05-기하학적딥러닝-survey-review.html#v.-future-work-and-open-problems",
    "title": "[PAPER] A Comprehensive Survey on Geometric Deep Learning (+++)",
    "section": "V. FUTURE WORK AND OPEN PROBLEMS",
    "text": "V. FUTURE WORK AND OPEN PROBLEMS"
  },
  {
    "objectID": "posts/Study/2023-03-05-기하학적딥러닝-survey-review.html#vi.-conclusion",
    "href": "posts/Study/2023-03-05-기하학적딥러닝-survey-review.html#vi.-conclusion",
    "title": "[PAPER] A Comprehensive Survey on Geometric Deep Learning (+++)",
    "section": "VI. CONCLUSION",
    "text": "VI. CONCLUSION"
  },
  {
    "objectID": "posts/SOLAR/2023-05-01-차원조사.html",
    "href": "posts/SOLAR/2023-05-01-차원조사.html",
    "title": "[SOLAR] 차원조사",
    "section": "",
    "text": "ref: https://miruetoto.github.io/yechan3/posts/3_Researches/ITSTGCN/2022-12-29-STGCN-tutorial.html"
  },
  {
    "objectID": "posts/SOLAR/2023-05-01-차원조사.html#time-lag",
    "href": "posts/SOLAR/2023-05-01-차원조사.html#time-lag",
    "title": "[SOLAR] 차원조사",
    "section": "Time Lag",
    "text": "Time Lag\n\n\n\n\n\n\n\n설명변수\n반응변수\n\n\n\n\n\\[{\\bf X} = {\\tt features} = \\begin{bmatrix} {\\bf f}_1 & {\\bf f}_2 & {\\bf f}_3 & {\\bf f}_4 \\\\ {\\bf f}_2 & {\\bf f}_3 & {\\bf f}_4 & {\\bf f}_5 \\\\ \\dots & \\dots & \\dots & \\dots \\\\ {\\bf f}_{2564} & {\\bf f}_{2565} & {\\bf f}_{2566} & {\\bf f}_{2567} \\end{bmatrix}\\]\n\\[{\\bf y}= {\\tt targets} = \\begin{bmatrix} {\\bf f}_5 \\\\ {\\bf f}_6 \\\\ \\dots \\\\ {\\bf f}_{2568} \\end{bmatrix}\\]\n\n\n\n\nnp.array(dataset.features).shape, np.array(dataset.targets).shape\n\n((2564, 44, 4), (2564, 44))\n\n\n\n\\(\\bf X_{101 \\cdot} = [\\bf f_{101}, \\bf f_{102}, \\bf f_{103}, \\bf f_{104}]\\)\n- \\(\\bf f_{101}\\)\n\nnp.array(dataset.features)[100][:5], np.array(train_dataset.features)[100].shape\n\n(array([[0.  , 0.  , 0.05, 0.24],\n        [0.  , 0.  , 0.03, 0.22],\n        [0.  , 0.  , 0.04, 0.17],\n        [0.  , 0.  , 0.05, 0.21],\n        [0.  , 0.  , 0.01, 0.2 ]]),\n (44, 4))\n\n\n- \\(\\bf f_{102}\\)\n\nnp.array(dataset.features)[101][:5], np.array(train_dataset.features)[101].shape\n\n(array([[0.  , 0.05, 0.24, 0.38],\n        [0.  , 0.03, 0.22, 0.64],\n        [0.  , 0.04, 0.17, 0.5 ],\n        [0.  , 0.05, 0.21, 0.32],\n        [0.  , 0.01, 0.2 , 0.63]]),\n (44, 4))\n\n\n- \\(\\bf f_{103}\\)\n\nnp.array(dataset.features)[102][:5], np.array(train_dataset.features)[102].shape\n\n(array([[0.05, 0.24, 0.38, 0.57],\n        [0.03, 0.22, 0.64, 1.36],\n        [0.04, 0.17, 0.5 , 0.81],\n        [0.05, 0.21, 0.32, 0.45],\n        [0.01, 0.2 , 0.63, 1.03]]),\n (44, 4))\n\n\n- \\(\\bf f_{104}\\)\n\nnp.array(dataset.features)[103][:5], np.array(train_dataset.features)[103].shape\n\n(array([[0.24, 0.38, 0.57, 1.12],\n        [0.22, 0.64, 1.36, 1.7 ],\n        [0.17, 0.5 , 0.81, 1.5 ],\n        [0.21, 0.32, 0.45, 1.15],\n        [0.2 , 0.63, 1.03, 1.63]]),\n (44, 4))\n\n\n\n\n\\(\\bf y_{101} = \\bf f_{105}\\)\n- \\(\\bf f_{105}\\)\n\nnp.array(dataset.features)[104][:5], np.array(train_dataset.features)[104].shape\n\n(array([[0.38, 0.57, 1.12, 1.78],\n        [0.64, 1.36, 1.7 , 1.81],\n        [0.5 , 0.81, 1.5 , 2.41],\n        [0.32, 0.45, 1.15, 1.69],\n        [0.63, 1.03, 1.63, 1.56]]),\n (44, 4))\n\n\n- $\\bf y_{101} $\n\nnp.array(train_dataset.targets)[100]\n\narray([0.38, 0.64, 0.5 , 0.32, 0.63, 0.5 , 0.5 , 0.25, 0.16, 0.16, 0.17,\n       0.38, 0.4 , 0.24, 0.21, 0.18, 0.11, 0.19, 0.28, 0.27, 0.32, 0.19,\n       0.23, 0.14, 0.07, 0.11, 0.12, 0.34, 0.03, 0.23, 0.17, 0.24, 0.05,\n       0.23, 0.17, 0.41, 0.28, 0.07, 0.06, 0.3 , 0.35, 0.08, 0.17, 0.32])"
  },
  {
    "objectID": "posts/SOLAR/2023-04-25-s-stgcn-ver1-100에폭--이게진짜.html",
    "href": "posts/SOLAR/2023-04-25-s-stgcn-ver1-100에폭--이게진짜.html",
    "title": "[SOLAR] STGCN Ver1 (data2, -N +S) 30회 100epoch",
    "section": "",
    "text": "https://github.com/miruetoto/yechan3/tree/main/posts/3_Researches/ITSTGCN/itstgcn\nhttps://miruetoto.github.io/yechan3/posts/3_Researches/ITSTGCN/2023-03-18-SimulationPlanner-Tutorial.html#plnr_gnar_block\n\n\n\n\n\ntrain 2022-06-01 00:00:00 ~ 2022-08-14 17:00:00\ntest 2022-08-14 18:00:00 ~ 2022-09-15 23:00:00\n\n\n\n\n\nimport eptstgcn\nimport torch\nimport eptstgcn.planner\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\n\n\n\n\nurl = \"https://raw.githubusercontent.com/pinkocto/noteda/main/posts/SOLAR/data2/stgcn_data1.json\"\nloader = eptstgcn.DatasetLoader(url)\ndataset = loader.get_dataset(lags=4)\n\n\ntrain_dataset, test_dataset = eptstgcn.utils.temporal_signal_split(dataset, train_ratio = 0.7)\n\n\n\n\n\nlrnr = eptstgcn.StgcnLearner(train_dataset, dataset_name = 'data2(2022/06/01 ~ 2022/09/15)')\n\n\nlrnr.learn(filters=32, epoch=100)\n\n100/100\n\n\n\nimport pickle \nwith open('./lrnr_model/stgcn_ver1_data2_cancel_normal_100epoch.pickle','wb') as fw:\n    pickle.dump(lrnr, fw)\n\n\nimport pickle \nwith open('./lrnr_model/stgcn_ver1_data2_cancel_normal_100epoch.pickle', 'rb') as f: \n    lrnr_model = pickle.load(f)\n\n\n\n\n\n\n\nevtor = eptstgcn.Evaluator(lrnr_model, train_dataset, test_dataset)\n\n\nevtor.tr_plot(t=150, label='observed data')\n\n\n\n\n\n\n\n\nevtor.test_plot(t=150, label='observed data')\n\n\n\n\n\n\n\n\n\nplans_stgcn = {\n    'max_iteration': 30, \n    'method': ['STGCN'], \n    'lags': [4], \n    'nof_filters': [32], \n    'epoch': [100]\n}\n\n\nplnr = eptstgcn.planner.PLNR_STGCN(plans_stgcn,loader,dataset_name='data2')\n\n\nplnr.simulate()\n\n1/30 is done\n2/30 is done\n3/30 is done\n4/30 is done\n5/30 is done\n6/30 is done\n7/30 is done\n8/30 is done\n9/30 is done\n10/30 is done\n11/30 is done\n12/30 is done\n13/30 is done\n14/30 is done\n15/30 is done\n16/30 is done\n17/30 is done\n18/30 is done\n19/30 is done\n20/30 is done\n21/30 is done\n22/30 is done\n23/30 is done\n24/30 is done\n25/30 is done\n26/30 is done\n27/30 is done\n28/30 is done\n29/30 is done\n30/30 is done\nAll results are stored in ./simulation_results/2023-04-27_12-36-28.csv\n\n\n\nimport pickle\nwith open('./simul_model/stgcn_ver1_data2_cancel_normal_100epoch.pickle','wb') as fw:\n         pickle.dump(plnr, fw)\n\n\nimport pickle\nwith open('./simul_model/stgcn_ver1_data2_cancel_normal_100epoch.pickle','rb') as f:\n         simul_model = pickle.load(f)\n\n\ndf_simul_no = simul_model.simulation_results\ndf_simul_no\n\n\n\n\n\n  \n    \n      \n      dataset\n      method\n      lags\n      nof_filters\n      epoch\n      mse(train)\n      mse(test)\n      calculation_time\n    \n  \n  \n    \n      0\n      data2\n      STGCN\n      4\n      32\n      100\n      0.189243\n      0.171325\n      772.848698\n    \n    \n      1\n      data2\n      STGCN\n      4\n      32\n      100\n      0.189744\n      0.172561\n      817.378381\n    \n    \n      2\n      data2\n      STGCN\n      4\n      32\n      100\n      0.207822\n      0.199035\n      819.180893\n    \n    \n      3\n      data2\n      STGCN\n      4\n      32\n      100\n      0.193168\n      0.179314\n      814.309451\n    \n    \n      4\n      data2\n      STGCN\n      4\n      32\n      100\n      0.188224\n      0.169882\n      815.446167\n    \n    \n      5\n      data2\n      STGCN\n      4\n      32\n      100\n      0.188472\n      0.171604\n      810.853826\n    \n    \n      6\n      data2\n      STGCN\n      4\n      32\n      100\n      0.189101\n      0.174505\n      813.963314\n    \n    \n      7\n      data2\n      STGCN\n      4\n      32\n      100\n      0.191105\n      0.178127\n      817.652433\n    \n    \n      8\n      data2\n      STGCN\n      4\n      32\n      100\n      0.189744\n      0.174883\n      864.148679\n    \n    \n      9\n      data2\n      STGCN\n      4\n      32\n      100\n      0.192389\n      0.180111\n      841.731307\n    \n    \n      10\n      data2\n      STGCN\n      4\n      32\n      100\n      0.189369\n      0.173519\n      1089.791247\n    \n    \n      11\n      data2\n      STGCN\n      4\n      32\n      100\n      0.194758\n      0.183318\n      1069.243364\n    \n    \n      12\n      data2\n      STGCN\n      4\n      32\n      100\n      0.189176\n      0.172478\n      1000.280797\n    \n    \n      13\n      data2\n      STGCN\n      4\n      32\n      100\n      0.190803\n      0.172353\n      2673.002033\n    \n    \n      14\n      data2\n      STGCN\n      4\n      32\n      100\n      0.201632\n      0.187346\n      2715.75583\n    \n    \n      15\n      data2\n      STGCN\n      4\n      32\n      100\n      0.192502\n      0.179139\n      2321.917715\n    \n    \n      16\n      data2\n      STGCN\n      4\n      32\n      100\n      0.186289\n      0.170343\n      2352.800906\n    \n    \n      17\n      data2\n      STGCN\n      4\n      32\n      100\n      0.184571\n      0.168473\n      2333.993101\n    \n    \n      18\n      data2\n      STGCN\n      4\n      32\n      100\n      0.192246\n      0.180119\n      2318.096527\n    \n    \n      19\n      data2\n      STGCN\n      4\n      32\n      100\n      0.202523\n      0.192137\n      2283.376323\n    \n    \n      20\n      data2\n      STGCN\n      4\n      32\n      100\n      0.190118\n      0.176027\n      2209.563552\n    \n    \n      21\n      data2\n      STGCN\n      4\n      32\n      100\n      0.192123\n      0.180584\n      2203.745355\n    \n    \n      22\n      data2\n      STGCN\n      4\n      32\n      100\n      0.19005\n      0.171991\n      2254.78481\n    \n    \n      23\n      data2\n      STGCN\n      4\n      32\n      100\n      0.189719\n      0.172247\n      2702.167613\n    \n    \n      24\n      data2\n      STGCN\n      4\n      32\n      100\n      0.18996\n      0.17706\n      2807.790312\n    \n    \n      25\n      data2\n      STGCN\n      4\n      32\n      100\n      0.186305\n      0.172633\n      2481.448381\n    \n    \n      26\n      data2\n      STGCN\n      4\n      32\n      100\n      0.188398\n      0.169128\n      2431.156991\n    \n    \n      27\n      data2\n      STGCN\n      4\n      32\n      100\n      0.189949\n      0.174023\n      2236.444541\n    \n    \n      28\n      data2\n      STGCN\n      4\n      32\n      100\n      0.195153\n      0.182603\n      2414.528652\n    \n    \n      29\n      data2\n      STGCN\n      4\n      32\n      100\n      0.192687\n      0.179498\n      1819.399718\n    \n  \n\n\n\n\n\ndf_simul_no['mse(test)'].mean()\n\n0.1768788566191991\n\n\n\nprint('stgcn ver1 100에폭 끝!')\n\nstgcn ver1 100에폭 끝!\n\n\n\nimport matplotlib.pyplot as plt\nplt.boxplot(df_simul_no['mse(test)'])\nplt.show()"
  },
  {
    "objectID": "posts/SOLAR/2023-04-22-정규화-스케일링-stgcn-ver2.html",
    "href": "posts/SOLAR/2023-04-22-정규화-스케일링-stgcn-ver2.html",
    "title": "[SOLAR] STGCN Ver2 (data2, +N +S) 30회",
    "section": "",
    "text": "https://github.com/miruetoto/yechan3/tree/main/posts/3_Researches/ITSTGCN/itstgcn\nhttps://miruetoto.github.io/yechan3/posts/3_Researches/ITSTGCN/2023-03-18-SimulationPlanner-Tutorial.html#plnr_gnar_block\n\n\n\n\n\ntrain 2022-06-01 00:00:00 ~ 2022-08-14 17:00:00\ntest 2022-08-14 18:00:00 ~ 2022-09-15 23:00:00\n\n\n\n\n\nimport eptstgcn\nimport torch\nimport eptstgcn.planner\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\n\n\n\n\nurl = \"https://raw.githubusercontent.com/pinkocto/noteda/main/posts/SOLAR/data2/stgcn_data2.json\"\nloader = eptstgcn.DatasetLoader(url)\ndataset = loader.get_dataset(lags=4)\n\n\ntrain_dataset, test_dataset = eptstgcn.utils.temporal_signal_split(dataset, train_ratio = 0.7)\n\n\n\n\n\nref: https://seoyeonc.github.io/blog/posts/GCN/2023-03-17-ITSTGCN-Tutorial.html\n\n\nlrnr = eptstgcn.StgcnLearner(train_dataset, dataset_name = 'data2(2022/06/01 ~ 2022/09/15)')\n\n\nlrnr.learn(filters=32, epoch=50)\n\n50/50\n\n\n\n# import pickle \n# with open('./lrnr_model/stgcn_ver2_data2.pickle','wb') as fw:\n#     pickle.dump(lrnr, fw)\n\n\nimport pickle \nwith open('./lrnr_model/stgcn_ver2_data2.pickle', 'rb') as f: \n    model = pickle.load(f)\n\n\n\n\n\nevtor = eptstgcn.Evaluator(model, train_dataset, test_dataset)\n\n\n# fig = evtor.plot('--', label='observed data')\n# fig.tight_layout()\n# fig\n\n\n\n\nevtor.tr_plot(t=150, label='observed data')\n\n\n\n\n\n\n\n\nevtor.test_plot(t=150, label='observed data')\n\n\n\n\n\n\n\n\n\nplans_stgcn = {\n    'max_iteration': 30, \n    'method': ['EPT-STGCN'], \n    'lags': [4], \n    'nof_filters': [32], \n    'epoch': [50]\n}\n\n\n# plnr = eptstgcn.planner.PLNR_STGCN(plans_stgcn,loader,dataset_name='data2')\n\n\n# plnr.simulate()\n\n1/30 is done\n2/30 is done\n3/30 is done\n4/30 is done\n5/30 is done\n6/30 is done\n7/30 is done\n8/30 is done\n9/30 is done\n10/30 is done\n11/30 is done\n12/30 is done\n13/30 is done\n14/30 is done\n15/30 is done\n16/30 is done\n17/30 is done\n18/30 is done\n19/30 is done\n20/30 is done\n21/30 is done\n22/30 is done\n23/30 is done\n24/30 is done\n25/30 is done\n26/30 is done\n27/30 is done\n28/30 is done\n29/30 is done\n30/30 is done\nAll results are stored in ./simulation_results/2023-04-22_14-25-52.csv\n\n\n\n# import pickle\n# with open('./simul_model/stgcn_ver2_data2.pickle', 'wb') as fw:\n#     pickle.dump(plnr, fw)\n\n\nwith open('./simul_model/stgcn_ver2_data2.pickle', 'rb') as f:\n    simul_model = pickle.load(f)\n\n\ndf_simul = simul_model.simulation_results\ndf_simul\n\n\n\n\n\n  \n    \n      \n      dataset\n      method\n      lags\n      nof_filters\n      epoch\n      mse(train)\n      mse(test)\n      calculation_time\n    \n  \n  \n    \n      0\n      data2\n      EPT-STGCN\n      4\n      32\n      50\n      0.191743\n      0.174037\n      308.999537\n    \n    \n      1\n      data2\n      EPT-STGCN\n      4\n      32\n      50\n      0.188173\n      0.171402\n      310.277773\n    \n    \n      2\n      data2\n      EPT-STGCN\n      4\n      32\n      50\n      0.193801\n      0.177204\n      308.135715\n    \n    \n      3\n      data2\n      EPT-STGCN\n      4\n      32\n      50\n      0.193846\n      0.177513\n      307.202175\n    \n    \n      4\n      data2\n      EPT-STGCN\n      4\n      32\n      50\n      0.192977\n      0.172927\n      301.829093\n    \n    \n      5\n      data2\n      EPT-STGCN\n      4\n      32\n      50\n      0.192712\n      0.176857\n      301.443737\n    \n    \n      6\n      data2\n      EPT-STGCN\n      4\n      32\n      50\n      0.195432\n      0.179403\n      303.030302\n    \n    \n      7\n      data2\n      EPT-STGCN\n      4\n      32\n      50\n      0.193558\n      0.17668\n      302.182927\n    \n    \n      8\n      data2\n      EPT-STGCN\n      4\n      32\n      50\n      0.188431\n      0.170934\n      300.978617\n    \n    \n      9\n      data2\n      EPT-STGCN\n      4\n      32\n      50\n      0.194312\n      0.178338\n      301.406438\n    \n    \n      10\n      data2\n      EPT-STGCN\n      4\n      32\n      50\n      0.192146\n      0.17524\n      310.645684\n    \n    \n      11\n      data2\n      EPT-STGCN\n      4\n      32\n      50\n      0.21723\n      0.202964\n      309.016529\n    \n    \n      12\n      data2\n      EPT-STGCN\n      4\n      32\n      50\n      0.191419\n      0.175272\n      301.719725\n    \n    \n      13\n      data2\n      EPT-STGCN\n      4\n      32\n      50\n      0.189603\n      0.16854\n      298.208967\n    \n    \n      14\n      data2\n      EPT-STGCN\n      4\n      32\n      50\n      0.192472\n      0.175902\n      298.160489\n    \n    \n      15\n      data2\n      EPT-STGCN\n      4\n      32\n      50\n      0.195813\n      0.180936\n      298.502372\n    \n    \n      16\n      data2\n      EPT-STGCN\n      4\n      32\n      50\n      0.192051\n      0.172564\n      303.121567\n    \n    \n      17\n      data2\n      EPT-STGCN\n      4\n      32\n      50\n      0.186588\n      0.169016\n      298.217363\n    \n    \n      18\n      data2\n      EPT-STGCN\n      4\n      32\n      50\n      0.188448\n      0.17067\n      308.988231\n    \n    \n      19\n      data2\n      EPT-STGCN\n      4\n      32\n      50\n      0.192218\n      0.174493\n      314.624435\n    \n    \n      20\n      data2\n      EPT-STGCN\n      4\n      32\n      50\n      0.194702\n      0.178929\n      312.727251\n    \n    \n      21\n      data2\n      EPT-STGCN\n      4\n      32\n      50\n      0.191139\n      0.171002\n      307.64198\n    \n    \n      22\n      data2\n      EPT-STGCN\n      4\n      32\n      50\n      0.193083\n      0.176349\n      308.692932\n    \n    \n      23\n      data2\n      EPT-STGCN\n      4\n      32\n      50\n      0.188758\n      0.168046\n      298.516863\n    \n    \n      24\n      data2\n      EPT-STGCN\n      4\n      32\n      50\n      0.193287\n      0.176689\n      300.613522\n    \n    \n      25\n      data2\n      EPT-STGCN\n      4\n      32\n      50\n      0.196557\n      0.182426\n      300.518729\n    \n    \n      26\n      data2\n      EPT-STGCN\n      4\n      32\n      50\n      0.197129\n      0.17901\n      303.639919\n    \n    \n      27\n      data2\n      EPT-STGCN\n      4\n      32\n      50\n      0.188209\n      0.170222\n      305.739781\n    \n    \n      28\n      data2\n      EPT-STGCN\n      4\n      32\n      50\n      0.19453\n      0.17823\n      316.576063\n    \n    \n      29\n      data2\n      EPT-STGCN\n      4\n      32\n      50\n      0.194562\n      0.178458\n      304.878169\n    \n  \n\n\n\n\n\nimport matplotlib.pyplot as plt\nplt.boxplot(df_simul['mse(test)'])\nplt.show()"
  },
  {
    "objectID": "posts/SOLAR/2023-05-03-s-stgcn-ver1-시뮬레이션-10iter.html",
    "href": "posts/SOLAR/2023-05-03-s-stgcn-ver1-시뮬레이션-10iter.html",
    "title": "[SOLAR] STGCN Ver1 (data2, -N +S) 시뮬레이션(epoch, filter, lag)",
    "section": "",
    "text": "50 에폭 // 완료! (csv로 저장)\n\n\n100 에폭 // 완료!\n\n\n150 에폭 시작 (2023-05-05-오후1시54분) // 완료!\n\n10 iter 완료!!\n\n150 에폭 시작(2023-05-07 오후2시 38분 시작) // 완료! (5월 9일 오전 10시5분) – 50epoch 해야함\n\n\n100 에폭 시작(2023-05-09 오전 10시 46분 시작) // 완료 (5월 10일 정오)\n\n\n50에폭 시작(2023-05-10 오후 11시 10분 시작) // 완료 (5월 11일 오후 1시 36분)\n\n20 iter 완료!!\n\n50 에폭 시작(2023-05-11 오후 4시 40분 시작) // 완료 (5월 12일 오전 7시)\n\n\n100 에폭 시작(2023-05-12 오전 9시 20분 시작) // 완료 (5월 13일 오후 2시 30분)\n\n\n150 에폭 시작 (2023-05-14 오전 2시 30분 시작)\n\n240개 한꺼번에 저장된 파일(second/stgcn_v1_150epoch_2) – 2iteration\n\n\n\nhttps://github.com/miruetoto/yechan3/tree/main/posts/3_Researches/ITSTGCN/itstgcn\nhttps://miruetoto.github.io/yechan3/posts/3_Researches/ITSTGCN/2023-03-18-SimulationPlanner-Tutorial.html#plnr_gnar_block\n\n\n\n\n\ntrain 2022-06-01 00:00:00 ~ 2022-08-14 17:00:00\ntest 2022-08-14 18:00:00 ~ 2022-09-15 23:00:00"
  },
  {
    "objectID": "posts/SOLAR/2023-05-03-s-stgcn-ver1-시뮬레이션-10iter.html#epoch",
    "href": "posts/SOLAR/2023-05-03-s-stgcn-ver1-시뮬레이션-10iter.html#epoch",
    "title": "[SOLAR] STGCN Ver1 (data2, -N +S) 시뮬레이션(epoch, filter, lag)",
    "section": "50 epoch",
    "text": "50 epoch\n\n10iter (끝)\n20iter (on going)\n\n\nplans_stgcn = {\n    'max_iteration': 10, # 30 \n    'method': ['STGCN'], \n    'lags': [4, 8, 12, 24], \n    'nof_filters': [16, 32, 64], \n    'epoch': [50] # [50, 100, 150]\n}\n\n\nplnr = eptstgcn.planner.PLNR_STGCN(plans_stgcn,loader,dataset_name='data2')\n\n\nplans_stgcn\n\n{'max_iteration': 10,\n 'method': ['STGCN'],\n 'lags': [4, 8, 12, 24],\n 'nof_filters': [16, 32, 64],\n 'epoch': [50]}\n\n\n\nplnr.simulate()\neptstgcn.save_data(plnr,'./simul_model2/stgcn_v1/stgcn_v1_50epoch_3.pickle')\nsimul_model_50 = eptstgcn.load_data('./simul_model2/stgcn_v1/stgcn_v1_50epoch_3.pickle')\n\n1/10 is done\n11/50\n\n\n\nsimul_model_50.simulation_results\n\n\n\n\n\n  \n    \n      \n      dataset\n      method\n      normal\n      lags\n      nof_filters\n      epoch\n      mse(train)\n      mse(test)\n      calculation_time\n    \n  \n  \n    \n      0\n      data2\n      STGCN\n      X\n      4\n      16\n      50\n      0.183498\n      0.169735\n      550.123783\n    \n    \n      1\n      data2\n      STGCN\n      X\n      4\n      32\n      50\n      0.182225\n      0.162033\n      543.581154\n    \n    \n      2\n      data2\n      STGCN\n      X\n      4\n      64\n      50\n      0.183565\n      0.171925\n      419.522592\n    \n    \n      3\n      data2\n      STGCN\n      X\n      8\n      16\n      50\n      0.19624\n      0.173633\n      415.247636\n    \n    \n      4\n      data2\n      STGCN\n      X\n      8\n      32\n      50\n      0.197571\n      0.171606\n      422.306532\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      115\n      data2\n      STGCN\n      X\n      12\n      32\n      50\n      0.19375\n      0.168965\n      428.73169\n    \n    \n      116\n      data2\n      STGCN\n      X\n      12\n      64\n      50\n      0.19339\n      0.169359\n      443.226369\n    \n    \n      117\n      data2\n      STGCN\n      X\n      24\n      16\n      50\n      0.226857\n      0.209055\n      398.531218\n    \n    \n      118\n      data2\n      STGCN\n      X\n      24\n      32\n      50\n      0.257455\n      0.216844\n      404.345611\n    \n    \n      119\n      data2\n      STGCN\n      X\n      24\n      64\n      50\n      0.226526\n      0.194404\n      413.1882\n    \n  \n\n120 rows × 9 columns\n\n\n\n\n5월 11일 50에폭 3번째 이터레이션 돌리기 시작\n\nsimul_model_50.simulation_results\n\n\n\n\n\n  \n    \n      \n      dataset\n      method\n      normal\n      lags\n      nof_filters\n      epoch\n      mse(train)\n      mse(test)\n      calculation_time\n    \n  \n  \n    \n      0\n      data2\n      STGCN\n      X\n      4\n      16\n      50\n      0.177073\n      0.158718\n      317.86064\n    \n    \n      1\n      data2\n      STGCN\n      X\n      4\n      32\n      50\n      0.188271\n      0.173996\n      546.640334\n    \n    \n      2\n      data2\n      STGCN\n      X\n      4\n      64\n      50\n      0.183843\n      0.168644\n      473.151267\n    \n    \n      3\n      data2\n      STGCN\n      X\n      8\n      16\n      50\n      0.192224\n      0.169199\n      417.013636\n    \n    \n      4\n      data2\n      STGCN\n      X\n      8\n      32\n      50\n      0.193763\n      0.177408\n      422.140082\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      115\n      data2\n      STGCN\n      X\n      12\n      32\n      50\n      0.209933\n      0.182817\n      433.280491\n    \n    \n      116\n      data2\n      STGCN\n      X\n      12\n      64\n      50\n      0.204477\n      0.178089\n      450.442147\n    \n    \n      117\n      data2\n      STGCN\n      X\n      24\n      16\n      50\n      0.214642\n      0.190434\n      400.357081\n    \n    \n      118\n      data2\n      STGCN\n      X\n      24\n      32\n      50\n      0.25557\n      0.208072\n      410.695924\n    \n    \n      119\n      data2\n      STGCN\n      X\n      24\n      64\n      50\n      0.353404\n      0.279463\n      558.969701\n    \n  \n\n120 rows × 9 columns\n\n\n\n\nsimul_model_50.simulation_results\n\n\nplans_stgcn\n\n{'max_iteration': 10,\n 'method': ['STGCN'],\n 'lags': [4, 8, 12, 24],\n 'nof_filters': [16, 32, 64],\n 'epoch': [150]}\n\n\n\nsimul_model_50.simulation_results['calculation_time'].mean()\n\n1186.3822703550259\n\n\n\nprint('stgcn ver1 50epoch 시뮬레이션 끝!')\n\n\n첫번째 10iter m저장X (csv로만)\nDropbox/noteda/posts/SOLAR/simulation_results/2023-05-04_04-21-58.csv\n\n\nimport matplotlib.pyplot as plt\nplt.boxplot(simul_model_50.simulation_results['mse(test)'])\nplt.show()"
  },
  {
    "objectID": "posts/SOLAR/2023-05-03-s-stgcn-ver1-시뮬레이션-10iter.html#epoch-1",
    "href": "posts/SOLAR/2023-05-03-s-stgcn-ver1-시뮬레이션-10iter.html#epoch-1",
    "title": "[SOLAR] STGCN Ver1 (data2, -N +S) 시뮬레이션(epoch, filter, lag)",
    "section": "100 epoch",
    "text": "100 epoch\n\nplans_stgcn = {\n    'max_iteration': 10, # 30 \n    'method': ['STGCN'], \n    'lags': [4, 8, 12, 24], \n    'nof_filters': [16, 32, 64], \n    'epoch': [100] # [50, 100, 150]\n}\n\n\nplans_stgcn\n\n{'max_iteration': 10,\n 'method': ['STGCN'],\n 'lags': [4, 8, 12, 24],\n 'nof_filters': [16, 32, 64],\n 'epoch': [100]}\n\n\n\nplnr = eptstgcn.planner.PLNR_STGCN(plans_stgcn,loader,dataset_name='data2')\n\n\nplnr.simulate()\neptstgcn.save_data(plnr, './simul_model2/stgcn_v1/stgcn_v1_100epoch_3.pickle')\nsimul_model_100 = eptstgcn.load_data('./simul_model2/stgcn_v1/stgcn_v1_100epoch_3.pickle')\n\n1/10 is done\n2/10 is done\n100/100\n\n\n\nsimul_model_100.simulation_results\n\n\n\n\n\n  \n    \n      \n      dataset\n      method\n      normal\n      lags\n      nof_filters\n      epoch\n      mse(train)\n      mse(test)\n      calculation_time\n    \n  \n  \n    \n      0\n      data2\n      STGCN\n      X\n      4\n      16\n      100\n      0.183406\n      0.169097\n      601.416962\n    \n    \n      1\n      data2\n      STGCN\n      X\n      4\n      32\n      100\n      0.179978\n      0.161778\n      687.800131\n    \n    \n      2\n      data2\n      STGCN\n      X\n      4\n      64\n      100\n      0.180906\n      0.164964\n      844.361361\n    \n    \n      3\n      data2\n      STGCN\n      X\n      8\n      16\n      100\n      0.196384\n      0.169631\n      828.892196\n    \n    \n      4\n      data2\n      STGCN\n      X\n      8\n      32\n      100\n      0.197595\n      0.174515\n      957.064054\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      115\n      data2\n      STGCN\n      X\n      12\n      32\n      100\n      0.19678\n      0.172842\n      649.31667\n    \n    \n      116\n      data2\n      STGCN\n      X\n      12\n      64\n      100\n      0.207231\n      0.178266\n      657.416144\n    \n    \n      117\n      data2\n      STGCN\n      X\n      24\n      16\n      100\n      0.251782\n      0.208191\n      588.360123\n    \n    \n      118\n      data2\n      STGCN\n      X\n      24\n      32\n      100\n      0.257983\n      0.220628\n      599.18159\n    \n    \n      119\n      data2\n      STGCN\n      X\n      24\n      64\n      100\n      0.260816\n      0.224017\n      629.292965\n    \n  \n\n120 rows × 9 columns\n\n\n\n\nsimul_model_100.simulation_results\n\n\n\n\n\n  \n    \n      \n      dataset\n      method\n      normal\n      lags\n      nof_filters\n      epoch\n      mse(train)\n      mse(test)\n      calculation_time\n    \n  \n  \n    \n      0\n      data2\n      STGCN\n      X\n      4\n      16\n      100\n      0.195067\n      0.180725\n      594.303679\n    \n    \n      1\n      data2\n      STGCN\n      X\n      4\n      32\n      100\n      0.181248\n      0.16525\n      611.907454\n    \n    \n      2\n      data2\n      STGCN\n      X\n      4\n      64\n      100\n      0.183541\n      0.165472\n      629.378186\n    \n    \n      3\n      data2\n      STGCN\n      X\n      8\n      16\n      100\n      0.201609\n      0.180656\n      616.519384\n    \n    \n      4\n      data2\n      STGCN\n      X\n      8\n      32\n      100\n      0.191182\n      0.17075\n      625.537024\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      115\n      data2\n      STGCN\n      X\n      12\n      32\n      100\n      0.208179\n      0.181665\n      863.704366\n    \n    \n      116\n      data2\n      STGCN\n      X\n      12\n      64\n      100\n      0.192994\n      0.168374\n      894.694965\n    \n    \n      117\n      data2\n      STGCN\n      X\n      24\n      16\n      100\n      0.226653\n      0.203374\n      797.021305\n    \n    \n      118\n      data2\n      STGCN\n      X\n      24\n      32\n      100\n      0.25733\n      0.219492\n      805.615929\n    \n    \n      119\n      data2\n      STGCN\n      X\n      24\n      64\n      100\n      0.218003\n      0.196679\n      842.991321\n    \n  \n\n120 rows × 9 columns\n\n\n\n\n여기까지 완료!\n\n\n# eptstgcn.save_data(plnr, './simul_model2/stgcn_v1/stgcn_v1_100epoch.pickle')\n\n\n# simul_model_100 = eptstgcn.load_data('./simul_model2/stgcn_v1/stgcn_v1_100epoch.pickle')"
  },
  {
    "objectID": "posts/SOLAR/2023-05-03-s-stgcn-ver1-시뮬레이션-10iter.html#epoch-2",
    "href": "posts/SOLAR/2023-05-03-s-stgcn-ver1-시뮬레이션-10iter.html#epoch-2",
    "title": "[SOLAR] STGCN Ver1 (data2, -N +S) 시뮬레이션(epoch, filter, lag)",
    "section": "150 epoch",
    "text": "150 epoch\n\nplans_stgcn = {\n    'max_iteration': 10, # 30 \n    'method': ['STGCN'], \n    'lags': [4, 8, 12, 24], \n    'nof_filters': [16, 32, 64], \n    'epoch': [150] # [50, 100, 150]\n}\n\n\nplnr = eptstgcn.planner.PLNR_STGCN(plans_stgcn,loader,dataset_name='data2')\n\n\nplnr.simulate()\neptstgcn.save_data(plnr,'./simul_model2/stgcn_v1/stgcn_v1_150epoch.pickle')\nsimul_model_150 = eptstgcn.load_data('./simul_model2/stgcn_v1/stgcn_v1_150epoch.pickle')\n\n137/150\n\n\n\neptstgcn.save_data(plnr,'./simul_model2/stgcn_v1/stgcn_v1_150epoch.pickle')\n\n\nsimul_model_150 = eptstgcn.load_data('./simul_model2/stgcn_v1/stgcn_v1_150epoch.pickle')\n\n\nsimul_model_150 = eptstgcn.load_data('./simul_model2/stgcn_v1/second/stgcn_v1_150epoch_2.pickle')\n\n\nsimul_model_150.simulation_results\n\n\n\n\n\n  \n    \n      \n      dataset\n      method\n      normal\n      lags\n      nof_filters\n      epoch\n      mse(train)\n      mse(test)\n      calculation_time\n    \n  \n  \n    \n      0\n      data2\n      STGCN\n      X\n      4\n      16\n      150\n      0.186116\n      0.165823\n      1221.462088\n    \n    \n      1\n      data2\n      STGCN\n      X\n      4\n      32\n      150\n      0.185565\n      0.171283\n      1237.214506\n    \n    \n      2\n      data2\n      STGCN\n      X\n      4\n      64\n      150\n      0.200393\n      0.186591\n      1497.534026\n    \n    \n      3\n      data2\n      STGCN\n      X\n      8\n      16\n      150\n      0.198985\n      0.172985\n      1041.296445\n    \n    \n      4\n      data2\n      STGCN\n      X\n      8\n      32\n      150\n      0.201762\n      0.175557\n      948.47674\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      235\n      data2\n      STGCN\n      X\n      12\n      32\n      150\n      0.189189\n      0.168207\n      1310.145853\n    \n    \n      236\n      data2\n      STGCN\n      X\n      12\n      64\n      150\n      0.193969\n      0.176804\n      1346.117926\n    \n    \n      237\n      data2\n      STGCN\n      X\n      24\n      16\n      150\n      0.220608\n      0.190391\n      1204.447807\n    \n    \n      238\n      data2\n      STGCN\n      X\n      24\n      32\n      150\n      0.248845\n      0.21056\n      1234.316041\n    \n    \n      239\n      data2\n      STGCN\n      X\n      24\n      64\n      150\n      0.216271\n      0.191787\n      1002.52125\n    \n  \n\n240 rows × 9 columns\n\n\n\n240개 한꺼번에 저장된 파일(second/stgcn_v1_150epoch_2) – 2iteration"
  },
  {
    "objectID": "posts/SOLAR/2023-04-12-stgcn-ver2-train90.html",
    "href": "posts/SOLAR/2023-04-12-stgcn-ver2-train90.html",
    "title": "[SOLAR] STGCN Ver2 (MSE: 0.2019)",
    "section": "",
    "text": "import pandas as pd\nimport numpy as np\nimport json\nimport urllib\nimport time\n\n\n# 일반적인 모듈 \nimport numpy as np\nimport matplotlib.pyplot as plt \nimport networkx as nx \nfrom tqdm import tqdm \n\n# 파이토치 관련 \nimport torch\nimport torch.nn.functional as F\n\n# PyG 관련 \nfrom torch_geometric.data import Data ## Data: 그래프자료형을 만드는 클래스\n\n# STGCN 관련 \nimport torch_geometric_temporal\nfrom torch_geometric_temporal.nn.recurrent import GConvGRU\nfrom torch_geometric_temporal.signal import temporal_signal_split \n\n\nclass RecurrentGCN(torch.nn.Module):\n    def __init__(self, node_features, filters):\n        super(RecurrentGCN, self).__init__()\n        self.recurrent = GConvGRU(node_features, filters, 2)\n        self.linear = torch.nn.Linear(filters, 1)\n\n    def forward(self, x, edge_index, edge_weight):\n        h = self.recurrent(x, edge_index, edge_weight)\n        h = F.relu(h)\n        h = self.linear(h)\n        return h\n\n\nfrom mysolar import SolarEPTDatasetLoader\n\n\nloader = SolarEPTDatasetLoader()\ndataset = loader.get_dataset(lags=4)\ntrain_dataset, test_dataset = temporal_signal_split(dataset, train_ratio=0.7)\n\n\nprint(np.array(train_dataset.targets).shape)\nprint(np.array(test_dataset.targets).shape)\n\n(1645, 44)\n(705, 44)\n\n\n\ntrain: 2022-06-01 00:00:00 ~ 2022-08-14 17:00:00\ntest: 2022-08-14 18:00:00 ~ 2022-09-15 21:00:00"
  },
  {
    "objectID": "posts/SOLAR/2023-04-12-stgcn-ver2-train90.html#learn",
    "href": "posts/SOLAR/2023-04-12-stgcn-ver2-train90.html#learn",
    "title": "[SOLAR] STGCN Ver2 (MSE: 0.2019)",
    "section": "Learn",
    "text": "Learn\n\nmodel = RecurrentGCN(node_features=4, filters=32)\noptimizer = torch.optim.Adam(model.parameters(), lr=0.01)\nmodel.train()\n\nRecurrentGCN(\n  (recurrent): GConvGRU(\n    (conv_x_z): ChebConv(4, 32, K=2, normalization=sym)\n    (conv_h_z): ChebConv(32, 32, K=2, normalization=sym)\n    (conv_x_r): ChebConv(4, 32, K=2, normalization=sym)\n    (conv_h_r): ChebConv(32, 32, K=2, normalization=sym)\n    (conv_x_h): ChebConv(4, 32, K=2, normalization=sym)\n    (conv_h_h): ChebConv(32, 32, K=2, normalization=sym)\n  )\n  (linear): Linear(in_features=32, out_features=1, bias=True)\n)\n\n\n\nstart = time.time()\nfor epoch in tqdm(range(50)):\n    for t, snapshot in enumerate(train_dataset):\n        yt_hat = model(snapshot.x, snapshot.edge_index, snapshot.edge_attr)\n        cost = torch.mean((yt_hat-snapshot.y)**2)\n        cost.backward()\n        optimizer.step()\n        optimizer.zero_grad()\nend = time.time()\nprint(f\"{end-start:.5f} sec\")\n\n100%|██████████| 50/50 [04:28<00:00,  5.37s/it]\n\n\n268.36397 sec\n\n\n\n\n\n\nprint(268.36397/60, '분')\n\n4.472732833333334 분\n\n\n\nimport pickle \nwith open('./model/stgcn2_lag4_new.pickle','wb') as fw:\n    pickle.dump(model, fw)\n\n\nimport pickle \nwith open('./model/stgcn2_lag4_new.pickle', 'rb') as f: \n    model = pickle.load(f)\n\n\nmodel\n\nRecurrentGCN(\n  (recurrent): GConvGRU(\n    (conv_x_z): ChebConv(4, 32, K=2, normalization=sym)\n    (conv_h_z): ChebConv(32, 32, K=2, normalization=sym)\n    (conv_x_r): ChebConv(4, 32, K=2, normalization=sym)\n    (conv_h_r): ChebConv(32, 32, K=2, normalization=sym)\n    (conv_x_h): ChebConv(4, 32, K=2, normalization=sym)\n    (conv_h_h): ChebConv(32, 32, K=2, normalization=sym)\n  )\n  (linear): Linear(in_features=32, out_features=1, bias=True)\n)"
  },
  {
    "objectID": "posts/SOLAR/2023-04-12-stgcn-ver2-train90.html#모델평가",
    "href": "posts/SOLAR/2023-04-12-stgcn-ver2-train90.html#모델평가",
    "title": "[SOLAR] STGCN Ver2 (MSE: 0.2019)",
    "section": "모델평가",
    "text": "모델평가\n- train\n\nSTGCN Ver1 \\(\\to\\) MSE: 0.2102\n\n\nmodel.eval()\ncost = 0\nfor time, snapshot in enumerate(train_dataset):\n    y_hat = model(snapshot.x, snapshot.edge_index, snapshot.edge_attr)\n    cost = cost + torch.mean((y_hat-snapshot.y)**2)\ncost = cost / (time+1)\ncost = cost.item()\nprint(\"MSE: {:.4f}\".format(cost))\n\nMSE: 0.2181\n\n\n- test\n\nSTGCN Ver1 \\(\\to\\) MSE : 0.1899\n\n\nmodel.eval()\ncost = 0\nfor time, snapshot in enumerate(test_dataset):\n    y_hat = model(snapshot.x, snapshot.edge_index, snapshot.edge_attr)\n    cost = cost + torch.mean((y_hat-snapshot.y)**2)\ncost = cost / (time+1)\ncost = cost.item()\nprint(\"MSE: {:.4f}\".format(cost))\n\nMSE: 0.2019"
  },
  {
    "objectID": "posts/SOLAR/2023-04-06-stgcn.html",
    "href": "posts/SOLAR/2023-04-06-stgcn.html",
    "title": "ChikenpoxDataset",
    "section": "",
    "text": "ref: https://miruetoto.github.io/yechan3/posts/3_Researches/ITSTGCN/2022-12-29-STGCN-tutorial.html\nref: https://pytorch-geometric-temporal.readthedocs.io/en/latest/modules/signal.html\nref: https://pytorch-geometric-temporal.readthedocs.io/en/latest/modules/dataset.html#module-torch_geometric_temporal.dataset.chickenpox"
  },
  {
    "objectID": "posts/SOLAR/2023-04-06-stgcn.html#imports",
    "href": "posts/SOLAR/2023-04-06-stgcn.html#imports",
    "title": "ChikenpoxDataset",
    "section": "imports",
    "text": "imports\n\n# 일반적인 모듈 \nimport numpy as np\nimport matplotlib.pyplot as plt \nimport networkx as nx \nfrom tqdm import tqdm \n\n# 파이토치 관련 \nimport torch\nimport torch.nn.functional as F\n\n# PyG 관련 \nfrom torch_geometric.data import Data ## Data: 그래프자료형을 만드는 클래스\n\n# STGCN 관련 \nimport torch_geometric_temporal\nfrom torch_geometric_temporal.nn.recurrent import GConvGRU\nfrom torch_geometric_temporal.signal import temporal_signal_split \n\n- STGCN의 학습을 위한 클래스 선언\n\nclass RecurrentGCN(torch.nn.Module):\n    def __init__(self, node_features, filters):\n        super(RecurrentGCN, self).__init__()\n        self.recurrent = GConvGRU(node_features, filters, 2)\n        self.linear = torch.nn.Linear(filters, 1)\n\n    def forward(self, x, edge_index, edge_weight):\n        h = self.recurrent(x, edge_index, edge_weight)\n        h = F.relu(h)\n        h = self.linear(h)\n        return h"
  },
  {
    "objectID": "posts/SOLAR/2023-04-06-stgcn.html#pytorch-goemetric-temporal의-자료형",
    "href": "posts/SOLAR/2023-04-06-stgcn.html#pytorch-goemetric-temporal의-자료형",
    "title": "ChikenpoxDataset",
    "section": "PyTorch Goemetric Temporal의 자료형",
    "text": "PyTorch Goemetric Temporal의 자료형\n\n## Temporal Signal Iterators\ntorch_geometric_temporal.signal.StaticGraphTemporalSignal ##  시간에 따라 그래프 구조가 일정\ntorch_geometric_temporal.signal.DynamicGraphTemporalSignal\ntorch_geometric_temporal.signal.DynamicGraphStaticSignal\n## Heterogeneous Temporal Signal Iterators\ntorch_geometric_temporal.signal.StaticHeteroGraphTemporalSignal\ntorch_geometric_temporal.signal.DynamicHeteroGraphTemporalSignal\ntorch_geometric_temporal.signal.DynamicHeteroGraphStaticSignal\n\ntorch_geometric_temporal.signal.dynamic_hetero_graph_static_signal.DynamicHeteroGraphStaticSignal\n\n\nStaticGraphTemporalSignal는 시간에 따라서 그래프 구조가 일정한 경우, 즉 \\(\\cal{G}_t = \\{\\cal{V}, \\cal{E}\\}\\) 와 같은 구조를 의미한다."
  },
  {
    "objectID": "posts/SOLAR/2023-04-06-stgcn.html#예제-staticgraphtemporalsignal을-이용하여-데이터-셋-만들기",
    "href": "posts/SOLAR/2023-04-06-stgcn.html#예제-staticgraphtemporalsignal을-이용하여-데이터-셋-만들기",
    "title": "ChikenpoxDataset",
    "section": "(예제) StaticGraphTemporalSignal을 이용하여 데이터 셋 만들기",
    "text": "(예제) StaticGraphTemporalSignal을 이용하여 데이터 셋 만들기\n- json data \\(\\to\\) dict\n\nimport json\nimport urllib\n\n\nurl = \"https://raw.githubusercontent.com/benedekrozemberczki/pytorch_geometric_temporal/master/dataset/chickenpox.json\"\ndata_dict = json.loads(urllib.request.urlopen(url).read())\n# data_dict 출력이 김\n\n\n시각화\n모든 노드가 서로 연결되었다는 가정시\n\ndata_dict.keys() \n\ndict_keys(['edges', 'node_ids', 'FX'])\n\n\n\nnode_list = list(data_dict['node_ids'].keys())\nV = {v for i, v in enumerate(node_list)}\n#V\n\n\nfrom itertools import permutations\nE = list(permutations(node_list, 2))\n\n\nimport networkx as nx\nimport matplotlib.pyplot as plt\nG = nx.Graph()\nG.add_nodes_from(V)\nG.add_edges_from(E)\n\n\nnx.draw_networkx(G,node_size=2500,font_weight=900,font_size=25,alpha=0.8)\nfig=plt.gcf()\nfig.set_figheight(8)\nfig.set_figwidth(15)\n\n\n\n\n- 시각화 코드 정리\n\ndef plot(G):\n    nx.draw_networkx(G,node_size=2500,font_weight=900,font_size=25,alpha=0.8,arrowsize=20)\n    fig=plt.gcf()\n    fig.set_figheight(8)\n    fig.set_figwidth(15)\n\n- 속성체크\n\n\\(\\cal{V}, \\cal{E}\\)\n\n\n#print(f\"V = {G.nodes}\")\nprint(f\"E = {G.edges}\")\n\nE = [('PEST', 'BACS'), ('PEST', 'BUDAPEST'), ('PEST', 'FEJER'), ('PEST', 'HEVES'), ('PEST', 'JASZ'), ('PEST', 'KOMAROM'), ('PEST', 'NOGRAD'), ('PEST', 'PEST'), ('BACS', 'JASZ'), ('BACS', 'FEJER'), ('BACS', 'BARANYA'), ('BACS', 'BACS'), ('BACS', 'CSONGRAD'), ('BACS', 'TOLNA'), ('SZABOLCS', 'BORSOD'), ('SZABOLCS', 'HAJDU'), ('SZABOLCS', 'SZABOLCS'), ('BORSOD', 'HAJDU'), ('BORSOD', 'NOGRAD'), ('BORSOD', 'HEVES'), ('BORSOD', 'JASZ'), ('BORSOD', 'BORSOD'), ('HEVES', 'HEVES'), ('HEVES', 'NOGRAD'), ('HEVES', 'JASZ'), ('CSONGRAD', 'BEKES'), ('CSONGRAD', 'JASZ'), ('CSONGRAD', 'CSONGRAD'), ('GYOR', 'GYOR'), ('GYOR', 'VAS'), ('GYOR', 'KOMAROM'), ('GYOR', 'VESZPREM'), ('ZALA', 'SOMOGY'), ('ZALA', 'VAS'), ('ZALA', 'VESZPREM'), ('ZALA', 'ZALA'), ('TOLNA', 'BARANYA'), ('TOLNA', 'FEJER'), ('TOLNA', 'SOMOGY'), ('TOLNA', 'TOLNA'), ('VESZPREM', 'FEJER'), ('VESZPREM', 'KOMAROM'), ('VESZPREM', 'SOMOGY'), ('VESZPREM', 'VAS'), ('VESZPREM', 'VESZPREM'), ('HAJDU', 'BEKES'), ('HAJDU', 'HAJDU'), ('HAJDU', 'JASZ'), ('BEKES', 'JASZ'), ('BEKES', 'BEKES'), ('FEJER', 'FEJER'), ('FEJER', 'SOMOGY'), ('FEJER', 'KOMAROM'), ('NOGRAD', 'NOGRAD'), ('SOMOGY', 'BARANYA'), ('SOMOGY', 'SOMOGY'), ('BUDAPEST', 'BUDAPEST'), ('BARANYA', 'BARANYA'), ('VAS', 'VAS'), ('JASZ', 'JASZ'), ('KOMAROM', 'KOMAROM')]\n\n\n\nlen(E), len(data_dict['edges']), data_dict['edges'][:5]\n\n(102, 102, [[0, 10], [0, 6], [0, 13], [0, 1], [0, 0]])\n\n\n이번에는 원래대로\n\nnode_list = list(data_dict['node_ids'].keys())\nV = {v for i, v in enumerate(node_list)}\n\n\nE = []\nfor i in range(len(data_dict['edges'])):\n    E.append((node_list[data_dict['edges'][i][0]], node_list[data_dict['edges'][i][1]]))\n\n\nimport networkx as nx\nimport matplotlib.pyplot as plt\nG = nx.Graph()\nG.add_nodes_from(V)\nG.add_edges_from(E)\n\n\nnx.draw_networkx(G,node_size=2500,font_weight=900,font_size=15,alpha=0.8)\nfig=plt.gcf()\nfig.set_figheight(8)\nfig.set_figwidth(15)\n\n\n\n\n- 살펴보기\n\nnp.array(data_dict['edges']).T\n\narray([[ 0,  0,  0,  0,  0,  0,  0,  1,  1,  1,  1,  2,  2,  2,  2,  3,\n         3,  3,  3,  3,  3,  4,  4,  5,  5,  5,  5,  6,  6,  6,  6,  6,\n         6,  6,  7,  7,  7,  7,  8,  8,  8,  8,  8,  9,  9,  9,  9,  9,\n        10, 10, 10, 10, 10, 10, 10, 10, 11, 11, 11, 11, 11, 12, 12, 12,\n        12, 13, 13, 13, 13, 13, 13, 13, 13, 14, 14, 14, 14, 14, 14, 15,\n        15, 15, 16, 16, 16, 16, 16, 17, 17, 17, 17, 18, 18, 18, 18, 18,\n        18, 18, 19, 19, 19, 19],\n       [10,  6, 13,  1,  0,  5, 16,  0, 16,  1, 14, 10,  8,  2,  5,  8,\n        15, 12,  9, 10,  3,  4, 13,  0, 10,  2,  5,  0, 16,  6, 14, 13,\n        11, 18,  7, 17, 11, 18,  3,  2, 15,  8, 10,  9, 13,  3, 12, 10,\n         5,  9,  8,  3, 10,  2, 13,  0,  6, 11,  7, 13, 18,  3,  9, 13,\n        12, 13,  9,  6,  4, 12,  0, 11, 10, 18, 19,  1, 14,  6, 16,  3,\n        15,  8, 16, 14,  1,  0,  6,  7, 19, 17, 18, 14, 18, 17,  7,  6,\n        19, 11, 18, 14, 19, 17]])\n\n\n\nlen(data_dict['edges'])\n\n102\n\n\n\ndata_dict['edges'][:6] ## double list\n\n[[0, 10], [0, 6], [0, 13], [0, 1], [0, 0], [0, 5]]\n\n\n\n\\(\\cal{E} = \\{(0,10), (0,6), \\dots, (19,17)\\}\\)\n혹은 \\(\\cal{E} = \\{\\tt{(BACS,JASZ)}, \\tt{(BACS,FEJER)}, \\dots, \\tt{(ZALA,VAS)}\\}\\)\n\n\ndata_dict['node_ids']\n\n{'BACS': 0,\n 'BARANYA': 1,\n 'BEKES': 2,\n 'BORSOD': 3,\n 'BUDAPEST': 4,\n 'CSONGRAD': 5,\n 'FEJER': 6,\n 'GYOR': 7,\n 'HAJDU': 8,\n 'HEVES': 9,\n 'JASZ': 10,\n 'KOMAROM': 11,\n 'NOGRAD': 12,\n 'PEST': 13,\n 'SOMOGY': 14,\n 'SZABOLCS': 15,\n 'TOLNA': 16,\n 'VAS': 17,\n 'VESZPREM': 18,\n 'ZALA': 19}\n\n\n\n\\(\\cal{V} = \\{\\tt{BACS}, \\tt{BARANYA}, \\dots, \\tt{ZALA}\\}\\)\n\n\nnp.array(data_dict['FX']), np.array(data_dict['FX']).shape \n\n(array([[-1.08135724e-03, -7.11136085e-01, -3.22808515e+00, ...,\n          1.09445310e+00, -7.08747750e-01, -1.82280792e+00],\n        [ 2.85705967e-02, -5.98430173e-01, -2.29097341e-01, ...,\n         -1.59220988e+00, -2.24597623e-01,  7.86330575e-01],\n        [ 3.54742090e-01,  1.90511208e-01,  1.61028185e+00, ...,\n          1.38183225e-01, -7.08747750e-01, -5.61724314e-01],\n        ...,\n        [-4.75512620e-01, -1.19952837e+00, -3.89043358e-01, ...,\n         -1.00023329e+00, -1.71429032e+00,  4.70746677e-02],\n        [-2.08645035e-01,  6.03766218e-01,  1.08216835e-02, ...,\n          4.71099041e-02,  2.45684924e+00, -3.44296107e-01],\n        [ 1.21464875e+00,  7.16472130e-01,  1.29038982e+00, ...,\n          4.56939849e-01,  7.43702632e-01,  1.00375878e+00]]),\n (521, 20))\n\n\n\n\\({\\bf f}=\\begin{bmatrix} {\\bf f}_1\\\\ {\\bf f}_2\\\\ \\dots \\\\ {\\bf f}_{521} \\end{bmatrix}=\\begin{bmatrix} f(t=1,v=\\tt{BACS}) & \\dots & f(t=1,v=\\tt{ZALA}) \\\\ f(t=2,v=\\tt{BACS}) & \\dots & f(t=2,v=\\tt{ZALA}) \\\\ \\dots & \\dots & \\dots \\\\ f(t=521,v=\\tt{BACS}) & \\dots & f(t=521,v=\\tt{ZALA}) \\end{bmatrix}\\)\n\n즉, data_dict는 아래와 같이 구성되어 있다.\n\n\n\n\n\n\n\n\n\n\n수학 기호\n코드에 저장된 변수\n자료형\n차원\n설명\n\n\n\n\n\\({\\cal V}\\)\ndata_dict['node_ids']\ndict\n20\n20개의 노드에 대한 설명이 있음\n\n\n\\({\\cal E}\\)\ndata_dict['edges']\nlist (double list)\n(102,2)\n노드들에 대한 102개의 연결을 정의함\n\n\n\\({\\bf f}\\)\ndata_dict['node_ids']\ndict\n(521,20)\n\\(f(t,v)\\) for \\(v \\in {\\cal V}\\) and \\(t = 1,\\dots, T\\)\n\n\n\n- 주어진 자료를 정리하여 그래프신호 \\(\\big(\\{{\\cal V},{\\cal E},{\\bf W}\\},{\\bf f}\\big)\\)를 만들면 아래와 같다.\n\nedges = np.array(data_dict[\"edges\"]).T\nedge_weight = np.ones(edges.shape[1]) # 여기서는 0으로 초기값을 줌.\nf = np.array(data_dict[\"FX\"])\n\n- data_dict \\(\\to\\) dl\n\nlags = 4\nfeatures = [f[i : i + lags, :].T for i in range(f.shape[0] - lags)]\ntargets = [f[i + lags, :].T for i in range(f.shape[0] - lags)]\n\n\nnp.array(features).shape\n\n(517, 20, 4)\n\n\n\nnp.array(targets).shape\n\n(517, 20)\n\n\n\n\n\n\n\n\n\n설명변수\n반응변수\n\n\n\n\n\\({\\bf X} = {\\tt features} = \\begin{bmatrix} {\\bf f}_1 & {\\bf f}_2 & {\\bf f}_3 & {\\bf f}_4 \\\\ {\\bf f}_2 & {\\bf f}_3 & {\\bf f}_4 & {\\bf f}_5 \\\\ \\dots & \\dots & \\dots & \\dots \\\\ {\\bf f}_{517} & {\\bf f}_{518} & {\\bf f}_{519} & {\\bf f}_{520} \\end{bmatrix}\\)\n\\({\\bf y}= {\\tt targets} = \\begin{bmatrix} {\\bf f}_5 \\\\ {\\bf f}_6 \\\\ \\dots \\\\ {\\bf f}_{521} \\end{bmatrix}\\)\n\n\n\n\ndataset = torch_geometric_temporal.signal.StaticGraphTemporalSignal(\n    edge_index= edges,\n    edge_weight = edge_weight,\n    features = features,\n    targets = targets\n)\n\n\ndataset\n\n<torch_geometric_temporal.signal.static_graph_temporal_signal.StaticGraphTemporalSignal at 0x7f04c5584fa0>\n\n\n- 그런데 이 과정을 아래와 같이 할 수도 있음.\n\n# PyTorch Geometric Temporal 공식홈페이지에 소개된 코드\nloader = torch_geometric_temporal.dataset.ChickenpoxDatasetLoader()\ndataset = loader.get_dataset(lags=4)\n\n- dataset은 dataset[0], \\(\\dots\\), dataset[516]과 같은 방식으로 각 시점별 자료에 접근가능\n\ndataset[0]\n\nData(x=[20, 4], edge_index=[2, 102], edge_attr=[102], y=[20])\n\n\n각 시점에 대한 자료형은 아까 살펴보았던 PyG의 Data 자료형과 같음\n\ntype(dataset[0])\n\ntorch_geometric.data.data.Data\n\n\n\ndataset[0].x \n\ntensor([[-1.0814e-03,  2.8571e-02,  3.5474e-01,  2.9544e-01],\n        [-7.1114e-01, -5.9843e-01,  1.9051e-01,  1.0922e+00],\n        [-3.2281e+00, -2.2910e-01,  1.6103e+00, -1.5487e+00],\n        [ 6.4750e-01, -2.2117e+00, -9.6858e-01,  1.1862e+00],\n        [-1.7302e-01, -9.4717e-01,  1.0347e+00, -6.3751e-01],\n        [ 3.6345e-01, -7.5468e-01,  2.9768e-01, -1.6273e-01],\n        [-3.4174e+00,  1.7031e+00, -1.6434e+00,  1.7434e+00],\n        [-1.9641e+00,  5.5208e-01,  1.1811e+00,  6.7002e-01],\n        [-2.2133e+00,  3.0492e+00, -2.3839e+00,  1.8545e+00],\n        [-3.3141e-01,  9.5218e-01, -3.7281e-01, -8.2971e-02],\n        [-1.8380e+00, -5.8728e-01, -3.5514e-02, -7.2298e-02],\n        [-3.4669e-01, -1.9827e-01,  3.9540e-01, -2.4774e-01],\n        [ 1.4219e+00, -1.3266e+00,  5.2338e-01, -1.6374e-01],\n        [-7.7044e-01,  3.2872e-01, -1.0400e+00,  3.4945e-01],\n        [-7.8061e-01, -6.5022e-01,  1.4361e+00, -1.2864e-01],\n        [-1.0993e+00,  1.2732e-01,  5.3621e-01,  1.9023e-01],\n        [ 2.4583e+00, -1.7811e+00,  5.0732e-02, -9.4371e-01],\n        [ 1.0945e+00, -1.5922e+00,  1.3818e-01,  1.1855e+00],\n        [-7.0875e-01, -2.2460e-01, -7.0875e-01,  1.5630e+00],\n        [-1.8228e+00,  7.8633e-01, -5.6172e-01,  1.2647e+00]])\n\n\n\n이 값들은 features[0]의 값들과 같음. 즉, \\([{\\bf f}_1~ {\\bf f}_2~ {\\bf f}_3~ {\\bf f}_4]\\)를 의미함\n\n\ndataset[0].y\n\ntensor([ 0.7106, -0.0725,  2.6099,  1.7870,  0.8024, -0.2614, -0.8370,  1.9674,\n        -0.4212,  0.1655,  1.2519,  2.3743,  0.7877,  0.4531, -0.1721, -0.0614,\n         1.0452,  0.3203, -1.3791,  0.0036])\n\n\n\n이 값들은 targets[0]의 값들과 같음. 즉, \\({\\bf f}_5\\)를 의미함."
  },
  {
    "objectID": "posts/SOLAR/2023-04-06-stgcn.html#chikenpoxdataset-분석",
    "href": "posts/SOLAR/2023-04-06-stgcn.html#chikenpoxdataset-분석",
    "title": "ChikenpoxDataset",
    "section": "ChikenpoxDataset 분석",
    "text": "ChikenpoxDataset 분석\nref: https://pytorch-geometric-temporal.readthedocs.io/en/latest/modules/dataset.html#module-torch_geometric_temporal.dataset.chickenpox\nA dataset of county level chicken pox cases in Hungary between 2004 and 2014. We made it public during the development of PyTorch Geometric Temporal. The underlying graph is static - vertices are counties and edges are neighbourhoods. Vertex features are lagged weekly counts of the chickenpox cases (we included 4 lags). The target is the weekly number of cases for the upcoming week (signed integers). Our dataset consist of more than 500 snapshots (weeks).\n\nloader = torch_geometric_temporal.dataset.ChickenpoxDatasetLoader()\ndataset = loader.get_dataset(lags=4)\ntrain_dataset, test_dataset = temporal_signal_split(dataset, train_ratio=0.8)\n\n\nLearn\n\nmodel = RecurrentGCN(node_features=4, filters=32)\noptimizer = torch.optim.Adam(model.parameters(), lr=0.01)\nmodel.train()\n\nfor epoch in tqdm(range(50)):\n    for t, snapshot in enumerate(train_dataset):\n        yt_hat = model(snapshot.x, snapshot.edge_index, snapshot.edge_attr)\n        cost = torch.mean((yt_hat-snapshot.y)**2)\n        cost.backward()\n        optimizer.step()\n        optimizer.zero_grad()\n\n100%|█████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:55<00:00,  1.12s/it]\n\n\n\n\nVisualization\n\nmodel.eval()\n\nRecurrentGCN(\n  (recurrent): GConvGRU(\n    (conv_x_z): ChebConv(4, 32, K=2, normalization=sym)\n    (conv_h_z): ChebConv(32, 32, K=2, normalization=sym)\n    (conv_x_r): ChebConv(4, 32, K=2, normalization=sym)\n    (conv_h_r): ChebConv(32, 32, K=2, normalization=sym)\n    (conv_x_h): ChebConv(4, 32, K=2, normalization=sym)\n    (conv_h_h): ChebConv(32, 32, K=2, normalization=sym)\n  )\n  (linear): Linear(in_features=32, out_features=1, bias=True)\n)\n\n\n\nyhat_train = torch.stack([model(snapshot.x,snapshot.edge_index, snapshot.edge_attr) for snapshot in train_dataset]).detach().numpy()\nyhat_test = torch.stack([model(snapshot.x,snapshot.edge_index, snapshot.edge_attr) for snapshot in test_dataset]).detach().numpy()\n\n\nyhat_train.shape, yhat_test.shape\n\n((413, 20, 1), (104, 20, 1))\n\n\n\nV = list(data_dict['node_ids'].keys())\nV\n\n['BACS',\n 'BARANYA',\n 'BEKES',\n 'BORSOD',\n 'BUDAPEST',\n 'CSONGRAD',\n 'FEJER',\n 'GYOR',\n 'HAJDU',\n 'HEVES',\n 'JASZ',\n 'KOMAROM',\n 'NOGRAD',\n 'PEST',\n 'SOMOGY',\n 'SZABOLCS',\n 'TOLNA',\n 'VAS',\n 'VESZPREM',\n 'ZALA']\n\n\n\nfig,ax = plt.subplots(20,1,figsize=(10,50))\nfor k in range(20):\n    ax[k].plot(f[:,k],'--',alpha=0.5,label='observed')\n    ax[k].set_title('node: {}'.format(V[k]))\n    ax[k].plot(yhat_train[:,k],label='predicted (tr)')\n    ax[k].plot(range(yhat_train.shape[0],yhat_train.shape[0]+yhat_test.shape[0]),yhat_test[:,k],label='predicted (test)')\n    ax[k].legend()\nfig.tight_layout()\n\n\n\n\n\nref(오류해결): https://stackoverflow.com/questions/48837384/how-to-create-tuple-with-a-loop-in-python"
  },
  {
    "objectID": "posts/SOLAR/2023-04-29-s-stgcn-ver2-시뮬레이션.html",
    "href": "posts/SOLAR/2023-04-29-s-stgcn-ver2-시뮬레이션.html",
    "title": "[SOLAR] STGCN Ver2 (data2, -N +S) 30회 시뮬레이션 (epoch, filter, lag)",
    "section": "",
    "text": "1 iteration, 다시해야하뮤ㅠㅠㅠ (utils 문제)-> 다시\n\n\n\n\nhttps://github.com/miruetoto/yechan3/tree/main/posts/3_Researches/ITSTGCN/itstgcn\nhttps://miruetoto.github.io/yechan3/posts/3_Researches/ITSTGCN/2023-03-18-SimulationPlanner-Tutorial.html#plnr_gnar_block\n\n\n\n\n\ntrain 2022-06-01 00:00:00 ~ 2022-08-14 17:00:00\ntest 2022-08-14 18:00:00 ~ 2022-09-15 23:00:00"
  },
  {
    "objectID": "posts/SOLAR/2023-04-29-s-stgcn-ver2-시뮬레이션.html#epoch",
    "href": "posts/SOLAR/2023-04-29-s-stgcn-ver2-시뮬레이션.html#epoch",
    "title": "[SOLAR] STGCN Ver2 (data2, -N +S) 30회 시뮬레이션 (epoch, filter, lag)",
    "section": "50 epoch",
    "text": "50 epoch\n\nplans_stgcn = {\n    'max_iteration': 1,   # 30, \n    'method': ['EPT-STGCN'], \n    'lags': [4, 8, 12],  # [4, 8, 12]\n    'nof_filters': [16, 32, 64], # [16, 32, 64]\n    'epoch': [50] # [50, 100, 150]\n}\n\n\nplnr = eptstgcn.planner.PLNR_STGCN(plans_stgcn,loader,dataset_name='data2')\n\n\nplnr.simulate()\n\n1/1 is done\nAll results are stored in ./simulation_results/2023-05-02_10-10-24.csv\n\n\n\neptstgcn.save_data(plnr, './simul_model2/stgcn_v2_50epoch_.pickle')\n\n\nsimul_model = eptstgcn.load_data('./simul_model2/stgcn_v2_50epoch_.pickle')\n\n\ndf_simul_no = simul_model.simulation_results\ndf_simul_no\n\n\n\n\n\n  \n    \n      \n      dataset\n      method\n      normal\n      lags\n      nof_filters\n      epoch\n      mse(train)\n      mse(test)\n      calculation_time\n    \n  \n  \n    \n      0\n      data2\n      EPT-STGCN\n      X\n      4\n      16\n      50\n      0.186759\n      0.163494\n      295.1279\n    \n    \n      1\n      data2\n      EPT-STGCN\n      X\n      4\n      32\n      50\n      0.180856\n      0.159167\n      298.478652\n    \n    \n      2\n      data2\n      EPT-STGCN\n      X\n      4\n      64\n      50\n      0.190731\n      0.175991\n      307.732803\n    \n    \n      3\n      data2\n      EPT-STGCN\n      X\n      8\n      16\n      50\n      0.202791\n      0.174041\n      305.746121\n    \n    \n      4\n      data2\n      EPT-STGCN\n      X\n      8\n      32\n      50\n      0.19739\n      0.169384\n      306.544829\n    \n    \n      5\n      data2\n      EPT-STGCN\n      X\n      8\n      64\n      50\n      0.206705\n      0.176656\n      322.366115\n    \n    \n      6\n      data2\n      EPT-STGCN\n      X\n      12\n      16\n      50\n      0.205929\n      0.175041\n      311.189126\n    \n    \n      7\n      data2\n      EPT-STGCN\n      X\n      12\n      32\n      50\n      0.202787\n      0.175517\n      320.403812\n    \n    \n      8\n      data2\n      EPT-STGCN\n      X\n      12\n      64\n      50\n      0.214775\n      0.180072\n      326.717989"
  },
  {
    "objectID": "posts/SOLAR/2023-04-29-s-stgcn-ver2-시뮬레이션.html#epoch-1",
    "href": "posts/SOLAR/2023-04-29-s-stgcn-ver2-시뮬레이션.html#epoch-1",
    "title": "[SOLAR] STGCN Ver2 (data2, -N +S) 30회 시뮬레이션 (epoch, filter, lag)",
    "section": "100epoch",
    "text": "100epoch\n\nplans_stgcn = {\n    'max_iteration': 1,   # 30, \n    'method': ['EPT-STGCN'], \n    'lags': [4, 8, 12],  # [4, 8, 12]\n    'nof_filters': [16, 32, 64], # [16, 32, 64]\n    'epoch': [100] # [50, 100, 150]\n}\n\n\nplnr = eptstgcn.planner.PLNR_STGCN(plans_stgcn,loader,dataset_name='data2')\n\n\nplnr.simulate()\n\n1/1 is done\nAll results are stored in ./simulation_results/2023-05-02_11-58-22.csv\n\n\n\neptstgcn.save_data(plnr,'./simul_model2/stgcn_v2_100epoch.pickle')\n\n\nsimul_model_100 = eptstgcn.load_data('./simul_model2/stgcn_v2_100epoch.pickle')\n\n\nsimul_model_100.simulation_results\n\n\n\n\n\n  \n    \n      \n      dataset\n      method\n      normal\n      lags\n      nof_filters\n      epoch\n      mse(train)\n      mse(test)\n      calculation_time\n    \n  \n  \n    \n      0\n      data2\n      EPT-STGCN\n      X\n      4\n      16\n      100\n      0.181167\n      0.161676\n      593.648996\n    \n    \n      1\n      data2\n      EPT-STGCN\n      X\n      4\n      32\n      100\n      0.18646\n      0.164435\n      600.581012\n    \n    \n      2\n      data2\n      EPT-STGCN\n      X\n      4\n      64\n      100\n      0.186766\n      0.166847\n      629.295468\n    \n    \n      3\n      data2\n      EPT-STGCN\n      X\n      8\n      16\n      100\n      0.192071\n      0.166316\n      615.509619\n    \n    \n      4\n      data2\n      EPT-STGCN\n      X\n      8\n      32\n      100\n      0.194886\n      0.176269\n      619.257265\n    \n    \n      5\n      data2\n      EPT-STGCN\n      X\n      8\n      64\n      100\n      0.191762\n      0.168039\n      644.2939\n    \n    \n      6\n      data2\n      EPT-STGCN\n      X\n      12\n      16\n      100\n      0.190366\n      0.167113\n      624.165449\n    \n    \n      7\n      data2\n      EPT-STGCN\n      X\n      12\n      32\n      100\n      0.211055\n      0.176866\n      634.041832\n    \n    \n      8\n      data2\n      EPT-STGCN\n      X\n      12\n      64\n      100\n      0.199227\n      0.17213\n      656.926851\n    \n  \n\n\n\n\n\nprint('끝났따! ㅎㅎ')\n\n끝났따! ㅎㅎ"
  },
  {
    "objectID": "posts/SOLAR/2023-04-29-s-stgcn-ver2-시뮬레이션.html#epoch-2",
    "href": "posts/SOLAR/2023-04-29-s-stgcn-ver2-시뮬레이션.html#epoch-2",
    "title": "[SOLAR] STGCN Ver2 (data2, -N +S) 30회 시뮬레이션 (epoch, filter, lag)",
    "section": "150epoch",
    "text": "150epoch\n\nplans_stgcn = {\n    'max_iteration': 1,   # 30, \n    'method': ['EPT-STGCN'], \n    'lags': [4, 8, 12],  # [4, 8, 12]\n    'nof_filters': [16, 32, 64], # [16, 32, 64]\n    'epoch': [150] # [50, 100, 150]\n}\n\n\nplnr = eptstgcn.planner.PLNR_STGCN(plans_stgcn,loader,dataset_name='data2')\n\n\nplnr.simulate()\n\n1/1 is done\nAll results are stored in ./simulation_results/2023-05-02_14-22-41.csv\n\n\n\neptstgcn.save_data(plnr,'./simul_model2/stgcn_v2_150epoch.pickle')\n\n\nsimul_model_150 = eptstgcn.load_data('./simul_model2/stgcn_v2_150epoch.pickle')\n\n\nsimul_model_150.simulation_results\n\n\n\n\n\n  \n    \n      \n      dataset\n      method\n      normal\n      lags\n      nof_filters\n      epoch\n      mse(train)\n      mse(test)\n      calculation_time\n    \n  \n  \n    \n      0\n      data2\n      EPT-STGCN\n      X\n      4\n      16\n      150\n      0.189039\n      0.16644\n      890.523769\n    \n    \n      1\n      data2\n      EPT-STGCN\n      X\n      4\n      32\n      150\n      0.1839\n      0.163163\n      901.624805\n    \n    \n      2\n      data2\n      EPT-STGCN\n      X\n      4\n      64\n      150\n      0.188576\n      0.16788\n      930.632719\n    \n    \n      3\n      data2\n      EPT-STGCN\n      X\n      8\n      16\n      150\n      0.191546\n      0.163098\n      922.549719\n    \n    \n      4\n      data2\n      EPT-STGCN\n      X\n      8\n      32\n      150\n      0.196264\n      0.171726\n      934.935377\n    \n    \n      5\n      data2\n      EPT-STGCN\n      X\n      8\n      64\n      150\n      0.193626\n      0.169606\n      971.07701\n    \n    \n      6\n      data2\n      EPT-STGCN\n      X\n      12\n      16\n      150\n      0.196048\n      0.16558\n      946.160373\n    \n    \n      7\n      data2\n      EPT-STGCN\n      X\n      12\n      32\n      150\n      0.196824\n      0.174657\n      953.823792\n    \n    \n      8\n      data2\n      EPT-STGCN\n      X\n      12\n      64\n      150\n      0.223708\n      0.18818\n      991.851157\n    \n  \n\n\n\n\n\nprint('stgcn ver2 150epoch 시뮬레이션 끄읕!^^')\n\nstgcn ver2 150epoch 시뮬레이션 끄읕!^^"
  },
  {
    "objectID": "posts/SOLAR/2023-04-29-s-stgcn-ver2-시뮬레이션.html#epoch-3",
    "href": "posts/SOLAR/2023-04-29-s-stgcn-ver2-시뮬레이션.html#epoch-3",
    "title": "[SOLAR] STGCN Ver2 (data2, -N +S) 30회 시뮬레이션 (epoch, filter, lag)",
    "section": "50 epoch",
    "text": "50 epoch"
  },
  {
    "objectID": "posts/SOLAR/2023-04-29-s-stgcn-ver2-시뮬레이션.html#epoch-4",
    "href": "posts/SOLAR/2023-04-29-s-stgcn-ver2-시뮬레이션.html#epoch-4",
    "title": "[SOLAR] STGCN Ver2 (data2, -N +S) 30회 시뮬레이션 (epoch, filter, lag)",
    "section": "100 epoch",
    "text": "100 epoch"
  },
  {
    "objectID": "posts/SOLAR/2023-04-29-s-stgcn-ver2-시뮬레이션.html#epoch-5",
    "href": "posts/SOLAR/2023-04-29-s-stgcn-ver2-시뮬레이션.html#epoch-5",
    "title": "[SOLAR] STGCN Ver2 (data2, -N +S) 30회 시뮬레이션 (epoch, filter, lag)",
    "section": "150 epoch",
    "text": "150 epoch\n\nimport matplotlib.pyplot as plt\nplt.boxplot(df_simul_no['mse(test)'])\nplt.show()"
  },
  {
    "objectID": "posts/SOLAR/2023-04-20-데이터수정3.html",
    "href": "posts/SOLAR/2023-04-20-데이터수정3.html",
    "title": "[SOLAR] Create Dataset (data3: 0815/0910) 재수정",
    "section": "",
    "text": "train: 08월 학습, 10일 test\n\n0412 first  0415 update (time 수정)\n\n변경내용 : 00$$23까지 모든 시간대 채운 후 기간설정 (22/06~22/09/15)"
  },
  {
    "objectID": "posts/SOLAR/2023-04-20-데이터수정3.html#import",
    "href": "posts/SOLAR/2023-04-20-데이터수정3.html#import",
    "title": "[SOLAR] Create Dataset (data3: 0815/0910) 재수정",
    "section": "import",
    "text": "import\n\nimport pandas as pd\nimport numpy as np\nimport json\nimport urllib\n\nimport matplotlib.pyplot as plt\nimport time"
  },
  {
    "objectID": "posts/SOLAR/2023-04-20-데이터수정3.html#solar_radiation",
    "href": "posts/SOLAR/2023-04-20-데이터수정3.html#solar_radiation",
    "title": "[SOLAR] Create Dataset (data3: 0815/0910) 재수정",
    "section": "solar_radiation",
    "text": "solar_radiation\n\n# df = pd.read_csv(\"./data/solar_radiation.csv\")\ndf = pd.read_csv('./data/solar_radiation2.csv')\n\n\ndf.shape\n\n(770880, 3)\n\n\n\ndf.duplicated().sum()\n\n0\n\n\n\ndf_ = df.drop_duplicates()\n\n\ndf.duplicated().sum()\n\n0\n\n\n\ndf.shape\n\n(770880, 3)\n\n\n\n# df_.to_csv('./data/solar_radiation.csv', index=False) ## 전에 것.\n\n\nsolar 데이터 수정완료 (solar_radiation2.csv로 변경)"
  },
  {
    "objectID": "posts/SOLAR/2023-04-20-데이터수정3.html#날짜-재설정-train-test",
    "href": "posts/SOLAR/2023-04-20-데이터수정3.html#날짜-재설정-train-test",
    "title": "[SOLAR] Create Dataset (data3: 0815/0910) 재수정",
    "section": "날짜 재설정, train / test",
    "text": "날짜 재설정, train / test\n\nimport gc\ngc.collect()\n\n1538\n\n\n\n# df = pd.read_csv('./data/solar_radiation.csv')\n\n\ndf.duplicated().sum()\n\n0\n\n\n0815/0910 fullm\n\ntrain = df.query(\"date >= '2022-08-15-00:00' and date <= '2022-08-31-23:00'\")\ntest = df.query(\"date >= '2022-09-01-00:00' and date <= '2022-09-10-23:00'\")\n\n\ntrain.shape, test.shape, \n\n((17952, 3), (10560, 3))\n\n\n\nprint(train.shape[0]/(train.shape[0]+test.shape[0]))\nprint(test.shape[0]/(train.shape[0]+test.shape[0]))\n\n0.6296296296296297\n0.37037037037037035\n\n\n\ntrain[:200].plot(backend='plotly',x='date',y='solar_radiation',color='region')\n\n\n                                                \n\n\n\n중복되는 것 잘 처리된 듯.\n\n\ntrain = train.reset_index(drop=True)\ntest = test.reset_index(drop=True)\n\n\ntrain.to_csv('./data3/train.csv', index=False)\ntest.to_csv('./data3/test.csv', index=False)\n\n\nsolar_radiation = pd.concat([train, test])\nsolar_radiation.to_csv('./data3/solar_radiation.csv')\n\n\n23/04/15 재생성"
  },
  {
    "objectID": "posts/SOLAR/2023-04-20-데이터수정3.html#weight",
    "href": "posts/SOLAR/2023-04-20-데이터수정3.html#weight",
    "title": "[SOLAR] Create Dataset (data3: 0815/0910) 재수정",
    "section": "Weight",
    "text": "Weight\n\nimport rpy2\n%load_ext rpy2.ipython \n\nThe rpy2.ipython extension is already loaded. To reload it, use:\n  %reload_ext rpy2.ipython\n\n\n\n%R -i train\n\n\n%%R\nlibrary(data.table)\nlibrary(tidyverse)\nlibrary(dplyr)\nlibrary(corrplot)\nlibrary(lubridate)\n\n\n%%R\nhead(train)\n\n  region solar_radiation             date\n0 북춘천               0 2022-08-15-00:00\n1 북춘천               0 2022-08-15-01:00\n2 북춘천               0 2022-08-15-02:00\n3 북춘천               0 2022-08-15-03:00\n4 북춘천               0 2022-08-15-04:00\n5 북춘천               0 2022-08-15-05:00\n\n\n\n%%R\ntrain = train |> mutate(date = ymd_hm(date))\n\n\n%%R\ntrain <- train %>%\n              group_by(region) %>%\n              mutate(row = row_number()) %>%\n              tidyr::pivot_wider(names_from = region, values_from = solar_radiation) %>%\n              select(-row)\n\n\n%%R\nnum_vars <- train %>% select(-date)\nweight <- cor(num_vars)\nweight\n\n          북춘천      철원    대관령      춘천    백령도    북강릉      강릉\n북춘천 1.0000000 0.9665014 0.8676406 0.9905586 0.9124785 0.8498203 0.8398575\n철원   0.9665014 1.0000000 0.8459175 0.9612058 0.9361341 0.8173580 0.8158285\n대관령 0.8676406 0.8459175 1.0000000 0.8580424 0.7406484 0.9588833 0.9566090\n춘천   0.9905586 0.9612058 0.8580424 1.0000000 0.9126064 0.8414889 0.8308896\n백령도 0.9124785 0.9361341 0.7406484 0.9126064 1.0000000 0.7089984 0.7090984\n북강릉 0.8498203 0.8173580 0.9588833 0.8414889 0.7089984 1.0000000 0.9840376\n강릉   0.8398575 0.8158285 0.9566090 0.8308896 0.7090984 0.9840376 1.0000000\n서울   0.9365005 0.9217237 0.7862134 0.9426855 0.8931777 0.7797975 0.7743385\n인천   0.9586519 0.9488937 0.8547050 0.9613312 0.9075589 0.8360588 0.8336797\n원주   0.9054877 0.8705595 0.8786925 0.9126374 0.8136393 0.8743302 0.8741981\n울릉도 0.8084346 0.7882297 0.8834539 0.8090458 0.6630169 0.8911027 0.8848383\n수원   0.9399975 0.9243481 0.8725327 0.9439573 0.8743172 0.8437161 0.8432163\n서산   0.9000610 0.8796863 0.8695632 0.8947074 0.8629653 0.8543112 0.8517806\n청주   0.8611482 0.8319409 0.8809256 0.8678977 0.7641780 0.8741435 0.8724600\n대전   0.8216215 0.7987433 0.8963844 0.8279753 0.7241614 0.8902295 0.8924839\n추풍령 0.7519200 0.7242906 0.8397465 0.7589504 0.6380367 0.8506990 0.8549578\n안동   0.8094494 0.7800362 0.8764552 0.8177274 0.6887846 0.8777939 0.8666397\n포항   0.6811470 0.6527614 0.7830896 0.6868770 0.5431092 0.8111415 0.8110628\n대구   0.7227752 0.7003675 0.8211468 0.7238487 0.5981430 0.8452508 0.8483571\n전주   0.7377676 0.7119287 0.8113022 0.7452667 0.6482097 0.8247020 0.8270365\n창원   0.6565234 0.6369439 0.7583167 0.6665614 0.5217493 0.7935026 0.7876640\n광주   0.5807583 0.5799228 0.6682283 0.5981904 0.5394154 0.7000826 0.7028999\n부산   0.6639765 0.6534376 0.7330341 0.6725752 0.5280383 0.7698198 0.7675433\n목포   0.6780935 0.6898699 0.7206235 0.6919340 0.6537061 0.7406772 0.7428741\n여수   0.6789891 0.6736455 0.7460999 0.6904693 0.5852041 0.7786885 0.7782749\n흑산도 0.5489378 0.5651173 0.6263111 0.5659377 0.5184586 0.6706972 0.6660309\n고창   0.7081524 0.7126460 0.7507314 0.7206039 0.6649395 0.7655157 0.7746100\n홍성   0.8897505 0.8565782 0.8979874 0.8922948 0.8113796 0.8708598 0.8666200\n제주   0.6441532 0.6538700 0.6558497 0.6501166 0.5943868 0.6744504 0.6681416\n고산   0.6234521 0.6334689 0.6142124 0.6311473 0.5934521 0.6567621 0.6449302\n진주   0.6688587 0.6471022 0.7476654 0.6813911 0.5495088 0.7764888 0.7785323\n고창군 0.7061089 0.7053213 0.7821725 0.7153729 0.6450042 0.7932888 0.7962211\n영광군 0.7119121 0.7142543 0.7800838 0.7256849 0.6741396 0.7968637 0.8006143\n김해시 0.6606160 0.6519428 0.7529844 0.6697301 0.5289128 0.7823148 0.7767609\n순창군 0.7281180 0.7268107 0.8135723 0.7388216 0.6550968 0.8298343 0.8325753\n북창원 0.6512097 0.6317126 0.7403075 0.6646309 0.5146200 0.7821665 0.7762883\n양산시 0.6683986 0.6565744 0.7525494 0.6785402 0.5356891 0.7904889 0.7847557\n보성군 0.6636398 0.6563947 0.7514979 0.6723801 0.5778611 0.7682372 0.7702322\n강진군 0.6771357 0.6936115 0.7310724 0.6906075 0.6397485 0.7546287 0.7513723\n의령군 0.6618755 0.6417245 0.7546756 0.6725847 0.5346822 0.7907188 0.7871482\n함양군 0.7084714 0.6935498 0.8086824 0.7135671 0.5983090 0.8276591 0.8348229\n광양시 0.7172495 0.7096999 0.7865329 0.7290303 0.6251627 0.8019529 0.7963049\n청송군 0.7862383 0.7567174 0.8534148 0.7918394 0.6640112 0.8613630 0.8586282\n경주시 0.6638256 0.6324344 0.7715670 0.6705959 0.5088791 0.8083247 0.8054188\n            서울      인천      원주    울릉도      수원      서산      청주\n북춘천 0.9365005 0.9586519 0.9054877 0.8084346 0.9399975 0.9000610 0.8611482\n철원   0.9217237 0.9488937 0.8705595 0.7882297 0.9243481 0.8796863 0.8319409\n대관령 0.7862134 0.8547050 0.8786925 0.8834539 0.8725327 0.8695632 0.8809256\n춘천   0.9426855 0.9613312 0.9126374 0.8090458 0.9439573 0.8947074 0.8678977\n백령도 0.8931777 0.9075589 0.8136393 0.6630169 0.8743172 0.8629653 0.7641780\n북강릉 0.7797975 0.8360588 0.8743302 0.8911027 0.8437161 0.8543112 0.8741435\n강릉   0.7743385 0.8336797 0.8741981 0.8848383 0.8432163 0.8517806 0.8724600\n서울   1.0000000 0.9470918 0.8826506 0.7547963 0.9160434 0.8750522 0.8456077\n인천   0.9470918 1.0000000 0.8931055 0.8013486 0.9351545 0.9170600 0.8598221\n원주   0.8826506 0.8931055 1.0000000 0.8415091 0.9284974 0.9097367 0.9256166\n울릉도 0.7547963 0.8013486 0.8415091 1.0000000 0.8208782 0.7897569 0.8806099\n수원   0.9160434 0.9351545 0.9284974 0.8208782 1.0000000 0.9212225 0.9050331\n서산   0.8750522 0.9170600 0.9097367 0.7897569 0.9212225 1.0000000 0.8958587\n청주   0.8456077 0.8598221 0.9256166 0.8806099 0.9050331 0.8958587 1.0000000\n대전   0.7763433 0.8136386 0.8853999 0.8965382 0.8629801 0.8526847 0.9279683\n추풍령 0.6909970 0.7629451 0.8320753 0.8856766 0.7919782 0.7978117 0.8732739\n안동   0.7521713 0.8067711 0.8843757 0.9144644 0.8486225 0.8353626 0.9114717\n포항   0.6042630 0.6757125 0.7454452 0.8596462 0.7060992 0.7065736 0.8015177\n대구   0.6333413 0.7194413 0.7768234 0.8796101 0.7411319 0.7517588 0.8124003\n전주   0.6974292 0.7555592 0.8126635 0.8566621 0.7898208 0.8065125 0.8497158\n창원   0.5863968 0.6588092 0.7061334 0.8717525 0.6829446 0.6533903 0.7515724\n광주   0.5762525 0.5887122 0.6556997 0.7692402 0.6427095 0.6380119 0.7177917\n부산   0.5901339 0.6583309 0.6923164 0.8712931 0.6744843 0.6405011 0.7458282\n목포   0.6168231 0.6942240 0.7161425 0.7707390 0.7260516 0.7359857 0.7496216\n여수   0.6169776 0.6891985 0.7159171 0.8511565 0.7056622 0.7012557 0.7697149\n흑산도 0.4824258 0.5404782 0.5970829 0.7160842 0.5932045 0.5917276 0.6686747\n고창   0.6548939 0.7240656 0.7738871 0.8123158 0.7689861 0.7667292 0.8015432\n홍성   0.8620268 0.9029228 0.9294087 0.8474114 0.9334386 0.9522176 0.9284848\n제주   0.5735950 0.6356622 0.6394287 0.7634823 0.6535560 0.6408242 0.6650314\n고산   0.5679666 0.6094368 0.6198385 0.7408331 0.6158646 0.6231919 0.6477740\n진주   0.6077105 0.6781500 0.7248788 0.8634368 0.7021846 0.6802224 0.7622334\n고창군 0.6591706 0.7265318 0.7838383 0.8394474 0.7700803 0.7885881 0.8093965\n영광군 0.6579428 0.7231798 0.7776360 0.8203164 0.7639740 0.7918768 0.8217300\n김해시 0.5884623 0.6633196 0.6940338 0.8725664 0.6731866 0.6478440 0.7488224\n순창군 0.6647286 0.7401187 0.7883054 0.8738374 0.7667344 0.7743389 0.8297902\n북창원 0.5868275 0.6570992 0.6977356 0.8571440 0.6799346 0.6612988 0.7471792\n양산시 0.5920607 0.6661038 0.6988131 0.8688425 0.6851516 0.6583956 0.7525319\n보성군 0.5965439 0.6779947 0.7184096 0.8442479 0.6952581 0.6959054 0.7664950\n강진군 0.6166267 0.6898281 0.7173723 0.7840152 0.7143295 0.7260897 0.7586522\n의령군 0.5898519 0.6654904 0.7172560 0.8685546 0.6870086 0.6800000 0.7656704\n함양군 0.6355838 0.7189058 0.7688034 0.8820559 0.7476711 0.7605734 0.8099248\n광양시 0.6597585 0.7286347 0.7531124 0.8758573 0.7383722 0.7323753 0.8015781\n청송군 0.7277856 0.7819696 0.8527790 0.9000770 0.8174954 0.8071824 0.8935565\n경주시 0.5802259 0.6504053 0.7319310 0.8729885 0.6894496 0.6754109 0.7836962\n            대전    추풍령      안동      포항      대구      전주      창원\n북춘천 0.8216215 0.7519200 0.8094494 0.6811470 0.7227752 0.7377676 0.6565234\n철원   0.7987433 0.7242906 0.7800362 0.6527614 0.7003675 0.7119287 0.6369439\n대관령 0.8963844 0.8397465 0.8764552 0.7830896 0.8211468 0.8113022 0.7583167\n춘천   0.8279753 0.7589504 0.8177274 0.6868770 0.7238487 0.7452667 0.6665614\n백령도 0.7241614 0.6380367 0.6887846 0.5431092 0.5981430 0.6482097 0.5217493\n북강릉 0.8902295 0.8506990 0.8777939 0.8111415 0.8452508 0.8247020 0.7935026\n강릉   0.8924839 0.8549578 0.8666397 0.8110628 0.8483571 0.8270365 0.7876640\n서울   0.7763433 0.6909970 0.7521713 0.6042630 0.6333413 0.6974292 0.5863968\n인천   0.8136386 0.7629451 0.8067711 0.6757125 0.7194413 0.7555592 0.6588092\n원주   0.8853999 0.8320753 0.8843757 0.7454452 0.7768234 0.8126635 0.7061334\n울릉도 0.8965382 0.8856766 0.9144644 0.8596462 0.8796101 0.8566621 0.8717525\n수원   0.8629801 0.7919782 0.8486225 0.7060992 0.7411319 0.7898208 0.6829446\n서산   0.8526847 0.7978117 0.8353626 0.7065736 0.7517588 0.8065125 0.6533903\n청주   0.9279683 0.8732739 0.9114717 0.8015177 0.8124003 0.8497158 0.7515724\n대전   1.0000000 0.9119693 0.9307872 0.8689539 0.8859246 0.8915654 0.8294050\n추풍령 0.9119693 1.0000000 0.9525037 0.9130101 0.9453581 0.9353461 0.8816511\n안동   0.9307872 0.9525037 1.0000000 0.9092215 0.9245054 0.9107612 0.8661519\n포항   0.8689539 0.9130101 0.9092215 1.0000000 0.9542593 0.8794247 0.9218113\n대구   0.8859246 0.9453581 0.9245054 0.9542593 1.0000000 0.9204689 0.9219292\n전주   0.8915654 0.9353461 0.9107612 0.8794247 0.9204689 1.0000000 0.8468222\n창원   0.8294050 0.8816511 0.8661519 0.9218113 0.9219292 0.8468222 1.0000000\n광주   0.7617605 0.7708499 0.7907602 0.8140294 0.7870618 0.7813535 0.8108583\n부산   0.8135963 0.8569102 0.8429691 0.9088345 0.9021609 0.8246058 0.9567867\n목포   0.8175289 0.8381466 0.8223617 0.8231666 0.8429878 0.8408652 0.8094674\n여수   0.8361754 0.8729323 0.8634580 0.9067705 0.9090305 0.8599071 0.9463305\n흑산도 0.7639440 0.7655342 0.7446138 0.7881498 0.7894883 0.7604512 0.8214624\n고창   0.8498482 0.8852601 0.8588626 0.8362757 0.8685732 0.8906104 0.8130373\n홍성   0.9038931 0.8474368 0.8944856 0.7635505 0.8001969 0.8554945 0.7205565\n제주   0.7146339 0.7131749 0.7343653 0.7529339 0.7644171 0.7075914 0.8195382\n고산   0.7008161 0.7228292 0.7302654 0.7543234 0.7658824 0.7349488 0.8140677\n진주   0.8432286 0.8963498 0.8800447 0.9181803 0.9296777 0.8780141 0.9613568\n고창군 0.8648497 0.8985137 0.8839960 0.8632498 0.8838257 0.9144315 0.8327353\n영광군 0.8735840 0.8949228 0.8846632 0.8749419 0.8965140 0.9079360 0.8432528\n김해시 0.8212040 0.8635190 0.8506581 0.9063987 0.9170509 0.8281184 0.9695989\n순창군 0.9022292 0.9298650 0.9169641 0.9217250 0.9362180 0.9204433 0.9111902\n북창원 0.8214765 0.8749001 0.8567266 0.9165221 0.9155495 0.8540759 0.9793273\n양산시 0.8289236 0.8720306 0.8550334 0.9147105 0.9216755 0.8384062 0.9741085\n보성군 0.8418936 0.8820647 0.8701082 0.8942080 0.9055749 0.8707475 0.9308584\n강진군 0.8241532 0.8439771 0.8324531 0.8382390 0.8558506 0.8346140 0.8564907\n의령군 0.8452909 0.9080844 0.8874102 0.9372158 0.9448508 0.8752245 0.9702599\n함양군 0.8832451 0.9354366 0.9192191 0.9379411 0.9602969 0.9184937 0.9255711\n광양시 0.8661455 0.8948043 0.8876137 0.9099097 0.9203348 0.8978348 0.9374702\n청송군 0.9317074 0.9529616 0.9679490 0.9377054 0.9438619 0.9096050 0.8728633\n경주시 0.8548963 0.9077224 0.8983793 0.9721295 0.9510429 0.8626115 0.9495921\n            광주      부산      목포      여수    흑산도      고창      홍성\n북춘천 0.5807583 0.6639765 0.6780935 0.6789891 0.5489378 0.7081524 0.8897505\n철원   0.5799228 0.6534376 0.6898699 0.6736455 0.5651173 0.7126460 0.8565782\n대관령 0.6682283 0.7330341 0.7206235 0.7460999 0.6263111 0.7507314 0.8979874\n춘천   0.5981904 0.6725752 0.6919340 0.6904693 0.5659377 0.7206039 0.8922948\n백령도 0.5394154 0.5280383 0.6537061 0.5852041 0.5184586 0.6649395 0.8113796\n북강릉 0.7000826 0.7698198 0.7406772 0.7786885 0.6706972 0.7655157 0.8708598\n강릉   0.7028999 0.7675433 0.7428741 0.7782749 0.6660309 0.7746100 0.8666200\n서울   0.5762525 0.5901339 0.6168231 0.6169776 0.4824258 0.6548939 0.8620268\n인천   0.5887122 0.6583309 0.6942240 0.6891985 0.5404782 0.7240656 0.9029228\n원주   0.6556997 0.6923164 0.7161425 0.7159171 0.5970829 0.7738871 0.9294087\n울릉도 0.7692402 0.8712931 0.7707390 0.8511565 0.7160842 0.8123158 0.8474114\n수원   0.6427095 0.6744843 0.7260516 0.7056622 0.5932045 0.7689861 0.9334386\n서산   0.6380119 0.6405011 0.7359857 0.7012557 0.5917276 0.7667292 0.9522176\n청주   0.7177917 0.7458282 0.7496216 0.7697149 0.6686747 0.8015432 0.9284848\n대전   0.7617605 0.8135963 0.8175289 0.8361754 0.7639440 0.8498482 0.9038931\n추풍령 0.7708499 0.8569102 0.8381466 0.8729323 0.7655342 0.8852601 0.8474368\n안동   0.7907602 0.8429691 0.8223617 0.8634580 0.7446138 0.8588626 0.8944856\n포항   0.8140294 0.9088345 0.8231666 0.9067705 0.7881498 0.8362757 0.7635505\n대구   0.7870618 0.9021609 0.8429878 0.9090305 0.7894883 0.8685732 0.8001969\n전주   0.7813535 0.8246058 0.8408652 0.8599071 0.7604512 0.8906104 0.8554945\n창원   0.8108583 0.9567867 0.8094674 0.9463305 0.8214624 0.8130373 0.7205565\n광주   1.0000000 0.7848072 0.8033530 0.8189305 0.8032688 0.8025328 0.6732265\n부산   0.7848072 1.0000000 0.8063633 0.9362355 0.8224429 0.8048127 0.6992092\n목포   0.8033530 0.8063633 1.0000000 0.8782728 0.8947025 0.9148345 0.7590584\n여수   0.8189305 0.9362355 0.8782728 1.0000000 0.8644579 0.8632834 0.7458988\n흑산도 0.8032688 0.8224429 0.8947025 0.8644579 1.0000000 0.8282903 0.6239047\n고창   0.8025328 0.8048127 0.9148345 0.8632834 0.8282903 1.0000000 0.8025170\n홍성   0.6732265 0.6992092 0.7590584 0.7458988 0.6239047 0.8025170 1.0000000\n제주   0.7549749 0.8463593 0.8217152 0.8592872 0.8147902 0.7742429 0.6592111\n고산   0.7808581 0.8325527 0.8331540 0.8758519 0.8452999 0.7881321 0.6322480\n진주   0.8300538 0.9410736 0.8398177 0.9422783 0.8200121 0.8486972 0.7480279\n고창군 0.8046908 0.8102427 0.9046583 0.8637749 0.8095030 0.9244844 0.8306129\n영광군 0.8318732 0.8356529 0.9332890 0.8908366 0.8791699 0.9520346 0.8179800\n김해시 0.7867470 0.9670828 0.7966974 0.9225753 0.8057136 0.7969285 0.7063799\n순창군 0.8362604 0.8911256 0.8976286 0.9169548 0.8487318 0.9148916 0.8126807\n북창원 0.8111774 0.9597132 0.8011566 0.9416778 0.8041198 0.8137209 0.7168661\n양산시 0.7911661 0.9728328 0.8154781 0.9420771 0.8213273 0.8159293 0.7115602\n보성군 0.8073908 0.9127006 0.8792755 0.9560035 0.8581026 0.8620331 0.7530730\n강진군 0.7941833 0.8471543 0.9375761 0.9094795 0.9028406 0.8900708 0.7474912\n의령군 0.8187884 0.9466423 0.8382663 0.9502871 0.8294111 0.8407297 0.7424661\n함양군 0.8188588 0.9025819 0.8693950 0.9337001 0.8216808 0.9023083 0.8106495\n광양시 0.8133531 0.9226753 0.8606085 0.9559896 0.8322999 0.8692124 0.7852015\n청송군 0.7920206 0.8519807 0.8406470 0.8703602 0.7560202 0.8758821 0.8655180\n경주시 0.8137952 0.9262983 0.8197885 0.9227412 0.8067368 0.8340261 0.7359533\n            제주      고산      진주    고창군    영광군    김해시    순창군\n북춘천 0.6441532 0.6234521 0.6688587 0.7061089 0.7119121 0.6606160 0.7281180\n철원   0.6538700 0.6334689 0.6471022 0.7053213 0.7142543 0.6519428 0.7268107\n대관령 0.6558497 0.6142124 0.7476654 0.7821725 0.7800838 0.7529844 0.8135723\n춘천   0.6501166 0.6311473 0.6813911 0.7153729 0.7256849 0.6697301 0.7388216\n백령도 0.5943868 0.5934521 0.5495088 0.6450042 0.6741396 0.5289128 0.6550968\n북강릉 0.6744504 0.6567621 0.7764888 0.7932888 0.7968637 0.7823148 0.8298343\n강릉   0.6681416 0.6449302 0.7785323 0.7962211 0.8006143 0.7767609 0.8325753\n서울   0.5735950 0.5679666 0.6077105 0.6591706 0.6579428 0.5884623 0.6647286\n인천   0.6356622 0.6094368 0.6781500 0.7265318 0.7231798 0.6633196 0.7401187\n원주   0.6394287 0.6198385 0.7248788 0.7838383 0.7776360 0.6940338 0.7883054\n울릉도 0.7634823 0.7408331 0.8634368 0.8394474 0.8203164 0.8725664 0.8738374\n수원   0.6535560 0.6158646 0.7021846 0.7700803 0.7639740 0.6731866 0.7667344\n서산   0.6408242 0.6231919 0.6802224 0.7885881 0.7918768 0.6478440 0.7743389\n청주   0.6650314 0.6477740 0.7622334 0.8093965 0.8217300 0.7488224 0.8297902\n대전   0.7146339 0.7008161 0.8432286 0.8648497 0.8735840 0.8212040 0.9022292\n추풍령 0.7131749 0.7228292 0.8963498 0.8985137 0.8949228 0.8635190 0.9298650\n안동   0.7343653 0.7302654 0.8800447 0.8839960 0.8846632 0.8506581 0.9169641\n포항   0.7529339 0.7543234 0.9181803 0.8632498 0.8749419 0.9063987 0.9217250\n대구   0.7644171 0.7658824 0.9296777 0.8838257 0.8965140 0.9170509 0.9362180\n전주   0.7075914 0.7349488 0.8780141 0.9144315 0.9079360 0.8281184 0.9204433\n창원   0.8195382 0.8140677 0.9613568 0.8327353 0.8432528 0.9695989 0.9111902\n광주   0.7549749 0.7808581 0.8300538 0.8046908 0.8318732 0.7867470 0.8362604\n부산   0.8463593 0.8325527 0.9410736 0.8102427 0.8356529 0.9670828 0.8911256\n목포   0.8217152 0.8331540 0.8398177 0.9046583 0.9332890 0.7966974 0.8976286\n여수   0.8592872 0.8758519 0.9422783 0.8637749 0.8908366 0.9225753 0.9169548\n흑산도 0.8147902 0.8452999 0.8200121 0.8095030 0.8791699 0.8057136 0.8487318\n고창   0.7742429 0.7881321 0.8486972 0.9244844 0.9520346 0.7969285 0.9148916\n홍성   0.6592111 0.6322480 0.7480279 0.8306129 0.8179800 0.7063799 0.8126807\n제주   1.0000000 0.9273760 0.8020888 0.7595657 0.8061107 0.8189268 0.8030353\n고산   0.9273760 1.0000000 0.8048042 0.7698768 0.8254057 0.8077049 0.8051336\n진주   0.8020888 0.8048042 1.0000000 0.8624845 0.8778907 0.9360035 0.9249471\n고창군 0.7595657 0.7698768 0.8624845 1.0000000 0.9327240 0.8048444 0.9182945\n영광군 0.8061107 0.8254057 0.8778907 0.9327240 1.0000000 0.8334300 0.9384535\n김해시 0.8189268 0.8077049 0.9360035 0.8048444 0.8334300 1.0000000 0.8982821\n순창군 0.8030353 0.8051336 0.9249471 0.9182945 0.9384535 0.8982821 1.0000000\n북창원 0.8177725 0.8089568 0.9565541 0.8296537 0.8397645 0.9651250 0.9006506\n양산시 0.8321651 0.8171159 0.9468438 0.8201303 0.8500990 0.9790632 0.9152760\n보성군 0.8331415 0.8521020 0.9349213 0.8556322 0.8922799 0.9181137 0.9132778\n강진군 0.8261467 0.8594053 0.8618769 0.8652090 0.9152089 0.8486955 0.8942555\n의령군 0.8053959 0.8111741 0.9745918 0.8611940 0.8773540 0.9482125 0.9289536\n함양군 0.7867384 0.7883798 0.9415142 0.9048758 0.9216138 0.9015664 0.9561080\n광양시 0.8158936 0.8442496 0.9483671 0.8718609 0.8978551 0.9248950 0.9198958\n청송군 0.7280228 0.7271437 0.8807002 0.8824316 0.8901227 0.8613231 0.9250967\n경주시 0.7918679 0.7800593 0.9344554 0.8478487 0.8608375 0.9337425 0.9095627\n          북창원    양산시    보성군    강진군    의령군    함양군    광양시\n북춘천 0.6512097 0.6683986 0.6636398 0.6771357 0.6618755 0.7084714 0.7172495\n철원   0.6317126 0.6565744 0.6563947 0.6936115 0.6417245 0.6935498 0.7096999\n대관령 0.7403075 0.7525494 0.7514979 0.7310724 0.7546756 0.8086824 0.7865329\n춘천   0.6646309 0.6785402 0.6723801 0.6906075 0.6725847 0.7135671 0.7290303\n백령도 0.5146200 0.5356891 0.5778611 0.6397485 0.5346822 0.5983090 0.6251627\n북강릉 0.7821665 0.7904889 0.7682372 0.7546287 0.7907188 0.8276591 0.8019529\n강릉   0.7762883 0.7847557 0.7702322 0.7513723 0.7871482 0.8348229 0.7963049\n서울   0.5868275 0.5920607 0.5965439 0.6166267 0.5898519 0.6355838 0.6597585\n인천   0.6570992 0.6661038 0.6779947 0.6898281 0.6654904 0.7189058 0.7286347\n원주   0.6977356 0.6988131 0.7184096 0.7173723 0.7172560 0.7688034 0.7531124\n울릉도 0.8571440 0.8688425 0.8442479 0.7840152 0.8685546 0.8820559 0.8758573\n수원   0.6799346 0.6851516 0.6952581 0.7143295 0.6870086 0.7476711 0.7383722\n서산   0.6612988 0.6583956 0.6959054 0.7260897 0.6800000 0.7605734 0.7323753\n청주   0.7471792 0.7525319 0.7664950 0.7586522 0.7656704 0.8099248 0.8015781\n대전   0.8214765 0.8289236 0.8418936 0.8241532 0.8452909 0.8832451 0.8661455\n추풍령 0.8749001 0.8720306 0.8820647 0.8439771 0.9080844 0.9354366 0.8948043\n안동   0.8567266 0.8550334 0.8701082 0.8324531 0.8874102 0.9192191 0.8876137\n포항   0.9165221 0.9147105 0.8942080 0.8382390 0.9372158 0.9379411 0.9099097\n대구   0.9155495 0.9216755 0.9055749 0.8558506 0.9448508 0.9602969 0.9203348\n전주   0.8540759 0.8384062 0.8707475 0.8346140 0.8752245 0.9184937 0.8978348\n창원   0.9793273 0.9741085 0.9308584 0.8564907 0.9702599 0.9255711 0.9374702\n광주   0.8111774 0.7911661 0.8073908 0.7941833 0.8187884 0.8188588 0.8133531\n부산   0.9597132 0.9728328 0.9127006 0.8471543 0.9466423 0.9025819 0.9226753\n목포   0.8011566 0.8154781 0.8792755 0.9375761 0.8382663 0.8693950 0.8606085\n여수   0.9416778 0.9420771 0.9560035 0.9094795 0.9502871 0.9337001 0.9559896\n흑산도 0.8041198 0.8213273 0.8581026 0.9028406 0.8294111 0.8216808 0.8322999\n고창   0.8137209 0.8159293 0.8620331 0.8900708 0.8407297 0.9023083 0.8692124\n홍성   0.7168661 0.7115602 0.7530730 0.7474912 0.7424661 0.8106495 0.7852015\n제주   0.8177725 0.8321651 0.8331415 0.8261467 0.8053959 0.7867384 0.8158936\n고산   0.8089568 0.8171159 0.8521020 0.8594053 0.8111741 0.7883798 0.8442496\n진주   0.9565541 0.9468438 0.9349213 0.8618769 0.9745918 0.9415142 0.9483671\n고창군 0.8296537 0.8201303 0.8556322 0.8652090 0.8611940 0.9048758 0.8718609\n영광군 0.8397645 0.8500990 0.8922799 0.9152089 0.8773540 0.9216138 0.8978551\n김해시 0.9651250 0.9790632 0.9181137 0.8486955 0.9482125 0.9015664 0.9248950\n순창군 0.9006506 0.9152760 0.9132778 0.8942555 0.9289536 0.9561080 0.9198958\n북창원 1.0000000 0.9722951 0.9149775 0.8478443 0.9685204 0.9203654 0.9350347\n양산시 0.9722951 1.0000000 0.9155880 0.8599827 0.9603439 0.9225160 0.9254057\n보성군 0.9149775 0.9155880 1.0000000 0.9261005 0.9338861 0.9271567 0.9489019\n강진군 0.8478443 0.8599827 0.9261005 1.0000000 0.8686075 0.8768863 0.8992567\n의령군 0.9685204 0.9603439 0.9338861 0.8686075 1.0000000 0.9495130 0.9461485\n함양군 0.9203654 0.9225160 0.9271567 0.8768863 0.9495130 1.0000000 0.9216557\n광양시 0.9350347 0.9254057 0.9489019 0.8992567 0.9461485 0.9216557 1.0000000\n청송군 0.8599791 0.8674542 0.8745260 0.8428627 0.8955464 0.9221807 0.8933446\n경주시 0.9422085 0.9356869 0.9104429 0.8400636 0.9611459 0.9388628 0.9210299\n          청송군    경주시\n북춘천 0.7862383 0.6638256\n철원   0.7567174 0.6324344\n대관령 0.8534148 0.7715670\n춘천   0.7918394 0.6705959\n백령도 0.6640112 0.5088791\n북강릉 0.8613630 0.8083247\n강릉   0.8586282 0.8054188\n서울   0.7277856 0.5802259\n인천   0.7819696 0.6504053\n원주   0.8527790 0.7319310\n울릉도 0.9000770 0.8729885\n수원   0.8174954 0.6894496\n서산   0.8071824 0.6754109\n청주   0.8935565 0.7836962\n대전   0.9317074 0.8548963\n추풍령 0.9529616 0.9077224\n안동   0.9679490 0.8983793\n포항   0.9377054 0.9721295\n대구   0.9438619 0.9510429\n전주   0.9096050 0.8626115\n창원   0.8728633 0.9495921\n광주   0.7920206 0.8137952\n부산   0.8519807 0.9262983\n목포   0.8406470 0.8197885\n여수   0.8703602 0.9227412\n흑산도 0.7560202 0.8067368\n고창   0.8758821 0.8340261\n홍성   0.8655180 0.7359533\n제주   0.7280228 0.7918679\n고산   0.7271437 0.7800593\n진주   0.8807002 0.9344554\n고창군 0.8824316 0.8478487\n영광군 0.8901227 0.8608375\n김해시 0.8613231 0.9337425\n순창군 0.9250967 0.9095627\n북창원 0.8599791 0.9422085\n양산시 0.8674542 0.9356869\n보성군 0.8745260 0.9104429\n강진군 0.8428627 0.8400636\n의령군 0.8955464 0.9611459\n함양군 0.9221807 0.9388628\n광양시 0.8933446 0.9210299\n청송군 1.0000000 0.9146385\n경주시 0.9146385 1.0000000\n\n\n\n%%R\nwrite.csv(weight, './data3/weight.csv', row.names=FALSE)"
  },
  {
    "objectID": "posts/SOLAR/2023-04-20-데이터수정3.html#ept-weight",
    "href": "posts/SOLAR/2023-04-20-데이터수정3.html#ept-weight",
    "title": "[SOLAR] Create Dataset (data3: 0815/0910) 재수정",
    "section": "EPT Weight",
    "text": "EPT Weight\n\n# train = pd.read_csv('./data2/train.csv')\n\n\ntrain.duplicated().sum()\n\n0\n\n\n\n%R -i train\n\n\n%%R\nlibrary(EPT)\ntrain%>%head()\n\n  region solar_radiation             date\n0 북춘천               0 2022-08-15-00:00\n1 북춘천               0 2022-08-15-01:00\n2 북춘천               0 2022-08-15-02:00\n3 북춘천               0 2022-08-15-03:00\n4 북춘천               0 2022-08-15-04:00\n5 북춘천               0 2022-08-15-05:00\n\n\n\n%%R\nhead(train)\n\n  region solar_radiation             date\n0 북춘천               0 2022-08-15-00:00\n1 북춘천               0 2022-08-15-01:00\n2 북춘천               0 2022-08-15-02:00\n3 북춘천               0 2022-08-15-03:00\n4 북춘천               0 2022-08-15-04:00\n5 북춘천               0 2022-08-15-05:00\n\n\n\nPlot\n\n%%R\nfor (i in 1:44){\n     assign(paste0('data',1:44)[i],train |> filter(region == unique(train$region)[i]))\n     assign(paste0('data',1:44)[i],eval(parse(text=paste0('data',i)))[order(eval(parse(text=paste0('data',i)))$date),])\n     assign(paste0('y',1:44)[i], eval(parse(text=paste0('data',i)))$solar_radiation)\n}\n\n\n# %%R\n# for (i in 1:44){\n#     plot(eval(parse(text=paste0('y',i)))[1:500], ann=FALSE)\n#     lines(eval(parse(text=paste0('y',i))),lty=2)\n#     title(main = as.character(unique(train$region)[i]), xlab='time', ylab='solar radiation')\n#     }\n\n\n\nEPT 수행\n\n%%R\nept = function(y){\n    EpM = eptransf(signal=y,tau=24,process=c(\"envelope\",\"average\"))$EpM\n    EpM*2\n}\n\n\n%%R\nlibrary(tictoc)\n\nR[write to console]: \nAttaching package: ‘tictoc’\n\n\nR[write to console]: The following object is masked from ‘package:data.table’:\n\n    shift\n\n\n\n\n\n%%R\ntic('지역별 yU계산')\nfor (i in 1:44){\n    assign(paste0('yU',1:44)[i], ept(eval(parse(text=paste0('y',i)))))\n}\ntoc()\n\n지역별 yU계산: 8.198 sec elapsed\n\n\n\n\nyU저장\n\n%%R\ndf_yU = do.call(cbind.data.frame, mget(paste0('yU', 1:44)))\n\n\n%%R\nwrite.csv(df_yU, './data3/df_yU.csv', row.names=FALSE)\n\n\n\n시각화\n\n# %%R\n# for (i in 1:44){\n#     plot(eval(parse(text=paste0('y',i)))[1:500], ann=FALSE)\n#     lines(eval(parse(text=paste0('yU',i))),col = 2, lty=2)\n#     title(main = as.character(unique(train$region)[i]), xlab='time', ylab='solar radiation')\n#     }\n\n\n\nyU Correlation\n\n%%R\nyU_cor = cor(df_yU)\n\n\n%%R\nyU_cor\n\n             yU1          yU2        yU3         yU4          yU5         yU6\nyU1   1.00000000  0.917562575  0.7141615  0.98378027  0.772345840  0.70274065\nyU2   0.91756258  1.000000000  0.6889568  0.91076897  0.822494376  0.61871563\nyU3   0.71416154  0.688956780  1.0000000  0.69136796  0.460892559  0.94410334\nyU4   0.98378027  0.910768974  0.6913680  1.00000000  0.804042979  0.69085577\nyU5   0.77234584  0.822494376  0.4608926  0.80404298  1.000000000  0.37628476\nyU6   0.70274065  0.618715631  0.9441033  0.69085577  0.376284763  1.00000000\nyU7   0.64300010  0.575970407  0.9350892  0.63540734  0.326854593  0.97636175\nyU8   0.95316666  0.901434117  0.5970855  0.95949700  0.846613144  0.57498434\nyU9   0.96278405  0.911765148  0.7362982  0.96623186  0.789825112  0.70403112\nyU10  0.84673554  0.685552594  0.8000418  0.81692009  0.586358056  0.82330151\nyU11  0.76749857  0.616306442  0.8161532  0.76684873  0.307890461  0.87058966\nyU12  0.92860942  0.862074535  0.6797868  0.93262581  0.697668024  0.67308287\nyU13  0.88363053  0.850754765  0.8161065  0.87997506  0.697672842  0.78767117\nyU14  0.76411019  0.575660537  0.8157097  0.75325938  0.402858434  0.87774020\nyU15  0.71670146  0.567089736  0.8473111  0.73070440  0.422014793  0.90531761\nyU16  0.49602010  0.354918117  0.7634435  0.51235674  0.203093502  0.83829484\nyU17  0.61264076  0.437879022  0.8564263  0.61488407  0.286606303  0.93271801\nyU18  0.32517341  0.167278275  0.5792926  0.35432248 -0.081242387  0.69918085\nyU19  0.41879427  0.336599501  0.7533705  0.42697936  0.079907022  0.79552963\nyU20  0.48100335  0.369712688  0.7396777  0.50040594  0.236885837  0.77510543\nyU21  0.19489215  0.112345202  0.4912882  0.24949623 -0.177910876  0.60141877\nyU22  0.01232872 -0.036889897  0.2122360  0.10378317 -0.008064238  0.30942383\nyU23  0.16921812  0.084317132  0.3641365  0.20222557 -0.300845401  0.48984607\nyU24  0.05973644  0.120935319  0.3003309  0.12741173  0.104164121  0.37655971\nyU25  0.08434586  0.050456020  0.3708343  0.14610425 -0.239842034  0.49866849\nyU26 -0.04423212  0.006779177  0.1768526  0.05615531 -0.026867367  0.30175540\nyU27  0.26594305  0.278786864  0.5669837  0.31426478  0.155364908  0.61293934\nyU28  0.83928563  0.696220108  0.8682066  0.82547505  0.538174566  0.86349772\nyU29 -0.40202912 -0.287304991 -0.2003993 -0.36686045 -0.466281920 -0.05466567\nyU30 -0.32588026 -0.277663816 -0.1876117 -0.26402145 -0.282848298 -0.02957440\nyU31  0.27823204  0.165032074  0.4657259  0.34457099 -0.070395925  0.60205666\nyU32  0.38118749  0.355155747  0.6589626  0.41974769  0.220588432  0.71656812\nyU33  0.14878967  0.185847478  0.5054818  0.20548984  0.190791514  0.54157641\nyU34  0.26305788  0.173889683  0.4546673  0.32052179 -0.141513832  0.56160872\nyU35  0.33318965  0.300950265  0.6377808  0.40303239  0.126084607  0.71433675\nyU36  0.20092531  0.132064091  0.4502469  0.25963360 -0.183725288  0.56481151\nyU37  0.14559259  0.069715822  0.4010517  0.19779629 -0.257226795  0.50871186\nyU38  0.16550252  0.059187967  0.4866391  0.21695938 -0.133356794  0.58672840\nyU39  0.18293708  0.246455844  0.4057079  0.25182878  0.145238190  0.45624103\nyU40  0.25967619  0.137944591  0.5288561  0.31080186 -0.124821047  0.65159242\nyU41  0.29194710  0.168000108  0.6323488  0.32872964 -0.013994309  0.72674293\nyU42  0.35608439  0.238895541  0.5588334  0.40651706  0.037404794  0.68941913\nyU43  0.64768635  0.493416671  0.8106167  0.63630269  0.292999363  0.88655914\nyU44  0.30138576  0.165674003  0.6138973  0.31434827 -0.154036803  0.73870832\n             yU7         yU8          yU9        yU10        yU11        yU12\nyU1   0.64300010  0.95316666  0.962784051  0.84673554  0.76749857  0.92860942\nyU2   0.57597041  0.90143412  0.911765148  0.68555259  0.61630644  0.86207454\nyU3   0.93508918  0.59708549  0.736298151  0.80004176  0.81615323  0.67978679\nyU4   0.63540734  0.95949700  0.966231855  0.81692009  0.76684873  0.93262581\nyU5   0.32685459  0.84661314  0.789825112  0.58635806  0.30789046  0.69766802\nyU6   0.97636175  0.57498434  0.704031124  0.82330151  0.87058966  0.67308287\nyU7   1.00000000  0.52577279  0.660720696  0.81995848  0.86020370  0.65934125\nyU8   0.52577279  1.00000000  0.929016263  0.79795785  0.63056114  0.90647769\nyU9   0.66072070  0.92901626  1.000000000  0.82992581  0.75590030  0.89722955\nyU10  0.81995848  0.79795785  0.829925811  1.00000000  0.79163693  0.83824756\nyU11  0.86020370  0.63056114  0.755900303  0.79163693  1.00000000  0.77124514\nyU12  0.65934125  0.90647769  0.897229548  0.83824756  0.77124514  1.00000000\nyU13  0.77176659  0.80459053  0.905104559  0.86500266  0.79020276  0.90905622\nyU14  0.86793186  0.66538186  0.727696067  0.92433774  0.87841617  0.82145137\nyU15  0.88396023  0.63398898  0.689677769  0.86240218  0.86712569  0.76477493\nyU16  0.84202506  0.40640393  0.528775436  0.74768505  0.78442285  0.52186771\nyU17  0.92611313  0.49682563  0.605135578  0.84130755  0.86307286  0.61498439\nyU18  0.70705963  0.19262502  0.327395107  0.51639513  0.77135201  0.41017329\nyU19  0.79351440  0.29592678  0.442446173  0.58534200  0.76902582  0.42500827\nyU20  0.78996432  0.41405775  0.510668306  0.72646404  0.72208061  0.57070597\nyU21  0.57351577  0.08708227  0.236666422  0.27155438  0.66867376  0.24303241\nyU22  0.30589458  0.03045372  0.019999430  0.05561629  0.33996595  0.12868282\nyU23  0.46601233  0.05077585  0.164840313  0.16983948  0.63179618  0.20079416\nyU24  0.37822836  0.01171873  0.153255785  0.16282630  0.25034207  0.16884959\nyU25  0.50554796 -0.01513007  0.148494842  0.18832220  0.55864216  0.19921224\nyU26  0.27149962 -0.09204863 -0.003913205 -0.04202216  0.24411383  0.04395419\nyU27  0.63559532  0.19954055  0.320884468  0.43161942  0.52804713  0.41124453\nyU28  0.84816792  0.73930864  0.847417621  0.92991215  0.88733406  0.85918848\nyU29 -0.09616677 -0.48668360 -0.392703725 -0.51350831 -0.07681743 -0.39433557\nyU30 -0.11491206 -0.37152101 -0.293572692 -0.41555721 -0.07840674 -0.37896801\nyU31  0.59787795  0.18736978  0.323766428  0.38263198  0.70996647  0.33375742\nyU32  0.72053304  0.32080823  0.442302274  0.55402036  0.61571367  0.49175617\nyU33  0.53157459  0.07940895  0.221058703  0.30277671  0.35902239  0.20261376\nyU34  0.53850915  0.14120072  0.281932023  0.25715374  0.71448475  0.32799601\nyU35  0.71612101  0.25133620  0.401439359  0.46365839  0.68015464  0.43640256\nyU36  0.54350191  0.10457079  0.238383683  0.24563377  0.66157758  0.25892539\nyU37  0.48314015  0.02260485  0.175085996  0.16673639  0.62371590  0.20697885\nyU38  0.60368115  0.05762834  0.234838082  0.37393277  0.63895836  0.25058791\nyU39  0.42731762  0.11680385  0.242982889  0.20040700  0.37126482  0.26206690\nyU40  0.64560896  0.15421207  0.306816556  0.40593555  0.72876102  0.32114671\nyU41  0.75943116  0.17770398  0.378278489  0.55924451  0.72371253  0.36360101\nyU42  0.65846671  0.26454057  0.416611634  0.47594024  0.71866468  0.35476481\nyU43  0.86227444  0.54090268  0.620552244  0.82117367  0.83910184  0.64924327\nyU44  0.73390216  0.15396499  0.297895183  0.48332165  0.76383846  0.36343090\n           yU13       yU14        yU15       yU16        yU17        yU18\nyU1   0.8836305  0.7641102  0.71670146  0.4960201  0.61264076  0.32517341\nyU2   0.8507548  0.5756605  0.56708974  0.3549181  0.43787902  0.16727828\nyU3   0.8161065  0.8157097  0.84731111  0.7634435  0.85642625  0.57929263\nyU4   0.8799751  0.7532594  0.73070440  0.5123567  0.61488407  0.35432248\nyU5   0.6976728  0.4028584  0.42201479  0.2030935  0.28660630 -0.08124239\nyU6   0.7876712  0.8777402  0.90531761  0.8382948  0.93271801  0.69918085\nyU7   0.7717666  0.8679319  0.88396023  0.8420251  0.92611313  0.70705963\nyU8   0.8045905  0.6653819  0.63398898  0.4064039  0.49682563  0.19262502\nyU9   0.9051046  0.7276961  0.68967777  0.5287754  0.60513558  0.32739511\nyU10  0.8650027  0.9243377  0.86240218  0.7476850  0.84130755  0.51639513\nyU11  0.7902028  0.8784162  0.86712569  0.7844228  0.86307286  0.77135201\nyU12  0.9090562  0.8214514  0.76477493  0.5218677  0.61498439  0.41017329\nyU13  1.0000000  0.8368347  0.80954886  0.6547286  0.72571666  0.47785900\nyU14  0.8368347  1.0000000  0.95731181  0.8221154  0.92026511  0.71831143\nyU15  0.8095489  0.9573118  1.00000000  0.9015811  0.95599844  0.79703775\nyU16  0.6547286  0.8221154  0.90158106  1.0000000  0.94116025  0.90025254\nyU17  0.7257167  0.9202651  0.95599844  0.9411602  1.00000000  0.82197782\nyU18  0.4778590  0.7183114  0.79703775  0.9002525  0.82197782  1.00000000\nyU19  0.5525690  0.7006844  0.81680433  0.9399492  0.85363273  0.92309690\nyU20  0.6661112  0.8144580  0.89617133  0.9627825  0.88200923  0.87348610\nyU21  0.3129536  0.5063537  0.62507213  0.7436961  0.64951313  0.88742608\nyU22  0.1141175  0.2563020  0.41842092  0.3819917  0.37817633  0.48932622\nyU23  0.1753547  0.3996491  0.49030744  0.6023438  0.51108199  0.82608431\nyU24  0.3552593  0.2892471  0.44487653  0.5870442  0.41670669  0.58164464\nyU25  0.2937975  0.4331919  0.54010509  0.6960846  0.55373912  0.86439150\nyU26  0.1742350  0.1762027  0.37660553  0.4678064  0.34450091  0.58793968\nyU27  0.5555233  0.5625396  0.70473200  0.7976573  0.66926580  0.77824031\nyU28  0.9324805  0.9457624  0.90118918  0.7633997  0.86431909  0.60741417\nyU29 -0.3117508 -0.3262404 -0.21299487 -0.1106813 -0.16111945  0.14325062\nyU30 -0.2771622 -0.2692887 -0.08547045  0.0835418 -0.04785605  0.26132337\nyU31  0.4022013  0.5612939  0.67187418  0.8203090  0.70177041  0.93199319\nyU32  0.6224939  0.6576529  0.78757844  0.8696484  0.75764492  0.80484925\nyU33  0.4370639  0.4149887  0.60337690  0.7362946  0.60130595  0.67048143\nyU34  0.3393421  0.5031475  0.60751767  0.6793624  0.60165401  0.87792752\nyU35  0.5649781  0.6329690  0.77420679  0.8667874  0.76500693  0.88689416\nyU36  0.2940911  0.4664133  0.58669834  0.7095542  0.60270854  0.87013802\nyU37  0.2320139  0.4229684  0.53170826  0.6455244  0.54409900  0.85487180\nyU38  0.4000801  0.5746094  0.66681446  0.8344987  0.71623527  0.91226526\nyU39  0.4234391  0.3704039  0.53922666  0.6283239  0.48082080  0.65013745\nyU40  0.4026547  0.6029218  0.70570689  0.8512780  0.74449928  0.95303469\nyU41  0.5317181  0.6893075  0.76013198  0.9330590  0.83705493  0.92538628\nyU42  0.4630297  0.6155202  0.72876408  0.8823857  0.76521784  0.91453750\nyU43  0.7207308  0.8932167  0.94856329  0.9521539  0.94542952  0.85789358\nyU44  0.4343288  0.6964446  0.76937535  0.8712832  0.81003725  0.97516628\n           yU19       yU20        yU21         yU22        yU23       yU24\nyU1  0.41879427  0.4810034  0.19489215  0.012328716  0.16921812 0.05973644\nyU2  0.33659950  0.3697127  0.11234520 -0.036889897  0.08431713 0.12093532\nyU3  0.75337046  0.7396777  0.49128825  0.212236046  0.36413645 0.30033085\nyU4  0.42697936  0.5004059  0.24949623  0.103783170  0.20222557 0.12741173\nyU5  0.07990702  0.2368858 -0.17791088 -0.008064238 -0.30084540 0.10416412\nyU6  0.79552963  0.7751054  0.60141877  0.309423829  0.48984607 0.37655971\nyU7  0.79351440  0.7899643  0.57351577  0.305894583  0.46601233 0.37822836\nyU8  0.29592678  0.4140577  0.08708227  0.030453721  0.05077585 0.01171873\nyU9  0.44244617  0.5106683  0.23666642  0.019999430  0.16484031 0.15325578\nyU10 0.58534200  0.7264640  0.27155438  0.055616285  0.16983948 0.16282630\nyU11 0.76902582  0.7220806  0.66867376  0.339965951  0.63179618 0.25034207\nyU12 0.42500827  0.5707060  0.24303241  0.128682823  0.20079416 0.16884959\nyU13 0.55256902  0.6661112  0.31295357  0.114117455  0.17535473 0.35525930\nyU14 0.70068443  0.8144580  0.50635367  0.256301965  0.39964914 0.28924715\nyU15 0.81680433  0.8961713  0.62507213  0.418420920  0.49030744 0.44487653\nyU16 0.93994923  0.9627825  0.74369608  0.381991672  0.60234382 0.58704419\nyU17 0.85363273  0.8820092  0.64951313  0.378176333  0.51108199 0.41670669\nyU18 0.92309690  0.8734861  0.88742608  0.489326218  0.82608431 0.58164464\nyU19 1.00000000  0.9092198  0.83203903  0.391413723  0.75466495 0.57053597\nyU20 0.90921977  1.0000000  0.69308895  0.352421109  0.55099938 0.63038571\nyU21 0.83203903  0.6930890  1.00000000  0.552524936  0.93321227 0.54013485\nyU22 0.39141372  0.3524211  0.55252494  1.000000000  0.42556112 0.45903957\nyU23 0.75466495  0.5509994  0.93321227  0.425561124  1.00000000 0.36356966\nyU24 0.57053597  0.6303857  0.54013485  0.459039572  0.36356966 1.00000000\nyU25 0.76812352  0.6605844  0.93425158  0.543834597  0.86018193 0.68668046\nyU26 0.50994108  0.4662113  0.67513051  0.672789629  0.53170348 0.86560312\nyU27 0.78498930  0.8633230  0.66041600  0.479898987  0.50479079 0.88249319\nyU28 0.64642461  0.7484562  0.43493960  0.201857747  0.29219484 0.25515638\nyU29 0.04939858 -0.1820808  0.39747303  0.405095558  0.42867897 0.30885354\nyU30 0.20531610  0.0215249  0.48055093  0.472624471  0.45249861 0.50635435\nyU31 0.85306983  0.7595585  0.94023202  0.524895722  0.87758622 0.59225999\nyU32 0.83872657  0.9076046  0.68665144  0.501458258  0.53040711 0.82355010\nyU33 0.73431696  0.7650166  0.59562905  0.467087158  0.38690160 0.91736270\nyU34 0.78791442  0.6509955  0.96320733  0.549492230  0.95011168 0.51380781\nyU35 0.87409144  0.8742836  0.85815991  0.555011297  0.70921081 0.77188364\nyU36 0.80792177  0.6708077  0.98285361  0.516659824  0.95514478 0.52465085\nyU37 0.77324872  0.6201920  0.97211022  0.487787080  0.96690929 0.50495755\nyU38 0.83819713  0.7882034  0.90042291  0.519079446  0.75703131 0.68648171\nyU39 0.65938480  0.6709484  0.67150873  0.448365977  0.51106815 0.93583422\nyU40 0.88850334  0.7990473  0.96882594  0.523349694  0.89245266 0.58951688\nyU41 0.89570736  0.8853177  0.82520670  0.427469434  0.68165280 0.66138019\nyU42 0.90040109  0.8090194  0.92089851  0.485181959  0.82360428 0.63315465\nyU43 0.91165316  0.9234718  0.66784535  0.335049250  0.58226610 0.48460143\nyU44 0.92478752  0.8284732  0.91809870  0.453611273  0.87724069 0.52909462\n            yU25         yU26      yU27       yU28        yU29         yU30\nyU1   0.08434586 -0.044232117 0.2659430  0.8392856 -0.40202912 -0.325880260\nyU2   0.05045602  0.006779177 0.2787869  0.6962201 -0.28730499 -0.277663816\nyU3   0.37083428  0.176852622 0.5669837  0.8682066 -0.20039926 -0.187611715\nyU4   0.14610425  0.056155309 0.3142648  0.8254750 -0.36686045 -0.264021451\nyU5  -0.23984203 -0.026867367 0.1553649  0.5381746 -0.46628192 -0.282848298\nyU6   0.49866849  0.301755398 0.6129393  0.8634977 -0.05466567 -0.029574402\nyU7   0.50554796  0.271499619 0.6355953  0.8481679 -0.09616677 -0.114912058\nyU8  -0.01513007 -0.092048626 0.1995406  0.7393086 -0.48668360 -0.371521014\nyU9   0.14849484 -0.003913205 0.3208845  0.8474176 -0.39270372 -0.293572692\nyU10  0.18832220 -0.042022164 0.4316194  0.9299121 -0.51350831 -0.415557214\nyU11  0.55864216  0.244113828 0.5280471  0.8873341 -0.07681743 -0.078406741\nyU12  0.19921224  0.043954185 0.4112445  0.8591885 -0.39433557 -0.378968014\nyU13  0.29379749  0.174234982 0.5555233  0.9324805 -0.31175080 -0.277162221\nyU14  0.43319186  0.176202727 0.5625396  0.9457624 -0.32624039 -0.269288686\nyU15  0.54010509  0.376605528 0.7047320  0.9011892 -0.21299487 -0.085470446\nyU16  0.69608455  0.467806351 0.7976573  0.7633997 -0.11068134  0.083541805\nyU17  0.55373912  0.344500909 0.6692658  0.8643191 -0.16111945 -0.047856053\nyU18  0.86439150  0.587939676 0.7782403  0.6074142  0.14325062  0.261323367\nyU19  0.76812352  0.509941077 0.7849893  0.6464246  0.04939858  0.205316096\nyU20  0.66058443  0.466211253 0.8633230  0.7484562 -0.18208084  0.021524903\nyU21  0.93425158  0.675130508 0.6604160  0.4349396  0.39747303  0.480550929\nyU22  0.54383460  0.672789629 0.4798990  0.2018577  0.40509556  0.472624471\nyU23  0.86018193  0.531703484 0.5047908  0.2921948  0.42867897  0.452498612\nyU24  0.68668046  0.865603121 0.8824932  0.2551564  0.30885354  0.506354354\nyU25  1.00000000  0.753442057 0.7229232  0.3480721  0.43492897  0.476726337\nyU26  0.75344206  1.000000000 0.7507798  0.1136271  0.59232611  0.736783639\nyU27  0.72292317  0.750779831 1.0000000  0.5220748  0.16002211  0.309199634\nyU28  0.34807209  0.113627115 0.5220748  1.0000000 -0.35203197 -0.303764644\nyU29  0.43492897  0.592326114 0.1600221 -0.3520320  1.00000000  0.856785673\nyU30  0.47672634  0.736783639 0.3091996 -0.3037646  0.85678567  1.000000000\nyU31  0.91902657  0.671439303 0.7245220  0.4910905  0.27686758  0.411792168\nyU32  0.72280230  0.664148856 0.9639400  0.6214877  0.07746612  0.251931238\nyU33  0.65050099  0.813438715 0.9147313  0.3908409  0.20952155  0.451294308\nyU34  0.89501953  0.666625012 0.6526147  0.4367832  0.40350068  0.464803366\nyU35  0.85489140  0.753062434 0.9227969  0.5942708  0.22452065  0.364931661\nyU36  0.91550136  0.662131759 0.6678216  0.3944317  0.41572892  0.486909400\nyU37  0.90700088  0.650543087 0.6266142  0.3411471  0.44595537  0.504167012\nyU38  0.92569089  0.695519698 0.7540348  0.5095890  0.22424895  0.346561035\nyU39  0.75467501  0.889808423 0.8650491  0.3352586  0.29617657  0.485934024\nyU40  0.92932164  0.645885478 0.7396675  0.5261757  0.26858658  0.386252501\nyU41  0.83477818  0.564522243 0.8112755  0.6428946  0.08600182  0.215848071\nyU42  0.88237010  0.647147092 0.7221311  0.5552705  0.21195544  0.418746796\nyU43  0.59877707  0.370935333 0.7197533  0.8166255 -0.16759866  0.001817438\nyU44  0.87951924  0.553399621 0.7231079  0.5753675  0.21770642  0.282836156\n            yU31       yU32       yU33       yU34      yU35       yU36\nyU1   0.27823204 0.38118749 0.14878967  0.2630579 0.3331897  0.2009253\nyU2   0.16503207 0.35515575 0.18584748  0.1738897 0.3009503  0.1320641\nyU3   0.46572588 0.65896260 0.50548185  0.4546673 0.6377808  0.4502469\nyU4   0.34457099 0.41974769 0.20548984  0.3205218 0.4030324  0.2596336\nyU5  -0.07039593 0.22058843 0.19079151 -0.1415138 0.1260846 -0.1837253\nyU6   0.60205666 0.71656812 0.54157641  0.5616087 0.7143368  0.5648115\nyU7   0.59787795 0.72053304 0.53157459  0.5385091 0.7161210  0.5435019\nyU8   0.18736978 0.32080823 0.07940895  0.1412007 0.2513362  0.1045708\nyU9   0.32376643 0.44230227 0.22105870  0.2819320 0.4014394  0.2383837\nyU10  0.38263198 0.55402036 0.30277671  0.2571537 0.4636584  0.2456338\nyU11  0.70996647 0.61571367 0.35902239  0.7144848 0.6801546  0.6615776\nyU12  0.33375742 0.49175617 0.20261376  0.3279960 0.4364026  0.2589254\nyU13  0.40220127 0.62249388 0.43706386  0.3393421 0.5649781  0.2940911\nyU14  0.56129386 0.65765288 0.41498873  0.5031475 0.6329690  0.4664133\nyU15  0.67187418 0.78757844 0.60337690  0.6075177 0.7742068  0.5866983\nyU16  0.82030900 0.86964844 0.73629456  0.6793624 0.8667874  0.7095542\nyU17  0.70177041 0.75764492 0.60130595  0.6016540 0.7650069  0.6027085\nyU18  0.93199319 0.80484925 0.67048143  0.8779275 0.8868942  0.8701380\nyU19  0.85306983 0.83872657 0.73431696  0.7879144 0.8740914  0.8079218\nyU20  0.75955848 0.90760457 0.76501664  0.6509955 0.8742836  0.6708077\nyU21  0.94023202 0.68665144 0.59562905  0.9632073 0.8581599  0.9828536\nyU22  0.52489572 0.50145826 0.46708716  0.5494922 0.5550113  0.5166598\nyU23  0.87758622 0.53040711 0.38690160  0.9501117 0.7092108  0.9551448\nyU24  0.59225999 0.82355010 0.91736270  0.5138078 0.7718836  0.5246509\nyU25  0.91902657 0.72280230 0.65050099  0.8950195 0.8548914  0.9155014\nyU26  0.67143930 0.66414886 0.81343871  0.6666250 0.7530624  0.6621318\nyU27  0.72452200 0.96393999 0.91473131  0.6526147 0.9227969  0.6678216\nyU28  0.49109047 0.62148773 0.39084092  0.4367832 0.5942708  0.3944317\nyU29  0.27686758 0.07746612 0.20952155  0.4035007 0.2245206  0.4157289\nyU30  0.41179217 0.25193124 0.45129431  0.4648034 0.3649317  0.4869094\nyU31  1.00000000 0.75254147 0.63395099  0.9267192 0.8962239  0.9459734\nyU32  0.75254147 1.00000000 0.87429277  0.6544691 0.9308783  0.6841638\nyU33  0.63395099 0.87429277 1.00000000  0.5353973 0.8456124  0.5590335\nyU34  0.92671923 0.65446907 0.53539734  1.0000000 0.8330031  0.9758991\nyU35  0.89622392 0.93087832 0.84561245  0.8330031 1.0000000  0.8561738\nyU36  0.94597344 0.68416375 0.55903348  0.9758991 0.8561738  1.0000000\nyU37  0.90734008 0.62914673 0.52655528  0.9829265 0.8120204  0.9838825\nyU38  0.91471778 0.75251944 0.71674508  0.8420314 0.8648768  0.8511301\nyU39  0.67182719 0.80052064 0.89991430  0.6536871 0.8181246  0.6513684\nyU40  0.98257917 0.77542193 0.64567655  0.9363410 0.9043821  0.9602471\nyU41  0.89451607 0.85086993 0.73707193  0.7668871 0.9059000  0.7961070\nyU42  0.95458507 0.78589151 0.69845375  0.8681414 0.8824313  0.8949258\nyU43  0.72783750 0.81504474 0.64021764  0.6354161 0.7745609  0.6346446\nyU44  0.91016283 0.76896060 0.61969505  0.8860153 0.8582344  0.8956392\n            yU37        yU38      yU39       yU40        yU41       yU42\nyU1   0.14559259  0.16550252 0.1829371  0.2596762  0.29194710 0.35608439\nyU2   0.06971582  0.05918797 0.2464558  0.1379446  0.16800011 0.23889554\nyU3   0.40105172  0.48663907 0.4057079  0.5288561  0.63234875 0.55883341\nyU4   0.19779629  0.21695938 0.2518288  0.3108019  0.32872964 0.40651706\nyU5  -0.25722680 -0.13335679 0.1452382 -0.1248210 -0.01399431 0.03740479\nyU6   0.50871186  0.58672840 0.4562410  0.6515924  0.72674293 0.68941913\nyU7   0.48314015  0.60368115 0.4273176  0.6456090  0.75943116 0.65846671\nyU8   0.02260485  0.05762834 0.1168038  0.1542121  0.17770398 0.26454057\nyU9   0.17508600  0.23483808 0.2429829  0.3068166  0.37827849 0.41661163\nyU10  0.16673639  0.37393277 0.2004070  0.4059355  0.55924451 0.47594024\nyU11  0.62371590  0.63895836 0.3712648  0.7287610  0.72371253 0.71866468\nyU12  0.20697885  0.25058791 0.2620669  0.3211467  0.36360101 0.35476481\nyU13  0.23201388  0.40008011 0.4234391  0.4026547  0.53171808 0.46302968\nyU14  0.42296842  0.57460944 0.3704039  0.6029218  0.68930754 0.61552016\nyU15  0.53170826  0.66681446 0.5392267  0.7057069  0.76013198 0.72876408\nyU16  0.64552440  0.83449874 0.6283239  0.8512780  0.93305896 0.88238570\nyU17  0.54409900  0.71623527 0.4808208  0.7444993  0.83705493 0.76521784\nyU18  0.85487180  0.91226526 0.6501375  0.9530347  0.92538628 0.91453750\nyU19  0.77324872  0.83819713 0.6593848  0.8885033  0.89570736 0.90040109\nyU20  0.62019196  0.78820341 0.6709484  0.7990473  0.88531770 0.80901937\nyU21  0.97211022  0.90042291 0.6715087  0.9688259  0.82520670 0.92089851\nyU22  0.48778708  0.51907945 0.4483660  0.5233497  0.42746943 0.48518196\nyU23  0.96690929  0.75703131 0.5110682  0.8924527  0.68165280 0.82360428\nyU24  0.50495755  0.68648171 0.9358342  0.5895169  0.66138019 0.63315465\nyU25  0.90700088  0.92569089 0.7546750  0.9293216  0.83477818 0.88237010\nyU26  0.65054309  0.69551970 0.8898084  0.6458855  0.56452224 0.64714709\nyU27  0.62661424  0.75403482 0.8650491  0.7396675  0.81127554 0.72213113\nyU28  0.34114709  0.50958902 0.3352586  0.5261757  0.64289458 0.55527053\nyU29  0.44595537  0.22424895 0.2961766  0.2685866  0.08600182 0.21195544\nyU30  0.50416701  0.34656104 0.4859340  0.3862525  0.21584807 0.41874680\nyU31  0.90734008  0.91471778 0.6718272  0.9825792  0.89451607 0.95458507\nyU32  0.62914673  0.75251944 0.8005206  0.7754219  0.85086993 0.78589151\nyU33  0.52655528  0.71674508 0.8999143  0.6456765  0.73707193 0.69845375\nyU34  0.98292647  0.84203139 0.6536871  0.9363410  0.76688711 0.86814144\nyU35  0.81202040  0.86487683 0.8181246  0.9043821  0.90589996 0.88243131\nyU36  0.98388248  0.85113009 0.6513684  0.9602471  0.79610698 0.89492583\nyU37  1.00000000  0.82960937 0.6401009  0.9307630  0.75302180 0.85469150\nyU38  0.82960937  1.00000000 0.7484175  0.9396701  0.93001417 0.91620362\nyU39  0.64010095  0.74841747 1.0000000  0.6752336  0.66115806 0.70738551\nyU40  0.93076302  0.93967009 0.6752336  1.0000000  0.92084768 0.96025257\nyU41  0.75302180  0.93001417 0.6611581  0.9208477  1.00000000 0.90892648\nyU42  0.85469150  0.91620362 0.7073855  0.9602526  0.90892648 1.00000000\nyU43  0.58524977  0.71317450 0.5602152  0.7630495  0.81487743 0.81079393\nyU44  0.88584469  0.88918754 0.6189214  0.9512395  0.89666211 0.90855252\n             yU43       yU44\nyU1   0.647686354  0.3013858\nyU2   0.493416671  0.1656740\nyU3   0.810616736  0.6138973\nyU4   0.636302693  0.3143483\nyU5   0.292999363 -0.1540368\nyU6   0.886559138  0.7387083\nyU7   0.862274443  0.7339022\nyU8   0.540902683  0.1539650\nyU9   0.620552244  0.2978952\nyU10  0.821173671  0.4833216\nyU11  0.839101844  0.7638385\nyU12  0.649243274  0.3634309\nyU13  0.720730767  0.4343288\nyU14  0.893216668  0.6964446\nyU15  0.948563289  0.7693753\nyU16  0.952153933  0.8712832\nyU17  0.945429520  0.8100372\nyU18  0.857893581  0.9751663\nyU19  0.911653161  0.9247875\nyU20  0.923471786  0.8284732\nyU21  0.667845349  0.9180987\nyU22  0.335049250  0.4536113\nyU23  0.582266097  0.8772407\nyU24  0.484601429  0.5290946\nyU25  0.598777065  0.8795192\nyU26  0.370935333  0.5533996\nyU27  0.719753315  0.7231079\nyU28  0.816625507  0.5753675\nyU29 -0.167598665  0.2177064\nyU30  0.001817438  0.2828362\nyU31  0.727837497  0.9101628\nyU32  0.815044738  0.7689606\nyU33  0.640217640  0.6196950\nyU34  0.635416071  0.8860153\nyU35  0.774560853  0.8582344\nyU36  0.634644571  0.8956392\nyU37  0.585249770  0.8858447\nyU38  0.713174504  0.8891875\nyU39  0.560215169  0.6189214\nyU40  0.763049521  0.9512395\nyU41  0.814877432  0.8966621\nyU42  0.810793926  0.9085525\nyU43  1.000000000  0.8465266\nyU44  0.846526604  1.0000000\n\n\n\n%%R\nwrite.csv(yU_cor, './data3/yU_weight.csv', row.names=FALSE)"
  },
  {
    "objectID": "posts/SOLAR/2023-04-20-데이터수정3.html#create-stgcn-datset",
    "href": "posts/SOLAR/2023-04-20-데이터수정3.html#create-stgcn-datset",
    "title": "[SOLAR] Create Dataset (data3: 0815/0910) 재수정",
    "section": "Create STGCN Datset",
    "text": "Create STGCN Datset\n\nimport\n\nimport pandas as pd\nimport numpy as np\n\n\ndf = pd.read_csv('./data3/solar_radiation.csv')\nweight = pd.read_csv('./data3/weight.csv')\nept_weight = pd.read_csv('./data3/yU_weight.csv')\n\n\ndf.head(30)\n\n\n\n\n\n  \n    \n      \n      Unnamed: 0\n      region\n      solar_radiation\n      date\n    \n  \n  \n    \n      0\n      0\n      북춘천\n      0.00\n      2022-08-15-00:00\n    \n    \n      1\n      1\n      북춘천\n      0.00\n      2022-08-15-01:00\n    \n    \n      2\n      2\n      북춘천\n      0.00\n      2022-08-15-02:00\n    \n    \n      3\n      3\n      북춘천\n      0.00\n      2022-08-15-03:00\n    \n    \n      4\n      4\n      북춘천\n      0.00\n      2022-08-15-04:00\n    \n    \n      5\n      5\n      북춘천\n      0.00\n      2022-08-15-05:00\n    \n    \n      6\n      6\n      북춘천\n      0.00\n      2022-08-15-06:00\n    \n    \n      7\n      7\n      북춘천\n      0.00\n      2022-08-15-07:00\n    \n    \n      8\n      8\n      북춘천\n      0.09\n      2022-08-15-08:00\n    \n    \n      9\n      9\n      북춘천\n      0.10\n      2022-08-15-09:00\n    \n    \n      10\n      10\n      북춘천\n      0.26\n      2022-08-15-10:00\n    \n    \n      11\n      11\n      북춘천\n      0.47\n      2022-08-15-11:00\n    \n    \n      12\n      12\n      북춘천\n      0.88\n      2022-08-15-12:00\n    \n    \n      13\n      13\n      북춘천\n      1.14\n      2022-08-15-13:00\n    \n    \n      14\n      14\n      북춘천\n      0.89\n      2022-08-15-14:00\n    \n    \n      15\n      15\n      북춘천\n      0.38\n      2022-08-15-15:00\n    \n    \n      16\n      16\n      북춘천\n      0.26\n      2022-08-15-16:00\n    \n    \n      17\n      17\n      북춘천\n      0.17\n      2022-08-15-17:00\n    \n    \n      18\n      18\n      북춘천\n      0.07\n      2022-08-15-18:00\n    \n    \n      19\n      19\n      북춘천\n      0.03\n      2022-08-15-19:00\n    \n    \n      20\n      20\n      북춘천\n      0.01\n      2022-08-15-20:00\n    \n    \n      21\n      21\n      북춘천\n      0.00\n      2022-08-15-21:00\n    \n    \n      22\n      22\n      북춘천\n      0.00\n      2022-08-15-22:00\n    \n    \n      23\n      23\n      북춘천\n      0.00\n      2022-08-15-23:00\n    \n    \n      24\n      24\n      북춘천\n      0.00\n      2022-08-16-00:00\n    \n    \n      25\n      25\n      북춘천\n      0.00\n      2022-08-16-01:00\n    \n    \n      26\n      26\n      북춘천\n      0.00\n      2022-08-16-02:00\n    \n    \n      27\n      27\n      북춘천\n      0.00\n      2022-08-16-03:00\n    \n    \n      28\n      28\n      북춘천\n      0.00\n      2022-08-16-04:00\n    \n    \n      29\n      29\n      북춘천\n      0.00\n      2022-08-16-05:00\n    \n  \n\n\n\n\n\ndf.tail()\n\n\n\n\n\n  \n    \n      \n      Unnamed: 0\n      region\n      solar_radiation\n      date\n    \n  \n  \n    \n      28507\n      10555\n      경주시\n      0.04\n      2022-09-10-19:00\n    \n    \n      28508\n      10556\n      경주시\n      0.00\n      2022-09-10-20:00\n    \n    \n      28509\n      10557\n      경주시\n      0.00\n      2022-09-10-21:00\n    \n    \n      28510\n      10558\n      경주시\n      0.00\n      2022-09-10-22:00\n    \n    \n      28511\n      10559\n      경주시\n      0.00\n      2022-09-10-23:00\n    \n  \n\n\n\n\n\ndf.duplicated().sum()\n\n0\n\n\n\ndf = df.iloc[:,1:]\n\n\ndf.head()\n\n\n\n\n\n  \n    \n      \n      region\n      solar_radiation\n      date\n    \n  \n  \n    \n      0\n      북춘천\n      0.0\n      2022-08-15-00:00\n    \n    \n      1\n      북춘천\n      0.0\n      2022-08-15-01:00\n    \n    \n      2\n      북춘천\n      0.0\n      2022-08-15-02:00\n    \n    \n      3\n      북춘천\n      0.0\n      2022-08-15-03:00\n    \n    \n      4\n      북춘천\n      0.0\n      2022-08-15-04:00\n    \n  \n\n\n\n\n\n%R -i df\n\n\n%%R\ndf = df |> mutate(date=ymd_hm(date))\ndf <- df %>%\n          group_by(region) %>%\n          mutate(row = row_number()) %>%\n          tidyr::pivot_wider(names_from = region, values_from = solar_radiation) %>%\n          select(-row)\n\n\n%%R\ndf %>% head()\n\n# A tibble: 6 × 45\n  date                북춘천  철원 대관령  춘천 백령도 북강릉  강릉  서울  인천\n  <dttm>               <dbl> <dbl>  <dbl> <dbl>  <dbl>  <dbl> <dbl> <dbl> <dbl>\n1 2022-08-15 00:00:00      0     0      0     0      0      0     0     0     0\n2 2022-08-15 01:00:00      0     0      0     0      0      0     0     0     0\n3 2022-08-15 02:00:00      0     0      0     0      0      0     0     0     0\n4 2022-08-15 03:00:00      0     0      0     0      0      0     0     0     0\n5 2022-08-15 04:00:00      0     0      0     0      0      0     0     0     0\n6 2022-08-15 05:00:00      0     0      0     0      0      0     0     0     0\n# … with 35 more variables: 원주 <dbl>, 울릉도 <dbl>, 수원 <dbl>, 서산 <dbl>,\n#   청주 <dbl>, 대전 <dbl>, 추풍령 <dbl>, 안동 <dbl>, 포항 <dbl>, 대구 <dbl>,\n#   전주 <dbl>, 창원 <dbl>, 광주 <dbl>, 부산 <dbl>, 목포 <dbl>, 여수 <dbl>,\n#   흑산도 <dbl>, 고창 <dbl>, 홍성 <dbl>, 제주 <dbl>, 고산 <dbl>, 진주 <dbl>,\n#   고창군 <dbl>, 영광군 <dbl>, 김해시 <dbl>, 순창군 <dbl>, 북창원 <dbl>,\n#   양산시 <dbl>, 보성군 <dbl>, 강진군 <dbl>, 의령군 <dbl>, 함양군 <dbl>,\n#   광양시 <dbl>, 청송군 <dbl>, 경주시 <dbl>\n# ℹ Use `colnames()` to see all variable names\n\n\n\n%%R\nwrite.csv(df,'./data3/restructuring_data.csv', row.names=FALSE)\n\n\nimport gc\ngc.collect()\n\n949\n\n\n\n\nSTGCN Ver1\n\ndf = pd.read_csv('./data3/restructuring_data.csv')\ndf.head()\n\n\n\n\n\n  \n    \n      \n      date\n      북춘천\n      철원\n      대관령\n      춘천\n      백령도\n      북강릉\n      강릉\n      서울\n      인천\n      ...\n      순창군\n      북창원\n      양산시\n      보성군\n      강진군\n      의령군\n      함양군\n      광양시\n      청송군\n      경주시\n    \n  \n  \n    \n      0\n      2022-08-15 00:00:00\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      ...\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n    \n    \n      1\n      2022-08-15 01:00:00\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      ...\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n    \n    \n      2\n      2022-08-15 02:00:00\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      ...\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n    \n    \n      3\n      2022-08-15 03:00:00\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      ...\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n    \n    \n      4\n      2022-08-15 04:00:00\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      ...\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n    \n  \n\n5 rows × 45 columns\n\n\n\n\ndf2 = df.iloc[:,1:]\n\n\nnode_list =(df2.columns).tolist()\nnode_ids = {node : i for i, node in enumerate(node_list)}\nnode_ids\n\n{'북춘천': 0,\n '철원': 1,\n '대관령': 2,\n '춘천': 3,\n '백령도': 4,\n '북강릉': 5,\n '강릉': 6,\n '서울': 7,\n '인천': 8,\n '원주': 9,\n '울릉도': 10,\n '수원': 11,\n '서산': 12,\n '청주': 13,\n '대전': 14,\n '추풍령': 15,\n '안동': 16,\n '포항': 17,\n '대구': 18,\n '전주': 19,\n '창원': 20,\n '광주': 21,\n '부산': 22,\n '목포': 23,\n '여수': 24,\n '흑산도': 25,\n '고창': 26,\n '홍성': 27,\n '제주': 28,\n '고산': 29,\n '진주': 30,\n '고창군': 31,\n '영광군': 32,\n '김해시': 33,\n '순창군': 34,\n '북창원': 35,\n '양산시': 36,\n '보성군': 37,\n '강진군': 38,\n '의령군': 39,\n '함양군': 40,\n '광양시': 41,\n '청송군': 42,\n '경주시': 43}\n\n\n\nedges = []    \n \nfor i in range(44):\n    for j in range(44):\n        if i != j:\n            edges.append([i,j]) \n# print(edges)\n\n\nweights = []    \n \nfor i in range(44):\n    for j in range(44):\n        if i != j:\n            weights.append(weight.iloc[i,j]) \n\n\nnp.array(weights).shape\n\n(1892,)\n\n\n\nlen(df['date']) # time\n\n648\n\n\n\nFX = []    \nfor i in range(648):\n    FX.append(list(df2.iloc[i,:])) \n#FX\n\n\nnp.array(FX).shape\n\n(648, 44)\n\n\n- weights, edges, node_ids, FX\n\ndata_dict = {'edges':edges, 'node_ids':node_ids, 'weights':weights, 'FX':FX}\n\n\ndata_dict.keys()\n\ndict_keys(['edges', 'node_ids', 'weights', 'FX'])\n\n\n\nfile_path = './data3/stgcn_data1.json'\n\n\nwith open(file_path, 'w') as f:\n    json.dump(data_dict, f)\n\n\nwith open(file_path, 'r') as f:\n    test = json.load(f, encoding='cp949')\n\n\nimport gc\ngc.collect()\n\n1278\n\n\n\nnp.array(data_dict['weights']).mean()\n\n0.804297152836019\n\n\n\n\nSTGCN Ver2\n\n# ept_weight\n\n\nept_weights = []    \n \nfor i in range(44):\n    for j in range(44):\n        if i != j:\n            ept_weights.append(ept_weight.iloc[i,j]) \n\n\nnp.mean(weights), np.mean(ept_weights)\n\n(0.804297152836019, 0.5443066638191911)\n\n\n\ndata_dict2 = data_dict.copy()\n\n\ndata_dict2['weights'] = ept_weights\n\n\ndata_dict2['weights'][:10]\n\n[0.917562575466497,\n 0.714161542098812,\n 0.983780267648513,\n 0.772345839639418,\n 0.702740650367063,\n 0.643000103675074,\n 0.953166656242359,\n 0.962784051238124,\n 0.8467355397264,\n 0.767498572057223]\n\n\n\nnp.array(data_dict2['weights']).mean()\n\n0.5443066638191911\n\n\n\nfile_path = './data3/stgcn_data2.json'\n\n\nwith open(file_path, 'w') as f:\n    json.dump(data_dict2, f)\n\n\nwith open(file_path, 'r') as f:\n    test2 = json.load(f, encoding='cp949')"
  },
  {
    "objectID": "posts/SOLAR/2023-04-20-데이터수정3.html#comparision",
    "href": "posts/SOLAR/2023-04-20-데이터수정3.html#comparision",
    "title": "[SOLAR] Create Dataset (data3: 0815/0910) 재수정",
    "section": "Comparision",
    "text": "Comparision\n\nplt.hist(np.array(weights), alpha = 0.5, label = 'weights')\nplt.hist(np.array(ept_weights), alpha = 0.5, label = 'EPT weights')\nplt.legend(loc='upper left')\n\n<matplotlib.legend.Legend at 0x7f89cbf3ffd0>\n\n\n\n\n\n\ntest2.keys()\n\ndict_keys(['edges', 'node_ids', 'weights', 'FX'])\n\n\n\nnp.array(test2['FX']).shape\n\n(648, 44)\n\n\n\n모듈 수정"
  },
  {
    "objectID": "posts/SOLAR/2023-04-21-정규화-스케일링-stgcn-ver1--guebin.html",
    "href": "posts/SOLAR/2023-04-21-정규화-스케일링-stgcn-ver1--guebin.html",
    "title": "[SOLAR] STGCN Ver1 (+N +S) (MSE: 0.1864) – guebin",
    "section": "",
    "text": "train 2022-06-01 00:00:00 ~ 2022-08-14 17:00:00\ntest 2022-08-14 18:00:00 ~ 2022-09-15 23:00:00"
  },
  {
    "objectID": "posts/SOLAR/2023-04-21-정규화-스케일링-stgcn-ver1--guebin.html#import",
    "href": "posts/SOLAR/2023-04-21-정규화-스케일링-stgcn-ver1--guebin.html#import",
    "title": "[SOLAR] STGCN Ver1 (+N +S) (MSE: 0.1864) – guebin",
    "section": "import",
    "text": "import\n\nimport pandas as pd\nimport numpy as np\nimport json\nimport urllib\nimport time\n\n\n# 일반적인 모듈 \nimport numpy as np\nimport matplotlib.pyplot as plt \nimport networkx as nx \nfrom tqdm import tqdm \n\n# 파이토치 관련 \nimport torch\nimport torch.nn.functional as F\n\n# PyG 관련 \nfrom torch_geometric.data import Data ## Data: 그래프자료형을 만드는 클래스\n\n# STGCN 관련 \nimport torch_geometric_temporal\nfrom torch_geometric_temporal.nn.recurrent import GConvGRU\nfrom torch_geometric_temporal.signal import temporal_signal_split \n\n\nclass RecurrentGCN(torch.nn.Module):\n    def __init__(self, node_features, filters):\n        super(RecurrentGCN, self).__init__()\n        self.recurrent = GConvGRU(node_features, filters, 2)\n        self.linear = torch.nn.Linear(filters, 1)\n\n    def forward(self, x, edge_index, edge_weight):\n        h = self.recurrent(x, edge_index, edge_weight)\n        h = F.relu(h)\n        h = self.linear(h)\n        return h\n\n\nfrom mysolar2 import SolarDatasetLoader\n\n\nurl = \"https://raw.githubusercontent.com/pinkocto/noteda/main/posts/SOLAR/data2/stgcn_data1.json\"\nloader = SolarDatasetLoader(url)\ndataset = loader.get_dataset(lags=4)\n\n\ndef minmaxscaler(arr):\n    arr = arr - arr.min()\n    arr = arr/arr.max()\n    return arr \n\n\ndataset.edge_weight = minmaxscaler(dataset.edge_weight)\ntrain_dataset, test_dataset = temporal_signal_split(dataset, train_ratio=0.7)"
  },
  {
    "objectID": "posts/SOLAR/2023-04-21-정규화-스케일링-stgcn-ver1--guebin.html#learn",
    "href": "posts/SOLAR/2023-04-21-정규화-스케일링-stgcn-ver1--guebin.html#learn",
    "title": "[SOLAR] STGCN Ver1 (+N +S) (MSE: 0.1864) – guebin",
    "section": "Learn",
    "text": "Learn\n\nmodel = RecurrentGCN(node_features=4, filters=32)\noptimizer = torch.optim.Adam(model.parameters(), lr=0.01)\nmodel.train()\n\nfor epoch in tqdm(range(50)):\n    for t, snapshot in enumerate(train_dataset):\n        yt_hat = model(snapshot.x, snapshot.edge_index, snapshot.edge_attr)\n        cost = torch.mean((yt_hat-snapshot.y)**2)\n        cost.backward()\n        optimizer.step()\n        optimizer.zero_grad()\n\n100%|██████████| 50/50 [05:15<00:00,  6.31s/it]\n\n\n\n# import pickle \n# with open('./model3/normal_stgcn1_lag4_new.pickle','wb') as fw:\n#     pickle.dump(model, fw)\n\n\n# import pickle \n# with open('./model3/normal_stgcn1_lag4_new.pickle', 'rb') as f: \n#     model = pickle.load(f)\n\n- train\n\nMSE: 0.2102 (before normalize)\n\n\nmodel.eval()\ncost = 0\nfor time, snapshot in enumerate(train_dataset):\n    y_hat = model(snapshot.x, snapshot.edge_index, snapshot.edge_attr)\n    cost = cost + torch.mean((y_hat-snapshot.y)**2)\ncost = cost / (time+1)\ncost = cost.item()\nprint(\"MSE: {:.4f}\".format(cost))\n\nMSE: 0.2005\n\n\n- test\n\nMSE: 0.1899 (before normalize)\n\n\nmodel.eval()\ncost = 0\nfor time, snapshot in enumerate(test_dataset):\n    y_hat = model(snapshot.x, snapshot.edge_index, snapshot.edge_attr)\n    cost = cost + torch.mean((y_hat-snapshot.y)**2)\ncost = cost / (time+1)\ncost = cost.item()\nprint(\"MSE: {:.4f}\".format(cost))\n\nMSE: 0.1864"
  },
  {
    "objectID": "posts/SOLAR/2023-04-21-정규화-스케일링-stgcn-ver1--guebin.html#visualization",
    "href": "posts/SOLAR/2023-04-21-정규화-스케일링-stgcn-ver1--guebin.html#visualization",
    "title": "[SOLAR] STGCN Ver1 (+N +S) (MSE: 0.1864) – guebin",
    "section": "Visualization",
    "text": "Visualization\n\nurl = 'https://raw.githubusercontent.com/pinkocto/noteda/main/posts/SOLAR/data2/stgcn_data1.json'\n\n\ndata_dict = json.loads(urllib.request.urlopen(url).read())\nV = list(data_dict['node_ids'].keys())\nf = np.array(data_dict[\"FX\"])\n\n\nyhat_train = torch.stack([model(snapshot.x,snapshot.edge_index, snapshot.edge_attr) for snapshot in train_dataset]).detach().numpy()\nyhat_test = torch.stack([model(snapshot.x,snapshot.edge_index, snapshot.edge_attr) for snapshot in test_dataset]).detach().numpy()\n\n\nf.shape\n\n(2568, 44)\n\n\n\nyhat_test.shape[0] +  yhat_train.shape[0]\n\n2564\n\n\n\nyhat_test.shape, yhat_train.shape\n\n((770, 44, 1), (1794, 44, 1))\n\n\n\nimport matplotlib.pyplot as plt\nplt.rcParams['font.family'] = 'NanumGothic'\n\n\ntrain\n\nfig,ax = plt.subplots(44,1,figsize=(10,50))\nlag= 0 \nT = 100 \nfor k in range(44):\n    ax[k].plot(np.array(train_dataset.targets)[lag:(lag+T),k],'--',alpha=0.5,label='observed', color='green')\n    ax[k].set_title('node: {}'.format(V[k]))\n    ax[k].plot(yhat_train[:T,k],label='predicted (tr)', color = 'orange')\n#    ax[k].plot(range(yhat_train.shape[0],yhat_train.shape[0]+yhat_test.shape[0]),yhat_test[:,k],label='predicted (test)')\n    ax[k].legend()\nfig.tight_layout()\n\n# plt.savefig('stgcn-ver2-lag4-vis.png')\n\n\n\n\n\nnp.array(dataset.features).shape\n\n(2564, 44, 4)\n\n\n\nnp.array(dataset.targets).shape\n\n(2564, 44)\n\n\n\nnp.array(train_dataset.targets).shape\n\n(1794, 44)\n\n\n\nnp.array(test_dataset.targets).shape\n\n(770, 44)\n\n\n\n\ntest\n\nfig,ax = plt.subplots(44,1,figsize=(10,50))\nlag= 0\nT = 100 \nfor k in range(44):\n    ax[k].plot(np.array(test_dataset.targets)[lag:(lag+T),k],'--',alpha=0.5,label='observed')\n    ax[k].set_title('node: {}'.format(V[k]))\n    ax[k].plot(yhat_test[:T,k],label='predicted (test)', color='red')\n#    ax[k].plot(range(yhat_train.shape[0],yhat_train.shape[0]+yhat_test.shape[0]),yhat_test[:,k],label='predicted (test)')\n    ax[k].legend()\nfig.tight_layout()\n\n# plt.savefig('stgcn-ver2-lag4-vis.png')"
  },
  {
    "objectID": "posts/SOLAR/2023-04-24-정규화제거-결과비교.html",
    "href": "posts/SOLAR/2023-04-24-정규화제거-결과비교.html",
    "title": "[SOLAR] Comparison of 30 simulation results (-N)",
    "section": "",
    "text": "train : 2022-06-01 00:00:00 ~ 2022-08-14 17:00:00\ntest : 2022-08-14 18:00:00 ~ 2022-09-15 23:00:00\n힌남노 활동기간: 2022년 8월 28일 15시 ~ 2022년 9월 6일 21시\n\n\n\n\nimport eptstgcn\nimport torch\nimport eptstgcn.planner \n\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n\nstgcn_ver1 = eptstgcn.load_data('./simul_model/stgcn_ver1_data2_cancel_normal.pickle')\nstgcn_ver2 = eptstgcn.load_data('./simul_model/stgcn_ver2_data2_cancel_normal.pickle')\n\n\n\n\n\nstgcn_ver1.simulation_results\n\n\n\n\n\n  \n    \n      \n      dataset\n      method\n      lags\n      nof_filters\n      epoch\n      mse(train)\n      mse(test)\n      calculation_time\n    \n  \n  \n    \n      0\n      data2\n      STGCN\n      4\n      32\n      50\n      0.184729\n      0.16915\n      377.234105\n    \n    \n      1\n      data2\n      STGCN\n      4\n      32\n      50\n      0.194348\n      0.179128\n      404.002319\n    \n    \n      2\n      data2\n      STGCN\n      4\n      32\n      50\n      0.186852\n      0.171011\n      404.872347\n    \n    \n      3\n      data2\n      STGCN\n      4\n      32\n      50\n      0.192293\n      0.177862\n      404.354106\n    \n    \n      4\n      data2\n      STGCN\n      4\n      32\n      50\n      0.184383\n      0.165967\n      404.739908\n    \n    \n      5\n      data2\n      STGCN\n      4\n      32\n      50\n      0.187998\n      0.171345\n      403.504373\n    \n    \n      6\n      data2\n      STGCN\n      4\n      32\n      50\n      0.20575\n      0.195115\n      404.138369\n    \n    \n      7\n      data2\n      STGCN\n      4\n      32\n      50\n      0.185384\n      0.172689\n      403.663877\n    \n    \n      8\n      data2\n      STGCN\n      4\n      32\n      50\n      0.194767\n      0.179806\n      403.539248\n    \n    \n      9\n      data2\n      STGCN\n      4\n      32\n      50\n      0.180619\n      0.16791\n      403.825341\n    \n    \n      10\n      data2\n      STGCN\n      4\n      32\n      50\n      0.185755\n      0.168067\n      403.919527\n    \n    \n      11\n      data2\n      STGCN\n      4\n      32\n      50\n      0.182045\n      0.165334\n      403.761422\n    \n    \n      12\n      data2\n      STGCN\n      4\n      32\n      50\n      0.179984\n      0.163826\n      416.916373\n    \n    \n      13\n      data2\n      STGCN\n      4\n      32\n      50\n      0.182908\n      0.168465\n      418.946952\n    \n    \n      14\n      data2\n      STGCN\n      4\n      32\n      50\n      0.180602\n      0.168306\n      420.972627\n    \n    \n      15\n      data2\n      STGCN\n      4\n      32\n      50\n      0.188245\n      0.173417\n      407.305866\n    \n    \n      16\n      data2\n      STGCN\n      4\n      32\n      50\n      0.191077\n      0.174629\n      406.501366\n    \n    \n      17\n      data2\n      STGCN\n      4\n      32\n      50\n      0.182869\n      0.166464\n      408.495907\n    \n    \n      18\n      data2\n      STGCN\n      4\n      32\n      50\n      0.19079\n      0.173249\n      408.574794\n    \n    \n      19\n      data2\n      STGCN\n      4\n      32\n      50\n      0.180641\n      0.169462\n      407.30098\n    \n    \n      20\n      data2\n      STGCN\n      4\n      32\n      50\n      0.183225\n      0.16961\n      408.664111\n    \n    \n      21\n      data2\n      STGCN\n      4\n      32\n      50\n      0.18652\n      0.170032\n      408.306077\n    \n    \n      22\n      data2\n      STGCN\n      4\n      32\n      50\n      0.185923\n      0.171719\n      408.045289\n    \n    \n      23\n      data2\n      STGCN\n      4\n      32\n      50\n      0.19706\n      0.176483\n      407.953204\n    \n    \n      24\n      data2\n      STGCN\n      4\n      32\n      50\n      0.184862\n      0.168875\n      407.763272\n    \n    \n      25\n      data2\n      STGCN\n      4\n      32\n      50\n      0.197922\n      0.186466\n      404.780481\n    \n    \n      26\n      data2\n      STGCN\n      4\n      32\n      50\n      0.192646\n      0.179262\n      402.828646\n    \n    \n      27\n      data2\n      STGCN\n      4\n      32\n      50\n      0.183524\n      0.166634\n      401.142154\n    \n    \n      28\n      data2\n      STGCN\n      4\n      32\n      50\n      0.18306\n      0.16839\n      400.589833\n    \n    \n      29\n      data2\n      STGCN\n      4\n      32\n      50\n      0.188916\n      0.173284\n      402.841741\n    \n  \n\n\n\n\n\n\n\n\nstgcn_ver2.simulation_results\n\n\n\n\n\n  \n    \n      \n      dataset\n      method\n      lags\n      nof_filters\n      epoch\n      mse(train)\n      mse(test)\n      calculation_time\n    \n  \n  \n    \n      0\n      data2\n      EPT-STGCN\n      4\n      32\n      50\n      0.207058\n      0.192318\n      405.406879\n    \n    \n      1\n      data2\n      EPT-STGCN\n      4\n      32\n      50\n      0.183151\n      0.166525\n      406.358098\n    \n    \n      2\n      data2\n      EPT-STGCN\n      4\n      32\n      50\n      0.187727\n      0.170964\n      405.92099\n    \n    \n      3\n      data2\n      EPT-STGCN\n      4\n      32\n      50\n      0.183493\n      0.165333\n      405.771331\n    \n    \n      4\n      data2\n      EPT-STGCN\n      4\n      32\n      50\n      0.183788\n      0.163304\n      406.80101\n    \n    \n      5\n      data2\n      EPT-STGCN\n      4\n      32\n      50\n      0.184463\n      0.166215\n      404.526357\n    \n    \n      6\n      data2\n      EPT-STGCN\n      4\n      32\n      50\n      0.184557\n      0.168805\n      404.531185\n    \n    \n      7\n      data2\n      EPT-STGCN\n      4\n      32\n      50\n      0.182589\n      0.16412\n      403.679201\n    \n    \n      8\n      data2\n      EPT-STGCN\n      4\n      32\n      50\n      0.18965\n      0.168722\n      404.699471\n    \n    \n      9\n      data2\n      EPT-STGCN\n      4\n      32\n      50\n      0.181751\n      0.161628\n      404.820747\n    \n    \n      10\n      data2\n      EPT-STGCN\n      4\n      32\n      50\n      0.193702\n      0.174698\n      404.747668\n    \n    \n      11\n      data2\n      EPT-STGCN\n      4\n      32\n      50\n      0.186056\n      0.169208\n      405.390504\n    \n    \n      12\n      data2\n      EPT-STGCN\n      4\n      32\n      50\n      0.183449\n      0.164652\n      418.454221\n    \n    \n      13\n      data2\n      EPT-STGCN\n      4\n      32\n      50\n      0.181829\n      0.164456\n      431.528654\n    \n    \n      14\n      data2\n      EPT-STGCN\n      4\n      32\n      50\n      0.181213\n      0.162173\n      407.844052\n    \n    \n      15\n      data2\n      EPT-STGCN\n      4\n      32\n      50\n      0.185801\n      0.163754\n      411.968251\n    \n    \n      16\n      data2\n      EPT-STGCN\n      4\n      32\n      50\n      0.180674\n      0.162226\n      409.180396\n    \n    \n      17\n      data2\n      EPT-STGCN\n      4\n      32\n      50\n      0.183327\n      0.165314\n      410.445006\n    \n    \n      18\n      data2\n      EPT-STGCN\n      4\n      32\n      50\n      0.188633\n      0.171534\n      410.336946\n    \n    \n      19\n      data2\n      EPT-STGCN\n      4\n      32\n      50\n      0.183651\n      0.162947\n      407.536792\n    \n    \n      20\n      data2\n      EPT-STGCN\n      4\n      32\n      50\n      0.181314\n      0.16315\n      407.53003\n    \n    \n      21\n      data2\n      EPT-STGCN\n      4\n      32\n      50\n      0.189536\n      0.173027\n      407.360921\n    \n    \n      22\n      data2\n      EPT-STGCN\n      4\n      32\n      50\n      0.194188\n      0.180879\n      407.03145\n    \n    \n      23\n      data2\n      EPT-STGCN\n      4\n      32\n      50\n      0.19195\n      0.173795\n      406.137764\n    \n    \n      24\n      data2\n      EPT-STGCN\n      4\n      32\n      50\n      0.201777\n      0.183143\n      409.344015\n    \n    \n      25\n      data2\n      EPT-STGCN\n      4\n      32\n      50\n      0.188091\n      0.170836\n      408.617722\n    \n    \n      26\n      data2\n      EPT-STGCN\n      4\n      32\n      50\n      0.184508\n      0.163219\n      407.710896\n    \n    \n      27\n      data2\n      EPT-STGCN\n      4\n      32\n      50\n      0.187269\n      0.170395\n      408.118827\n    \n    \n      28\n      data2\n      EPT-STGCN\n      4\n      32\n      50\n      0.184121\n      0.163209\n      407.103555\n    \n    \n      29\n      data2\n      EPT-STGCN\n      4\n      32\n      50\n      0.195845\n      0.175516\n      373.846944\n    \n  \n\n\n\n\n\n\n\n\nrslt1 = stgcn_ver1.simulation_results[['method', 'mse(train)', 'mse(test)']]\nrslt2 = stgcn_ver2.simulation_results[['method', 'mse(train)', 'mse(test)']]\n\n\nrslt = pd.concat([rslt1, rslt2], axis=0)\n# rslt\n\n\nrslt.groupby('method').agg(['mean', 'median', 'var']).reset_index()\n\n\n\n\n\n  \n    \n      \n      method\n      mse(train)\n      mse(test)\n    \n    \n      \n      \n      mean\n      median\n      var\n      mean\n      median\n      var\n    \n  \n  \n    \n      0\n      EPT-STGCN\n      0.187172\n      0.184532\n      0.000039\n      0.168869\n      0.166370\n      0.000050\n    \n    \n      1\n      STGCN\n      0.187523\n      0.185839\n      0.000037\n      0.172399\n      0.170521\n      0.000044\n    \n  \n\n\n\n\n- train\n\nsns.boxplot(x = rslt['method'],\n            y = rslt['mse(train)'])\nplt.title('Comparison of 30 simulation results(tr_mse)')\nplt.show()\n\n\n\n\n- test\n\nsns.boxplot(x = rslt['method'],\n            y = rslt['mse(test)'])\nplt.title('Comparison of 30 simulation results(test_mse)')\nplt.show()\n\n\n\n\n- histogram (test)\n\nrslt1['mse(test)'].hist(alpha=.5, label='STGCN', color='blue')\nrslt2['mse(test)'].hist(alpha=.5, label = 'EPT-STGCN', color='red')\nplt.title('Comparison of 30 simulation results(test_mse)')\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\nurl = \"https://raw.githubusercontent.com/pinkocto/noteda/main/posts/SOLAR/data2/stgcn_data1.json\"\nloader = eptstgcn.DatasetLoader(url)\ndataset = loader.get_dataset(lags=4)\ntrain_dataset, test_dataset = eptstgcn.utils.temporal_signal_split(dataset, train_ratio = 0.7)\n\n\nlrnr1 = eptstgcn.load_data('./lrnr_model/stgcn_ver1_data2_cancel_normal.pickle')\n\n\nevtor = eptstgcn.Evaluator(lrnr1, train_dataset, test_dataset)\n\n/home/jy/Dropbox/noteda/posts/SOLAR/eptstgcn/learners.py:70: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /opt/conda/conda-bld/pytorch_1678402421473/work/torch/csrc/utils/tensor_new.cpp:245.)\n  X = torch.tensor(dataset.features).float()\n\n\n\n\n\nevtor.tr_plot(t=150, label='observed data')\n\n\n\n\n\n\n\n\nevtor.test_plot(t=150, label='observed data')\n\n\n\n\n\n\n\n\n\nurl = \"https://raw.githubusercontent.com/pinkocto/noteda/main/posts/SOLAR/data2/stgcn_data2.json\"\nloader = eptstgcn.DatasetLoader(url)\ndataset = loader.get_dataset(lags=4)\ntrain_dataset, test_dataset = eptstgcn.utils.temporal_signal_split(dataset, train_ratio = 0.7)\n\n\nlrnr2 = eptstgcn.load_data('./lrnr_model/stgcn_ver2_data2_cancel_normal.pickle')\n\n\nevtor2 = eptstgcn.Evaluator(lrnr2, train_dataset, test_dataset)\n\n\n\n\nevtor2.tr_plot(t=150, label='observed data')\n\n\n\n\n\n\n\n\nevtor2.test_plot(t=150, label='observed data')"
  },
  {
    "objectID": "posts/SOLAR/2023-05-03-시뮬결과.html",
    "href": "posts/SOLAR/2023-05-03-시뮬결과.html",
    "title": "[SOLAR] 시뮬레이션 결과정리 1-iter (epoch, filter, lag)",
    "section": "",
    "text": "import eptstgcn\nimport torch\nimport eptstgcn.planner\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\nimport pandas as pd\nimport numpy as np\nimport gc\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nplans_stgcn = {\n    'max_iteration': 1,   # 30, \n    'method': ['EPT-STGCN'], \n    'lags': [4, 8, 12],  \n    'nof_filters': [16, 32, 64], \n    'epoch': [50, 100, 150]\n}\n\n# ver1_50epoch = eptstgcn.load_data('./simul_model2/stgcn_v1_50epoch.pickle')\n# ver1_100epoch = eptstgcn.load_data('./simul_model2/stgcn_v1_100epoch.pickle')\n# ver1_150epoch = eptstgcn.load_data('./simul_model2/stgcn_v1_150epoch.pickle')\n\n# ver2_50epoch = eptstgcn.load_data('./simul_model2/stgcn_v2_50epoch_.pickle')\n# ver2_100epoch = eptstgcn.load_data('./simul_model2/stgcn_v2_100epoch.pickle')\n# ver2_150epoch = eptstgcn.load_data('./simul_model2/stgcn_v2_150epoch.pickle')\n\n## + data normalization\n# ver1_50_nor = eptstgcn.load_data('./simul_model2/normal/stgcn_v1_50epoch.pickle')\n# ver1_100_nor = eptstgcn.load_data('./simul_model2/normal/stgcn_v1_100epoch.pickle')\n# ver1_150_nor = eptstgcn.load_data('./simul_model2/normal/stgcn_v1_150epoch.pickle')\n\n# ver2_50_nor = eptstgcn.load_data('./simul_model2/normal/stgcn_v2_50epoch_.pickle')\n# ver2_100_nor = eptstgcn.load_data('./simul_model2/normal/stgcn_v2_100epoch.pickle')\n# ver2_150_nor = eptstgcn.load_data('./simul_model2/normal/stgcn_v2_150epoch.pickle')\n\n\n## ver1\n# a_ = ver1_50epoch.simulation_results\n# a_.insert(2, 'normal' , ['X']*9)\n# b_ = ver1_100epoch.simulation_results\n# b_.insert(2, 'normal' , ['X']*9)\n# c_ = ver1_150epoch.simulation_results\n# c_.insert(2, 'normal' , ['X']*9)\n# a__ = ver1_50_nor.simulation_results\n# b__ = ver1_100_nor.simulation_results\n# c__ = ver1_150_nor.simulation_results\n\n\n## ver2\n# a2_ = ver2_50epoch.simulation_results\n# b2_ = ver2_100epoch.simulation_results\n# c2_ = ver2_150epoch.simulation_results\n\n# a2__ = ver2_50_nor.simulation_results\n# b2__ = ver2_100_nor.simulation_results\n# c2__ = ver2_150_nor.simulation_results\n\n# rslt = pd.concat([a_,b_,c_, a__, b__, c__, a2_, b2_, c2_, a2__, b2__, c2__])\n\n\n# rslt.to_csv('./simulation_results/simul_rlst.csv', index=False)\n\n\nrslt = pd.read_csv('./simulation_results/simul_rlst.csv')\n\n\nrslt\n\n\n\n\n\n  \n    \n      \n      dataset\n      method\n      normal\n      lags\n      nof_filters\n      epoch\n      mse(train)\n      mse(test)\n      calculation_time\n    \n  \n  \n    \n      0\n      data2\n      STGCN\n      X\n      4\n      16\n      50\n      0.182058\n      0.167798\n      299.051996\n    \n    \n      1\n      data2\n      STGCN\n      X\n      4\n      32\n      50\n      0.201436\n      0.188044\n      305.620220\n    \n    \n      2\n      data2\n      STGCN\n      X\n      4\n      64\n      50\n      0.191472\n      0.174166\n      316.454904\n    \n    \n      3\n      data2\n      STGCN\n      X\n      8\n      16\n      50\n      0.192159\n      0.173960\n      304.476469\n    \n    \n      4\n      data2\n      STGCN\n      X\n      8\n      32\n      50\n      0.205647\n      0.177749\n      309.493689\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      103\n      data2\n      EPT-STGCN\n      O\n      8\n      32\n      150\n      0.196512\n      0.188642\n      931.657403\n    \n    \n      104\n      data2\n      EPT-STGCN\n      O\n      8\n      64\n      150\n      0.184796\n      0.175644\n      962.807430\n    \n    \n      105\n      data2\n      EPT-STGCN\n      O\n      12\n      16\n      150\n      0.183245\n      0.173610\n      937.009531\n    \n    \n      106\n      data2\n      EPT-STGCN\n      O\n      12\n      32\n      150\n      0.184576\n      0.173852\n      972.509811\n    \n    \n      107\n      data2\n      EPT-STGCN\n      O\n      12\n      64\n      150\n      0.182424\n      0.172484\n      1004.384947\n    \n  \n\n108 rows × 9 columns\n\n\n\n\nrslt[rslt['mse(test)'] == min(rslt['mse(test)'])]\n\n\n\n\n\n  \n    \n      \n      dataset\n      method\n      normal\n      lags\n      nof_filters\n      epoch\n      mse(train)\n      mse(test)\n      calculation_time\n    \n  \n  \n    \n      55\n      data2\n      EPT-STGCN\n      X\n      4\n      32\n      50\n      0.180856\n      0.159167\n      298.478652\n    \n  \n\n\n\n\n\n\n\nrslt.query('lags==4 and nof_filters==16 and epoch==50')\n\n\n\n\n\n  \n    \n      \n      dataset\n      method\n      normal\n      lags\n      nof_filters\n      epoch\n      mse(train)\n      mse(test)\n      calculation_time\n    \n  \n  \n    \n      0\n      data2\n      STGCN\n      X\n      4\n      16\n      50\n      0.182058\n      0.167798\n      299.051996\n    \n    \n      27\n      data2\n      STGCN\n      O\n      4\n      16\n      50\n      0.181886\n      0.170189\n      301.377795\n    \n    \n      54\n      data2\n      EPT-STGCN\n      X\n      4\n      16\n      50\n      0.186759\n      0.163494\n      295.127900\n    \n    \n      81\n      data2\n      EPT-STGCN\n      O\n      4\n      16\n      50\n      0.191065\n      0.178842\n      295.075789\n    \n  \n\n\n\n\n\nrslt.query('lags==4 and nof_filters==32 and epoch==50')\n\n\n\n\n\n  \n    \n      \n      dataset\n      method\n      normal\n      lags\n      nof_filters\n      epoch\n      mse(train)\n      mse(test)\n      calculation_time\n    \n  \n  \n    \n      1\n      data2\n      STGCN\n      X\n      4\n      32\n      50\n      0.201436\n      0.188044\n      305.620220\n    \n    \n      28\n      data2\n      STGCN\n      O\n      4\n      32\n      50\n      0.198904\n      0.190715\n      296.457600\n    \n    \n      55\n      data2\n      EPT-STGCN\n      X\n      4\n      32\n      50\n      0.180856\n      0.159167\n      298.478652\n    \n    \n      82\n      data2\n      EPT-STGCN\n      O\n      4\n      32\n      50\n      0.180618\n      0.166902\n      298.276487\n    \n  \n\n\n\n\n\nrslt.query('lags==4 and nof_filters==64 and epoch==50')\n\n\n\n\n\n  \n    \n      \n      dataset\n      method\n      normal\n      lags\n      nof_filters\n      epoch\n      mse(train)\n      mse(test)\n      calculation_time\n    \n  \n  \n    \n      2\n      data2\n      STGCN\n      X\n      4\n      64\n      50\n      0.191472\n      0.174166\n      316.454904\n    \n    \n      29\n      data2\n      STGCN\n      O\n      4\n      64\n      50\n      0.195493\n      0.188309\n      308.646654\n    \n    \n      56\n      data2\n      EPT-STGCN\n      X\n      4\n      64\n      50\n      0.190731\n      0.175991\n      307.732803\n    \n    \n      83\n      data2\n      EPT-STGCN\n      O\n      4\n      64\n      50\n      0.185092\n      0.174121\n      307.609691\n    \n  \n\n\n\n\n\n\n\n\nrslt.query('lags==8 and nof_filters==16 and epoch==50')\n\n\n\n\n\n  \n    \n      \n      dataset\n      method\n      normal\n      lags\n      nof_filters\n      epoch\n      mse(train)\n      mse(test)\n      calculation_time\n    \n  \n  \n    \n      3\n      data2\n      STGCN\n      X\n      8\n      16\n      50\n      0.192159\n      0.173960\n      304.476469\n    \n    \n      30\n      data2\n      STGCN\n      O\n      8\n      16\n      50\n      0.189424\n      0.177908\n      303.527294\n    \n    \n      57\n      data2\n      EPT-STGCN\n      X\n      8\n      16\n      50\n      0.202791\n      0.174041\n      305.746121\n    \n    \n      84\n      data2\n      EPT-STGCN\n      O\n      8\n      16\n      50\n      0.188840\n      0.173830\n      304.973405\n    \n  \n\n\n\n\n\nrslt.query('lags==8 and nof_filters==32 and epoch==50')\n\n\n\n\n\n  \n    \n      \n      dataset\n      method\n      normal\n      lags\n      nof_filters\n      epoch\n      mse(train)\n      mse(test)\n      calculation_time\n    \n  \n  \n    \n      4\n      data2\n      STGCN\n      X\n      8\n      32\n      50\n      0.205647\n      0.177749\n      309.493689\n    \n    \n      31\n      data2\n      STGCN\n      O\n      8\n      32\n      50\n      0.213567\n      0.208104\n      307.255326\n    \n    \n      58\n      data2\n      EPT-STGCN\n      X\n      8\n      32\n      50\n      0.197390\n      0.169384\n      306.544829\n    \n    \n      85\n      data2\n      EPT-STGCN\n      O\n      8\n      32\n      50\n      0.213520\n      0.206142\n      308.734710\n    \n  \n\n\n\n\n\nrslt.query('lags==8 and nof_filters==64 and epoch==50')\n\n\n\n\n\n  \n    \n      \n      dataset\n      method\n      normal\n      lags\n      nof_filters\n      epoch\n      mse(train)\n      mse(test)\n      calculation_time\n    \n  \n  \n    \n      5\n      data2\n      STGCN\n      X\n      8\n      64\n      50\n      0.193967\n      0.170748\n      320.984409\n    \n    \n      32\n      data2\n      STGCN\n      O\n      8\n      64\n      50\n      0.190067\n      0.175568\n      319.699453\n    \n    \n      59\n      data2\n      EPT-STGCN\n      X\n      8\n      64\n      50\n      0.206705\n      0.176656\n      322.366115\n    \n    \n      86\n      data2\n      EPT-STGCN\n      O\n      8\n      64\n      50\n      0.194730\n      0.184389\n      317.388223\n    \n  \n\n\n\n\n\n\n\n\nrslt.query('lags==12 and nof_filters==16 and epoch==50')\n\n\n\n\n\n  \n    \n      \n      dataset\n      method\n      normal\n      lags\n      nof_filters\n      epoch\n      mse(train)\n      mse(test)\n      calculation_time\n    \n  \n  \n    \n      6\n      data2\n      STGCN\n      X\n      12\n      16\n      50\n      0.201442\n      0.177695\n      315.960462\n    \n    \n      33\n      data2\n      STGCN\n      O\n      12\n      16\n      50\n      0.189747\n      0.180983\n      315.895220\n    \n    \n      60\n      data2\n      EPT-STGCN\n      X\n      12\n      16\n      50\n      0.205929\n      0.175041\n      311.189126\n    \n    \n      87\n      data2\n      EPT-STGCN\n      O\n      12\n      16\n      50\n      0.184434\n      0.175556\n      311.789555\n    \n  \n\n\n\n\n\nrslt.query('lags==12 and nof_filters==32 and epoch==50')\n\n\n\n\n\n  \n    \n      \n      dataset\n      method\n      normal\n      lags\n      nof_filters\n      epoch\n      mse(train)\n      mse(test)\n      calculation_time\n    \n  \n  \n    \n      7\n      data2\n      STGCN\n      X\n      12\n      32\n      50\n      0.191433\n      0.177609\n      317.608783\n    \n    \n      34\n      data2\n      STGCN\n      O\n      12\n      32\n      50\n      0.201539\n      0.201505\n      320.217695\n    \n    \n      61\n      data2\n      EPT-STGCN\n      X\n      12\n      32\n      50\n      0.202787\n      0.175517\n      320.403812\n    \n    \n      88\n      data2\n      EPT-STGCN\n      O\n      12\n      32\n      50\n      0.200415\n      0.192586\n      316.290751\n    \n  \n\n\n\n\n\nrslt.query('lags==12 and nof_filters==64 and epoch==50')\n\n\n\n\n\n  \n    \n      \n      dataset\n      method\n      normal\n      lags\n      nof_filters\n      epoch\n      mse(train)\n      mse(test)\n      calculation_time\n    \n  \n  \n    \n      8\n      data2\n      STGCN\n      X\n      12\n      64\n      50\n      0.195411\n      0.177827\n      327.971840\n    \n    \n      35\n      data2\n      STGCN\n      O\n      12\n      64\n      50\n      0.193679\n      0.187321\n      322.395950\n    \n    \n      62\n      data2\n      EPT-STGCN\n      X\n      12\n      64\n      50\n      0.214775\n      0.180072\n      326.717989\n    \n    \n      89\n      data2\n      EPT-STGCN\n      O\n      12\n      64\n      50\n      0.189591\n      0.177227\n      325.705265\n    \n  \n\n\n\n\n\nrslt.query(\"epoch==50\").plot.box(backend='plotly',x='lags',color='method',y='mse(test)')\n\n\n                                                \n\n\n\nrslt.query(\"epoch==100\").plot.box(backend='plotly',x='lags',color='method',y='mse(test)')\n\n\n                                                \n\n\n\nrslt.query(\"epoch==150\").plot.box(backend='plotly',x='lags',color='method',y='mse(test)')\n\n\n                                                \n\n\n\nrslt.plot.box(backend='plotly',x='lags',color='method',y='mse(test)', facet_col='normal',facet_row='nof_filters', height=1000)\n\n\n                                                \n\n\n\n아직 결과 비교가 어려움. (적어도 30이상은 되어야 함. 중심극한정리 처럼..)\n만약 24lag에서 결과가 좋으면 주기가 24시간과 연결시키면 될 것.\n전체적으로 어떤 모델의 결과가 좋은데 어떤 조건 어떤 조건일 때가 최적이고, 이런 이런 조건에서는 오히려~~가 더 좋더라.. 이런식으로\n만약 필터가 많았을 때 결과가 좋다면, 좋은성능의 원인은 필터의 수가 많음일 지도.. (이 모델이 잘 맞춘다기 보다는 그냥 필터의 능력일지도)\ntop (cpu 사용량 확인) – 잘 돌아가고 있나\n경로수정필요"
  },
  {
    "objectID": "posts/SOLAR/2023-04-15-stgcn-ver2-수정본.html",
    "href": "posts/SOLAR/2023-04-15-stgcn-ver2-수정본.html",
    "title": "[SOLAR] STGCN Ver2 수정본 (MSE: 0.2000)",
    "section": "",
    "text": "import pandas as pd\nimport numpy as np\nimport json\nimport urllib\nimport time\n\n\n# 일반적인 모듈 \nimport numpy as np\nimport matplotlib.pyplot as plt \nimport networkx as nx \nfrom tqdm import tqdm \n\n# 파이토치 관련 \nimport torch\nimport torch.nn.functional as F\n\n# PyG 관련 \nfrom torch_geometric.data import Data ## Data: 그래프자료형을 만드는 클래스\n\n# STGCN 관련 \nimport torch_geometric_temporal\nfrom torch_geometric_temporal.nn.recurrent import GConvGRU\nfrom torch_geometric_temporal.signal import temporal_signal_split \n\n\nclass RecurrentGCN(torch.nn.Module):\n    def __init__(self, node_features, filters):\n        super(RecurrentGCN, self).__init__()\n        self.recurrent = GConvGRU(node_features, filters, 2)\n        self.linear = torch.nn.Linear(filters, 1)\n\n    def forward(self, x, edge_index, edge_weight):\n        h = self.recurrent(x, edge_index, edge_weight)\n        h = F.relu(h)\n        h = self.linear(h)\n        return h\n\n\nfrom mysolar import SolarEPTDatasetLoader\n\n\nloader = SolarEPTDatasetLoader()\ndataset = loader.get_dataset(lags=4)\ntrain_dataset, test_dataset = temporal_signal_split(dataset, train_ratio=0.7)\n\n\nprint(np.array(train_dataset.targets).shape)\nprint(np.array(test_dataset.targets).shape)\n\n(1794, 44)\n(770, 44)"
  },
  {
    "objectID": "posts/SOLAR/2023-04-15-stgcn-ver2-수정본.html#learn",
    "href": "posts/SOLAR/2023-04-15-stgcn-ver2-수정본.html#learn",
    "title": "[SOLAR] STGCN Ver2 수정본 (MSE: 0.2000)",
    "section": "Learn",
    "text": "Learn\n\nmodel = RecurrentGCN(node_features=4, filters=32)\noptimizer = torch.optim.Adam(model.parameters(), lr=0.01)\nmodel.train()\n\nRecurrentGCN(\n  (recurrent): GConvGRU(\n    (conv_x_z): ChebConv(4, 32, K=2, normalization=sym)\n    (conv_h_z): ChebConv(32, 32, K=2, normalization=sym)\n    (conv_x_r): ChebConv(4, 32, K=2, normalization=sym)\n    (conv_h_r): ChebConv(32, 32, K=2, normalization=sym)\n    (conv_x_h): ChebConv(4, 32, K=2, normalization=sym)\n    (conv_h_h): ChebConv(32, 32, K=2, normalization=sym)\n  )\n  (linear): Linear(in_features=32, out_features=1, bias=True)\n)\n\n\n\nstart = time.time()\nfor epoch in tqdm(range(50)):\n    for t, snapshot in enumerate(train_dataset):\n        yt_hat = model(snapshot.x, snapshot.edge_index, snapshot.edge_attr)\n        cost = torch.mean((yt_hat-snapshot.y)**2)\n        cost.backward()\n        optimizer.step()\n        optimizer.zero_grad()\nend = time.time()\nprint(f\"{end-start:.5f} sec\")\n\n100%|██████████| 50/50 [06:14<00:00,  7.48s/it]\n\n\n374.15209 sec\n\n\n\n\n\n\nprint(352.31150/60, '분')\n\n5.871858333333334 분\n\n\n\nimport pickle \nwith open('./model2/stgcn2_lag4_new.pickle','wb') as fw:\n    pickle.dump(model, fw)\n\n\nimport pickle \nwith open('./model2/stgcn2_lag4_new.pickle', 'rb') as f: \n    model = pickle.load(f)\n\n\nmodel\n\nRecurrentGCN(\n  (recurrent): GConvGRU(\n    (conv_x_z): ChebConv(4, 32, K=2, normalization=sym)\n    (conv_h_z): ChebConv(32, 32, K=2, normalization=sym)\n    (conv_x_r): ChebConv(4, 32, K=2, normalization=sym)\n    (conv_h_r): ChebConv(32, 32, K=2, normalization=sym)\n    (conv_x_h): ChebConv(4, 32, K=2, normalization=sym)\n    (conv_h_h): ChebConv(32, 32, K=2, normalization=sym)\n  )\n  (linear): Linear(in_features=32, out_features=1, bias=True)\n)"
  },
  {
    "objectID": "posts/SOLAR/2023-04-15-stgcn-ver2-수정본.html#모델평가",
    "href": "posts/SOLAR/2023-04-15-stgcn-ver2-수정본.html#모델평가",
    "title": "[SOLAR] STGCN Ver2 수정본 (MSE: 0.2000)",
    "section": "모델평가",
    "text": "모델평가\n- train\n\nSTGCN Ver1 \\(\\to\\) MSE: 0.2102\nSTGCN Ver2 (70) \\(\\to\\) MSE: 0.2181\nSTGCN Ver2 (90) \\(\\to\\) MSE : 0.2639\n\n\nmodel.eval()\ncost = 0\nfor time, snapshot in enumerate(train_dataset):\n    y_hat = model(snapshot.x, snapshot.edge_index, snapshot.edge_attr)\n    cost = cost + torch.mean((y_hat-snapshot.y)**2)\ncost = cost / (time+1)\ncost = cost.item()\nprint(\"MSE: {:.4f}\".format(cost))\n\nMSE: 0.2161\n\n\n- test\n\nSTGCN Ver1 \\(\\to\\) MSE : 0.1899\nSTGCN Ver2 (70) \\(\\to\\) MSE : 0.2019\nSTGCN Ver2 (90) \\(\\to\\) MSE : 0.1635\n\n\nmodel.eval()\ncost = 0\nfor time, snapshot in enumerate(test_dataset):\n    y_hat = model(snapshot.x, snapshot.edge_index, snapshot.edge_attr)\n    cost = cost + torch.mean((y_hat-snapshot.y)**2)\ncost = cost / (time+1)\ncost = cost.item()\nprint(\"MSE: {:.4f}\".format(cost))\n\nMSE: 0.2000\n\n\n\nurl = 'https://raw.githubusercontent.com/pinkocto/noteda/main/posts/SOLAR/data2/stgcn_data2.json'\n\n\ndata_dict = json.loads(urllib.request.urlopen(url).read())\nV = list(data_dict['node_ids'].keys())\nf = np.array(data_dict[\"FX\"])\n\n\nyhat_train = torch.stack([model(snapshot.x,snapshot.edge_index, snapshot.edge_attr) for snapshot in train_dataset]).detach().numpy()\nyhat_test = torch.stack([model(snapshot.x,snapshot.edge_index, snapshot.edge_attr) for snapshot in test_dataset]).detach().numpy()\n\n\nyhat_test.shape, yhat_train.shape\n\n((770, 44, 1), (1794, 44, 1))\n\n\n\nimport matplotlib.pyplot as plt\nplt.rcParams['font.family'] = 'NanumGothic'\n\n\nfig,ax = plt.subplots(44,1,figsize=(10,50))\nlag= 0 \nT = 100 \nfor k in range(44):\n    ax[k].plot(np.array(train_dataset.targets)[lag:(lag+T),k],'--',alpha=0.5,label='observed')\n    ax[k].set_title('node: {}'.format(V[k]))\n    ax[k].plot(yhat_train[:T,k],label='predicted (tr)')\n#    ax[k].plot(range(yhat_train.shape[0],yhat_train.shape[0]+yhat_test.shape[0]),yhat_test[:,k],label='predicted (test)')\n    ax[k].legend()\nfig.tight_layout()\n\n# plt.savefig('stgcn-ver2-lag4-vis.png')\n\n\n\n\n\nfig,ax = plt.subplots(44,1,figsize=(10,50))\nlag= 0\nT = 100 \nfor k in range(44):\n    ax[k].plot(np.array(test_dataset.targets)[lag:(lag+T),k],'--',alpha=0.5,label='observed')\n    ax[k].set_title('node: {}'.format(V[k]))\n    ax[k].plot(yhat_test[:T,k],label='predicted (test)')\n#    ax[k].plot(range(yhat_train.shape[0],yhat_train.shape[0]+yhat_test.shape[0]),yhat_test[:,k],label='predicted (test)')\n    ax[k].legend()\nfig.tight_layout()\n\n# plt.savefig('stgcn-ver2-lag4-vis.png')"
  },
  {
    "objectID": "posts/SOLAR/2023-04-09-soloar-stgcn-ver1-lag1.html",
    "href": "posts/SOLAR/2023-04-09-soloar-stgcn-ver1-lag1.html",
    "title": "[SOLAR] STGCN Ver1 lag1",
    "section": "",
    "text": "import pandas as pd\nimport numpy as np\nimport json\nimport urllib\nimport time\n\n\n# 일반적인 모듈 \nimport numpy as np\nimport matplotlib.pyplot as plt \nimport networkx as nx \nfrom tqdm import tqdm \n\n# 파이토치 관련 \nimport torch\nimport torch.nn.functional as F\n\n# PyG 관련 \nfrom torch_geometric.data import Data ## Data: 그래프자료형을 만드는 클래스\n\n# STGCN 관련 \nimport torch_geometric_temporal\nfrom torch_geometric_temporal.nn.recurrent import GConvGRU\nfrom torch_geometric_temporal.signal import temporal_signal_split \n\n\nclass RecurrentGCN(torch.nn.Module):\n    def __init__(self, node_features, filters):\n        super(RecurrentGCN, self).__init__()\n        self.recurrent = GConvGRU(node_features, filters, 2)\n        self.linear = torch.nn.Linear(filters, 1)\n\n    def forward(self, x, edge_index, edge_weight):\n        h = self.recurrent(x, edge_index, edge_weight)\n        h = F.relu(h)\n        h = self.linear(h)\n        return h\n\n\nfrom mysolar import SolarDatasetLoader\n\n\nloader = SolarDatasetLoader()\ndataset = loader.get_dataset(lags=1)\ntrain_dataset, test_dataset = temporal_signal_split(dataset, train_ratio=0.8)\n\n\nnp.array(dataset.features).shape\n\n(18249, 44, 1)"
  },
  {
    "objectID": "posts/SOLAR/2023-04-09-soloar-stgcn-ver1-lag1.html#learn",
    "href": "posts/SOLAR/2023-04-09-soloar-stgcn-ver1-lag1.html#learn",
    "title": "[SOLAR] STGCN Ver1 lag1",
    "section": "Learn",
    "text": "Learn\n\nmodel = RecurrentGCN(node_features=1, filters=32)\noptimizer = torch.optim.Adam(model.parameters(), lr=0.01)\nmodel.train()\n\nRecurrentGCN(\n  (recurrent): GConvGRU(\n    (conv_x_z): ChebConv(1, 32, K=2, normalization=sym)\n    (conv_h_z): ChebConv(32, 32, K=2, normalization=sym)\n    (conv_x_r): ChebConv(1, 32, K=2, normalization=sym)\n    (conv_h_r): ChebConv(32, 32, K=2, normalization=sym)\n    (conv_x_h): ChebConv(1, 32, K=2, normalization=sym)\n    (conv_h_h): ChebConv(32, 32, K=2, normalization=sym)\n  )\n  (linear): Linear(in_features=32, out_features=1, bias=True)\n)\n\n\n\nstart = time.time()\nfor epoch in tqdm(range(50)):\n    for t, snapshot in enumerate(train_dataset):\n        yt_hat = model(snapshot.x, snapshot.edge_index, snapshot.edge_attr)\n        cost = torch.mean((yt_hat-snapshot.y)**2)\n        cost.backward()\n        optimizer.step()\n        optimizer.zero_grad()\nend = time.time()\nprint(f\"{end-start:.5f} sec\")\n\n100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [48:36<00:00, 58.33s/it]\n\n\n2916.28218 sec\n\n\n\n\n\n\nprint(2916/60, '분')\n\n48.6 분\n\n\n\n# import pickle \n# with open('stgcn1_lag1.pickle','wb') as fw:\n#     pickle.dump(model, fw)\n\n\nimport pickle \nwith open('stgcn1_lag1.pickle', 'rb') as f: \n    model = pickle.load(f)\n\n\nmodel\n\nRecurrentGCN(\n  (recurrent): GConvGRU(\n    (conv_x_z): ChebConv(1, 32, K=2, normalization=sym)\n    (conv_h_z): ChebConv(32, 32, K=2, normalization=sym)\n    (conv_x_r): ChebConv(1, 32, K=2, normalization=sym)\n    (conv_h_r): ChebConv(32, 32, K=2, normalization=sym)\n    (conv_x_h): ChebConv(1, 32, K=2, normalization=sym)\n    (conv_h_h): ChebConv(32, 32, K=2, normalization=sym)\n  )\n  (linear): Linear(in_features=32, out_features=1, bias=True)\n)"
  },
  {
    "objectID": "posts/SOLAR/2023-04-09-soloar-stgcn-ver1-lag1.html#모델평가",
    "href": "posts/SOLAR/2023-04-09-soloar-stgcn-ver1-lag1.html#모델평가",
    "title": "[SOLAR] STGCN Ver1 lag1",
    "section": "모델평가",
    "text": "모델평가\n\nmodel.eval()\ncost = 0\nfor time, snapshot in enumerate(train_dataset):\n    y_hat = model(snapshot.x, snapshot.edge_index, snapshot.edge_attr)\n    cost = cost + torch.mean((y_hat-snapshot.y)**2)\ncost = cost / (time+1)\ncost = cost.item()\nprint(\"MSE: {:.4f}\".format(cost))\n\nMSE: 0.1695\n\n\n\nmodel.eval()\ncost = 0\nfor time, snapshot in enumerate(test_dataset):\n    y_hat = model(snapshot.x, snapshot.edge_index, snapshot.edge_attr)\n    cost = cost + torch.mean((y_hat-snapshot.y)**2)\ncost = cost / (time+1)\ncost = cost.item()\nprint(\"MSE: {:.4f}\".format(cost))\n\nMSE: 0.1443\n\n\n\nyhat_train = torch.stack([model(snapshot.x,snapshot.edge_index, snapshot.edge_attr) for snapshot in train_dataset]).detach().numpy()\nyhat_test = torch.stack([model(snapshot.x,snapshot.edge_index, snapshot.edge_attr) for snapshot in test_dataset]).detach().numpy()\n\n\nurl = 'https://raw.githubusercontent.com/pinkocto/noteda/main/posts/SOLAR/data/solar.json'\ndata_dict = json.loads(urllib.request.urlopen(url).read())\nV = list(data_dict['node_ids'].keys())\nf = np.array(data_dict[\"FX\"])"
  },
  {
    "objectID": "posts/SOLAR/2023-04-09-soloar-stgcn-ver1-lag1.html#visualization",
    "href": "posts/SOLAR/2023-04-09-soloar-stgcn-ver1-lag1.html#visualization",
    "title": "[SOLAR] STGCN Ver1 lag1",
    "section": "Visualization",
    "text": "Visualization\n\nimport matplotlib.pyplot as plt\nplt.rcParams['font.family'] = 'NanumGothic'\n\n\nyhat_train.shape\n\n(14599, 44, 1)\n\n\n\nt1= 0\nt2= 100\nfig,ax = plt.subplots(5,1,figsize=(10,10))\nfor k in range(5):\n    ax[k].plot(f[t1:t2,k],'--',alpha=0.5,label='observed')\n    ax[k].set_title('node: {}'.format(V[k]))\n    ax[k].plot(yhat_train[t1:t2,k],label='predicted (tr)')\n    # test_time_index = range(yhat_train.shape[0],yhat_train.shape[0]+yhat_test.shape[0])\n    # test_predicted = yhat_test[:,k]\n    # ax[k].plot(test_time_index[t1:t2],test_predicted[t1:t2],label='predicted (test)')\n    ax[k].legend()\nfig.tight_layout()"
  },
  {
    "objectID": "posts/SOLAR/2023-03-01-todolist.html",
    "href": "posts/SOLAR/2023-03-01-todolist.html",
    "title": "[SOLAR] To do list",
    "section": "",
    "text": "04/19 update\n\n\nhttps://pytorch-geometric-temporal.readthedocs.io/en/latest/notes/introduction.html#data-structures\n\n\n\n\n데이터 중복문제\n데이터 기간 재설정: 6월-8월15 // 8월15 ~9월15\n가중치 데이터 새로\n가중치 스케일링 고려?\n\n\n\n\n\n가중치 스케일링 진행\n30번 정도 반복 실험 및 결과 기록 (우연한 결과인지?)\n시각화 (boxplot)\n결과 잘 안나오면 Logn term, Short term 모델 고려\n우선 데이터2로 먼저 돌려보고, 결과확인후 잘안되면 data3로 해야지.\n\n\n\n\n\nscaling이 필요할까..? (우선 스케일링안된 데이터 사용)\n\n\n\n\nhttps://pinkocto.github.io/noteda/posts/SOLAR/2023-04-07-stcgn-data-ver2.html#comparison\n\n\n\n\n\n지역별 correlation\nlag4 : \\(\\tt{MSE}: 0.0934\\) (약 1시간)\nlag1,2 등 정보가 더 적을때도 STGCN ver1이 더 좋은가?\n\n\n\n\n\nenvelope의 correlation\nlag4: \\(\\tt{MSE}: 0.0938\\) (약 1시간)\n\n\n\n\n\n\nimport pandas as pd\n\n\ncol = ['Model', 'lag', 'epoch','learning rate','scaling','EPT', 'train(MSE)','test(MSE)', 'Time(sec)']\n\n\ndf_row = pd.DataFrame(columns = col)\ndf_row['Model'] = ['STGCN v1','STGCN v2','STGCN v1', 'STGCN v2']\ndf_row['lag'] = ['lag4', 'lag4', 'lag1', 'lag1']\ndf_row['epoch'] = [50, 50, 50, 50]\ndf_row['learning rate'] = [0.01, 0.01, 0.01, 0.01]\ndf_row['scaling'] = ['X', 'X', 'X', 'X']\ndf_row['EPT'] = ['X', 'O', 'X', 'O']\n# df_row['Undersampling'] = ['X', 'X']\n# df_row['hyper tunning'] = ['X', 'O']\ndf_row['train(MSE)'] = [0.1041, 0.1069,0.1695, 0.1711]\ndf_row['test(MSE)'] = [0.0934, 0.0938, 0.1443, 0.1452]\ndf_row['Time(sec)'] = ['약 1시간 (시간측정X)','약 1시간 (시간측정X)', '2916.28218 (약 48.60분)', '2888.63086 (약 48.14분)']\n\n\ndf_row\n\n\n\n\n\n  \n    \n      \n      Model\n      lag\n      epoch\n      learning rate\n      scaling\n      EPT\n      train(MSE)\n      test(MSE)\n      Time(sec)\n    \n  \n  \n    \n      0\n      STGCN v1\n      lag4\n      50\n      0.01\n      X\n      X\n      0.1041\n      0.0934\n      약 1시간 (시간측정X)\n    \n    \n      1\n      STGCN v2\n      lag4\n      50\n      0.01\n      X\n      O\n      0.1069\n      0.0938\n      약 1시간 (시간측정X)\n    \n    \n      2\n      STGCN v1\n      lag1\n      50\n      0.01\n      X\n      X\n      0.1695\n      0.1443\n      2916.28218 (약 48.60분)\n    \n    \n      3\n      STGCN v2\n      lag1\n      50\n      0.01\n      X\n      O\n      0.1711\n      0.1452\n      2888.63086 (약 48.14분)\n    \n  \n\n\n\n\n- STGCN ver1\n\n\n\nSTGCN ve1 lag4\n\n\n- STGCN ver2\n\n\n\nSTGCN ver2 lag4\n\n\n\nver2가 더 성능이 잘 나올줄 알았는데 뭔가 잘못했나??\n시각화 그림을 보면 위에 가위로 자른 것 같이 생김. 일사량이 2.5이상으로 관측되면 잘 예측을 못하는 것 같음.\n맥시멈이 2.5인느낌. (너무 안전하게 예측하려고 하나?)\n\n\n\n\n\n\ndata2 : 22/06/01~22/09/15\ndata3 : 22/08/15~22/09/10"
  },
  {
    "objectID": "posts/SOLAR/2023-03-01-todolist.html#arma",
    "href": "posts/SOLAR/2023-03-01-todolist.html#arma",
    "title": "[SOLAR] To do list",
    "section": "ARMA",
    "text": "ARMA\nhttps://www.kaggle.com/code/javigallego/time-series-forecasting-tutorial#4-%7C-Time-Series-Components\n\n시계열 모델 돌릴때 이전에 임의로 결측값을 \\(0\\)으로 채운 것 다른방법으로도 채워서 해봐야하나??"
  },
  {
    "objectID": "posts/SOLAR/2023-03-01-todolist.html#lstm",
    "href": "posts/SOLAR/2023-03-01-todolist.html#lstm",
    "title": "[SOLAR] To do list",
    "section": "LSTM",
    "text": "LSTM\n\nhttps://machinelearningmastery.com/lstm-for-time-series-prediction-in-pytorch/\n가장 기본모델로 돌려보자."
  },
  {
    "objectID": "posts/SOLAR/2023-03-01-todolist.html#gru",
    "href": "posts/SOLAR/2023-03-01-todolist.html#gru",
    "title": "[SOLAR] To do list",
    "section": "GRU",
    "text": "GRU"
  },
  {
    "objectID": "posts/SOLAR/2023-04-19-데이터탐색용.html",
    "href": "posts/SOLAR/2023-04-19-데이터탐색용.html",
    "title": "[SOLAR] 데이터 탐색용",
    "section": "",
    "text": "data2/solar_radiation.csv 기반으로 재구조한 데이터\n\n\nimport pandas as pd\nimport numpy as np\nimport json\nimport urllib\nimport time\n\n\ndf = pd.read_csv('./data2/restructuring_data.csv')\n\n\ndf_ = pd.read_csv('./data3/restructuring_data.csv')\n\n\ndf_.shape[0]*0.756\n\n489.888\n\n\n\n407/648\n\n0.6280864197530864\n\n\n\ndf_.shape\n\n(648, 45)\n\n\n\ndf_.iloc[407]\n\ndate    2022-08-31 23:00:00\n북춘천                     0.0\n철원                      0.0\n대관령                     0.0\n춘천                      0.0\n백령도                     0.0\n북강릉                     0.0\n강릉                      0.0\n서울                      0.0\n인천                      0.0\n원주                      0.0\n울릉도                     0.0\n수원                      0.0\n서산                      0.0\n청주                      0.0\n대전                      0.0\n추풍령                     0.0\n안동                      0.0\n포항                      0.0\n대구                      0.0\n전주                      0.0\n창원                      0.0\n광주                      0.0\n부산                      0.0\n목포                      0.0\n여수                      0.0\n흑산도                     0.0\n고창                      0.0\n홍성                      0.0\n제주                      0.0\n고산                      0.0\n진주                      0.0\n고창군                     0.0\n영광군                     0.0\n김해시                     0.0\n순창군                     0.0\n북창원                     0.0\n양산시                     0.0\n보성군                     0.0\n강진군                     0.0\n의령군                     0.0\n함양군                     0.0\n광양시                     0.0\n청송군                     0.0\n경주시                     0.0\nName: 407, dtype: object\n\n\n\ndf.shape\n\n(2568, 45)\n\n\n\ndf.head()\n\n\n\n\n\n  \n    \n      \n      date\n      북춘천\n      철원\n      대관령\n      춘천\n      백령도\n      북강릉\n      강릉\n      서울\n      인천\n      ...\n      순창군\n      북창원\n      양산시\n      보성군\n      강진군\n      의령군\n      함양군\n      광양시\n      청송군\n      경주시\n    \n  \n  \n    \n      0\n      2022-06-01 00:00:00\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      ...\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n    \n    \n      1\n      2022-06-01 01:00:00\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      ...\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n    \n    \n      2\n      2022-06-01 02:00:00\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      ...\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n    \n    \n      3\n      2022-06-01 03:00:00\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      ...\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n    \n    \n      4\n      2022-06-01 04:00:00\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      ...\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n    \n  \n\n5 rows × 45 columns\n\n\n\n\nprint('train', df.iloc[0]['date'], '~', df.iloc[1793]['date'])\nprint('test',  df.iloc[1794]['date'], '~', df.iloc[-1]['date'])\n\ntrain 2022-06-01 00:00:00 ~ 2022-08-14 17:00:00\ntest 2022-08-14 18:00:00 ~ 2022-09-15 23:00:00\n\n\n[힌남노] 활동기간 : 2022년 8월 28일 15시 ~ 2022년 9월 6일 21시\n[노루] 활동기간: 2022년 9월 23일 15시 ~ 2022년 9월 28일 21시 –> 한국영향X"
  },
  {
    "objectID": "posts/SOLAR/2023-04-12-stgcn-ver2.html",
    "href": "posts/SOLAR/2023-04-12-stgcn-ver2.html",
    "title": "[SOLAR] STGCN Ver2 90% (MSE: 0.1635)",
    "section": "",
    "text": "import pandas as pd\nimport numpy as np\nimport json\nimport urllib\nimport time\n\n\n# 일반적인 모듈 \nimport numpy as np\nimport matplotlib.pyplot as plt \nimport networkx as nx \nfrom tqdm import tqdm \n\n# 파이토치 관련 \nimport torch\nimport torch.nn.functional as F\n\n# PyG 관련 \nfrom torch_geometric.data import Data ## Data: 그래프자료형을 만드는 클래스\n\n# STGCN 관련 \nimport torch_geometric_temporal\nfrom torch_geometric_temporal.nn.recurrent import GConvGRU\nfrom torch_geometric_temporal.signal import temporal_signal_split \n\n\nclass RecurrentGCN(torch.nn.Module):\n    def __init__(self, node_features, filters):\n        super(RecurrentGCN, self).__init__()\n        self.recurrent = GConvGRU(node_features, filters, 2)\n        self.linear = torch.nn.Linear(filters, 1)\n\n    def forward(self, x, edge_index, edge_weight):\n        h = self.recurrent(x, edge_index, edge_weight)\n        h = F.relu(h)\n        h = self.linear(h)\n        return h\n\n\nfrom mysolar import SolarEPTDatasetLoader\n\n\nloader = SolarEPTDatasetLoader()\ndataset = loader.get_dataset(lags=4)\ntrain_dataset, test_dataset = temporal_signal_split(dataset, train_ratio=0.9)\n\n\nprint(np.array(train_dataset.targets).shape)\nprint(np.array(test_dataset.targets).shape)\n\n(2115, 44)\n(235, 44)\n\n\n\ntrain: 2022-06-01 00:00:00 ~ 2022-09-05 03:00:00\ntest: 2022-09-05 04:00:00 ~ 2022-09-15 21:00:00"
  },
  {
    "objectID": "posts/SOLAR/2023-04-12-stgcn-ver2.html#learn",
    "href": "posts/SOLAR/2023-04-12-stgcn-ver2.html#learn",
    "title": "[SOLAR] STGCN Ver2 90% (MSE: 0.1635)",
    "section": "Learn",
    "text": "Learn\n\nmodel = RecurrentGCN(node_features=4, filters=32)\noptimizer = torch.optim.Adam(model.parameters(), lr=0.01)\nmodel.train()\n\nRecurrentGCN(\n  (recurrent): GConvGRU(\n    (conv_x_z): ChebConv(4, 32, K=2, normalization=sym)\n    (conv_h_z): ChebConv(32, 32, K=2, normalization=sym)\n    (conv_x_r): ChebConv(4, 32, K=2, normalization=sym)\n    (conv_h_r): ChebConv(32, 32, K=2, normalization=sym)\n    (conv_x_h): ChebConv(4, 32, K=2, normalization=sym)\n    (conv_h_h): ChebConv(32, 32, K=2, normalization=sym)\n  )\n  (linear): Linear(in_features=32, out_features=1, bias=True)\n)\n\n\n\nstart = time.time()\nfor epoch in tqdm(range(50)):\n    for t, snapshot in enumerate(train_dataset):\n        yt_hat = model(snapshot.x, snapshot.edge_index, snapshot.edge_attr)\n        cost = torch.mean((yt_hat-snapshot.y)**2)\n        cost.backward()\n        optimizer.step()\n        optimizer.zero_grad()\nend = time.time()\nprint(f\"{end-start:.5f} sec\")\n\n100%|██████████| 50/50 [05:52<00:00,  7.05s/it]\n\n\n352.31150 sec\n\n\n\n\n\n\nprint(352.31150/60, '분')\n\n5.871858333333334 분\n\n\n\nimport pickle \nwith open('./model/stgcn2_lag4_90_new.pickle','wb') as fw:\n    pickle.dump(model, fw)\n\n\nimport pickle \nwith open('./model/stgcn2_lag4_90_new.pickle', 'rb') as f: \n    model = pickle.load(f)\n\n\nmodel\n\nRecurrentGCN(\n  (recurrent): GConvGRU(\n    (conv_x_z): ChebConv(4, 32, K=2, normalization=sym)\n    (conv_h_z): ChebConv(32, 32, K=2, normalization=sym)\n    (conv_x_r): ChebConv(4, 32, K=2, normalization=sym)\n    (conv_h_r): ChebConv(32, 32, K=2, normalization=sym)\n    (conv_x_h): ChebConv(4, 32, K=2, normalization=sym)\n    (conv_h_h): ChebConv(32, 32, K=2, normalization=sym)\n  )\n  (linear): Linear(in_features=32, out_features=1, bias=True)\n)"
  },
  {
    "objectID": "posts/SOLAR/2023-04-12-stgcn-ver2.html#모델평가",
    "href": "posts/SOLAR/2023-04-12-stgcn-ver2.html#모델평가",
    "title": "[SOLAR] STGCN Ver2 90% (MSE: 0.1635)",
    "section": "모델평가",
    "text": "모델평가\n- train\n\nSTGCN Ver1 \\(\\to\\) MSE: 0.2102\nSTGCN Ver2 (70) \\(\\to\\) MSE: 0.2181\nSTGCN Ver2 (90) \\(\\to\\) MSE : 0.2639\n\n\nmodel.eval()\ncost = 0\nfor time, snapshot in enumerate(train_dataset):\n    y_hat = model(snapshot.x, snapshot.edge_index, snapshot.edge_attr)\n    cost = cost + torch.mean((y_hat-snapshot.y)**2)\ncost = cost / (time+1)\ncost = cost.item()\nprint(\"MSE: {:.4f}\".format(cost))\n\nMSE: 0.2639\n\n\n- test\n\nSTGCN Ver1 \\(\\to\\) MSE : 0.1899\nSTGCN Ver2 (70) \\(\\to\\) MSE : 0.2019\nSTGCN Ver2 (90) \\(\\to\\) MSE : 0.1635\n\n\nmodel.eval()\ncost = 0\nfor time, snapshot in enumerate(test_dataset):\n    y_hat = model(snapshot.x, snapshot.edge_index, snapshot.edge_attr)\n    cost = cost + torch.mean((y_hat-snapshot.y)**2)\ncost = cost / (time+1)\ncost = cost.item()\nprint(\"MSE: {:.4f}\".format(cost))\n\nMSE: 0.1635"
  },
  {
    "objectID": "posts/SOLAR/2023-04-06-ept-by-region.html",
    "href": "posts/SOLAR/2023-04-06-ept-by-region.html",
    "title": "[SOLAR] EPT by region",
    "section": "",
    "text": "ref: https://www.sciencedirect.com/science/article/pii/S2352711021000492"
  },
  {
    "objectID": "posts/SOLAR/2023-04-06-ept-by-region.html#데이터-처리",
    "href": "posts/SOLAR/2023-04-06-ept-by-region.html#데이터-처리",
    "title": "[SOLAR] EPT by region",
    "section": "데이터 처리",
    "text": "데이터 처리\n\ndf = df |> mutate(date=ymd_hm(date))\ndf %>% head()\n\n\n\nA tibble: 6 × 3\n\n    regionsolar_radiationdate\n    <chr><dbl><dttm>\n\n\n    북춘천02021-01-01 00:00:00\n    북춘천02021-01-01 01:00:00\n    북춘천02021-01-01 02:00:00\n    북춘천02021-01-01 03:00:00\n    북춘천02021-01-01 04:00:00\n    북춘천02021-01-01 05:00:00\n\n\n\n\n\ndim(df)\n\n\n8030003\n\n\n\nunique(df$region) %>% length()\n\n44"
  },
  {
    "objectID": "posts/SOLAR/2023-04-06-ept-by-region.html#plot",
    "href": "posts/SOLAR/2023-04-06-ept-by-region.html#plot",
    "title": "[SOLAR] EPT by region",
    "section": "Plot",
    "text": "Plot\n\nfor (i in 1:44){\n     assign(paste0('data',1:44)[i],df |> filter(region == unique(df$region)[i]))\n     assign(paste0('data',1:44)[i],eval(parse(text=paste0('data',i)))[order(eval(parse(text=paste0('data',i)))$date),])\n     assign(paste0('y',1:44)[i], eval(parse(text=paste0('data',i)))$solar_radiation)\n}\n\n\nfor (i in 1:44){\n    plot(eval(parse(text=paste0('y',i)))[1:500], ann=FALSE)\n    lines(eval(parse(text=paste0('y',i))),lty=2)\n    title(main = as.character(unique(df$region)[i]), xlab='time', ylab='solar radiation')\n    }"
  },
  {
    "objectID": "posts/SOLAR/2023-04-06-ept-by-region.html#etp-수행",
    "href": "posts/SOLAR/2023-04-06-ept-by-region.html#etp-수행",
    "title": "[SOLAR] EPT by region",
    "section": "ETP 수행",
    "text": "ETP 수행\n\nept = function(y){\n    EpM = eptransf(signal=y,tau=24,process=c(\"envelope\",\"average\"))$EpM\n    EpM*2\n}\n\n\n아래 코드 오래걸림 주의\n\n\nlibrary(tictoc)\n\n\ntic('지역별 yU계산')\nfor (i in 1:44){\n    assign(paste0('yU',1:44)[i], ept(eval(parse(text=paste0('y',i)))))\n}\ntoc()\n\n\nfor (i in 1:44){\n    plot(eval(parse(text=paste0('y',i)))[1:500], ann=FALSE)\n    lines(eval(parse(text=paste0('yU',i))),col = 2, lty=2)\n    title(main = as.character(unique(df$region)[i]), xlab='time', ylab='solar radiation')\n    }\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nref : https://jobmanager1.tistory.com/84\nref : https://rbasall.tistory.com/101"
  },
  {
    "objectID": "posts/SOLAR/2023-04-17-정규화-stgcn-ver2.html",
    "href": "posts/SOLAR/2023-04-17-정규화-stgcn-ver2.html",
    "title": "[SOLAR] STGCN Ver2 (data2, +N) (MSE: 0.1834)",
    "section": "",
    "text": "train 2022-06-01 00:00:00 ~ 2022-08-14 17:00:00\ntest 2022-08-14 18:00:00 ~ 2022-09-15 23:00:00"
  },
  {
    "objectID": "posts/SOLAR/2023-04-17-정규화-stgcn-ver2.html#import",
    "href": "posts/SOLAR/2023-04-17-정규화-stgcn-ver2.html#import",
    "title": "[SOLAR] STGCN Ver2 (data2, +N) (MSE: 0.1834)",
    "section": "import",
    "text": "import\n\nimport pandas as pd\nimport numpy as np\nimport json\nimport urllib\nimport time\n\n\n# 일반적인 모듈 \nimport numpy as np\nimport matplotlib.pyplot as plt \nimport networkx as nx \nfrom tqdm import tqdm \n\n# 파이토치 관련 \nimport torch\nimport torch.nn.functional as F\n\n# PyG 관련 \nfrom torch_geometric.data import Data ## Data: 그래프자료형을 만드는 클래스\n\n# STGCN 관련 \nimport torch_geometric_temporal\nfrom torch_geometric_temporal.nn.recurrent import GConvGRU\nfrom torch_geometric_temporal.signal import temporal_signal_split \n\n\nclass RecurrentGCN(torch.nn.Module):\n    def __init__(self, node_features, filters):\n        super(RecurrentGCN, self).__init__()\n        self.recurrent = GConvGRU(node_features, filters, 2)\n        self.linear = torch.nn.Linear(filters, 1)\n\n    def forward(self, x, edge_index, edge_weight):\n        h = self.recurrent(x, edge_index, edge_weight)\n        h = F.relu(h)\n        h = self.linear(h)\n        return h\n\n\nfrom mysolar2 import NormalSolarEPTDatasetLoader\n\n\nloader = NormalSolarEPTDatasetLoader()\ndataset = loader.get_dataset(lags=4)\ntrain_dataset, test_dataset = temporal_signal_split(dataset, train_ratio=0.7)\n\n\nprint(np.array(train_dataset.targets).shape)\nprint(np.array(test_dataset.targets).shape)\n\n(1794, 44)\n(770, 44)"
  },
  {
    "objectID": "posts/SOLAR/2023-04-17-정규화-stgcn-ver2.html#learn",
    "href": "posts/SOLAR/2023-04-17-정규화-stgcn-ver2.html#learn",
    "title": "[SOLAR] STGCN Ver2 (data2, +N) (MSE: 0.1834)",
    "section": "Learn",
    "text": "Learn\n\nmodel = RecurrentGCN(node_features=4, filters=32)\noptimizer = torch.optim.Adam(model.parameters(), lr=0.01)\nmodel.train()\n\nRecurrentGCN(\n  (recurrent): GConvGRU(\n    (conv_x_z): ChebConv(4, 32, K=2, normalization=sym)\n    (conv_h_z): ChebConv(32, 32, K=2, normalization=sym)\n    (conv_x_r): ChebConv(4, 32, K=2, normalization=sym)\n    (conv_h_r): ChebConv(32, 32, K=2, normalization=sym)\n    (conv_x_h): ChebConv(4, 32, K=2, normalization=sym)\n    (conv_h_h): ChebConv(32, 32, K=2, normalization=sym)\n  )\n  (linear): Linear(in_features=32, out_features=1, bias=True)\n)\n\n\n\nstart = time.time()\nfor epoch in tqdm(range(50)):\n    for t, snapshot in enumerate(train_dataset):\n        yt_hat = model(snapshot.x, snapshot.edge_index, snapshot.edge_attr)\n        cost = torch.mean((yt_hat-snapshot.y)**2)\n        cost.backward()\n        optimizer.step()\n        optimizer.zero_grad()\nend = time.time()\nprint(f\"{end-start:.5f} sec\")\n\n100%|██████████| 50/50 [04:56<00:00,  5.94s/it]\n\n\n296.83938 sec\n\n\n\n\n\n\nprint(352.31150/60, '분')\n\n5.871858333333334 분\n\n\n\nimport pickle \nwith open('./model3/normal_stgcn2_lag4_new.pickle','wb') as fw:\n    pickle.dump(model, fw)\n\n\nimport pickle \nwith open('./model3/normal_stgcn2_lag4_new.pickle', 'rb') as f: \n    model = pickle.load(f)\n\n\nmodel\n\nRecurrentGCN(\n  (recurrent): GConvGRU(\n    (conv_x_z): ChebConv(4, 32, K=2, normalization=sym)\n    (conv_h_z): ChebConv(32, 32, K=2, normalization=sym)\n    (conv_x_r): ChebConv(4, 32, K=2, normalization=sym)\n    (conv_h_r): ChebConv(32, 32, K=2, normalization=sym)\n    (conv_x_h): ChebConv(4, 32, K=2, normalization=sym)\n    (conv_h_h): ChebConv(32, 32, K=2, normalization=sym)\n  )\n  (linear): Linear(in_features=32, out_features=1, bias=True)\n)"
  },
  {
    "objectID": "posts/SOLAR/2023-04-17-정규화-stgcn-ver2.html#모델평가",
    "href": "posts/SOLAR/2023-04-17-정규화-stgcn-ver2.html#모델평가",
    "title": "[SOLAR] STGCN Ver2 (data2, +N) (MSE: 0.1834)",
    "section": "모델평가",
    "text": "모델평가\n- train\n\nSTGCN Ver1 \\(\\to\\) MSE: 0.2102 (2년간)\n\n—> 기간재설정\n\nSTGCN Ver2 (70) \\(\\to\\) MSE: 0.2181 (데이터 채워넣기 전)\nSTGCN Ver2 (90) \\(\\to\\) MSE : 0.2639 (데이터 채워넣기 전)\n\n—-> 데이터추가 (시간대)\n\nSTGCN Ver2 (70) \\(\\to\\) MSE : 0.2161 (데이터 추가, 정규화 전)\n\n\nmodel.eval()\ncost = 0\nfor time, snapshot in enumerate(train_dataset):\n    y_hat = model(snapshot.x, snapshot.edge_index, snapshot.edge_attr)\n    cost = cost + torch.mean((y_hat-snapshot.y)**2)\ncost = cost / (time+1)\ncost = cost.item()\nprint(\"MSE: {:.4f}\".format(cost))\n\nMSE: 0.2005\n\n\n- test\n\nSTGCN Ver1 \\(\\to\\) MSE : 0.1899 (2년간)\n\n—> 기간재설정\n\nSTGCN Ver2 (70) \\(\\to\\) MSE : 0.2019 (데이터 채워넣기 전)\nSTGCN Ver2 (90) \\(\\to\\) MSE : 0.1635 (데이터 채워넣기 전)\n\n—-> 데이터추가 (시간대) - STGCN Ver2 (70) \\(\\to\\) MSE : 0.2000 (데이터 추가, 정규화 전)\n\nmodel.eval()\ncost = 0\nfor time, snapshot in enumerate(test_dataset):\n    y_hat = model(snapshot.x, snapshot.edge_index, snapshot.edge_attr)\n    cost = cost + torch.mean((y_hat-snapshot.y)**2)\ncost = cost / (time+1)\ncost = cost.item()\nprint(\"MSE: {:.4f}\".format(cost))\n\nMSE: 0.1834"
  },
  {
    "objectID": "posts/SOLAR/2023-04-17-정규화-stgcn-ver2.html#visualization",
    "href": "posts/SOLAR/2023-04-17-정규화-stgcn-ver2.html#visualization",
    "title": "[SOLAR] STGCN Ver2 (data2, +N) (MSE: 0.1834)",
    "section": "Visualization",
    "text": "Visualization\n\nurl = 'https://raw.githubusercontent.com/pinkocto/noteda/main/posts/SOLAR/data2/stgcn_data2.json'\n\n\ndata_dict = json.loads(urllib.request.urlopen(url).read())\nV = list(data_dict['node_ids'].keys())\nf = np.array(data_dict[\"FX\"])\n\n\nyhat_train = torch.stack([model(snapshot.x,snapshot.edge_index, snapshot.edge_attr) for snapshot in train_dataset]).detach().numpy()\nyhat_test = torch.stack([model(snapshot.x,snapshot.edge_index, snapshot.edge_attr) for snapshot in test_dataset]).detach().numpy()\n\n\nyhat_test.shape, yhat_train.shape\n\n((770, 44, 1), (1794, 44, 1))\n\n\n\nimport matplotlib.pyplot as plt\nplt.rcParams['font.family'] = 'NanumGothic'\n\n\ntrain\n\nfig,ax = plt.subplots(44,1,figsize=(10,50))\nlag= 0 \nT = 100 \nfor k in range(44):\n    ax[k].plot(np.array(train_dataset.targets)[lag:(lag+T),k],'--',alpha=0.5,label='observed')\n    ax[k].set_title('node: {}'.format(V[k]))\n    ax[k].plot(yhat_train[:T,k],label='predicted (tr)', color='orange')\n#    ax[k].plot(range(yhat_train.shape[0],yhat_train.shape[0]+yhat_test.shape[0]),yhat_test[:,k],label='predicted (test)')\n    ax[k].legend()\nfig.tight_layout()\n\n# plt.savefig('stgcn-ver2-lag4-vis.png')\n\n\n\n\n\n\ntest\n\nfig,ax = plt.subplots(44,1,figsize=(10,50))\nlag= 0\nT = 100 \nfor k in range(44):\n    ax[k].plot(np.array(test_dataset.targets)[lag:(lag+T),k],'--',alpha=0.5,label='observed')\n    ax[k].set_title('node: {}'.format(V[k]))\n    ax[k].plot(yhat_test[:T,k],label='predicted (test)', color='red')\n#    ax[k].plot(range(yhat_train.shape[0],yhat_train.shape[0]+yhat_test.shape[0]),yhat_test[:,k],label='predicted (test)')\n    ax[k].legend()\nfig.tight_layout()\n\n# plt.savefig('stgcn-ver2-lag4-vis.png')"
  },
  {
    "objectID": "posts/SOLAR/2023-04-22-시각화코드수정.html",
    "href": "posts/SOLAR/2023-04-22-시각화코드수정.html",
    "title": "[SOLAR] 연습용 (시각화 코드 수정)",
    "section": "",
    "text": "연습용 (시각화 코드 수정)\n\nimport eptstgcn\nimport torch\nimport eptstgcn.planner \n\n\nurl = \"https://raw.githubusercontent.com/pinkocto/noteda/main/posts/SOLAR/data2/stgcn_data2.json\"\nloader = eptstgcn.DatasetLoader(url)\ndataset = loader.get_dataset(lags=4)\n\n\ntrain_dataset, test_dataset = eptstgcn.utils.temporal_signal_split(dataset, train_ratio = 0.7)\n\n\nimport pickle \nwith open('./lrnr_model/stgcn_ver2_data2.pickle', 'rb') as f: \n    model = pickle.load(f)\n\n\nevtor = eptstgcn.Evaluator(model, train_dataset, test_dataset)\n\n/home/jy/Dropbox/noteda/posts/SOLAR/eptstgcn/learners.py:70: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /opt/conda/conda-bld/pytorch_1678402421473/work/torch/csrc/utils/tensor_new.cpp:245.)\n  X = torch.tensor(dataset.features).float()\n\n\n\nimport matplotlib.pyplot as plt\nclass Evaluator():\n    def __init__(self,learner,train_dataset,test_dataset):\n        self.learner = learner\n        # self.learner.model.eval()\n        try:self.learner.model.eval()\n        except:pass\n        self.train_dataset = train_dataset\n        self.test_dataset = test_dataset\n        self.lags = self.learner.lags\n        rslt_tr = self.learner(self.train_dataset) \n        rslt_test = self.learner(self.test_dataset)\n        self.X_tr = rslt_tr['X']\n        self.y_tr = rslt_tr['y']\n        self.f_tr = torch.concat([self.train_dataset[0].x.T,self.y_tr],axis=0).float()\n        self.yhat_tr = rslt_tr['yhat']\n        self.fhat_tr = torch.concat([self.train_dataset[0].x.T,self.yhat_tr],axis=0).float()\n        self.X_test = rslt_test['X']\n        self.y_test = rslt_test['y']\n        self.f_test = self.y_test \n        self.yhat_test = rslt_test['yhat']\n        self.fhat_test = self.yhat_test\n        self.f = torch.concat([self.f_tr,self.f_test],axis=0)\n        self.fhat = torch.concat([self.fhat_tr,self.fhat_test],axis=0)\n    def calculate_mse(self):\n        test_base_mse_eachnode = ((self.y_test - self.y_test.mean(axis=0).reshape(-1,self.y_test.shape[-1]))**2).mean(axis=0).tolist()\n        test_base_mse_total = ((self.y_test - self.y_test.mean(axis=0).reshape(-1,self.y_test.shape[-1]))**2).mean().item()\n        train_mse_eachnode = ((self.y_tr-self.yhat_tr)**2).mean(axis=0).tolist()\n        train_mse_total = ((self.y_tr-self.yhat_tr)**2).mean().item()\n        test_mse_eachnode = ((self.y_test-self.yhat_test)**2).mean(axis=0).tolist()\n        test_mse_total = ((self.y_test-self.yhat_test)**2).mean().item()\n        self.mse = {'train': {'each_node': train_mse_eachnode, 'total': train_mse_total},\n                    'test': {'each_node': test_mse_eachnode, 'total': test_mse_total},\n                    'test(base)': {'each_node': test_base_mse_eachnode, 'total': test_base_mse_total},\n                   }\n    def _plot(self,*args,t=None,h=2.5,max_node=5,**kwargs):\n        T,N = self.f.shape\n        if t is None: t = range(T)\n        fig = plt.figure()\n        nof_axs = max(min(N,max_node),2)\n        if min(N,max_node)<2: \n            print('max_node should be >=2')\n        ax = fig.subplots(nof_axs ,1)\n        for n in range(nof_axs):\n            ax[n].plot(t,self.f[:,n],color='gray',*args,**kwargs)\n            # ax[n].set_title('node='+str(n))\n            ax[n].set_title(str(n))\n        fig.set_figheight(nof_axs*h)\n        fig.tight_layout()\n        plt.close()\n        return fig\n    def plot(self,*args,t=None,h=2.5,**kwargs):\n        self.calculate_mse()\n        fig = self._plot(*args,t=None,h=2.5,**kwargs)\n        ax = fig.get_axes()\n        node_ids = ['북춘천', '철원', '대관령', '춘천', '백령도', '북강릉', '강릉', '서울', '인천', '원주',\n       '울릉도', '수원', '서산', '청주', '대전', '추풍령', '안동', '포항', '대구', '전주', '창원',\n       '광주', '부산', '목포', '여수', '흑산도', '고창', '홍성', '제주', '고산', '진주', '고창군',\n       '영광군', '김해시', '순창군', '북창원', '양산시', '보성군', '강진군', '의령군', '함양군',\n       '광양시', '청송군', '경주시']\n        for i,a in enumerate(ax):\n            _mse1= self.mse['train']['each_node'][i]\n            _mse2= self.mse['test']['each_node'][i]\n            _mse3= self.mse['test(base)']['each_node'][i]\n            \"\"\"\n            # _mrate = self.learner.mrate_eachnode if set(dir(self.learner.mrate_eachnode)) & {'__getitem__'} == set() else self.learner.mrate_eachnode[i]\n            # _title = 'node{0}, mrate: {1:.2f}% \\n mse(train) = {2:.2f}, mse(test) = {3:.2f}, mse(test_base) = {4:.2f}'.format(i,_mrate*100,_mse1,_mse2,_mse3)\n            \"\"\"\n            # _title = 'node{0}, \\n mse(train) = {1:.2f}, mse(test) = {2:.2f}, mse(test_base) = {3:.2f}'.format(i, _mse1, _mse2, _mse3)\n            _title = 'node: {0}, \\n mse(train) = {1:.2f}, mse(test) = {2:.2f}, mse(test_base) = {3:.2f}'.format(node_ids[i], _mse1, _mse2, _mse3)\n            a.set_title(_title)\n            _t1 = self.lags\n            _t2 = self.yhat_tr.shape[0]+self.lags\n            _t3 = len(self.f)\n            a.plot(range(_t1,_t2),self.yhat_tr[:,i],label='fitted (train)',color='C0')\n            a.plot(range(_t2,_t3),self.yhat_test[:,i],label='fitted (test)',color='C1')\n            a.legend()\n        _mse1= self.mse['train']['total']\n        _mse2= self.mse['test']['total']\n        _mse3= self.mse['test(base)']['total']\n        _title =\\\n        'dataset: {0} \\n method: {1} \\n epochs={2} \\n number of filters={3} \\n lags = {4} \\n mse(train) = {5:.2f}, mse(test) = {6:.2f}, mse(test_base) = {7:.2f} \\n'.\\\n        format(self.learner.dataset_name,self.learner.method,self.learner.epochs,self.learner.nof_filters,self.learner.lags,_mse1,_mse2,_mse3)\n        fig.suptitle(_title)\n        fig.tight_layout()\n        return fig\n    \n    ## 추가\n    def _plot2(self,*args,t=None,h=2.5,max_node=44,**kwargs):\n        T,N = self.f_tr.shape\n        # if t is None: t = range(T)\n        if t is None: t = 150\n        fig = plt.figure()\n        nof_axs = max(min(N,max_node),2)\n        if min(N,max_node)<2: \n            print('max_node should be >=2')\n        ax = fig.subplots(nof_axs ,1)\n        for n in range(nof_axs):\n            # ax[n].plot(t,self.f_tr[:,n],color='gray',*args,**kwargs)\n            ax[n].plot(np.array(self.train_dataset.targets)[:t,n], color='gray',*args,**kwargs)\n            # ax[n].set_title('node='+str(n))\n            ax[n].set_title(str(n))\n        fig.set_figheight(nof_axs*h)\n        fig.tight_layout()\n        plt.close()\n        return fig\n    \n    def tr_plot(self,*args,t=None,h=2.5,**kwargs):\n        self.calculate_mse()\n        fig = self._plot2(*args,t=None,h=2.5,**kwargs)\n        ax = fig.get_axes()\n        node_ids = ['북춘천', '철원', '대관령', '춘천', '백령도', '북강릉', '강릉', '서울', '인천', '원주',\n                   '울릉도', '수원', '서산', '청주', '대전', '추풍령', '안동', '포항', '대구', '전주', '창원',\n                   '광주', '부산', '목포', '여수', '흑산도', '고창', '홍성', '제주', '고산', '진주', '고창군',\n                   '영광군', '김해시', '순창군', '북창원', '양산시', '보성군', '강진군', '의령군', '함양군',\n                   '광양시', '청송군', '경주시']\n        for i,a in enumerate(ax):\n            _mse1= self.mse['train']['each_node'][i]\n            # _mse2= self.mse['test']['each_node'][i]\n            # _mse3= self.mse['test(base)']['each_node'][i]\n            \"\"\"\n            # _mrate = self.learner.mrate_eachnode if set(dir(self.learner.mrate_eachnode)) & {'__getitem__'} == set() else self.learner.mrate_eachnode[i]\n            # _title = 'node{0}, mrate: {1:.2f}% \\n mse(train) = {2:.2f}, mse(test) = {3:.2f}, mse(test_base) = {4:.2f}'.format(i,_mrate*100,_mse1,_mse2,_mse3)\n            \"\"\"\n            # _title = 'node{0}, \\n mse(train) = {1:.2f}, mse(test) = {2:.2f}, mse(test_base) = {3:.2f}'.format(i, _mse1, _mse2, _mse3)\n            # _title = 'node: {0}, \\n mse(train) = {1:.2f}, mse(test) = {2:.2f}, mse(test_base) = {3:.2f}'.format(node_ids[i], _mse1, _mse2, _mse3)\n            _title = 'node: {0}, \\n mse(train) = {1:.2f}'.format(node_ids[i], _mse1)\n            a.set_title(_title)\n            # _t1 = self.lags\n            # _t2 = self.yhat_tr.shape[0]+self.lags\n            # _t3 = len(self.f)\n            a.plot(range(t),self.yhat_tr[:t,i],label='fitted (train)',color='C0')\n            # a.plot(range(_t2,_t3),self.yhat_test[:,i],label='fitted (test)',color='C1')\n            a.legend()\n        _mse1= self.mse['train']['total']\n        _mse2= self.mse['test']['total']\n        _mse3= self.mse['test(base)']['total']\n        _title =\\\n        'dataset: {0} \\n method: {1} \\n epochs={2} \\n number of filters={3} \\n lags = {4} \\n mse(train) = {5:.2f}, mse(test) = {6:.2f}, mse(test_base) = {7:.2f} \\n'.\\\n        format(self.learner.dataset_name,self.learner.method,self.learner.epochs,self.learner.nof_filters,self.learner.lags,_mse1,_mse2,_mse3)\n        # fig.suptitle(_title)\n        fig.suptitle(_title, y=1.00)\n        fig.tight_layout()\n        return fig\n    \n    \n        ## 추가\n        \n    def _plot3(self,*args,t=None,h=2.5,max_node=44,**kwargs):\n        T,N = self.f_tr.shape\n        # if t is None: t = range(T)\n        if t is None: t = 150\n        fig = plt.figure()\n        nof_axs = max(min(N,max_node),2)\n        if min(N,max_node)<2: \n            print('max_node should be >=2')\n        ax = fig.subplots(nof_axs ,1)\n        for n in range(nof_axs):\n            # ax[n].plot(t,self.f_tr[:,n],color='gray',*args,**kwargs)\n            ax[n].plot(np.array(self.test_dataset.targets)[:t,n], color='gray',linestyle='dashed',*args,**kwargs)\n            # ax[n].set_title('node='+str(n))\n            ax[n].set_title(str(n))\n        fig.set_figheight(nof_axs*h)\n        fig.tight_layout()\n        plt.close()\n        return fig\n    \n    def test_plot(self,*args,t=None,h=2.5,**kwargs):\n        self.calculate_mse()\n        fig = self._plot3(*args,t=None,h=2.5,**kwargs)\n        ax = fig.get_axes()\n        node_ids = ['북춘천', '철원', '대관령', '춘천', '백령도', '북강릉', '강릉', '서울', '인천', '원주',\n                   '울릉도', '수원', '서산', '청주', '대전', '추풍령', '안동', '포항', '대구', '전주', '창원',\n                   '광주', '부산', '목포', '여수', '흑산도', '고창', '홍성', '제주', '고산', '진주', '고창군',\n                   '영광군', '김해시', '순창군', '북창원', '양산시', '보성군', '강진군', '의령군', '함양군',\n                   '광양시', '청송군', '경주시']\n        for i,a in enumerate(ax):\n            _mse1= self.mse['train']['each_node'][i]\n            _mse2= self.mse['test']['each_node'][i]\n            # _mse3= self.mse['test(base)']['each_node'][i]\n            \"\"\"\n            # _mrate = self.learner.mrate_eachnode if set(dir(self.learner.mrate_eachnode)) & {'__getitem__'} == set() else self.learner.mrate_eachnode[i]\n            # _title = 'node{0}, mrate: {1:.2f}% \\n mse(train) = {2:.2f}, mse(test) = {3:.2f}, mse(test_base) = {4:.2f}'.format(i,_mrate*100,_mse1,_mse2,_mse3)\n            \"\"\"\n            # _title = 'node{0}, \\n mse(train) = {1:.2f}, mse(test) = {2:.2f}, mse(test_base) = {3:.2f}'.format(i, _mse1, _mse2, _mse3)\n            # _title = 'node: {0}, \\n mse(train) = {1:.2f}, mse(test) = {2:.2f}, mse(test_base) = {3:.2f}'.format(node_ids[i], _mse1, _mse2, _mse3)\n            _title = 'node: {0}, \\n mse(train) = {1:.2f}, mse(test) = {2:.2f}'.format(node_ids[i], _mse1, _mse2)\n            a.set_title(_title)\n            # _t1 = self.lags\n            # _t2 = self.yhat_tr.shape[0]+self.lags\n            # _t3 = len(self.f)\n            # a.plot(range(t),self.yhat_tr[:t,i],label='fitted (train)',color='C0')\n            a.plot(range(t),self.yhat_test[:t,i],label='fitted (test)',color='C1')\n            a.legend()\n        _mse1= self.mse['train']['total']\n        _mse2= self.mse['test']['total']\n        _mse3= self.mse['test(base)']['total']\n        _title =\\\n        'dataset: {0} \\n method: {1} \\n epochs={2} \\n number of filters={3} \\n lags = {4} \\n mse(train) = {5:.2f}, mse(test) = {6:.2f}, mse(test_base) = {7:.2f} \\n'.\\\n        format(self.learner.dataset_name,self.learner.method,self.learner.epochs,self.learner.nof_filters,self.learner.lags,_mse1,_mse2,_mse3)\n        # fig.suptitle(_title)\n        # fig.get_axes()[0].annotate(_title, (0.5, 0.999), \n        #                     xycoords='figure fraction', ha='center')\n        fig.suptitle(_title, y=0.999)\n        fig.tight_layout()\n        return fig\n\n\nevtor2 = Evaluator(model, train_dataset, test_dataset)\n\n\nimport numpy as np\nfig = evtor2.tr_plot(t=150, label='observed data')\nfig\n\n\n\n\n\nimport numpy as np\nfig = evtor2.test_plot(t=150, label='observed data')\nfig\n\n\n\n\n\n# fig2 = evtor.test_plot(t=150, label='observed data')\n# fig2.tight_layout()\n# fig2"
  },
  {
    "objectID": "posts/SOLAR/2023-04-07-stcgn-data-ver2.html",
    "href": "posts/SOLAR/2023-04-07-stcgn-data-ver2.html",
    "title": "[SOLAR] Dataset for STGCN Ver2",
    "section": "",
    "text": "data\n\n\n\n\nimport pandas as pd\nimport numpy as np\nimport json\nimport urllib\n\nimport matplotlib.pyplot as plt\n\n\n# 일반적인 모듈 \nimport numpy as np\nimport matplotlib.pyplot as plt \nimport networkx as nx \nfrom tqdm import tqdm \n\n# 파이토치 관련 \nimport torch\nimport torch.nn.functional as F\n\n# PyG 관련 \nfrom torch_geometric.data import Data ## Data: 그래프자료형을 만드는 클래스\n\n# STGCN 관련 \nimport torch_geometric_temporal\nfrom torch_geometric_temporal.nn.recurrent import GConvGRU\nfrom torch_geometric_temporal.signal import temporal_signal_split \n\n- solar.json\n\nurl = 'https://raw.githubusercontent.com/pinkocto/noteda/main/posts/SOLAR/data/solar.json'\ndata_dict = json.loads(urllib.request.urlopen(url).read())\n\n\ndata_dict.keys()\n\ndict_keys(['edges', 'node_ids', 'weights', 'FX'])\n\n\n\nnp.array(data_dict['weights']).shape\n\n(1892,)\n\n\n- EPT weights\n\nurl2 = 'https://raw.githubusercontent.com/pinkocto/noteda/main/posts/SOLAR/data/yU_weight.csv'\nyu_weight = pd.read_csv(url2)\n\n\nyu_weight.shape\n\n(44, 44)\n\n\n\ndata_dict['weights'][:10], \n\n([0.962366714092048,\n  0.909825582944558,\n  0.985656552711889,\n  0.871680934662379,\n  0.90065860620053,\n  0.890926813199931,\n  0.94308108402774,\n  0.936899352767745,\n  0.94447272168175,\n  0.840858046009325],\n 0.8927396029030008)\n\n\n\nweights = []    \n \nfor i in range(44):\n    for j in range(44):\n        if i != j:\n            weights.append(yu_weight.iloc[i,j]) \n\n\nweights[:10], \n\n([0.936531892351231,\n  0.7910049258531,\n  0.971789275111083,\n  0.687837348221919,\n  0.770130634080735,\n  0.736971292542263,\n  0.901832850136046,\n  0.881446449497764,\n  0.895348289525123,\n  0.636585300037113],)\n\n\n\n\n\n\nnp.mean(data_dict['weights']), np.mean(weights)\n\n(0.8927396029030008, 0.7271816268896101)\n\n\n\nplt.hist(np.array(data_dict['weights']), alpha = 0.5, label = 'weights')\nplt.hist(np.array(weights), alpha = 0.5, label = 'EPT weights')\nplt.legend(loc='upper left')\n\n<matplotlib.legend.Legend at 0x7f752626fd90>\n\n\n\n\n\n- start\n\nnp.array(data_dict['weights']).shape\n\n(1892,)\n\n\n\nnp.array(weights).shape\n\n(1892,)\n\n\n\ndata_dict['weights'] = weights\n\n\ndata_dict['weights'][:10]\n\n[0.936531892351231,\n 0.7910049258531,\n 0.971789275111083,\n 0.687837348221919,\n 0.770130634080735,\n 0.736971292542263,\n 0.901832850136046,\n 0.881446449497764,\n 0.895348289525123,\n 0.636585300037113]\n\n\n\nnp.array(data_dict['weights']).mean()\n\n0.7271816268896101\n\n\n\ndata_dict.keys()\n\ndict_keys(['edges', 'node_ids', 'weights', 'FX'])\n\n\n\n# file_path = './data/solar2.json'\n\n\n# with open(file_path, 'w') as f:\n#     json.dump(data_dict, f)\n\n\nwith open(file_path, 'r') as f:\n    test = json.load(f, encoding='cp949')\n\n- 테스트\n\nfrom mysolar import SolarEPTDatasetLoader\n\n\nloader = SolarEPTDatasetLoader()\ndataset = loader.get_dataset(lags=4)\ntrain_dataset, test_dataset = temporal_signal_split(dataset, train_ratio=0.8)\n\n\ndata_train=[]\nfor time, snapshot in enumerate(train_dataset):\n    data_train.append([time, snapshot])\n\n\ndata_train[0][1].x.shape,data_train[0][1].y.shape,data_train[0][1].edge_index.shape,data_train[0][1].edge_attr.shape\n\n(torch.Size([44, 4]),\n torch.Size([44]),\n torch.Size([2, 1892]),\n torch.Size([1892]))\n\n\n\ndata_test=[]\nfor time, snapshot in enumerate(test_dataset):\n    data_test.append([time,snapshot])\n\n\ndata_test[0][1].x.shape,data_test[0][1].y.shape,data_test[0][1].edge_index.shape,data_test[0][1].edge_attr.shape\n\n(torch.Size([44, 4]),\n torch.Size([44]),\n torch.Size([2, 1892]),\n torch.Size([1892]))"
  },
  {
    "objectID": "posts/SOLAR/2023-04-20-정규화-데이터3-stgcn-ver2.html",
    "href": "posts/SOLAR/2023-04-20-정규화-데이터3-stgcn-ver2.html",
    "title": "[SOLAR] STGCN Ver2 (Full: 08/15~09/10 data3) (MSE: 0.1927)",
    "section": "",
    "text": "train: 08월 학습, 9월 10일간 test"
  },
  {
    "objectID": "posts/SOLAR/2023-04-20-정규화-데이터3-stgcn-ver2.html#import",
    "href": "posts/SOLAR/2023-04-20-정규화-데이터3-stgcn-ver2.html#import",
    "title": "[SOLAR] STGCN Ver2 (Full: 08/15~09/10 data3) (MSE: 0.1927)",
    "section": "import",
    "text": "import\n\nimport pandas as pd\nimport numpy as np\nimport json\nimport urllib\nimport time\n\n\n# 일반적인 모듈 \nimport numpy as np\nimport matplotlib.pyplot as plt \nimport networkx as nx \nfrom tqdm import tqdm \n\n# 파이토치 관련 \nimport torch\nimport torch.nn.functional as F\n\n# PyG 관련 \nfrom torch_geometric.data import Data ## Data: 그래프자료형을 만드는 클래스\n\n# STGCN 관련 \nimport torch_geometric_temporal\nfrom torch_geometric_temporal.nn.recurrent import GConvGRU\nfrom torch_geometric_temporal.signal import temporal_signal_split \n\n\nclass RecurrentGCN(torch.nn.Module):\n    def __init__(self, node_features, filters):\n        super(RecurrentGCN, self).__init__()\n        self.recurrent = GConvGRU(node_features, filters, 2)\n        self.linear = torch.nn.Linear(filters, 1)\n\n    def forward(self, x, edge_index, edge_weight):\n        h = self.recurrent(x, edge_index, edge_weight)\n        h = F.relu(h)\n        h = self.linear(h)\n        return h\n\n\nfrom mysolar import SolarDatasetLoader\n\n\nfrom mysolar2 import NormalSolarDatasetLoader\n\n\n# url_ = \"https://raw.githubusercontent.com/pinkocto/noteda/main/posts/SOLAR/data3/stgcn_data2.json\"\n# loader_ = SolarDatasetLoader(url_)\n# dataset_ = loader_.get_dataset(lags=4)\n# # train_dataset_, test_dataset_ = temporal_signal_split(dataset_, train_ratio=0.756)\n\n\nnp.array(dataset_.features).shape,np.array(dataset_.targets).shape\n\n((644, 44, 4), (644, 44))\n\n\n\ndf_.shape\n\n(648, 45)\n\n\n\nurl = \"https://raw.githubusercontent.com/pinkocto/noteda/main/posts/SOLAR/data3/stgcn_data2.json\"\nloader = NormalSolarDatasetLoader(url)\ndataset = loader.get_dataset(lags=4)\n# train_dataset, test_dataset = temporal_signal_split(dataset, train_ratio=0.756)\ntrain_dataset = dataset[:405]  ## 2022-08-01 23:00:00 ~ 2022-08-31 23:00:00\ntest_dataset = dataset[405:]   ## 2022-09-01 23:00:00 ~ 2022-09-10 23:00:00\n\nfeature lag을 고려하여 08-31-23:00 까지 학습용 데이터로 만드려면 404번째 인덱스까지 포함시키면 됨.\n- 학습용 데이터의 마지막 인덱스의 feature의 꼴은 아래와 같다.\n\\[\\begin{bmatrix} f_{08-31-20:00} & f_{08-31-21:00} & f_{08-31-22:00} & f_{08-31-23:00} \\\\\n\\vdots & \\vdots & \\vdots & \\vdots  \\\\\n\\vdots & \\vdots & \\vdots & \\vdots \\\\\n\\vdots & \\vdots & \\vdots & \\vdots\n\\end{bmatrix}\\]"
  },
  {
    "objectID": "posts/SOLAR/2023-04-20-정규화-데이터3-stgcn-ver2.html#train-test-나누기-위한-사전작업-넘어가..",
    "href": "posts/SOLAR/2023-04-20-정규화-데이터3-stgcn-ver2.html#train-test-나누기-위한-사전작업-넘어가..",
    "title": "[SOLAR] STGCN Ver2 (Full: 08/15~09/10 data3) (MSE: 0.1927)",
    "section": "train test 나누기 위한 사전작업 (넘어가..)",
    "text": "train test 나누기 위한 사전작업 (넘어가..)\n\n# np.array(dataset_[:405].features)[-1]\n\n\n# np.array(dataset_.features)[404]\n\n\n# print(np.array(dataset_.targets).shape)\n\n\n# np.array(dataset_.features)[-1]\n\n\n# np.array(train_dataset_.features)[404]\n\n\ndf_ = pd.read_csv('./data3/restructuring_data.csv')\n\n\ndf_.query(\"date == '2022-08-31 23:00:00'\")\n\n\n\n\n\n  \n    \n      \n      date\n      북춘천\n      철원\n      대관령\n      춘천\n      백령도\n      북강릉\n      강릉\n      서울\n      인천\n      ...\n      순창군\n      북창원\n      양산시\n      보성군\n      강진군\n      의령군\n      함양군\n      광양시\n      청송군\n      경주시\n    \n  \n  \n    \n      407\n      2022-08-31 23:00:00\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      ...\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n    \n  \n\n1 rows × 45 columns\n\n\n\n\ndf_.query(\"date == '2022-08-31 20:00:00'\")\n\n\n\n\n\n  \n    \n      \n      date\n      북춘천\n      철원\n      대관령\n      춘천\n      백령도\n      북강릉\n      강릉\n      서울\n      인천\n      ...\n      순창군\n      북창원\n      양산시\n      보성군\n      강진군\n      의령군\n      함양군\n      광양시\n      청송군\n      경주시\n    \n  \n  \n    \n      404\n      2022-08-31 20:00:00\n      0.0\n      0.0\n      0.0\n      0.0\n      0.01\n      0.0\n      0.0\n      0.0\n      0.0\n      ...\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n    \n  \n\n1 rows × 45 columns\n\n\n\n\ndf_.iloc[404]\n\ndate    2022-08-31 20:00:00\n북춘천                     0.0\n철원                      0.0\n대관령                     0.0\n춘천                      0.0\n백령도                    0.01\n북강릉                     0.0\n강릉                      0.0\n서울                      0.0\n인천                      0.0\n원주                      0.0\n울릉도                     0.0\n수원                      0.0\n서산                      0.0\n청주                      0.0\n대전                     0.01\n추풍령                     0.0\n안동                      0.0\n포항                      0.0\n대구                      0.0\n전주                      0.0\n창원                      0.0\n광주                     0.05\n부산                      0.0\n목포                      0.0\n여수                      0.0\n흑산도                    0.02\n고창                     0.01\n홍성                      0.0\n제주                      0.0\n고산                      0.0\n진주                      0.0\n고창군                    0.01\n영광군                     0.0\n김해시                     0.0\n순창군                     0.0\n북창원                     0.0\n양산시                     0.0\n보성군                     0.0\n강진군                     0.0\n의령군                     0.0\n함양군                     0.0\n광양시                     0.0\n청송군                     0.0\n경주시                     0.0\nName: 404, dtype: object\n\n\n\ndf_.shape\n\n(648, 45)"
  },
  {
    "objectID": "posts/SOLAR/2023-04-20-정규화-데이터3-stgcn-ver2.html#learn",
    "href": "posts/SOLAR/2023-04-20-정규화-데이터3-stgcn-ver2.html#learn",
    "title": "[SOLAR] STGCN Ver2 (Full: 08/15~09/10 data3) (MSE: 0.1927)",
    "section": "Learn",
    "text": "Learn\n\nmodel = RecurrentGCN(node_features=4, filters=32)\noptimizer = torch.optim.Adam(model.parameters(), lr=0.01)\nmodel.train()\n\nRecurrentGCN(\n  (recurrent): GConvGRU(\n    (conv_x_z): ChebConv(4, 32, K=2, normalization=sym)\n    (conv_h_z): ChebConv(32, 32, K=2, normalization=sym)\n    (conv_x_r): ChebConv(4, 32, K=2, normalization=sym)\n    (conv_h_r): ChebConv(32, 32, K=2, normalization=sym)\n    (conv_x_h): ChebConv(4, 32, K=2, normalization=sym)\n    (conv_h_h): ChebConv(32, 32, K=2, normalization=sym)\n  )\n  (linear): Linear(in_features=32, out_features=1, bias=True)\n)\n\n\n\nstart = time.time()\nfor epoch in tqdm(range(50)):\n    for t, snapshot in enumerate(train_dataset):\n        yt_hat = model(snapshot.x, snapshot.edge_index, snapshot.edge_attr)\n        cost = torch.mean((yt_hat-snapshot.y)**2)\n        cost.backward()\n        optimizer.step()\n        optimizer.zero_grad()\nend = time.time()\nprint(f\"{end-start:.5f} sec\")\n\n100%|██████████| 50/50 [01:07<00:00,  1.35s/it]\n\n\n67.46643 sec\n\n\n\n\n\n\nprint(67.46643/60, '분')\n\n1.1244405 분\n\n\n\nimport pickle \nwith open('./model3/normal_stgcn2_lag4_new.pickle','wb') as fw:\n    pickle.dump(model, fw)\n\n\nimport pickle \nwith open('./model3/normal_stgcn2_lag4_new.pickle', 'rb') as f: \n    model = pickle.load(f)\n\n\nmodel\n\nRecurrentGCN(\n  (recurrent): GConvGRU(\n    (conv_x_z): ChebConv(4, 32, K=2, normalization=sym)\n    (conv_h_z): ChebConv(32, 32, K=2, normalization=sym)\n    (conv_x_r): ChebConv(4, 32, K=2, normalization=sym)\n    (conv_h_r): ChebConv(32, 32, K=2, normalization=sym)\n    (conv_x_h): ChebConv(4, 32, K=2, normalization=sym)\n    (conv_h_h): ChebConv(32, 32, K=2, normalization=sym)\n  )\n  (linear): Linear(in_features=32, out_features=1, bias=True)\n)"
  },
  {
    "objectID": "posts/SOLAR/2023-04-20-정규화-데이터3-stgcn-ver2.html#모델평가",
    "href": "posts/SOLAR/2023-04-20-정규화-데이터3-stgcn-ver2.html#모델평가",
    "title": "[SOLAR] STGCN Ver2 (Full: 08/15~09/10 data3) (MSE: 0.1927)",
    "section": "모델평가",
    "text": "모델평가\n- train\n\nSTGCN Ver1 \\(\\to\\) MSE: 0.2102 (2년간)\n\n—> 기간재설정\n\nSTGCN Ver2 (70) \\(\\to\\) MSE: 0.2181 (데이터 채워넣기 전)\nSTGCN Ver2 (90) \\(\\to\\) MSE : 0.2639 (데이터 채워넣기 전)\n\n—-> 데이터추가 (시간대)\n\nSTGCN Ver2 (70) \\(\\to\\) MSE : 0.2161 (데이터 추가, 정규화 전)\n\n\nmodel.eval()\ncost = 0\nfor time, snapshot in enumerate(train_dataset):\n    y_hat = model(snapshot.x, snapshot.edge_index, snapshot.edge_attr)\n    cost = cost + torch.mean((y_hat-snapshot.y)**2)\ncost = cost / (time+1)\ncost = cost.item()\nprint(\"MSE: {:.4f}\".format(cost))\n\nMSE: 0.2490\n\n\n- test\n\nSTGCN Ver1 \\(\\to\\) MSE : 0.1899 (2년간)\n\n—> 기간재설정\n\nSTGCN Ver2 (70) \\(\\to\\) MSE : 0.2019 (데이터 채워넣기 전)\nSTGCN Ver2 (90) \\(\\to\\) MSE : 0.1635 (데이터 채워넣기 전)\n\n—-> 데이터추가 (시간대) - STGCN Ver2 (70) \\(\\to\\) MSE : 0.2000 (데이터 추가, 정규화 전)\n\nmodel.eval()\ncost = 0\nfor time, snapshot in enumerate(test_dataset):\n    y_hat = model(snapshot.x, snapshot.edge_index, snapshot.edge_attr)\n    cost = cost + torch.mean((y_hat-snapshot.y)**2)\ncost = cost / (time+1)\ncost = cost.item()\nprint(\"MSE: {:.4f}\".format(cost))\n\nMSE: 0.1927"
  },
  {
    "objectID": "posts/SOLAR/2023-04-20-정규화-데이터3-stgcn-ver2.html#visualization",
    "href": "posts/SOLAR/2023-04-20-정규화-데이터3-stgcn-ver2.html#visualization",
    "title": "[SOLAR] STGCN Ver2 (Full: 08/15~09/10 data3) (MSE: 0.1927)",
    "section": "Visualization",
    "text": "Visualization\n\nurl = 'https://raw.githubusercontent.com/pinkocto/noteda/main/posts/SOLAR/data3/stgcn_data2.json'\n\n\ndata_dict = json.loads(urllib.request.urlopen(url).read())\nV = list(data_dict['node_ids'].keys())\nf = np.array(data_dict[\"FX\"])\n\n\nyhat_train = torch.stack([model(snapshot.x,snapshot.edge_index, snapshot.edge_attr) for snapshot in train_dataset]).detach().numpy()\nyhat_test = torch.stack([model(snapshot.x,snapshot.edge_index, snapshot.edge_attr) for snapshot in test_dataset]).detach().numpy()\n\n\nyhat_test.shape, yhat_train.shape\n\n((239, 44, 1), (405, 44, 1))\n\n\n\nimport matplotlib.pyplot as plt\nplt.rcParams['font.family'] = 'NanumGothic'\n\n\ntrain\n\nfig,ax = plt.subplots(44,1,figsize=(10,50))\nlag= 0 \nT = 100 \nfor k in range(44):\n    ax[k].plot(np.array(train_dataset.targets)[lag:(lag+T),k],'--',alpha=0.5,label='observed')\n    ax[k].set_title('node: {}'.format(V[k]))\n    ax[k].plot(yhat_train[:T,k],label='predicted (tr)', color='orange')\n#    ax[k].plot(range(yhat_train.shape[0],yhat_train.shape[0]+yhat_test.shape[0]),yhat_test[:,k],label='predicted (test)')\n    ax[k].legend()\nfig.tight_layout()\n\n# plt.savefig('stgcn-ver2-lag4-vis.png')\n\n\n\n\n\n\ntest\n\nfig,ax = plt.subplots(44,1,figsize=(10,50))\nlag= 0\nT = 100 \nfor k in range(44):\n    ax[k].plot(np.array(test_dataset.targets)[lag:(lag+T),k],'--',alpha=0.5,label='observed')\n    ax[k].set_title('node: {}'.format(V[k]))\n    ax[k].plot(yhat_test[:T,k],label='predicted (test)', color='red')\n#    ax[k].plot(range(yhat_train.shape[0],yhat_train.shape[0]+yhat_test.shape[0]),yhat_test[:,k],label='predicted (test)')\n    ax[k].legend()\nfig.tight_layout()\n\n# plt.savefig('stgcn-ver2-lag4-vis.png')\n\nUserWarning: Glyph 8722 (\\N{MINUS SIGN}) missing from current font.\n  fig.tight_layout()\n/home/jy/anaconda3/envs/torch/lib/python3.8/site-packages/IPython/core/events.py:89: UserWarning: Glyph 8722 (\\N{MINUS SIGN}) missing from current font.\n  func(*args, **kwargs)\n/home/jy/anaconda3/envs/torch/lib/python3.8/site-packages/IPython/core/pylabtools.py:152: UserWarning: Glyph 8722 (\\N{MINUS SIGN}) missing from current font.\n  fig.canvas.print_figure(bytes_io, **kw)"
  },
  {
    "objectID": "posts/SOLAR/2023-04-27-s-stgcn-ver2-50에폭-64필터.html",
    "href": "posts/SOLAR/2023-04-27-s-stgcn-ver2-50에폭-64필터.html",
    "title": "[SOLAR] STGCN Ver2 (data2, -N +S) 30회 50 epoch 64filter",
    "section": "",
    "text": "https://github.com/miruetoto/yechan3/tree/main/posts/3_Researches/ITSTGCN/itstgcn\nhttps://miruetoto.github.io/yechan3/posts/3_Researches/ITSTGCN/2023-03-18-SimulationPlanner-Tutorial.html#plnr_gnar_block\n\n\n\n\n\ntrain 2022-06-01 00:00:00 ~ 2022-08-14 17:00:00\ntest 2022-08-14 18:00:00 ~ 2022-09-15 23:00:00\n\n\n\n\n\nimport eptstgcn\nimport torch\nimport eptstgcn.planner\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\n\n\n\n\nurl = \"https://raw.githubusercontent.com/pinkocto/noteda/main/posts/SOLAR/data2/stgcn_data2.json\"\nloader = eptstgcn.DatasetLoader(url)\ndataset = loader.get_dataset(lags=4)\n\n\ntrain_dataset, test_dataset = eptstgcn.utils.temporal_signal_split(dataset, train_ratio = 0.7)\n\n\n\n\n\nref: https://seoyeonc.github.io/blog/posts/GCN/2023-03-17-ITSTGCN-Tutorial.html\n\n\nlrnr = eptstgcn.StgcnLearner(train_dataset, dataset_name = 'data2(2022/06/01 ~ 2022/09/15)')\n\n\nlrnr.learn(filters=64, epoch=50)\n\n50/50\n\n\n\nimport pickle \nwith open('./lrnr_model/stgcn_ver2_data2_cancel_normal_64fil_50epoch.pickle','wb') as fw:\n    pickle.dump(lrnr, fw)\n\n\nimport pickle \nwith open('./lrnr_model/stgcn_ver2_data2_cancel_normal_64fil_50epoch.pickle', 'rb') as f: \n    model = pickle.load(f)\n\n\n\n\n\nevtor = eptstgcn.Evaluator(model, train_dataset, test_dataset)\n\n\n# fig = evtor.plot('--', label='observed data')\n# fig.tight_layout()\n# fig\n\n\n\n\nevtor.tr_plot(t=150, label='observed data')\n\n\n\n\n\n\n\n\nevtor.test_plot(t=150, label='observed data')\n\n\n\n\n\n\n\n\n\nplans_stgcn = {\n    'max_iteration': 30, \n    'method': ['EPT-STGCN'], \n    'lags': [4], \n    'nof_filters': [64], \n    'epoch': [50]\n}\n\n\nplnr = eptstgcn.planner.PLNR_STGCN(plans_stgcn,loader,dataset_name='data2')\n\n\nplnr.simulate()\n\n1/30 is done\n2/30 is done\n3/30 is done\n4/30 is done\n5/30 is done\n6/30 is done\n7/30 is done\n8/30 is done\n9/30 is done\n10/30 is done\n11/30 is done\n12/30 is done\n13/30 is done\n14/30 is done\n15/30 is done\n16/30 is done\n17/30 is done\n18/30 is done\n19/30 is done\n20/30 is done\n21/30 is done\n22/30 is done\n23/30 is done\n24/30 is done\n25/30 is done\n26/30 is done\n27/30 is done\n28/30 is done\n29/30 is done\n30/30 is done\nAll results are stored in ./simulation_results/2023-04-28_00-35-16.csv\n\n\n\nimport pickle\nwith open('./simul_model/stgcn_ver2_data2_cancel_normal_64fil_50epoch.pickle', 'wb') as fw:\n    pickle.dump(plnr, fw)\n\n\nwith open('./simul_model/stgcn_ver2_data2_cancel_normal_64fil_50epoch.pickle', 'rb') as f:\n    simul_model = pickle.load(f)\n\n\ndf_simul_no = simul_model.simulation_results\ndf_simul_no\n\n\n\n\n\n  \n    \n      \n      dataset\n      method\n      lags\n      nof_filters\n      epoch\n      mse(train)\n      mse(test)\n      calculation_time\n    \n  \n  \n    \n      0\n      data2\n      EPT-STGCN\n      4\n      64\n      50\n      0.201556\n      0.185774\n      1351.041261\n    \n    \n      1\n      data2\n      EPT-STGCN\n      4\n      64\n      50\n      0.191708\n      0.17401\n      1407.217314\n    \n    \n      2\n      data2\n      EPT-STGCN\n      4\n      64\n      50\n      0.191964\n      0.172454\n      1359.203281\n    \n    \n      3\n      data2\n      EPT-STGCN\n      4\n      64\n      50\n      0.191701\n      0.172115\n      1191.765499\n    \n    \n      4\n      data2\n      EPT-STGCN\n      4\n      64\n      50\n      0.192213\n      0.17583\n      1108.716425\n    \n    \n      5\n      data2\n      EPT-STGCN\n      4\n      64\n      50\n      0.191111\n      0.172632\n      1009.770985\n    \n    \n      6\n      data2\n      EPT-STGCN\n      4\n      64\n      50\n      0.19632\n      0.1816\n      1316.371055\n    \n    \n      7\n      data2\n      EPT-STGCN\n      4\n      64\n      50\n      0.189178\n      0.168785\n      1172.973039\n    \n    \n      8\n      data2\n      EPT-STGCN\n      4\n      64\n      50\n      0.199907\n      0.184294\n      1086.214674\n    \n    \n      9\n      data2\n      EPT-STGCN\n      4\n      64\n      50\n      0.202387\n      0.188535\n      1136.448364\n    \n    \n      10\n      data2\n      EPT-STGCN\n      4\n      64\n      50\n      0.194585\n      0.177979\n      1045.705328\n    \n    \n      11\n      data2\n      EPT-STGCN\n      4\n      64\n      50\n      0.188735\n      0.171109\n      1143.988995\n    \n    \n      12\n      data2\n      EPT-STGCN\n      4\n      64\n      50\n      0.193833\n      0.177464\n      805.054379\n    \n    \n      13\n      data2\n      EPT-STGCN\n      4\n      64\n      50\n      0.18973\n      0.172049\n      419.422963\n    \n    \n      14\n      data2\n      EPT-STGCN\n      4\n      64\n      50\n      0.190647\n      0.173043\n      420.268684\n    \n    \n      15\n      data2\n      EPT-STGCN\n      4\n      64\n      50\n      0.192465\n      0.176104\n      446.344912\n    \n    \n      16\n      data2\n      EPT-STGCN\n      4\n      64\n      50\n      0.210626\n      0.193371\n      524.717341\n    \n    \n      17\n      data2\n      EPT-STGCN\n      4\n      64\n      50\n      0.191269\n      0.172695\n      557.187191\n    \n    \n      18\n      data2\n      EPT-STGCN\n      4\n      64\n      50\n      0.2138\n      0.199079\n      558.634782\n    \n    \n      19\n      data2\n      EPT-STGCN\n      4\n      64\n      50\n      0.187822\n      0.169838\n      558.465742\n    \n    \n      20\n      data2\n      EPT-STGCN\n      4\n      64\n      50\n      0.19423\n      0.178299\n      557.87419\n    \n    \n      21\n      data2\n      EPT-STGCN\n      4\n      64\n      50\n      0.188992\n      0.17245\n      561.105105\n    \n    \n      22\n      data2\n      EPT-STGCN\n      4\n      64\n      50\n      0.191576\n      0.17421\n      556.668826\n    \n    \n      23\n      data2\n      EPT-STGCN\n      4\n      64\n      50\n      0.187219\n      0.168906\n      451.957108\n    \n    \n      24\n      data2\n      EPT-STGCN\n      4\n      64\n      50\n      0.188976\n      0.166926\n      470.617715\n    \n    \n      25\n      data2\n      EPT-STGCN\n      4\n      64\n      50\n      0.197003\n      0.18175\n      419.809141\n    \n    \n      26\n      data2\n      EPT-STGCN\n      4\n      64\n      50\n      0.189821\n      0.17256\n      420.457042\n    \n    \n      27\n      data2\n      EPT-STGCN\n      4\n      64\n      50\n      0.191726\n      0.172867\n      420.647158\n    \n    \n      28\n      data2\n      EPT-STGCN\n      4\n      64\n      50\n      0.193178\n      0.177383\n      420.392183\n    \n    \n      29\n      data2\n      EPT-STGCN\n      4\n      64\n      50\n      0.192243\n      0.174886\n      322.669026\n    \n  \n\n\n\n\n\ndf_simul_no['mse(test)'].mean()\n\n0.17663319557905197\n\n\n\nprint('stgcn ver2 64filter 50에폭 끝')\n\nstgcn ver2 64filter 50에폭 끝\n\n\n\nimport matplotlib.pyplot as plt\nplt.boxplot(df_simul_no['mse(test)'])\nplt.show()"
  },
  {
    "objectID": "posts/SOLAR/2023-04-22-정규화-스케일링-stgcn-ver1.html",
    "href": "posts/SOLAR/2023-04-22-정규화-스케일링-stgcn-ver1.html",
    "title": "[SOLAR] STGCN Ver1 (data2, +N +S) 30회",
    "section": "",
    "text": "https://github.com/miruetoto/yechan3/tree/main/posts/3_Researches/ITSTGCN/itstgcn\nhttps://miruetoto.github.io/yechan3/posts/3_Researches/ITSTGCN/2023-03-18-SimulationPlanner-Tutorial.html#plnr_gnar_block\n\n\n\n\n\ntrain 2022-06-01 00:00:00 ~ 2022-08-14 17:00:00\ntest 2022-08-14 18:00:00 ~ 2022-09-15 23:00:00\n\n\n\n\n\nimport eptstgcn\nimport torch\nimport eptstgcn.planner\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\n\n\n\n\nurl = \"https://raw.githubusercontent.com/pinkocto/noteda/main/posts/SOLAR/data2/stgcn_data1.json\"\nloader = eptstgcn.DatasetLoader(url)\ndataset = loader.get_dataset(lags=4)\n\n\ntrain_dataset, test_dataset = eptstgcn.utils.temporal_signal_split(dataset, train_ratio = 0.7)\n\n\n\n\n\nlrnr = eptstgcn.StgcnLearner(train_dataset, dataset_name = 'data2(2022/06/01 ~ 2022/09/15)')\n\n\nlrnr.learn(filters=32, epoch=50)\n\n50/50\n\n\n\n# import pickle \n# with open('./lrnr_model/stgcn_ver1_data2.pickle','wb') as fw:\n#     pickle.dump(lrnr, fw)\n\n\nimport pickle \nwith open('./lrnr_model/stgcn_ver1_data2.pickle', 'rb') as f: \n    lrnr_model = pickle.load(f)\n\n\n\n\n\n\n\nevtor = eptstgcn.Evaluator(lrnr_model, train_dataset, test_dataset)\n\n\nevtor.tr_plot(t=150, label='observed data')\n\n\n\n\n\n\n\n\nevtor.test_plot(t=150, label='observed data')\n\n\n\n\n\n\n\n\n\nplans_stgcn = {\n    'max_iteration': 30, \n    'method': ['STGCN'], \n    'lags': [4], \n    'nof_filters': [32], \n    'epoch': [50]\n}\n\n\n# plnr = eptstgcn.planner.PLNR_STGCN(plans_stgcn,loader,dataset_name='data2')\n\n\nplnr.simulate()\n\n1/30 is done\n2/30 is done\n3/30 is done\n4/30 is done\n5/30 is done\n6/30 is done\n7/30 is done\n8/30 is done\n9/30 is done\n10/30 is done\n11/30 is done\n12/30 is done\n13/30 is done\n14/30 is done\n15/30 is done\n16/30 is done\n17/30 is done\n18/30 is done\n19/30 is done\n20/30 is done\n21/30 is done\n22/30 is done\n23/30 is done\n24/30 is done\n25/30 is done\n26/30 is done\n27/30 is done\n28/30 is done\n29/30 is done\n30/30 is done\nAll results are stored in ./simulation_results/2023-04-22_19-37-52.csv\n\n\n\n# import pickle\n# with open('./simul_model/stgcn_ver1_data2_수정본.pickle','wb') as fw:\n#          pickle.dump(plnr, fw)\n\n\n# import pickle\n# with open('./simul_model/stgcn_ver1_data2.pickle','wb') as fw:\n#          pickle.dump(plnr, fw)\n\n\n# import pickle\nwith open('./simul_model/stgcn_ver1_data2.pickle', 'rb') as f:\n          simul_model = pickle.load(f)\n\n\ndf_simul = simul_model.simulation_results\ndf_simul\n\n\n\n\n\n  \n    \n      \n      dataset\n      method\n      lags\n      nof_filters\n      epoch\n      mse\n      calculation_time\n    \n  \n  \n    \n      0\n      data2\n      STGCN\n      4\n      32\n      50\n      0.183838\n      297.827193\n    \n    \n      1\n      data2\n      STGCN\n      4\n      32\n      50\n      0.197644\n      297.39739\n    \n    \n      2\n      data2\n      STGCN\n      4\n      32\n      50\n      0.174572\n      344.664682\n    \n    \n      3\n      data2\n      STGCN\n      4\n      32\n      50\n      0.175856\n      412.458746\n    \n    \n      4\n      data2\n      STGCN\n      4\n      32\n      50\n      0.183391\n      403.818523\n    \n    \n      5\n      data2\n      STGCN\n      4\n      32\n      50\n      0.182653\n      412.442706\n    \n    \n      6\n      data2\n      STGCN\n      4\n      32\n      50\n      0.173357\n      364.271884\n    \n    \n      7\n      data2\n      STGCN\n      4\n      32\n      50\n      0.180988\n      299.365499\n    \n    \n      8\n      data2\n      STGCN\n      4\n      32\n      50\n      0.194996\n      300.316778\n    \n    \n      9\n      data2\n      STGCN\n      4\n      32\n      50\n      0.192895\n      300.115653\n    \n    \n      10\n      data2\n      STGCN\n      4\n      32\n      50\n      0.171724\n      299.164049\n    \n    \n      11\n      data2\n      STGCN\n      4\n      32\n      50\n      0.178121\n      299.819023\n    \n    \n      12\n      data2\n      STGCN\n      4\n      32\n      50\n      0.174512\n      300.490552\n    \n    \n      13\n      data2\n      STGCN\n      4\n      32\n      50\n      0.175112\n      299.584245\n    \n    \n      14\n      data2\n      STGCN\n      4\n      32\n      50\n      0.180143\n      300.218299\n    \n    \n      15\n      data2\n      STGCN\n      4\n      32\n      50\n      0.180791\n      300.689956\n    \n    \n      16\n      data2\n      STGCN\n      4\n      32\n      50\n      0.166162\n      301.706746\n    \n    \n      17\n      data2\n      STGCN\n      4\n      32\n      50\n      0.182529\n      299.56468\n    \n    \n      18\n      data2\n      STGCN\n      4\n      32\n      50\n      0.176125\n      300.486649\n    \n    \n      19\n      data2\n      STGCN\n      4\n      32\n      50\n      0.177237\n      299.198548\n    \n    \n      20\n      data2\n      STGCN\n      4\n      32\n      50\n      0.181495\n      299.831336\n    \n    \n      21\n      data2\n      STGCN\n      4\n      32\n      50\n      0.19002\n      301.643143\n    \n    \n      22\n      data2\n      STGCN\n      4\n      32\n      50\n      0.179018\n      299.06001\n    \n    \n      23\n      data2\n      STGCN\n      4\n      32\n      50\n      0.176116\n      299.344622\n    \n    \n      24\n      data2\n      STGCN\n      4\n      32\n      50\n      0.199659\n      299.757764\n    \n    \n      25\n      data2\n      STGCN\n      4\n      32\n      50\n      0.177913\n      299.740376\n    \n    \n      26\n      data2\n      STGCN\n      4\n      32\n      50\n      0.191579\n      299.844217\n    \n    \n      27\n      data2\n      STGCN\n      4\n      32\n      50\n      0.181708\n      412.672964\n    \n    \n      28\n      data2\n      STGCN\n      4\n      32\n      50\n      0.174949\n      428.429988\n    \n    \n      29\n      data2\n      STGCN\n      4\n      32\n      50\n      0.189599\n      298.493461\n    \n  \n\n\n\n\n\nimport matplotlib.pyplot as plt\nplt.boxplot(df_simul['mse'])\nplt.show()"
  },
  {
    "objectID": "posts/SOLAR/2023-04-12-stgcn-ver1-train90.html",
    "href": "posts/SOLAR/2023-04-12-stgcn-ver1-train90.html",
    "title": "[SOLAR] STGCN Ver1 90% (MSE: 0.1206)",
    "section": "",
    "text": "import pandas as pd\nimport numpy as np\nimport json\nimport urllib\nimport time\n\n\n# 일반적인 모듈 \nimport numpy as np\nimport matplotlib.pyplot as plt \nimport networkx as nx \nfrom tqdm import tqdm \n\n# 파이토치 관련 \nimport torch\nimport torch.nn.functional as F\n\n# PyG 관련 \nfrom torch_geometric.data import Data ## Data: 그래프자료형을 만드는 클래스\n\n# STGCN 관련 \nimport torch_geometric_temporal\nfrom torch_geometric_temporal.nn.recurrent import GConvGRU\nfrom torch_geometric_temporal.signal import temporal_signal_split \n\n\nclass RecurrentGCN(torch.nn.Module):\n    def __init__(self, node_features, filters):\n        super(RecurrentGCN, self).__init__()\n        self.recurrent = GConvGRU(node_features, filters, 2)\n        self.linear = torch.nn.Linear(filters, 1)\n\n    def forward(self, x, edge_index, edge_weight):\n        h = self.recurrent(x, edge_index, edge_weight)\n        h = F.relu(h)\n        h = self.linear(h)\n        return h\n\n\nfrom mysolar import SolarDatasetLoader\n\n\nloader = SolarDatasetLoader()\ndataset = loader.get_dataset(lags=4)\ntrain_dataset, test_dataset = temporal_signal_split(dataset, train_ratio=0.9)\n\n\nprint(np.array(train_dataset.targets).shape)\nprint(np.array(test_dataset.targets).shape)\n\n(2115, 44)\n(235, 44)\n\n\n\ntrain: 2022-06-01 00:00:00 ~ 2022-09-05 03:00:00\ntest: 2022-09-05 04:00:00 ~ 2022-09-15 21:00:00"
  },
  {
    "objectID": "posts/SOLAR/2023-04-12-stgcn-ver1-train90.html#learn",
    "href": "posts/SOLAR/2023-04-12-stgcn-ver1-train90.html#learn",
    "title": "[SOLAR] STGCN Ver1 90% (MSE: 0.1206)",
    "section": "Learn",
    "text": "Learn\n\nmodel = RecurrentGCN(node_features=4, filters=32)\noptimizer = torch.optim.Adam(model.parameters(), lr=0.01)\nmodel.train()\n\nRecurrentGCN(\n  (recurrent): GConvGRU(\n    (conv_x_z): ChebConv(4, 32, K=2, normalization=sym)\n    (conv_h_z): ChebConv(32, 32, K=2, normalization=sym)\n    (conv_x_r): ChebConv(4, 32, K=2, normalization=sym)\n    (conv_h_r): ChebConv(32, 32, K=2, normalization=sym)\n    (conv_x_h): ChebConv(4, 32, K=2, normalization=sym)\n    (conv_h_h): ChebConv(32, 32, K=2, normalization=sym)\n  )\n  (linear): Linear(in_features=32, out_features=1, bias=True)\n)\n\n\n\nstart = time.time()\nfor epoch in tqdm(range(50)):\n    for t, snapshot in enumerate(train_dataset):\n        yt_hat = model(snapshot.x, snapshot.edge_index, snapshot.edge_attr)\n        cost = torch.mean((yt_hat-snapshot.y)**2)\n        cost.backward()\n        optimizer.step()\n        optimizer.zero_grad()\nend = time.time()\nprint(f\"{end-start:.5f} sec\")\n\n100%|██████████| 50/50 [05:50<00:00,  7.01s/it]\n\n\n350.50771 sec\n\n\n\n\n\n\nprint(350.50771/60, '분')\n\n5.8417951666666665 분\n\n\n\n# import pickle \n# with open('./model/stgcn1_lag4_90_new.pickle','wb') as fw:\n#     pickle.dump(model, fw)\n\n\nimport pickle \nwith open('./model/stgcn1_lag4_90_new.pickle', 'rb') as f: \n    model = pickle.load(f)\n\n\nmodel\n\nRecurrentGCN(\n  (recurrent): GConvGRU(\n    (conv_x_z): ChebConv(4, 32, K=2, normalization=sym)\n    (conv_h_z): ChebConv(32, 32, K=2, normalization=sym)\n    (conv_x_r): ChebConv(4, 32, K=2, normalization=sym)\n    (conv_h_r): ChebConv(32, 32, K=2, normalization=sym)\n    (conv_x_h): ChebConv(4, 32, K=2, normalization=sym)\n    (conv_h_h): ChebConv(32, 32, K=2, normalization=sym)\n  )\n  (linear): Linear(in_features=32, out_features=1, bias=True)\n)"
  },
  {
    "objectID": "posts/SOLAR/2023-04-12-stgcn-ver1-train90.html#모델평가",
    "href": "posts/SOLAR/2023-04-12-stgcn-ver1-train90.html#모델평가",
    "title": "[SOLAR] STGCN Ver1 90% (MSE: 0.1206)",
    "section": "모델평가",
    "text": "모델평가\n- train\n\nSTGCN Ver1 (70%) \\(\\to\\) MSE 0.2102\n\n\nmodel.eval()\ncost = 0\nfor time, snapshot in enumerate(train_dataset):\n    y_hat = model(snapshot.x, snapshot.edge_index, snapshot.edge_attr)\n    cost = cost + torch.mean((y_hat-snapshot.y)**2)\ncost = cost / (time+1)\ncost = cost.item()\nprint(\"MSE: {:.4f}\".format(cost))\n\nMSE: 0.2062\n\n\n- test\n\nSTGCN Ver1 (70%) \\(\\to\\) MSE 0.1899\n\n\nmodel.eval()\ncost = 0\nfor time, snapshot in enumerate(test_dataset):\n    y_hat = model(snapshot.x, snapshot.edge_index, snapshot.edge_attr)\n    cost = cost + torch.mean((y_hat-snapshot.y)**2)\ncost = cost / (time+1)\ncost = cost.item()\nprint(\"MSE: {:.4f}\".format(cost))\n\nMSE: 0.1206"
  },
  {
    "objectID": "posts/SOLAR/2023-04-15-stgcn-ver1-수정본.html",
    "href": "posts/SOLAR/2023-04-15-stgcn-ver1-수정본.html",
    "title": "[SOLAR] STGCN Ver1 수정본 (MSE: 0.1674)",
    "section": "",
    "text": "import pandas as pd\nimport numpy as np\nimport json\nimport urllib\nimport time\n\n\n# 일반적인 모듈 \nimport numpy as np\nimport matplotlib.pyplot as plt \nimport networkx as nx \nfrom tqdm import tqdm \n\n# 파이토치 관련 \nimport torch\nimport torch.nn.functional as F\n\n# PyG 관련 \nfrom torch_geometric.data import Data ## Data: 그래프자료형을 만드는 클래스\n\n# STGCN 관련 \nimport torch_geometric_temporal\nfrom torch_geometric_temporal.nn.recurrent import GConvGRU\nfrom torch_geometric_temporal.signal import temporal_signal_split \n\n\nclass RecurrentGCN(torch.nn.Module):\n    def __init__(self, node_features, filters):\n        super(RecurrentGCN, self).__init__()\n        self.recurrent = GConvGRU(node_features, filters, 2)\n        self.linear = torch.nn.Linear(filters, 1)\n\n    def forward(self, x, edge_index, edge_weight):\n        h = self.recurrent(x, edge_index, edge_weight)\n        h = F.relu(h)\n        h = self.linear(h)\n        return h\n\n\nfrom mysolar import SolarDatasetLoader\n\n\nloader = SolarDatasetLoader()\ndataset = loader.get_dataset(lags=4)\ntrain_dataset, test_dataset = temporal_signal_split(dataset, train_ratio=0.7)\n\n\nprint(np.array(train_dataset.targets).shape)\nprint(np.array(test_dataset.targets).shape)\n\n(1794, 44)\n(770, 44)\n\n\n\ndataset.\n\n2564\n\n\n\ntrain: 2022-06-01 00:00:00 ~ 2022-08-14 17:00:00\ntest: 2022-08-14 18:00:00 ~ 2022-09-15 21:00:00\n\n날짜 수정필요"
  },
  {
    "objectID": "posts/SOLAR/2023-04-15-stgcn-ver1-수정본.html#learn",
    "href": "posts/SOLAR/2023-04-15-stgcn-ver1-수정본.html#learn",
    "title": "[SOLAR] STGCN Ver1 수정본 (MSE: 0.1674)",
    "section": "Learn",
    "text": "Learn\n\nmodel = RecurrentGCN(node_features=4, filters=32)\noptimizer = torch.optim.Adam(model.parameters(), lr=0.01)\nmodel.train()\n\nfor epoch in tqdm(range(50)):\n    for t, snapshot in enumerate(train_dataset):\n        yt_hat = model(snapshot.x, snapshot.edge_index, snapshot.edge_attr)\n        cost = torch.mean((yt_hat-snapshot.y)**2)\n        cost.backward()\n        optimizer.step()\n        optimizer.zero_grad()\n\n100%|██████████| 50/50 [06:16<00:00,  7.53s/it]\n\n\n\nprint(271.29201/60, '분')\n\n4.5215335 분\n\n\n\nimport pickle \nwith open('./model2/stgcn1_lag4_new.pickle','wb') as fw:\n    pickle.dump(model, fw)\n\n\nimport pickle \nwith open('./model2/stgcn1_lag4_new.pickle', 'rb') as f: \n    model = pickle.load(f)\n\n\nmodel\n\nRecurrentGCN(\n  (recurrent): GConvGRU(\n    (conv_x_z): ChebConv(4, 32, K=2, normalization=sym)\n    (conv_h_z): ChebConv(32, 32, K=2, normalization=sym)\n    (conv_x_r): ChebConv(4, 32, K=2, normalization=sym)\n    (conv_h_r): ChebConv(32, 32, K=2, normalization=sym)\n    (conv_x_h): ChebConv(4, 32, K=2, normalization=sym)\n    (conv_h_h): ChebConv(32, 32, K=2, normalization=sym)\n  )\n  (linear): Linear(in_features=32, out_features=1, bias=True)\n)"
  },
  {
    "objectID": "posts/SOLAR/2023-04-15-stgcn-ver1-수정본.html#모델평가",
    "href": "posts/SOLAR/2023-04-15-stgcn-ver1-수정본.html#모델평가",
    "title": "[SOLAR] STGCN Ver1 수정본 (MSE: 0.1674)",
    "section": "모델평가",
    "text": "모델평가\n- train\n\nMSE: 0.2102\n\n\nmodel.eval()\ncost = 0\nfor time, snapshot in enumerate(train_dataset):\n    y_hat = model(snapshot.x, snapshot.edge_index, snapshot.edge_attr)\n    cost = cost + torch.mean((y_hat-snapshot.y)**2)\ncost = cost / (time+1)\ncost = cost.item()\nprint(\"MSE: {:.4f}\".format(cost))\n\nMSE: 0.1839\n\n\n- test\n\nMSE: 0.1899\n\n\nmodel.eval()\ncost = 0\nfor time, snapshot in enumerate(test_dataset):\n    y_hat = model(snapshot.x, snapshot.edge_index, snapshot.edge_attr)\n    cost = cost + torch.mean((y_hat-snapshot.y)**2)\ncost = cost / (time+1)\ncost = cost.item()\nprint(\"MSE: {:.4f}\".format(cost))\n\nMSE: 0.1674"
  },
  {
    "objectID": "posts/SOLAR/2023-04-15-stgcn-ver1-수정본.html#visualization",
    "href": "posts/SOLAR/2023-04-15-stgcn-ver1-수정본.html#visualization",
    "title": "[SOLAR] STGCN Ver1 수정본 (MSE: 0.1674)",
    "section": "Visualization",
    "text": "Visualization\n\nurl = 'https://raw.githubusercontent.com/pinkocto/noteda/main/posts/SOLAR/data2/stgcn_data1.json'\n\n\ndata_dict = json.loads(urllib.request.urlopen(url).read())\nV = list(data_dict['node_ids'].keys())\nf = np.array(data_dict[\"FX\"])\n\n\nyhat_train = torch.stack([model(snapshot.x,snapshot.edge_index, snapshot.edge_attr) for snapshot in train_dataset]).detach().numpy()\nyhat_test = torch.stack([model(snapshot.x,snapshot.edge_index, snapshot.edge_attr) for snapshot in test_dataset]).detach().numpy()\n\n\nf.shape\n\n(2354, 44)\n\n\n\n705 + 1645\n\n2350\n\n\n\nyhat_test.shape, yhat_train.shape\n\n((705, 44, 1), (1645, 44, 1))\n\n\n\nimport matplotlib.pyplot as plt\nplt.rcParams['font.family'] = 'NanumGothic'\n\n\nfig,ax = plt.subplots(44,1,figsize=(10,50))\nlag= 0 \nT = 100 \nfor k in range(44):\n    ax[k].plot(np.array(train_dataset.targets)[lag:(lag+T),k],'--',alpha=0.5,label='observed')\n    ax[k].set_title('node: {}'.format(V[k]))\n    ax[k].plot(yhat_train[:T,k],label='predicted (tr)')\n#    ax[k].plot(range(yhat_train.shape[0],yhat_train.shape[0]+yhat_test.shape[0]),yhat_test[:,k],label='predicted (test)')\n    ax[k].legend()\nfig.tight_layout()\n\n# plt.savefig('stgcn-ver2-lag4-vis.png')\n\n\n\n\n\nnp.array(dataset.features).shape\n\n(2350, 44, 4)\n\n\n\nnp.array(dataset.targets).shape\n\n(2350, 44)\n\n\n\nnp.array(train_dataset.targets).shape\n\n(1645, 44)\n\n\n\nnp.array(test_dataset.targets).shape\n\n(705, 44)\n\n\n\nfig,ax = plt.subplots(44,1,figsize=(10,50))\nlag= 0\nT = 100 \nfor k in range(44):\n    ax[k].plot(np.array(test_dataset.targets)[lag:(lag+T),k],'--',alpha=0.5,label='observed')\n    ax[k].set_title('node: {}'.format(V[k]))\n    ax[k].plot(yhat_test[:T,k],label='predicted (test)')\n#    ax[k].plot(range(yhat_train.shape[0],yhat_train.shape[0]+yhat_test.shape[0]),yhat_test[:,k],label='predicted (test)')\n    ax[k].legend()\nfig.tight_layout()\n\n# plt.savefig('stgcn-ver2-lag4-vis.png')"
  },
  {
    "objectID": "posts/SOLAR/2023-04-04-EPT.html",
    "href": "posts/SOLAR/2023-04-04-EPT.html",
    "title": "[SOLAR] EPT",
    "section": "",
    "text": "ref: https://www.sciencedirect.com/science/article/pii/S2352711021000492\n\n\nlibrary(tidyverse)\nlibrary(lubridate)\nlibrary(EPT)\n\n\nurl = 'https://raw.githubusercontent.com/miruetoto/yechan3/main/posts/3_Researches/SOLAR/solar_radiation.csv'\ndf = read_csv(url)\n\nRows: 803000 Columns: 3\n── Column specification ────────────────────────────────────────────\nDelimiter: \",\"\nchr (2): region, date\ndbl (1): solar_radiation\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\ndf = df |> filter(region == '북춘천') |> mutate(date=ymd_hm(date))\ndf\n\n\n\nA tibble: 18250 × 3\n\n    regionsolar_radiationdate\n    <chr><dbl><dttm>\n\n\n    북춘천0.002021-01-01 00:00:00\n    북춘천0.002021-01-01 01:00:00\n    북춘천0.002021-01-01 02:00:00\n    북춘천0.002021-01-01 03:00:00\n    북춘천0.002021-01-01 04:00:00\n    북춘천0.002021-01-01 05:00:00\n    북춘천0.002021-01-01 06:00:00\n    북춘천0.002021-01-01 07:00:00\n    북춘천0.002021-01-01 08:00:00\n    북춘천0.372021-01-01 09:00:00\n    북춘천0.962021-01-01 10:00:00\n    북춘천1.402021-01-01 11:00:00\n    북춘천1.722021-01-01 12:00:00\n    북춘천1.842021-01-01 13:00:00\n    북춘천1.742021-01-01 14:00:00\n    북춘천1.302021-01-01 15:00:00\n    북춘천0.932021-01-01 16:00:00\n    북춘천0.292021-01-01 17:00:00\n    북춘천0.012021-01-01 18:00:00\n    북춘천0.002021-01-01 19:00:00\n    북춘천0.002021-01-01 07:00:00\n    북춘천0.002021-01-01 20:00:00\n    북춘천0.002021-01-01 06:00:00\n    북춘천0.002021-01-01 21:00:00\n    북춘천0.002021-01-01 05:00:00\n    북춘천0.002021-01-02 00:00:00\n    북춘천0.002021-01-02 01:00:00\n    북춘천0.002021-01-02 02:00:00\n    북춘천0.002021-01-02 03:00:00\n    북춘천0.002021-01-02 04:00:00\n    ⋮⋮⋮\n    북춘천0.002022-12-30 07:00:00\n    북춘천0.002022-12-30 20:00:00\n    북춘천0.002022-12-30 06:00:00\n    북춘천0.002022-12-30 21:00:00\n    북춘천0.002022-12-30 05:00:00\n    북춘천0.002022-12-31 00:00:00\n    북춘천0.002022-12-31 01:00:00\n    북춘천0.002022-12-31 02:00:00\n    북춘천0.002022-12-31 03:00:00\n    북춘천0.002022-12-31 04:00:00\n    북춘천0.002022-12-31 05:00:00\n    북춘천0.002022-12-31 06:00:00\n    북춘천0.002022-12-31 07:00:00\n    북춘천0.002022-12-31 08:00:00\n    북춘천0.222022-12-31 09:00:00\n    북춘천0.502022-12-31 10:00:00\n    북춘천0.802022-12-31 11:00:00\n    북춘천2.132022-12-31 12:00:00\n    북춘천1.782022-12-31 13:00:00\n    북춘천1.452022-12-31 14:00:00\n    북춘천0.782022-12-31 15:00:00\n    북춘천0.382022-12-31 16:00:00\n    북춘천0.152022-12-31 17:00:00\n    북춘천0.002022-12-31 18:00:00\n    북춘천0.002022-12-31 19:00:00\n    북춘천0.002022-12-31 07:00:00\n    북춘천0.002022-12-31 20:00:00\n    북춘천0.002022-12-31 06:00:00\n    북춘천0.002022-12-31 21:00:00\n    북춘천0.002022-12-31 05:00:00\n\n\n\n\n- 지역을 북춘천으로 고정\n\ndf2 = df |> filter(region =='북춘천') \ndf2 = df2[order(df2$date),]\n\n\ny = df2$solar_radiation\ny\n\n\n0000000000000.370.961.41.721.841.741.30.930.290.010000000000000000.320.951.461.791.911.821.50.970.370.010000000000000000.290.891.41.751.761.350.820.520.30.010000000000000000.330.931.321.531.671.5110.790.1900000000000000000.190.791.411.761.931.851.561.050.450.020000000000000000.511.381.811.881.931.851.5210.410.020000000000000000.110.741.441.811.981.911.611.090.450.020000000000000000.360.971.491.8521.911.611.10.480.03000⋯000000000000.010.471.31.711.871.881.721.380.880.3200000000000000000.190.681.351.712.191.891.380.820.2600000000000000000.150.420.931.071.181.051.160.830.300000000000000000.080.280.430.741.41.841.530.850.2700000000000000000.411.021.841.921.851.721.420.930.340.010000000000000000.471.281.681.81.851.741.40.890.30.010000000000000000.150.641.11.732.121.741.290.860.310.010000000000000000.220.50.82.131.781.450.780.380.150000\n\n\n\nplot(y[1:500])\nlines(y[1:500],lty=2)\n\n\n\n\n- EPT 수행\n\nept = function(y){\n    EpM = eptransf(signal=y,tau=24,process=c(\"envelope\",\"average\"))$EpM\n    EpM*2\n}\n\n\nyU = ept(y)\n\n\nplot(y[1:500])\nlines(yU[1:500],col=2,lty=2)\n\n\n\n\n- todo: 모든 지역에대하여 yU를 구하여 저장"
  },
  {
    "objectID": "posts/SOLAR/2023-04-23-스케일링-stgcn-ver1-정규화취소.html",
    "href": "posts/SOLAR/2023-04-23-스케일링-stgcn-ver1-정규화취소.html",
    "title": "[SOLAR] STGCN Ver1 (data2, -N +S) 30회",
    "section": "",
    "text": "https://github.com/miruetoto/yechan3/tree/main/posts/3_Researches/ITSTGCN/itstgcn\nhttps://miruetoto.github.io/yechan3/posts/3_Researches/ITSTGCN/2023-03-18-SimulationPlanner-Tutorial.html#plnr_gnar_block\n\n\n\n\n\ntrain 2022-06-01 00:00:00 ~ 2022-08-14 17:00:00\ntest 2022-08-14 18:00:00 ~ 2022-09-15 23:00:00\n\n\n\n\n\nimport eptstgcn\nimport torch\nimport eptstgcn.planner\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\n\n\n\n\nurl = \"https://raw.githubusercontent.com/pinkocto/noteda/main/posts/SOLAR/data2/stgcn_data1.json\"\nloader = eptstgcn.DatasetLoader(url)\ndataset = loader.get_dataset(lags=4)\n\n\ntrain_dataset, test_dataset = eptstgcn.utils.temporal_signal_split(dataset, train_ratio = 0.7)\n\n\n\n\n\nlrnr = eptstgcn.StgcnLearner(train_dataset, dataset_name = 'data2(2022/06/01 ~ 2022/09/15)')\n\n\nlrnr.learn(filters=32, epoch=50)\n\n50/50\n\n\n\nimport pickle \nwith open('./lrnr_model/stgcn_ver1_data2_cancel_normal.pickle','wb') as fw:\n    pickle.dump(lrnr, fw)\n\n\nimport pickle \nwith open('./lrnr_model/stgcn_ver1_data2_cancel_normal.pickle', 'rb') as f: \n    lrnr_model = pickle.load(f)\n\n\n\n\n\n\n\nevtor = eptstgcn.Evaluator(lrnr_model, train_dataset, test_dataset)\n\n\nevtor.tr_plot(t=150, label='observed data')\n\n\n\n\n\n\n\n\nevtor.test_plot(t=150, label='observed data')\n\n\n\n\n\n\n\n\n\nplans_stgcn = {\n    'max_iteration': 30, \n    'method': ['STGCN'], \n    'lags': [4], \n    'nof_filters': [32], \n    'epoch': [50]\n}\n\n\n# plnr = eptstgcn.planner.PLNR_STGCN(plans_stgcn,loader,dataset_name='data2')\n\n\n# plnr.simulate()\n\n1/30 is done\n2/30 is done\n3/30 is done\n4/30 is done\n5/30 is done\n6/30 is done\n7/30 is done\n8/30 is done\n9/30 is done\n10/30 is done\n11/30 is done\n12/30 is done\n13/30 is done\n14/30 is done\n15/30 is done\n16/30 is done\n17/30 is done\n18/30 is done\n19/30 is done\n20/30 is done\n21/30 is done\n22/30 is done\n23/30 is done\n24/30 is done\n25/30 is done\n26/30 is done\n27/30 is done\n28/30 is done\n29/30 is done\n30/30 is done\nAll results are stored in ./simulation_results/2023-04-23_01-39-17.csv\n\n\n\n# import pickle\n# with open('./simul_model/stgcn_ver1_data2_cancel_normal.pickle','wb') as fw:\n#          pickle.dump(plnr, fw)\n\n\nimport pickle\nwith open('./simul_model/stgcn_ver1_data2_cancel_normal.pickle','rb') as f:\n         simul_model = pickle.load(f)\n\n\ndf_simul_no = simul_model.simulation_results\ndf_simul_no\n\n\n\n\n\n  \n    \n      \n      dataset\n      method\n      lags\n      nof_filters\n      epoch\n      mse(train)\n      mse(test)\n      calculation_time\n    \n  \n  \n    \n      0\n      data2\n      STGCN\n      4\n      32\n      50\n      0.184729\n      0.16915\n      377.234105\n    \n    \n      1\n      data2\n      STGCN\n      4\n      32\n      50\n      0.194348\n      0.179128\n      404.002319\n    \n    \n      2\n      data2\n      STGCN\n      4\n      32\n      50\n      0.186852\n      0.171011\n      404.872347\n    \n    \n      3\n      data2\n      STGCN\n      4\n      32\n      50\n      0.192293\n      0.177862\n      404.354106\n    \n    \n      4\n      data2\n      STGCN\n      4\n      32\n      50\n      0.184383\n      0.165967\n      404.739908\n    \n    \n      5\n      data2\n      STGCN\n      4\n      32\n      50\n      0.187998\n      0.171345\n      403.504373\n    \n    \n      6\n      data2\n      STGCN\n      4\n      32\n      50\n      0.20575\n      0.195115\n      404.138369\n    \n    \n      7\n      data2\n      STGCN\n      4\n      32\n      50\n      0.185384\n      0.172689\n      403.663877\n    \n    \n      8\n      data2\n      STGCN\n      4\n      32\n      50\n      0.194767\n      0.179806\n      403.539248\n    \n    \n      9\n      data2\n      STGCN\n      4\n      32\n      50\n      0.180619\n      0.16791\n      403.825341\n    \n    \n      10\n      data2\n      STGCN\n      4\n      32\n      50\n      0.185755\n      0.168067\n      403.919527\n    \n    \n      11\n      data2\n      STGCN\n      4\n      32\n      50\n      0.182045\n      0.165334\n      403.761422\n    \n    \n      12\n      data2\n      STGCN\n      4\n      32\n      50\n      0.179984\n      0.163826\n      416.916373\n    \n    \n      13\n      data2\n      STGCN\n      4\n      32\n      50\n      0.182908\n      0.168465\n      418.946952\n    \n    \n      14\n      data2\n      STGCN\n      4\n      32\n      50\n      0.180602\n      0.168306\n      420.972627\n    \n    \n      15\n      data2\n      STGCN\n      4\n      32\n      50\n      0.188245\n      0.173417\n      407.305866\n    \n    \n      16\n      data2\n      STGCN\n      4\n      32\n      50\n      0.191077\n      0.174629\n      406.501366\n    \n    \n      17\n      data2\n      STGCN\n      4\n      32\n      50\n      0.182869\n      0.166464\n      408.495907\n    \n    \n      18\n      data2\n      STGCN\n      4\n      32\n      50\n      0.19079\n      0.173249\n      408.574794\n    \n    \n      19\n      data2\n      STGCN\n      4\n      32\n      50\n      0.180641\n      0.169462\n      407.30098\n    \n    \n      20\n      data2\n      STGCN\n      4\n      32\n      50\n      0.183225\n      0.16961\n      408.664111\n    \n    \n      21\n      data2\n      STGCN\n      4\n      32\n      50\n      0.18652\n      0.170032\n      408.306077\n    \n    \n      22\n      data2\n      STGCN\n      4\n      32\n      50\n      0.185923\n      0.171719\n      408.045289\n    \n    \n      23\n      data2\n      STGCN\n      4\n      32\n      50\n      0.19706\n      0.176483\n      407.953204\n    \n    \n      24\n      data2\n      STGCN\n      4\n      32\n      50\n      0.184862\n      0.168875\n      407.763272\n    \n    \n      25\n      data2\n      STGCN\n      4\n      32\n      50\n      0.197922\n      0.186466\n      404.780481\n    \n    \n      26\n      data2\n      STGCN\n      4\n      32\n      50\n      0.192646\n      0.179262\n      402.828646\n    \n    \n      27\n      data2\n      STGCN\n      4\n      32\n      50\n      0.183524\n      0.166634\n      401.142154\n    \n    \n      28\n      data2\n      STGCN\n      4\n      32\n      50\n      0.18306\n      0.16839\n      400.589833\n    \n    \n      29\n      data2\n      STGCN\n      4\n      32\n      50\n      0.188916\n      0.173284\n      402.841741\n    \n  \n\n\n\n\n\nimport matplotlib.pyplot as plt\nplt.boxplot(df_simul_no['mse(test)'])\nplt.show()"
  },
  {
    "objectID": "posts/SOLAR/2023-04-28-s-stgcn-ver1-100에폭-64필터.html",
    "href": "posts/SOLAR/2023-04-28-s-stgcn-ver1-100에폭-64필터.html",
    "title": "[SOLAR] STGCN Ver1 (data2, -N +S) 30회 100epoch 64filter",
    "section": "",
    "text": "https://github.com/miruetoto/yechan3/tree/main/posts/3_Researches/ITSTGCN/itstgcn\nhttps://miruetoto.github.io/yechan3/posts/3_Researches/ITSTGCN/2023-03-18-SimulationPlanner-Tutorial.html#plnr_gnar_block\n\n\n\n\n\ntrain 2022-06-01 00:00:00 ~ 2022-08-14 17:00:00\ntest 2022-08-14 18:00:00 ~ 2022-09-15 23:00:00\n\n\n\n\n\nimport eptstgcn\nimport torch\nimport eptstgcn.planner\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\n\n\n\n\nurl = \"https://raw.githubusercontent.com/pinkocto/noteda/main/posts/SOLAR/data2/stgcn_data1.json\"\nloader = eptstgcn.DatasetLoader(url)\ndataset = loader.get_dataset(lags=4)\n\n\ntrain_dataset, test_dataset = eptstgcn.utils.temporal_signal_split(dataset, train_ratio = 0.7)\n\n\n\n\n\nlrnr = eptstgcn.StgcnLearner(train_dataset, dataset_name = 'data2(2022/06/01 ~ 2022/09/15)')\n\n\nlrnr.learn(filters=64, epoch=100)\n\n100/100\n\n\n\nimport pickle \nwith open('./lrnr_model/stgcn_ver1_data2_cancel_normal_64fil_100_epoch.pickle','wb') as fw:\n    pickle.dump(lrnr, fw)\n\n\nimport pickle \nwith open('./lrnr_model/stgcn_ver1_data2_cancel_normal_64fil_100_epoch.pickle', 'rb') as f: \n    lrnr_model = pickle.load(f)\n\n\n\n\n\n\n\nevtor = eptstgcn.Evaluator(lrnr_model, train_dataset, test_dataset)\n\n\nevtor.tr_plot(t=150, label='observed data')\n\n\n\n\n\n\n\n\nevtor.test_plot(t=150, label='observed data')\n\n\n\n\n\n\n\n\n\nplans_stgcn = {\n    'max_iteration': 30, \n    'method': ['STGCN'], \n    'lags': [4], \n    'nof_filters': [64], \n    'epoch': [100]\n}\n\n\nplnr = eptstgcn.planner.PLNR_STGCN(plans_stgcn,loader,dataset_name='data2')\n\n\nplnr.simulate()\n\n1/30 is done\n2/30 is done\n3/30 is done\n4/30 is done\n5/30 is done\n6/30 is done\n7/30 is done\n8/30 is done\n9/30 is done\n10/30 is done\n11/30 is done\n12/30 is done\n13/30 is done\n14/30 is done\n15/30 is done\n16/30 is done\n17/30 is done\n18/30 is done\n19/30 is done\n20/30 is done\n21/30 is done\n22/30 is done\n23/30 is done\n24/30 is done\n25/30 is done\n26/30 is done\n27/30 is done\n28/30 is done\n29/30 is done\n30/30 is done\nAll results are stored in ./simulation_results/2023-04-28_21-30-18.csv\n\n\n\nimport pickle\nwith open('./simul_model/stgcn_ver1_data2_cancel_normal_64fil_100epoch.pickle','wb') as fw:\n         pickle.dump(plnr, fw)\n\n\nimport pickle\nwith open('./simul_model/stgcn_ver1_data2_cancel_normal_64fil_100epoch.pickle','rb') as f:\n         simul_model = pickle.load(f)\n\n\ndf_simul_no = simul_model.simulation_results\ndf_simul_no\n\n\n\n\n\n  \n    \n      \n      dataset\n      method\n      lags\n      nof_filters\n      epoch\n      mse(train)\n      mse(test)\n      calculation_time\n    \n  \n  \n    \n      0\n      data2\n      STGCN\n      4\n      64\n      100\n      0.192972\n      0.179327\n      632.293362\n    \n    \n      1\n      data2\n      STGCN\n      4\n      64\n      100\n      0.194304\n      0.181454\n      629.009177\n    \n    \n      2\n      data2\n      STGCN\n      4\n      64\n      100\n      0.195103\n      0.182691\n      628.071399\n    \n    \n      3\n      data2\n      STGCN\n      4\n      64\n      100\n      0.191658\n      0.178774\n      619.383221\n    \n    \n      4\n      data2\n      STGCN\n      4\n      64\n      100\n      0.189748\n      0.172404\n      622.763928\n    \n    \n      5\n      data2\n      STGCN\n      4\n      64\n      100\n      0.189934\n      0.172464\n      617.618802\n    \n    \n      6\n      data2\n      STGCN\n      4\n      64\n      100\n      0.202452\n      0.189377\n      619.757186\n    \n    \n      7\n      data2\n      STGCN\n      4\n      64\n      100\n      0.193825\n      0.181064\n      623.445599\n    \n    \n      8\n      data2\n      STGCN\n      4\n      64\n      100\n      0.189649\n      0.176346\n      618.849603\n    \n    \n      9\n      data2\n      STGCN\n      4\n      64\n      100\n      0.191033\n      0.178531\n      622.506834\n    \n    \n      10\n      data2\n      STGCN\n      4\n      64\n      100\n      0.19138\n      0.177812\n      618.966335\n    \n    \n      11\n      data2\n      STGCN\n      4\n      64\n      100\n      0.192412\n      0.179417\n      625.441791\n    \n    \n      12\n      data2\n      STGCN\n      4\n      64\n      100\n      0.185615\n      0.169146\n      620.673752\n    \n    \n      13\n      data2\n      STGCN\n      4\n      64\n      100\n      0.190466\n      0.176582\n      620.487327\n    \n    \n      14\n      data2\n      STGCN\n      4\n      64\n      100\n      0.190809\n      0.17413\n      623.593211\n    \n    \n      15\n      data2\n      STGCN\n      4\n      64\n      100\n      0.193218\n      0.179902\n      618.909339\n    \n    \n      16\n      data2\n      STGCN\n      4\n      64\n      100\n      0.18949\n      0.172316\n      624.04318\n    \n    \n      17\n      data2\n      STGCN\n      4\n      64\n      100\n      0.191658\n      0.17943\n      634.844835\n    \n    \n      18\n      data2\n      STGCN\n      4\n      64\n      100\n      0.189286\n      0.171943\n      639.019952\n    \n    \n      19\n      data2\n      STGCN\n      4\n      64\n      100\n      0.190692\n      0.174668\n      620.599521\n    \n    \n      20\n      data2\n      STGCN\n      4\n      64\n      100\n      0.191272\n      0.178152\n      622.449273\n    \n    \n      21\n      data2\n      STGCN\n      4\n      64\n      100\n      0.196616\n      0.18022\n      618.711172\n    \n    \n      22\n      data2\n      STGCN\n      4\n      64\n      100\n      0.189093\n      0.170946\n      628.264614\n    \n    \n      23\n      data2\n      STGCN\n      4\n      64\n      100\n      0.19415\n      0.182165\n      622.366607\n    \n    \n      24\n      data2\n      STGCN\n      4\n      64\n      100\n      0.184953\n      0.170323\n      618.086066\n    \n    \n      25\n      data2\n      STGCN\n      4\n      64\n      100\n      0.188433\n      0.170015\n      615.751084\n    \n    \n      26\n      data2\n      STGCN\n      4\n      64\n      100\n      0.186794\n      0.172774\n      617.135813\n    \n    \n      27\n      data2\n      STGCN\n      4\n      64\n      100\n      0.18871\n      0.173203\n      616.304039\n    \n    \n      28\n      data2\n      STGCN\n      4\n      64\n      100\n      0.193447\n      0.180707\n      619.435481\n    \n    \n      29\n      data2\n      STGCN\n      4\n      64\n      100\n      0.193564\n      0.182343\n      622.227399\n    \n  \n\n\n\n\n\ndf_simul_no['mse(test)'].mean()\n\n0.17768246829509735\n\n\n\nprint('stgcn ver1 100에폭 64filter 끝!')\n\nstgcn ver1 100에폭 64filter 끝!\n\n\n\nimport matplotlib.pyplot as plt\nplt.boxplot(df_simul_no['mse(test)'])\nplt.show()"
  },
  {
    "objectID": "posts/SOLAR/2023-04-06-windmill.html",
    "href": "posts/SOLAR/2023-04-06-windmill.html",
    "title": "WindmillOutputLargeDataset 분석 (실패)",
    "section": "",
    "text": "중간에 커널 끊김 (학습시간 4시간 정도), 좀더 작은 버전으로 해볼 것."
  },
  {
    "objectID": "posts/SOLAR/2023-04-06-windmill.html#ref",
    "href": "posts/SOLAR/2023-04-06-windmill.html#ref",
    "title": "WindmillOutputLargeDataset 분석 (실패)",
    "section": "Ref",
    "text": "Ref\n\nhttps://pytorch-geometric-temporal.readthedocs.io/en/latest/modules/dataset.html#module-torch_geometric_temporal.dataset.chickenpox\nhttps://seoyeonc.github.io/blog/posts/GCN/2023-03-20-data%20load,%20data%20save%20as%20pickle.html#windmilloutputlargedatasetloader"
  },
  {
    "objectID": "posts/SOLAR/2023-04-06-windmill.html#import",
    "href": "posts/SOLAR/2023-04-06-windmill.html#import",
    "title": "WindmillOutputLargeDataset 분석 (실패)",
    "section": "import",
    "text": "import\n\nimport pandas as pd\nimport numpy as np\nimport json\nimport urllib\n\n\n# 일반적인 모듈 \nimport numpy as np\nimport matplotlib.pyplot as plt \nimport networkx as nx \nfrom tqdm import tqdm \n\n# 파이토치 관련 \nimport torch\nimport torch.nn.functional as F\n\n# PyG 관련 \nfrom torch_geometric.data import Data ## Data: 그래프자료형을 만드는 클래스\n\n# STGCN 관련 \nimport torch_geometric_temporal\nfrom torch_geometric_temporal.nn.recurrent import GConvGRU\nfrom torch_geometric_temporal.signal import temporal_signal_split \n\n\nclass RecurrentGCN(torch.nn.Module):\n    def __init__(self, node_features, filters):\n        super(RecurrentGCN, self).__init__()\n        self.recurrent = GConvGRU(node_features, filters, 2)\n        self.linear = torch.nn.Linear(filters, 1)\n\n    def forward(self, x, edge_index, edge_weight):\n        h = self.recurrent(x, edge_index, edge_weight)\n        h = F.relu(h)\n        h = self.linear(h)\n        return h"
  },
  {
    "objectID": "posts/SOLAR/2023-04-06-windmill.html#windmilloutputlargedataset-살펴보기",
    "href": "posts/SOLAR/2023-04-06-windmill.html#windmilloutputlargedataset-살펴보기",
    "title": "WindmillOutputLargeDataset 분석 (실패)",
    "section": "WindmillOutputLargeDataset 살펴보기",
    "text": "WindmillOutputLargeDataset 살펴보기\n\nweighted edges\n\nHourly energy output of windmills from a European country for more than 2 years. Vertices represent 319 windmills and weighted edges describe the strength of relationships. The target variable allows for regression tasks.\n\n\\(T = 17472\\)\n$V = $ 풍력발전소\n$N = $ 노드 수\n\\(E = 101761 = N^2\\) 에지 수\n\n\\({\\bf f}=\\begin{bmatrix} {\\bf f}_1\\\\ {\\bf f}_2\\\\ \\dots \\\\ {\\bf f}_{17472} \\end{bmatrix}=\\begin{bmatrix} f(t=1,v=\\tt{V1}) & \\dots & f(t=1,v=\\tt{V319}) \\\\ f(t=2,v=\\tt{V1}) & \\dots & f(t=2,v=\\tt{V319}) \\\\ \\dots & \\dots & \\dots \\\\ f(t=17472,v=\\tt{V1}) & \\dots & f(t=17472,v=\\tt{V319}) \\end{bmatrix}\\)\n\nurl = \"https://graphmining.ai/temporal_datasets/windmill_output.json\"\ndata_dict = json.loads(urllib.request.urlopen(url).read())\ndata_dict.keys()\n\ndict_keys(['block', 'time_periods', 'weights', 'edges'])\n\n\n\n365*2*24 # 1년 365일 기준 하루 24시간 --> 17520시간.\n\n17520\n\n\n\ndata_dict['time_periods']\n\n17472\n\n\n\nnp.array(data_dict['block']).shape # fx\n\n(17472, 319)\n\n\n\nlen(data_dict['weights'])\n\n101761\n\n\n\nnp.array(data_dict['edges']).shape\n\n(101761, 2)\n\n\n\n319 ** 2\n\n101761\n\n\n\nnp.array(data_dict['weights']).shape\n\n(101761,)\n\n\n\nnp.array(data_dict['weights']).reshape(319, 319)\n\narray([[1.        , 0.83313653, 0.76403123, ..., 0.03572003, 0.02756888,\n        0.01799128],\n       [0.83313653, 1.        , 0.91705372, ..., 0.03025762, 0.0241852 ,\n        0.01583424],\n       [0.76403123, 0.91705372, 1.        , ..., 0.02794797, 0.02269021,\n        0.01487937],\n       ...,\n       [0.03572003, 0.03025762, 0.02794797, ..., 1.        , 0.29412671,\n        0.21992883],\n       [0.02756888, 0.0241852 , 0.02269021, ..., 0.29412671, 1.        ,\n        0.64651593],\n       [0.01799128, 0.01583424, 0.01487937, ..., 0.21992883, 0.64651593,\n        1.        ]])\n\n\n\nnode_ids = {}\nfor i in range(319):\n    node_ids['node' + str(i+1)] = i\n\n\nedges = np.array(data_dict['edges']).T\nedge_weight = np.array(data_dict['weights'])"
  },
  {
    "objectID": "posts/SOLAR/2023-04-06-windmill.html#section",
    "href": "posts/SOLAR/2023-04-06-windmill.html#section",
    "title": "WindmillOutputLargeDataset 분석 (실패)",
    "section": "–",
    "text": "–"
  },
  {
    "objectID": "posts/SOLAR/2023-04-06-windmill.html#windmilloutputlargedatasetloader",
    "href": "posts/SOLAR/2023-04-06-windmill.html#windmilloutputlargedatasetloader",
    "title": "WindmillOutputLargeDataset 분석 (실패)",
    "section": "WindmillOutputLargeDatasetLoader",
    "text": "WindmillOutputLargeDatasetLoader\nref: https://github.com/benedekrozemberczki/pytorch_geometric_temporal/blob/master/docs/source/notes/introduction.rst\n\ntorch_geometric_temporal.signal.StaticGraphTemporalSignal \n\ntorch_geometric_temporal.signal.static_graph_temporal_signal.StaticGraphTemporalSignal\n\n\n\nloader = torch_geometric_temporal.dataset.WindmillOutputLargeDatasetLoader()\ndataset = loader.get_dataset(lags=4)\ntrain_dataset, test_dataset = temporal_signal_split(dataset, train_ratio=0.8)"
  },
  {
    "objectID": "posts/SOLAR/2023-04-06-windmill.html#learn",
    "href": "posts/SOLAR/2023-04-06-windmill.html#learn",
    "title": "WindmillOutputLargeDataset 분석 (실패)",
    "section": "Learn",
    "text": "Learn\n\nmodel = RecurrentGCN(node_features=4, filters=32)\noptimizer = torch.optim.Adam(model.parameters(), lr=0.01)\nmodel.train()\n\nfor epoch in tqdm(range(50)):\n    for t, snapshot in enumerate(train_dataset):\n        yt_hat = model(snapshot.x, snapshot.edge_index, snapshot.edge_attr)\n        cost = torch.mean((yt_hat-snapshot.y)**2)\n        cost.backward()\n        optimizer.step()\n        optimizer.zero_grad()\n\n  0%|                                                                                                              | 0/50 [00:26<?, ?it/s]\n\n\nKeyboardInterrupt: \n\n\n\n학습이 매우 느림.. (8시50분시작 ..새벽 1시 20분에 끝남..4시간넘게 걸린다.)"
  },
  {
    "objectID": "posts/SOLAR/2023-04-06-windmill.html#visualization",
    "href": "posts/SOLAR/2023-04-06-windmill.html#visualization",
    "title": "WindmillOutputLargeDataset 분석 (실패)",
    "section": "Visualization",
    "text": "Visualization\n\nmodel.eval()\ncost = 0\nfor time, snapshot in enumerate(test_dataset):\n    y_hat = model(snapshot.x, snapshot.edge_index, snapshot.edge_attr)\n    cost = cost + torch.mean((y_hat-snapshot.y)**2)\ncost = cost / (time+1)\ncost = cost.item()\nprint(\"MSE: {:.4f}\".format(cost))\n\nMSE: 1.0237\n\n\n\n# yhat_train = torch.stack([model(snapshot.x,snapshot.edge_index, snapshot.edge_attr) for snapshot in train_dataset]).detach().numpy()\n# yhat_test = torch.stack([model(snapshot.x,snapshot.edge_index, snapshot.edge_attr) for snapshot in test_dataset]).detach().numpy()\n\n\n커널 죽음ㅠㅠㅠ (사이즈를 줄여서 해야할 듯.)\n\n\n# V = list(node_ids)\n\n\nfig,ax = plt.subplots(319,1,figsize=(10,50))\nfor k in range(319):\n    ax[k].plot(f[:,k],'--',alpha=0.5,label='observed')\n    ax[k].set_title('node: {}'.format(V[k]))\n    ax[k].plot(yhat_train[:,k],label='predicted (tr)')\n    ax[k].plot(range(yhat_train.shape[0],yhat_train.shape[0]+yhat_test.shape[0]),yhat_test[:,k],label='predicted (test)')\n    ax[k].legend()\n# fig.tight_layout()\n\nNameError: name 'f' is not defined"
  },
  {
    "objectID": "posts/SOLAR/2023-04-20-정규화-데이터3-stgcn-ver1.html",
    "href": "posts/SOLAR/2023-04-20-정규화-데이터3-stgcn-ver1.html",
    "title": "[SOLAR] STGCN Ver1 (Full: 08/15~09/10 data3) (MSE: 0.1523)",
    "section": "",
    "text": "train: 08월 학습, 9월 10일간 test"
  },
  {
    "objectID": "posts/SOLAR/2023-04-20-정규화-데이터3-stgcn-ver1.html#import",
    "href": "posts/SOLAR/2023-04-20-정규화-데이터3-stgcn-ver1.html#import",
    "title": "[SOLAR] STGCN Ver1 (Full: 08/15~09/10 data3) (MSE: 0.1523)",
    "section": "import",
    "text": "import\n\nimport pandas as pd\nimport numpy as np\nimport json\nimport urllib\nimport time\n\n\n# 일반적인 모듈 \nimport numpy as np\nimport matplotlib.pyplot as plt \nimport networkx as nx \nfrom tqdm import tqdm \n\n# 파이토치 관련 \nimport torch\nimport torch.nn.functional as F\n\n# PyG 관련 \nfrom torch_geometric.data import Data ## Data: 그래프자료형을 만드는 클래스\n\n# STGCN 관련 \nimport torch_geometric_temporal\nfrom torch_geometric_temporal.nn.recurrent import GConvGRU\nfrom torch_geometric_temporal.signal import temporal_signal_split \n\n\nclass RecurrentGCN(torch.nn.Module):\n    def __init__(self, node_features, filters):\n        super(RecurrentGCN, self).__init__()\n        self.recurrent = GConvGRU(node_features, filters, 2)\n        self.linear = torch.nn.Linear(filters, 1)\n\n    def forward(self, x, edge_index, edge_weight):\n        h = self.recurrent(x, edge_index, edge_weight)\n        h = F.relu(h)\n        h = self.linear(h)\n        return h\n\n\nfrom mysolar2 import NormalSolarDatasetLoader\n\n\nurl = \"https://raw.githubusercontent.com/pinkocto/noteda/main/posts/SOLAR/data3/stgcn_data1.json\"\nloader = NormalSolarDatasetLoader()\ndataset = loader.get_dataset(lags=4)\n# train_dataset, test_dataset = temporal_signal_split(dataset, train_ratio=0.756)\ntrain_dataset = dataset[:405]  ## 2022-08-01 23:00:00 ~ 2022-08-31 23:00:00\ntest_dataset = dataset[405:]   ## 2022-09-01 23:00:00 ~ 2022-09-10 23:00:00\n\n\nprint(np.array(train_dataset.targets).shape)\nprint(np.array(test_dataset.targets).shape)\n\n(405, 44)\n(239, 44)"
  },
  {
    "objectID": "posts/SOLAR/2023-04-20-정규화-데이터3-stgcn-ver1.html#learn",
    "href": "posts/SOLAR/2023-04-20-정규화-데이터3-stgcn-ver1.html#learn",
    "title": "[SOLAR] STGCN Ver1 (Full: 08/15~09/10 data3) (MSE: 0.1523)",
    "section": "Learn",
    "text": "Learn\n\nmodel = RecurrentGCN(node_features=4, filters=32)\noptimizer = torch.optim.Adam(model.parameters(), lr=0.01)\nmodel.train()\n\nfor epoch in tqdm(range(50)):\n    for t, snapshot in enumerate(train_dataset):\n        yt_hat = model(snapshot.x, snapshot.edge_index, snapshot.edge_attr)\n        cost = torch.mean((yt_hat-snapshot.y)**2)\n        cost.backward()\n        optimizer.step()\n        optimizer.zero_grad()\n\n100%|██████████| 50/50 [01:10<00:00,  1.42s/it]\n\n\n\nimport pickle \nwith open('./model3/normal_stgcn1_lag4_new.pickle','wb') as fw:\n    pickle.dump(model, fw)\n\n\nimport pickle \nwith open('./model3/normal_stgcn1_lag4_new.pickle', 'rb') as f: \n    model = pickle.load(f)\n\n\nmodel\n\nRecurrentGCN(\n  (recurrent): GConvGRU(\n    (conv_x_z): ChebConv(4, 32, K=2, normalization=sym)\n    (conv_h_z): ChebConv(32, 32, K=2, normalization=sym)\n    (conv_x_r): ChebConv(4, 32, K=2, normalization=sym)\n    (conv_h_r): ChebConv(32, 32, K=2, normalization=sym)\n    (conv_x_h): ChebConv(4, 32, K=2, normalization=sym)\n    (conv_h_h): ChebConv(32, 32, K=2, normalization=sym)\n  )\n  (linear): Linear(in_features=32, out_features=1, bias=True)\n)"
  },
  {
    "objectID": "posts/SOLAR/2023-04-20-정규화-데이터3-stgcn-ver1.html#모델평가",
    "href": "posts/SOLAR/2023-04-20-정규화-데이터3-stgcn-ver1.html#모델평가",
    "title": "[SOLAR] STGCN Ver1 (Full: 08/15~09/10 data3) (MSE: 0.1523)",
    "section": "모델평가",
    "text": "모델평가\n- train\n\nMSE: 0.2102 (before normalize)\n\n\nmodel.eval()\ncost = 0\nfor time, snapshot in enumerate(train_dataset):\n    y_hat = model(snapshot.x, snapshot.edge_index, snapshot.edge_attr)\n    cost = cost + torch.mean((y_hat-snapshot.y)**2)\ncost = cost / (time+1)\ncost = cost.item()\nprint(\"MSE: {:.4f}\".format(cost))\n\nMSE: 0.2057\n\n\n- test\n\nMSE: 0.1899 (before normalize)\n\n\nmodel.eval()\ncost = 0\nfor time, snapshot in enumerate(test_dataset):\n    y_hat = model(snapshot.x, snapshot.edge_index, snapshot.edge_attr)\n    cost = cost + torch.mean((y_hat-snapshot.y)**2)\ncost = cost / (time+1)\ncost = cost.item()\nprint(\"MSE: {:.4f}\".format(cost))\n\nMSE: 0.1523"
  },
  {
    "objectID": "posts/SOLAR/2023-04-20-정규화-데이터3-stgcn-ver1.html#visualization",
    "href": "posts/SOLAR/2023-04-20-정규화-데이터3-stgcn-ver1.html#visualization",
    "title": "[SOLAR] STGCN Ver1 (Full: 08/15~09/10 data3) (MSE: 0.1523)",
    "section": "Visualization",
    "text": "Visualization\n\nurl = 'https://raw.githubusercontent.com/pinkocto/noteda/main/posts/SOLAR/data3/stgcn_data1.json'\n\n\ndata_dict = json.loads(urllib.request.urlopen(url).read())\nV = list(data_dict['node_ids'].keys())\nf = np.array(data_dict[\"FX\"])\n\n\nyhat_train = torch.stack([model(snapshot.x,snapshot.edge_index, snapshot.edge_attr) for snapshot in train_dataset]).detach().numpy()\nyhat_test = torch.stack([model(snapshot.x,snapshot.edge_index, snapshot.edge_attr) for snapshot in test_dataset]).detach().numpy()\n\n\nimport matplotlib.pyplot as plt\nplt.rcParams['font.family'] = 'NanumGothic'\n\n\ntrain\n\nfig,ax = plt.subplots(44,1,figsize=(10,50))\nlag= 0 \nT = 100 \nfor k in range(44):\n    ax[k].plot(np.array(train_dataset.targets)[lag:(lag+T),k],'--',alpha=0.5,label='observed', color='green')\n    ax[k].set_title('node: {}'.format(V[k]))\n    ax[k].plot(yhat_train[:T,k],label='predicted (tr)', color = 'orange')\n#    ax[k].plot(range(yhat_train.shape[0],yhat_train.shape[0]+yhat_test.shape[0]),yhat_test[:,k],label='predicted (test)')\n    ax[k].legend()\nfig.tight_layout()\n\n# plt.savefig('stgcn-ver2-lag4-vis.png')\n\n\n\n\n\n\ntest\n\nfig,ax = plt.subplots(44,1,figsize=(10,50))\nlag= 0\nT = 100 \nfor k in range(44):\n    ax[k].plot(np.array(test_dataset.targets)[lag:(lag+T),k],'--',alpha=0.5,label='observed')\n    ax[k].set_title('node: {}'.format(V[k]))\n    ax[k].plot(yhat_test[:T,k],label='predicted (test)', color='red')\n#    ax[k].plot(range(yhat_train.shape[0],yhat_train.shape[0]+yhat_test.shape[0]),yhat_test[:,k],label='predicted (test)')\n    ax[k].legend()\nfig.tight_layout()\n\n# plt.savefig('stgcn-ver2-lag4-vis.png')"
  },
  {
    "objectID": "posts/SOLAR/2023-04-26-s-stgcn-ver1-150에폭.html",
    "href": "posts/SOLAR/2023-04-26-s-stgcn-ver1-150에폭.html",
    "title": "[SOLAR] STGCN Ver1 (data2, -N +S) 30회 150epoch",
    "section": "",
    "text": "https://github.com/miruetoto/yechan3/tree/main/posts/3_Researches/ITSTGCN/itstgcn\nhttps://miruetoto.github.io/yechan3/posts/3_Researches/ITSTGCN/2023-03-18-SimulationPlanner-Tutorial.html#plnr_gnar_block\n\n\n\n\n\ntrain 2022-06-01 00:00:00 ~ 2022-08-14 17:00:00\ntest 2022-08-14 18:00:00 ~ 2022-09-15 23:00:00\n\n\n\n\n\nimport eptstgcn\nimport torch\nimport eptstgcn.planner\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\n\n\n\n\nurl = \"https://raw.githubusercontent.com/pinkocto/noteda/main/posts/SOLAR/data2/stgcn_data1.json\"\nloader = eptstgcn.DatasetLoader(url)\ndataset = loader.get_dataset(lags=4)\n\n\ntrain_dataset, test_dataset = eptstgcn.utils.temporal_signal_split(dataset, train_ratio = 0.7)\n\n\n\n\n\nlrnr = eptstgcn.StgcnLearner(train_dataset, dataset_name = 'data2(2022/06/01 ~ 2022/09/15)')\n\n\nlrnr.learn(filters=32, epoch=150)\n\n150/150\n\n\n\nimport pickle \nwith open('./lrnr_model/stgcn_ver1_data2_cancel_normal_150epoch.pickle','wb') as fw:\n    pickle.dump(lrnr, fw)\n\n\nimport pickle \nwith open('./lrnr_model/stgcn_ver1_data2_cancel_normal_150epoch.pickle', 'rb') as f: \n    lrnr_model = pickle.load(f)\n\n\n\n\n\n\n\nevtor = eptstgcn.Evaluator(lrnr_model, train_dataset, test_dataset)\n\n\nevtor.tr_plot(t=150, label='observed data')\n\n\n\n\n\n\n\n\nevtor.test_plot(t=150, label='observed data')\n\n\n\n\n\n\n\n\n\nplans_stgcn = {\n    'max_iteration': 30, \n    'method': ['STGCN'], \n    'lags': [4], \n    'nof_filters': [32], \n    'epoch': [150]\n}\n\n\nplnr = eptstgcn.planner.PLNR_STGCN(plans_stgcn,loader,dataset_name='data2')\n\n\nplnr.simulate()\n\n1/30 is done\n2/30 is done\n3/30 is done\n4/30 is done\n5/30 is done\n6/30 is done\n7/30 is done\n8/30 is done\n9/30 is done\n10/30 is done\n11/30 is done\n12/30 is done\n13/30 is done\n14/30 is done\n15/30 is done\n16/30 is done\n17/30 is done\n18/30 is done\n19/30 is done\n20/30 is done\n21/30 is done\n22/30 is done\n23/30 is done\n24/30 is done\n25/30 is done\n26/30 is done\n27/30 is done\n28/30 is done\n29/30 is done\n30/30 is done\nAll results are stored in ./simulation_results/2023-04-27_22-08-24.csv\n\n\n\nimport pickle\nwith open('./simul_model/stgcn_ver1_data2_cancel_normal_150epoch.pickle','wb') as fw:\n         pickle.dump(plnr, fw)\n\n\nimport pickle\nwith open('./simul_model/stgcn_ver1_data2_cancel_normal_150epoch.pickle','rb') as f:\n         simul_model = pickle.load(f)\n\n\ndf_simul_no = simul_model.simulation_results\ndf_simul_no\n\n\n\n\n\n  \n    \n      \n      dataset\n      method\n      lags\n      nof_filters\n      epoch\n      mse(train)\n      mse(test)\n      calculation_time\n    \n  \n  \n    \n      0\n      data2\n      STGCN\n      4\n      32\n      150\n      0.189996\n      0.173553\n      3742.851026\n    \n    \n      1\n      data2\n      STGCN\n      4\n      32\n      150\n      0.182216\n      0.16745\n      3893.023869\n    \n    \n      2\n      data2\n      STGCN\n      4\n      32\n      150\n      0.192126\n      0.175373\n      3864.806065\n    \n    \n      3\n      data2\n      STGCN\n      4\n      32\n      150\n      0.193484\n      0.180455\n      3739.179426\n    \n    \n      4\n      data2\n      STGCN\n      4\n      32\n      150\n      0.188898\n      0.175463\n      3679.028349\n    \n    \n      5\n      data2\n      STGCN\n      4\n      32\n      150\n      0.185832\n      0.169814\n      3412.443755\n    \n    \n      6\n      data2\n      STGCN\n      4\n      32\n      150\n      0.183825\n      0.16889\n      3371.447943\n    \n    \n      7\n      data2\n      STGCN\n      4\n      32\n      150\n      0.191254\n      0.177824\n      3405.519132\n    \n    \n      8\n      data2\n      STGCN\n      4\n      32\n      150\n      0.186609\n      0.174553\n      3566.582546\n    \n    \n      9\n      data2\n      STGCN\n      4\n      32\n      150\n      0.19144\n      0.178698\n      3121.731833\n    \n    \n      10\n      data2\n      STGCN\n      4\n      32\n      150\n      0.188561\n      0.170901\n      1913.605116\n    \n    \n      11\n      data2\n      STGCN\n      4\n      32\n      150\n      0.194103\n      0.183562\n      1217.098289\n    \n    \n      12\n      data2\n      STGCN\n      4\n      32\n      150\n      0.207146\n      0.197766\n      1216.3393\n    \n    \n      13\n      data2\n      STGCN\n      4\n      32\n      150\n      0.192239\n      0.173347\n      1215.570433\n    \n    \n      14\n      data2\n      STGCN\n      4\n      32\n      150\n      0.192682\n      0.179757\n      1216.822751\n    \n    \n      15\n      data2\n      STGCN\n      4\n      32\n      150\n      0.189387\n      0.17637\n      1220.243363\n    \n    \n      16\n      data2\n      STGCN\n      4\n      32\n      150\n      0.18901\n      0.170644\n      1217.20759\n    \n    \n      17\n      data2\n      STGCN\n      4\n      32\n      150\n      0.192833\n      0.181281\n      1219.012465\n    \n    \n      18\n      data2\n      STGCN\n      4\n      32\n      150\n      0.205684\n      0.195635\n      1222.42507\n    \n    \n      19\n      data2\n      STGCN\n      4\n      32\n      150\n      0.189798\n      0.175815\n      1227.614897\n    \n    \n      20\n      data2\n      STGCN\n      4\n      32\n      150\n      0.204807\n      0.19537\n      1224.741772\n    \n    \n      21\n      data2\n      STGCN\n      4\n      32\n      150\n      0.188715\n      0.176382\n      1226.533329\n    \n    \n      22\n      data2\n      STGCN\n      4\n      32\n      150\n      0.194854\n      0.182779\n      1232.029675\n    \n    \n      23\n      data2\n      STGCN\n      4\n      32\n      150\n      0.193083\n      0.180377\n      1234.611227\n    \n    \n      24\n      data2\n      STGCN\n      4\n      32\n      150\n      0.191385\n      0.179724\n      1232.618525\n    \n    \n      25\n      data2\n      STGCN\n      4\n      32\n      150\n      0.204002\n      0.194082\n      2664.735856\n    \n    \n      26\n      data2\n      STGCN\n      4\n      32\n      150\n      0.184933\n      0.171661\n      3063.993559\n    \n    \n      27\n      data2\n      STGCN\n      4\n      32\n      150\n      0.198384\n      0.185356\n      3719.31226\n    \n    \n      28\n      data2\n      STGCN\n      4\n      32\n      150\n      0.195301\n      0.183986\n      3448.4107\n    \n    \n      29\n      data2\n      STGCN\n      4\n      32\n      150\n      0.18867\n      0.170441\n      3441.653775\n    \n  \n\n\n\n\n\nprint('150에폭 stgcn ver1 끝')\n\n150에폭 stgcn ver1 끝\n\n\n\ndf_simul_no['mse(test)'].mean()\n\n0.17891031752030054\n\n\n\nimport matplotlib.pyplot as plt\nplt.boxplot(df_simul_no['mse(test)'])\nplt.show()"
  },
  {
    "objectID": "posts/SOLAR/2023-04-14-데이터수정2.html",
    "href": "posts/SOLAR/2023-04-14-데이터수정2.html",
    "title": "[SOLAR] Crate Dataset (data2: 22/06~22/09/15) 재수정",
    "section": "",
    "text": "0412 first  0415 update (time 수정)\n변경내용 : 00$$23까지 모든 시간대 채운 후 기간설정 (22/06~22/09/15)"
  },
  {
    "objectID": "posts/SOLAR/2023-04-14-데이터수정2.html#import",
    "href": "posts/SOLAR/2023-04-14-데이터수정2.html#import",
    "title": "[SOLAR] Crate Dataset (data2: 22/06~22/09/15) 재수정",
    "section": "import",
    "text": "import\n\nimport pandas as pd\nimport numpy as np\nimport json\nimport urllib\n\nimport matplotlib.pyplot as plt\nimport time"
  },
  {
    "objectID": "posts/SOLAR/2023-04-14-데이터수정2.html#solar_radiation",
    "href": "posts/SOLAR/2023-04-14-데이터수정2.html#solar_radiation",
    "title": "[SOLAR] Crate Dataset (data2: 22/06~22/09/15) 재수정",
    "section": "solar_radiation",
    "text": "solar_radiation\n\n# df = pd.read_csv(\"./data/solar_radiation.csv\")\ndf = pd.read_csv('./data/solar_radiation2.csv')\n\n\ndf.shape\n\n(770880, 3)\n\n\n\ndf.duplicated().sum()\n\n96360\n\n\n\ndf_ = df.drop_duplicates()\n\n\ndf.duplicated().sum()\n\n0\n\n\n\ndf.shape\n\n(770880, 3)\n\n\n\n# df_.to_csv('./data/solar_radiation.csv', index=False) ## 전에 것.\n\n\nsolar 데이터 수정완료 (solar_radiation2.csv로 변경)"
  },
  {
    "objectID": "posts/SOLAR/2023-04-14-데이터수정2.html#날짜-재설정-train-test",
    "href": "posts/SOLAR/2023-04-14-데이터수정2.html#날짜-재설정-train-test",
    "title": "[SOLAR] Crate Dataset (data2: 22/06~22/09/15) 재수정",
    "section": "날짜 재설정, train / test",
    "text": "날짜 재설정, train / test\n\nimport gc\ngc.collect()\n\n11358\n\n\n\n# df = pd.read_csv('./data/solar_radiation.csv')\n\n\ndf.duplicated().sum()\n\n0\n\n\n\ntrain = df.query(\"date >= '2022-06-01-00:00' and date <= '2022-08-15-23:00'\")\ntest = df.query(\"date >= '2022-08-16-00:00' and date <= '2022-09-15-23:00'\")\n\n\ntrain.shape, test.shape, \n\n((80256, 3), (32736, 3))\n\n\n\nprint(train.shape[0]/(train.shape[0]+test.shape[0]))\nprint(test.shape[0]/(train.shape[0]+test.shape[0]))\n\n0.7102803738317757\n0.2897196261682243\n\n\n\ntrain[:200].plot(backend='plotly',x='date',y='solar_radiation',color='region')\n\n\n                                                \n\n\n\n중복되는 것 잘 처리된 듯.\n\n\n# train = train.reset_index(drop=True)\n# test = test.reset_index(drop=True)\n\n\n# train.to_csv('./data2/train.csv', index=False)\n# test.to_csv('./data2/test.csv', index=False)\n\n\n# solar_radiation = pd.concat([train, test])\n# solar_radiation.to_csv('./data2/solar_radiation.csv')\n\n\n23/04/15 재생성"
  },
  {
    "objectID": "posts/SOLAR/2023-04-14-데이터수정2.html#weight",
    "href": "posts/SOLAR/2023-04-14-데이터수정2.html#weight",
    "title": "[SOLAR] Crate Dataset (data2: 22/06~22/09/15) 재수정",
    "section": "Weight",
    "text": "Weight\n\nimport rpy2\n%load_ext rpy2.ipython \n\nThe rpy2.ipython extension is already loaded. To reload it, use:\n  %reload_ext rpy2.ipython\n\n\n\n%R -i train\n\n\n%%R\nlibrary(data.table)\nlibrary(tidyverse)\nlibrary(dplyr)\nlibrary(corrplot)\nlibrary(lubridate)\n\n\n%%R\nhead(train)\n\n  region solar_radiation             date\n0 북춘천               0 2022-06-01-00:00\n1 북춘천               0 2022-06-01-01:00\n2 북춘천               0 2022-06-01-02:00\n3 북춘천               0 2022-06-01-03:00\n4 북춘천               0 2022-06-01-04:00\n5 북춘천               0 2022-06-01-05:00\n\n\n\n%%R\ntrain = train |> mutate(date = ymd_hm(date))\n\n\n%%R\ntrain <- train %>%\n              group_by(region) %>%\n              mutate(row = row_number()) %>%\n              tidyr::pivot_wider(names_from = region, values_from = solar_radiation) %>%\n              select(-row)\n\n\n%%R\nnum_vars <- train %>% select(-date)\nweight <- cor(num_vars)\nweight\n\n          북춘천      철원    대관령      춘천    백령도    북강릉      강릉\n북춘천 1.0000000 0.9354227 0.8484571 0.9804681 0.7787405 0.8096950 0.7958230\n철원   0.9354227 1.0000000 0.8046374 0.9318076 0.7915945 0.7648023 0.7490139\n대관령 0.8484571 0.8046374 1.0000000 0.8459128 0.7315027 0.9176170 0.9176780\n춘천   0.9804681 0.9318076 0.8459128 1.0000000 0.7860694 0.8107004 0.7944179\n백령도 0.7787405 0.7915945 0.7315027 0.7860694 1.0000000 0.7191890 0.7104943\n북강릉 0.8096950 0.7648023 0.9176170 0.8107004 0.7191890 1.0000000 0.9767518\n강릉   0.7958230 0.7490139 0.9176780 0.7944179 0.7104943 0.9767518 1.0000000\n서울   0.8950700 0.8924032 0.7847346 0.8949421 0.7550764 0.7454717 0.7273539\n인천   0.8800897 0.8835704 0.7856758 0.8882261 0.8258567 0.7636879 0.7440307\n원주   0.8872143 0.8569986 0.8560494 0.8929441 0.7108456 0.8249637 0.8188935\n울릉도 0.7704594 0.7315194 0.8082114 0.7743434 0.6521670 0.7894544 0.7815274\n수원   0.8874207 0.8752317 0.8148757 0.8901672 0.7720289 0.8001409 0.7849799\n서산   0.8556697 0.8328024 0.8056768 0.8537852 0.7760450 0.8033033 0.7865161\n청주   0.8385589 0.7952847 0.8303327 0.8424993 0.6970798 0.8232442 0.8103833\n대전   0.8205476 0.7818135 0.8328943 0.8259461 0.7084518 0.8350131 0.8162185\n추풍령 0.8054751 0.7651683 0.8508011 0.8146245 0.7122229 0.8579585 0.8441442\n안동   0.8200709 0.7757717 0.8725204 0.8300229 0.7108366 0.8765078 0.8661848\n포항   0.7386050 0.6991403 0.8149746 0.7490307 0.6685757 0.8136745 0.8092740\n대구   0.8018833 0.7701624 0.8509044 0.8107771 0.7136175 0.8393632 0.8251724\n전주   0.7914907 0.7559699 0.8141969 0.7978513 0.6981081 0.8135504 0.8015528\n창원   0.7677539 0.7281557 0.8072301 0.7734440 0.7016747 0.7918266 0.7841383\n광주   0.7976445 0.7670324 0.8050528 0.8036054 0.6888886 0.7896031 0.7803357\n부산   0.7648912 0.7353604 0.8043715 0.7685058 0.6958218 0.7925060 0.7844037\n목포   0.7773332 0.7462521 0.7845163 0.7841523 0.7278852 0.7709153 0.7606503\n여수   0.7743994 0.7431887 0.8001751 0.7801829 0.7207816 0.7854621 0.7787742\n흑산도 0.7123329 0.6867806 0.6944630 0.7273620 0.6976910 0.6772559 0.6777030\n고창   0.8024093 0.7763503 0.7934771 0.8111590 0.7106546 0.7821426 0.7751184\n홍성   0.8336545 0.8060729 0.8045889 0.8370223 0.7500782 0.8107383 0.7971153\n제주   0.7231531 0.7027542 0.7515182 0.7307226 0.7003067 0.7406647 0.7400761\n고산   0.7570940 0.7433290 0.7518443 0.7627983 0.7430247 0.7366984 0.7329499\n진주   0.7608540 0.7271996 0.8106935 0.7731004 0.7254829 0.8018893 0.7947315\n고창군 0.7909242 0.7534505 0.7984340 0.7971632 0.6992467 0.7928961 0.7782792\n영광군 0.7957767 0.7688266 0.7994055 0.8030415 0.7191916 0.7870528 0.7791394\n김해시 0.7583464 0.7248262 0.7980189 0.7610443 0.7041355 0.7870968 0.7798474\n순창군 0.8039828 0.7621579 0.8247022 0.8113552 0.6955489 0.8163301 0.8020242\n북창원 0.7398331 0.7029672 0.7982610 0.7474691 0.6834564 0.7921148 0.7894190\n양산시 0.7625488 0.7264823 0.8143695 0.7670135 0.6812135 0.8050859 0.7950266\n보성군 0.7813081 0.7540613 0.8047406 0.7941714 0.7278349 0.7952688 0.7871637\n강진군 0.7680688 0.7439198 0.7763671 0.7770252 0.7125364 0.7592658 0.7518227\n의령군 0.7724214 0.7320323 0.8178428 0.7799025 0.7142109 0.8192187 0.8131759\n함양군 0.7900454 0.7515202 0.8253053 0.7970284 0.7309059 0.8240476 0.8145880\n광양시 0.7703746 0.7386150 0.8029972 0.7790557 0.7161589 0.7808741 0.7752086\n청송군 0.8006122 0.7594425 0.8662752 0.8104820 0.6905146 0.8505242 0.8409919\n경주시 0.7428165 0.7006137 0.8264038 0.7464970 0.6746425 0.8282642 0.8187796\n            서울      인천      원주    울릉도      수원      서산      청주\n북춘천 0.8950700 0.8800897 0.8872143 0.7704594 0.8874207 0.8556697 0.8385589\n철원   0.8924032 0.8835704 0.8569986 0.7315194 0.8752317 0.8328024 0.7952847\n대관령 0.7847346 0.7856758 0.8560494 0.8082114 0.8148757 0.8056768 0.8303327\n춘천   0.8949421 0.8882261 0.8929441 0.7743434 0.8901672 0.8537852 0.8424993\n백령도 0.7550764 0.8258567 0.7108456 0.6521670 0.7720289 0.7760450 0.6970798\n북강릉 0.7454717 0.7636879 0.8249637 0.7894544 0.8001409 0.8033033 0.8232442\n강릉   0.7273539 0.7440307 0.8188935 0.7815274 0.7849799 0.7865161 0.8103833\n서울   1.0000000 0.9075920 0.8646234 0.7231200 0.9213448 0.8626228 0.8254537\n인천   0.9075920 1.0000000 0.8509204 0.7632528 0.9223731 0.8986444 0.8269454\n원주   0.8646234 0.8509204 1.0000000 0.8019892 0.9057287 0.8812039 0.9057582\n울릉도 0.7231200 0.7632528 0.8019892 1.0000000 0.7821390 0.7987002 0.8197666\n수원   0.9213448 0.9223731 0.9057287 0.7821390 1.0000000 0.9163459 0.8879367\n서산   0.8626228 0.8986444 0.8812039 0.7987002 0.9163459 1.0000000 0.8905734\n청주   0.8254537 0.8269454 0.9057582 0.8197666 0.8879367 0.8905734 1.0000000\n대전   0.8045725 0.8240112 0.8921154 0.8343263 0.8816110 0.8829204 0.9486995\n추풍령 0.7571073 0.7953719 0.8589197 0.8465245 0.8251923 0.8463974 0.8900001\n안동   0.7717312 0.7974855 0.8795653 0.8593971 0.8356330 0.8580419 0.8862872\n포항   0.7042770 0.7505359 0.8023670 0.8361979 0.7667115 0.7941330 0.8029933\n대구   0.7576377 0.7890054 0.8437847 0.8450632 0.8165979 0.8348965 0.8630802\n전주   0.7748940 0.8033923 0.8632212 0.8252344 0.8448909 0.8584521 0.8983073\n창원   0.7247798 0.7830687 0.7971585 0.8259602 0.7792334 0.8166273 0.8198843\n광주   0.7739573 0.8073761 0.8446152 0.8193953 0.8321581 0.8281263 0.8445766\n부산   0.7267366 0.7778564 0.7958301 0.8360944 0.7831722 0.8081823 0.8148162\n목포   0.7478112 0.8103706 0.8180612 0.8134798 0.8149547 0.8289395 0.8357523\n여수   0.7349063 0.7940036 0.7974536 0.7961611 0.7877397 0.8167997 0.8180792\n흑산도 0.6552938 0.7395035 0.7256981 0.7191936 0.7220583 0.7343682 0.7345308\n고창   0.7879034 0.8287633 0.8556922 0.8152044 0.8509336 0.8473799 0.8692871\n홍성   0.8330907 0.8666585 0.8803434 0.8043420 0.9070247 0.9427536 0.9097292\n제주   0.6861377 0.7332443 0.7586948 0.7716114 0.7399087 0.7498616 0.7802089\n고산   0.7263294 0.7748388 0.7768463 0.7604723 0.7770638 0.8005828 0.7814763\n진주   0.7308675 0.7888453 0.7960395 0.8199835 0.7883279 0.8181453 0.8278888\n고창군 0.7714615 0.8081741 0.8422706 0.8120771 0.8388608 0.8349858 0.8672080\n영광군 0.7856545 0.8316109 0.8459192 0.8131154 0.8498038 0.8479766 0.8607596\n김해시 0.7236723 0.7728616 0.7922322 0.8255345 0.7753970 0.8028617 0.8160600\n순창군 0.7633988 0.8040841 0.8549898 0.8211330 0.8269799 0.8390306 0.8712681\n북창원 0.7081317 0.7577317 0.7846845 0.8244524 0.7692072 0.7915682 0.8033833\n양산시 0.7207425 0.7714622 0.8019474 0.8331000 0.7798549 0.8049897 0.8273837\n보성군 0.7444682 0.8050190 0.8163243 0.8030997 0.7995106 0.8202220 0.8323769\n강진군 0.7393374 0.7913684 0.8057927 0.7934253 0.7926109 0.8054050 0.8284883\n의령군 0.7339333 0.7843832 0.8087071 0.8208664 0.7939649 0.8222798 0.8281865\n함양군 0.7462599 0.8018908 0.8273505 0.8157783 0.8106388 0.8266867 0.8536444\n광양시 0.7377343 0.7872414 0.8045165 0.8008060 0.7862616 0.8210310 0.8229320\n청송군 0.7584576 0.7806169 0.8600399 0.8482331 0.8099745 0.8349700 0.8643311\n경주시 0.6983266 0.7461917 0.7949394 0.8493105 0.7643184 0.7892714 0.8193505\n            대전    추풍령      안동      포항      대구      전주      창원\n북춘천 0.8205476 0.8054751 0.8200709 0.7386050 0.8018833 0.7914907 0.7677539\n철원   0.7818135 0.7651683 0.7757717 0.6991403 0.7701624 0.7559699 0.7281557\n대관령 0.8328943 0.8508011 0.8725204 0.8149746 0.8509044 0.8141969 0.8072301\n춘천   0.8259461 0.8146245 0.8300229 0.7490307 0.8107771 0.7978513 0.7734440\n백령도 0.7084518 0.7122229 0.7108366 0.6685757 0.7136175 0.6981081 0.7016747\n북강릉 0.8350131 0.8579585 0.8765078 0.8136745 0.8393632 0.8135504 0.7918266\n강릉   0.8162185 0.8441442 0.8661848 0.8092740 0.8251724 0.8015528 0.7841383\n서울   0.8045725 0.7571073 0.7717312 0.7042770 0.7576377 0.7748940 0.7247798\n인천   0.8240112 0.7953719 0.7974855 0.7505359 0.7890054 0.8033923 0.7830687\n원주   0.8921154 0.8589197 0.8795653 0.8023670 0.8437847 0.8632212 0.7971585\n울릉도 0.8343263 0.8465245 0.8593971 0.8361979 0.8450632 0.8252344 0.8259602\n수원   0.8816110 0.8251923 0.8356330 0.7667115 0.8165979 0.8448909 0.7792334\n서산   0.8829204 0.8463974 0.8580419 0.7941330 0.8348965 0.8584521 0.8166273\n청주   0.9486995 0.8900001 0.8862872 0.8029933 0.8630802 0.8983073 0.8198843\n대전   1.0000000 0.9098683 0.9015920 0.8296473 0.8830189 0.9204478 0.8347075\n추풍령 0.9098683 1.0000000 0.9365251 0.8827398 0.9233093 0.9043161 0.8881992\n안동   0.9015920 0.9365251 1.0000000 0.8922194 0.9206489 0.8888517 0.8794029\n포항   0.8296473 0.8827398 0.8922194 1.0000000 0.9034339 0.8335295 0.8729290\n대구   0.8830189 0.9233093 0.9206489 0.9034339 1.0000000 0.8841454 0.8916763\n전주   0.9204478 0.9043161 0.8888517 0.8335295 0.8841454 1.0000000 0.8483948\n창원   0.8347075 0.8881992 0.8794029 0.8729290 0.8916763 0.8483948 1.0000000\n광주   0.8746174 0.8867724 0.8797247 0.8500506 0.8808628 0.8965916 0.8723064\n부산   0.8393909 0.8858477 0.8761437 0.8706890 0.8902296 0.8564861 0.9429673\n목포   0.8642342 0.8652835 0.8533657 0.8264468 0.8591882 0.8700797 0.8739730\n여수   0.8291913 0.8758193 0.8675713 0.8477752 0.8703658 0.8537832 0.9172569\n흑산도 0.7473720 0.7679495 0.7630965 0.7262026 0.7383266 0.7471554 0.7886034\n고창   0.8900549 0.8813530 0.8800252 0.8332067 0.8714397 0.9086480 0.8651831\n홍성   0.9088735 0.8668802 0.8753952 0.8005149 0.8551211 0.8877977 0.8279025\n제주   0.7987814 0.8257396 0.8185776 0.8223840 0.8268896 0.8268862 0.8549883\n고산   0.7936877 0.8151624 0.8144313 0.7934415 0.8233033 0.8145462 0.8547772\n진주   0.8516335 0.8975177 0.8840588 0.8852573 0.9035810 0.8680514 0.9427169\n고창군 0.8957219 0.8898195 0.8831837 0.8265669 0.8738866 0.9186668 0.8483286\n영광군 0.8864233 0.8809810 0.8810531 0.8338475 0.8700861 0.9009446 0.8611013\n김해시 0.8415806 0.8854048 0.8837789 0.8706466 0.8926102 0.8597856 0.9468391\n순창군 0.8945274 0.9099243 0.8964970 0.8598803 0.8901746 0.9149830 0.8782432\n북창원 0.8323037 0.8826900 0.8832442 0.8802007 0.8933316 0.8506911 0.9507297\n양산시 0.8475328 0.8896409 0.8873669 0.8809988 0.9013496 0.8658630 0.9281826\n보성군 0.8534116 0.8921199 0.8800365 0.8559252 0.8776948 0.8671916 0.9094639\n강진군 0.8493000 0.8715725 0.8515353 0.8246902 0.8614979 0.8697880 0.8881013\n의령군 0.8547670 0.9064907 0.8953835 0.8982696 0.9226218 0.8741468 0.9395316\n함양군 0.8795260 0.9291810 0.9003307 0.8722584 0.9216866 0.8962253 0.8972223\n광양시 0.8461150 0.8763813 0.8666471 0.8563776 0.8782183 0.8557069 0.9128519\n청송군 0.8772535 0.9246171 0.9406354 0.9028637 0.9277331 0.8708771 0.8683750\n경주시 0.8424846 0.9006323 0.9027053 0.9340652 0.9119640 0.8421247 0.8871906\n            광주      부산      목포      여수    흑산도      고창      홍성\n북춘천 0.7976445 0.7648912 0.7773332 0.7743994 0.7123329 0.8024093 0.8336545\n철원   0.7670324 0.7353604 0.7462521 0.7431887 0.6867806 0.7763503 0.8060729\n대관령 0.8050528 0.8043715 0.7845163 0.8001751 0.6944630 0.7934771 0.8045889\n춘천   0.8036054 0.7685058 0.7841523 0.7801829 0.7273620 0.8111590 0.8370223\n백령도 0.6888886 0.6958218 0.7278852 0.7207816 0.6976910 0.7106546 0.7500782\n북강릉 0.7896031 0.7925060 0.7709153 0.7854621 0.6772559 0.7821426 0.8107383\n강릉   0.7803357 0.7844037 0.7606503 0.7787742 0.6777030 0.7751184 0.7971153\n서울   0.7739573 0.7267366 0.7478112 0.7349063 0.6552938 0.7879034 0.8330907\n인천   0.8073761 0.7778564 0.8103706 0.7940036 0.7395035 0.8287633 0.8666585\n원주   0.8446152 0.7958301 0.8180612 0.7974536 0.7256981 0.8556922 0.8803434\n울릉도 0.8193953 0.8360944 0.8134798 0.7961611 0.7191936 0.8152044 0.8043420\n수원   0.8321581 0.7831722 0.8149547 0.7877397 0.7220583 0.8509336 0.9070247\n서산   0.8281263 0.8081823 0.8289395 0.8167997 0.7343682 0.8473799 0.9427536\n청주   0.8445766 0.8148162 0.8357523 0.8180792 0.7345308 0.8692871 0.9097292\n대전   0.8746174 0.8393909 0.8642342 0.8291913 0.7473720 0.8900549 0.9088735\n추풍령 0.8867724 0.8858477 0.8652835 0.8758193 0.7679495 0.8813530 0.8668802\n안동   0.8797247 0.8761437 0.8533657 0.8675713 0.7630965 0.8800252 0.8753952\n포항   0.8500506 0.8706890 0.8264468 0.8477752 0.7262026 0.8332067 0.8005149\n대구   0.8808628 0.8902296 0.8591882 0.8703658 0.7383266 0.8714397 0.8551211\n전주   0.8965916 0.8564861 0.8700797 0.8537832 0.7471554 0.9086480 0.8877977\n창원   0.8723064 0.9429673 0.8739730 0.9172569 0.7886034 0.8651831 0.8279025\n광주   1.0000000 0.8732003 0.9157749 0.8895559 0.7814886 0.9354455 0.8531884\n부산   0.8732003 1.0000000 0.8621138 0.9165923 0.7820822 0.8639897 0.8157479\n목포   0.9157749 0.8621138 1.0000000 0.8833737 0.8154017 0.9200889 0.8453949\n여수   0.8895559 0.9165923 0.8833737 1.0000000 0.7975344 0.8736097 0.8213940\n흑산도 0.7814886 0.7820822 0.8154017 0.7975344 1.0000000 0.7993913 0.7365425\n고창   0.9354455 0.8639897 0.9200889 0.8736097 0.7993913 1.0000000 0.8711755\n홍성   0.8531884 0.8157479 0.8453949 0.8213940 0.7365425 0.8711755 1.0000000\n제주   0.8476692 0.8576752 0.8658086 0.8720765 0.7867144 0.8556978 0.7698267\n고산   0.8480616 0.8516989 0.8664310 0.8794714 0.7921233 0.8455374 0.7997860\n진주   0.8865481 0.9279030 0.8861643 0.9326409 0.7919127 0.8743341 0.8303011\n고창군 0.9336594 0.8513728 0.9067398 0.8658611 0.7750135 0.9616551 0.8702387\n영광군 0.9266217 0.8529821 0.9269081 0.8750576 0.7970334 0.9685725 0.8683728\n김해시 0.8639842 0.9442335 0.8517550 0.8991979 0.7635417 0.8599489 0.8224136\n순창군 0.9400263 0.8695631 0.9051394 0.8847313 0.7714842 0.9205238 0.8670029\n북창원 0.8713733 0.9262085 0.8611224 0.8986114 0.7559678 0.8587244 0.8096372\n양산시 0.8755878 0.9429008 0.8526661 0.8963623 0.7612346 0.8621316 0.8248143\n보성군 0.9117329 0.9017522 0.9182132 0.9366141 0.8159366 0.9013144 0.8383405\n강진군 0.9106757 0.8849763 0.9227550 0.9007305 0.7964077 0.8966640 0.8358259\n의령군 0.8867536 0.9204740 0.8811090 0.9176473 0.7732670 0.8783607 0.8335250\n함양군 0.8970065 0.8888454 0.8860737 0.8978821 0.7782743 0.8958516 0.8510965\n광양시 0.8923604 0.9044805 0.8900917 0.9301530 0.7910290 0.8787261 0.8276023\n청송군 0.8642843 0.8705428 0.8407307 0.8614996 0.7295021 0.8636560 0.8477039\n경주시 0.8495704 0.8885324 0.8310113 0.8502685 0.7418715 0.8396705 0.8110217\n            제주      고산      진주    고창군    영광군    김해시    순창군\n북춘천 0.7231531 0.7570940 0.7608540 0.7909242 0.7957767 0.7583464 0.8039828\n철원   0.7027542 0.7433290 0.7271996 0.7534505 0.7688266 0.7248262 0.7621579\n대관령 0.7515182 0.7518443 0.8106935 0.7984340 0.7994055 0.7980189 0.8247022\n춘천   0.7307226 0.7627983 0.7731004 0.7971632 0.8030415 0.7610443 0.8113552\n백령도 0.7003067 0.7430247 0.7254829 0.6992467 0.7191916 0.7041355 0.6955489\n북강릉 0.7406647 0.7366984 0.8018893 0.7928961 0.7870528 0.7870968 0.8163301\n강릉   0.7400761 0.7329499 0.7947315 0.7782792 0.7791394 0.7798474 0.8020242\n서울   0.6861377 0.7263294 0.7308675 0.7714615 0.7856545 0.7236723 0.7633988\n인천   0.7332443 0.7748388 0.7888453 0.8081741 0.8316109 0.7728616 0.8040841\n원주   0.7586948 0.7768463 0.7960395 0.8422706 0.8459192 0.7922322 0.8549898\n울릉도 0.7716114 0.7604723 0.8199835 0.8120771 0.8131154 0.8255345 0.8211330\n수원   0.7399087 0.7770638 0.7883279 0.8388608 0.8498038 0.7753970 0.8269799\n서산   0.7498616 0.8005828 0.8181453 0.8349858 0.8479766 0.8028617 0.8390306\n청주   0.7802089 0.7814763 0.8278888 0.8672080 0.8607596 0.8160600 0.8712681\n대전   0.7987814 0.7936877 0.8516335 0.8957219 0.8864233 0.8415806 0.8945274\n추풍령 0.8257396 0.8151624 0.8975177 0.8898195 0.8809810 0.8854048 0.9099243\n안동   0.8185776 0.8144313 0.8840588 0.8831837 0.8810531 0.8837789 0.8964970\n포항   0.8223840 0.7934415 0.8852573 0.8265669 0.8338475 0.8706466 0.8598803\n대구   0.8268896 0.8233033 0.9035810 0.8738866 0.8700861 0.8926102 0.8901746\n전주   0.8268862 0.8145462 0.8680514 0.9186668 0.9009446 0.8597856 0.9149830\n창원   0.8549883 0.8547772 0.9427169 0.8483286 0.8611013 0.9468391 0.8782432\n광주   0.8476692 0.8480616 0.8865481 0.9336594 0.9266217 0.8639842 0.9400263\n부산   0.8576752 0.8516989 0.9279030 0.8513728 0.8529821 0.9442335 0.8695631\n목포   0.8658086 0.8664310 0.8861643 0.9067398 0.9269081 0.8517550 0.9051394\n여수   0.8720765 0.8794714 0.9326409 0.8658611 0.8750576 0.8991979 0.8847313\n흑산도 0.7867144 0.7921233 0.7919127 0.7750135 0.7970334 0.7635417 0.7714842\n고창   0.8556978 0.8455374 0.8743341 0.9616551 0.9685725 0.8599489 0.9205238\n홍성   0.7698267 0.7997860 0.8303011 0.8702387 0.8683728 0.8224136 0.8670029\n제주   1.0000000 0.9195808 0.8697841 0.8412573 0.8553558 0.8460066 0.8418199\n고산   0.9195808 1.0000000 0.8622230 0.8281943 0.8456323 0.8363460 0.8351040\n진주   0.8697841 0.8622230 1.0000000 0.8672805 0.8770496 0.9161676 0.8916136\n고창군 0.8412573 0.8281943 0.8672805 1.0000000 0.9477629 0.8470734 0.9250342\n영광군 0.8553558 0.8456323 0.8770496 0.9477629 1.0000000 0.8488160 0.9106999\n김해시 0.8460066 0.8363460 0.9161676 0.8470734 0.8488160 1.0000000 0.8619900\n순창군 0.8418199 0.8351040 0.8916136 0.9250342 0.9106999 0.8619900 1.0000000\n북창원 0.8450125 0.8360490 0.9275843 0.8497099 0.8553942 0.9493347 0.8669589\n양산시 0.8418934 0.8314934 0.9101115 0.8572362 0.8557748 0.9480916 0.8763272\n보성군 0.8763200 0.8676251 0.9268251 0.8916869 0.9010706 0.8973596 0.9106348\n강진군 0.8679866 0.8582782 0.9064303 0.8925974 0.8940679 0.8763283 0.9055372\n의령군 0.8609871 0.8542850 0.9535980 0.8669814 0.8795171 0.9199973 0.8933512\n함양군 0.8537192 0.8395477 0.9227285 0.8936943 0.8980794 0.8896860 0.9208994\n광양시 0.8532900 0.8627387 0.9418029 0.8693560 0.8755298 0.8983077 0.9028231\n청송군 0.8197153 0.8090522 0.8805750 0.8644057 0.8578779 0.8703752 0.8884814\n경주시 0.8283827 0.7949522 0.8895716 0.8421892 0.8385824 0.8984183 0.8601992\n          북창원    양산시    보성군    강진군    의령군    함양군    광양시\n북춘천 0.7398331 0.7625488 0.7813081 0.7680688 0.7724214 0.7900454 0.7703746\n철원   0.7029672 0.7264823 0.7540613 0.7439198 0.7320323 0.7515202 0.7386150\n대관령 0.7982610 0.8143695 0.8047406 0.7763671 0.8178428 0.8253053 0.8029972\n춘천   0.7474691 0.7670135 0.7941714 0.7770252 0.7799025 0.7970284 0.7790557\n백령도 0.6834564 0.6812135 0.7278349 0.7125364 0.7142109 0.7309059 0.7161589\n북강릉 0.7921148 0.8050859 0.7952688 0.7592658 0.8192187 0.8240476 0.7808741\n강릉   0.7894190 0.7950266 0.7871637 0.7518227 0.8131759 0.8145880 0.7752086\n서울   0.7081317 0.7207425 0.7444682 0.7393374 0.7339333 0.7462599 0.7377343\n인천   0.7577317 0.7714622 0.8050190 0.7913684 0.7843832 0.8018908 0.7872414\n원주   0.7846845 0.8019474 0.8163243 0.8057927 0.8087071 0.8273505 0.8045165\n울릉도 0.8244524 0.8331000 0.8030997 0.7934253 0.8208664 0.8157783 0.8008060\n수원   0.7692072 0.7798549 0.7995106 0.7926109 0.7939649 0.8106388 0.7862616\n서산   0.7915682 0.8049897 0.8202220 0.8054050 0.8222798 0.8266867 0.8210310\n청주   0.8033833 0.8273837 0.8323769 0.8284883 0.8281865 0.8536444 0.8229320\n대전   0.8323037 0.8475328 0.8534116 0.8493000 0.8547670 0.8795260 0.8461150\n추풍령 0.8826900 0.8896409 0.8921199 0.8715725 0.9064907 0.9291810 0.8763813\n안동   0.8832442 0.8873669 0.8800365 0.8515353 0.8953835 0.9003307 0.8666471\n포항   0.8802007 0.8809988 0.8559252 0.8246902 0.8982696 0.8722584 0.8563776\n대구   0.8933316 0.9013496 0.8776948 0.8614979 0.9226218 0.9216866 0.8782183\n전주   0.8506911 0.8658630 0.8671916 0.8697880 0.8741468 0.8962253 0.8557069\n창원   0.9507297 0.9281826 0.9094639 0.8881013 0.9395316 0.8972223 0.9128519\n광주   0.8713733 0.8755878 0.9117329 0.9106757 0.8867536 0.8970065 0.8923604\n부산   0.9262085 0.9429008 0.9017522 0.8849763 0.9204740 0.8888454 0.9044805\n목포   0.8611224 0.8526661 0.9182132 0.9227550 0.8811090 0.8860737 0.8900917\n여수   0.8986114 0.8963623 0.9366141 0.9007305 0.9176473 0.8978821 0.9301530\n흑산도 0.7559678 0.7612346 0.8159366 0.7964077 0.7732670 0.7782743 0.7910290\n고창   0.8587244 0.8621316 0.9013144 0.8966640 0.8783607 0.8958516 0.8787261\n홍성   0.8096372 0.8248143 0.8383405 0.8358259 0.8335250 0.8510965 0.8276023\n제주   0.8450125 0.8418934 0.8763200 0.8679866 0.8609871 0.8537192 0.8532900\n고산   0.8360490 0.8314934 0.8676251 0.8582782 0.8542850 0.8395477 0.8627387\n진주   0.9275843 0.9101115 0.9268251 0.9064303 0.9535980 0.9227285 0.9418029\n고창군 0.8497099 0.8572362 0.8916869 0.8925974 0.8669814 0.8936943 0.8693560\n영광군 0.8553942 0.8557748 0.9010706 0.8940679 0.8795171 0.8980794 0.8755298\n김해시 0.9493347 0.9480916 0.8973596 0.8763283 0.9199973 0.8896860 0.8983077\n순창군 0.8669589 0.8763272 0.9106348 0.9055372 0.8933512 0.9208994 0.9028231\n북창원 1.0000000 0.9342488 0.8970792 0.8690147 0.9267859 0.8959904 0.9000617\n양산시 0.9342488 1.0000000 0.8886278 0.8673042 0.9173862 0.8899850 0.8877185\n보성군 0.8970792 0.8886278 1.0000000 0.9382588 0.9091896 0.9124610 0.9362963\n강진군 0.8690147 0.8673042 0.9382588 1.0000000 0.8893186 0.8950000 0.9144887\n의령군 0.9267859 0.9173862 0.9091896 0.8893186 1.0000000 0.9275468 0.9197782\n함양군 0.8959904 0.8899850 0.9124610 0.8950000 0.9275468 1.0000000 0.8975226\n광양시 0.9000617 0.8877185 0.9362963 0.9144887 0.9197782 0.8975226 1.0000000\n청송군 0.8780949 0.8796186 0.8632409 0.8436956 0.8927085 0.9011481 0.8683635\n경주시 0.9005268 0.9061114 0.8588689 0.8344361 0.9032779 0.8871879 0.8602823\n          청송군    경주시\n북춘천 0.8006122 0.7428165\n철원   0.7594425 0.7006137\n대관령 0.8662752 0.8264038\n춘천   0.8104820 0.7464970\n백령도 0.6905146 0.6746425\n북강릉 0.8505242 0.8282642\n강릉   0.8409919 0.8187796\n서울   0.7584576 0.6983266\n인천   0.7806169 0.7461917\n원주   0.8600399 0.7949394\n울릉도 0.8482331 0.8493105\n수원   0.8099745 0.7643184\n서산   0.8349700 0.7892714\n청주   0.8643311 0.8193505\n대전   0.8772535 0.8424846\n추풍령 0.9246171 0.9006323\n안동   0.9406354 0.9027053\n포항   0.9028637 0.9340652\n대구   0.9277331 0.9119640\n전주   0.8708771 0.8421247\n창원   0.8683750 0.8871906\n광주   0.8642843 0.8495704\n부산   0.8705428 0.8885324\n목포   0.8407307 0.8310113\n여수   0.8614996 0.8502685\n흑산도 0.7295021 0.7418715\n고창   0.8636560 0.8396705\n홍성   0.8477039 0.8110217\n제주   0.8197153 0.8283827\n고산   0.8090522 0.7949522\n진주   0.8805750 0.8895716\n고창군 0.8644057 0.8421892\n영광군 0.8578779 0.8385824\n김해시 0.8703752 0.8984183\n순창군 0.8884814 0.8601992\n북창원 0.8780949 0.9005268\n양산시 0.8796186 0.9061114\n보성군 0.8632409 0.8588689\n강진군 0.8436956 0.8344361\n의령군 0.8927085 0.9032779\n함양군 0.9011481 0.8871879\n광양시 0.8683635 0.8602823\n청송군 1.0000000 0.9109886\n경주시 0.9109886 1.0000000\n\n\n\n%%R\nwrite.csv(weight, './data2/weight.csv', row.names=FALSE)"
  },
  {
    "objectID": "posts/SOLAR/2023-04-14-데이터수정2.html#ept-weight",
    "href": "posts/SOLAR/2023-04-14-데이터수정2.html#ept-weight",
    "title": "[SOLAR] Crate Dataset (data2: 22/06~22/09/15) 재수정",
    "section": "EPT Weight",
    "text": "EPT Weight\n\n# train = pd.read_csv('./data2/train.csv')\n\n\ntrain.duplicated().sum()\n\n0\n\n\n\n%R -i train\n\n\n%%R\nlibrary(EPT)\ntrain%>%head()\n\n  region solar_radiation             date\n0 북춘천               0 2022-06-01-00:00\n1 북춘천               0 2022-06-01-01:00\n2 북춘천               0 2022-06-01-02:00\n3 북춘천               0 2022-06-01-03:00\n4 북춘천               0 2022-06-01-04:00\n5 북춘천               0 2022-06-01-05:00\n\n\n\n%%R\nhead(train)\n\n  region solar_radiation             date\n0 북춘천               0 2022-06-01-00:00\n1 북춘천               0 2022-06-01-01:00\n2 북춘천               0 2022-06-01-02:00\n3 북춘천               0 2022-06-01-03:00\n4 북춘천               0 2022-06-01-04:00\n5 북춘천               0 2022-06-01-05:00\n\n\n\nPlot\n\n%%R\nfor (i in 1:44){\n     assign(paste0('data',1:44)[i],train |> filter(region == unique(train$region)[i]))\n     assign(paste0('data',1:44)[i],eval(parse(text=paste0('data',i)))[order(eval(parse(text=paste0('data',i)))$date),])\n     assign(paste0('y',1:44)[i], eval(parse(text=paste0('data',i)))$solar_radiation)\n}\n\n\n%%R\nfor (i in 1:44){\n    plot(eval(parse(text=paste0('y',i)))[1:500], ann=FALSE)\n    lines(eval(parse(text=paste0('y',i))),lty=2)\n    title(main = as.character(unique(train$region)[i]), xlab='time', ylab='solar radiation')\n    }\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEPT 수행\n\n%%R\nept = function(y){\n    EpM = eptransf(signal=y,tau=24,process=c(\"envelope\",\"average\"))$EpM\n    EpM*2\n}\n\n\n%%R\nlibrary(tictoc)\n\n\n%%R\ntic('지역별 yU계산')\nfor (i in 1:44){\n    assign(paste0('yU',1:44)[i], ept(eval(parse(text=paste0('y',i)))))\n}\ntoc()\n\n지역별 yU계산: 36.685 sec elapsed\n\n\n\n\nyU저장\n\n%%R\ndf_yU = do.call(cbind.data.frame, mget(paste0('yU', 1:44)))\n\n\n%%R\nwrite.csv(df_yU, './data2/df_yU.csv', row.names=FALSE)\n\n\n\n시각화\n\n%%R\nfor (i in 1:44){\n    plot(eval(parse(text=paste0('y',i)))[1:500], ann=FALSE)\n    lines(eval(parse(text=paste0('yU',i))),col = 2, lty=2)\n    title(main = as.character(unique(train$region)[i]), xlab='time', ylab='solar radiation')\n    }\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nyU Correlation\n\n%%R\nyU_cor = cor(df_yU)\n\n\n%%R\nyU_cor\n\n            yU1         yU2       yU3         yU4          yU5        yU6\nyU1  1.00000000  0.90775910 0.7410688 0.968835371  0.504767766 0.54452498\nyU2  0.90775910  1.00000000 0.5995099 0.920283238  0.588439418 0.41432764\nyU3  0.74106883  0.59950994 1.0000000 0.700021249  0.310621027 0.78033865\nyU4  0.96883537  0.92028324 0.7000212 1.000000000  0.529554560 0.52248673\nyU5  0.50476777  0.58843942 0.3106210 0.529554560  1.000000000 0.27819568\nyU6  0.54452498  0.41432764 0.7803386 0.522486733  0.278195680 1.00000000\nyU7  0.52782957  0.37153463 0.7775066 0.502420616  0.267958934 0.95130756\nyU8  0.80317249  0.91037825 0.5162182 0.813706373  0.528584187 0.35387659\nyU9  0.78148908  0.82619797 0.5349395 0.789274805  0.602470083 0.43238790\nyU10 0.71236612  0.64618170 0.5924253 0.701559439  0.239231085 0.53176559\nyU11 0.40966242  0.25357829 0.4838832 0.348824808  0.063568789 0.43725603\nyU12 0.78168589  0.76314244 0.5909334 0.764093689  0.447390084 0.51911409\nyU13 0.69722809  0.63893738 0.5562688 0.692851200  0.486729906 0.52750416\nyU14 0.56511801  0.45512196 0.5317052 0.524881856  0.172912168 0.44486957\nyU15 0.51975666  0.37317078 0.5847341 0.472781870  0.128757263 0.55452054\nyU16 0.45020976  0.29543776 0.6140391 0.438930923  0.161347344 0.65425019\nyU17 0.43643251  0.25340597 0.5903495 0.429042444  0.139228151 0.67352395\nyU18 0.22287421  0.08746853 0.4595471 0.192243042 -0.020043098 0.54197387\nyU19 0.40394201  0.26852631 0.5718450 0.387737272  0.158222258 0.60330342\nyU20 0.47455999  0.31447467 0.5657679 0.459768064  0.112960354 0.59604673\nyU21 0.35636263  0.28202400 0.4689127 0.351416353  0.174225413 0.46984754\nyU22 0.39991461  0.28721421 0.4632177 0.401462077  0.019002407 0.40549734\nyU23 0.33798984  0.23583037 0.4722500 0.327170903  0.145187229 0.47365684\nyU24 0.27421886  0.13661864 0.3212673 0.254428887  0.026106882 0.30865940\nyU25 0.32737641  0.24074037 0.4180409 0.333576758  0.219790469 0.40093996\nyU26 0.27743171  0.19066581 0.1967089 0.280553941  0.072975929 0.05580331\nyU27 0.37820546  0.28298612 0.3416627 0.373474297  0.051198524 0.32953114\nyU28 0.59876567  0.51040062 0.5300233 0.595395800  0.387314115 0.53671082\nyU29 0.01428798 -0.09343514 0.1573000 0.002335548 -0.056298868 0.21712103\nyU30 0.28012789  0.19681539 0.1717752 0.272193082  0.205226080 0.13921043\nyU31 0.27232483  0.18062928 0.4415774 0.283894690  0.194802134 0.47441819\nyU32 0.29717750  0.15641896 0.3920511 0.277458761 -0.048467789 0.39048693\nyU33 0.32433842  0.21118893 0.3541936 0.311127591  0.018666929 0.38122969\nyU34 0.20040000  0.11883252 0.3469145 0.184572596  0.087854264 0.42109479\nyU35 0.41834108  0.27507059 0.5868387 0.415588218  0.071753366 0.54213129\nyU36 0.19151939  0.09303279 0.3656745 0.171920055 -0.009870691 0.43933214\nyU37 0.31964146  0.21956265 0.4710210 0.284502126  0.067305026 0.46008021\nyU38 0.25250786  0.13972726 0.3847394 0.267682183  0.013872502 0.36681762\nyU39 0.26007425  0.15935117 0.3754509 0.255426392  0.007623380 0.33293784\nyU40 0.25335131  0.14927358 0.4343121 0.242377777  0.181098810 0.52087677\nyU41 0.33313990  0.20512096 0.4979875 0.309198725  0.136946318 0.55648726\nyU42 0.31792262  0.23432429 0.4303973 0.338496743  0.154094281 0.42978366\nyU43 0.48956813  0.32884176 0.6418807 0.479545234  0.147007636 0.66645405\nyU44 0.24175868  0.10990556 0.4938605 0.196056293  0.036087981 0.58167912\n            yU7         yU8        yU9      yU10       yU11      yU12      yU13\nyU1  0.52782957  0.80317249 0.78148908 0.7123661 0.40966242 0.7816859 0.6972281\nyU2  0.37153463  0.91037825 0.82619797 0.6461817 0.25357829 0.7631424 0.6389374\nyU3  0.77750662  0.51621823 0.53493947 0.5924253 0.48388316 0.5909334 0.5562688\nyU4  0.50242062  0.81370637 0.78927481 0.7015594 0.34882481 0.7640937 0.6928512\nyU5  0.26795893  0.52858419 0.60247008 0.2392311 0.06356879 0.4473901 0.4867299\nyU6  0.95130756  0.35387659 0.43238790 0.5317656 0.43725603 0.5191141 0.5275042\nyU7  1.00000000  0.31178892 0.40514646 0.5038555 0.40703223 0.4649312 0.4733705\nyU8  0.31178892  1.00000000 0.85925393 0.7124927 0.24354011 0.8589443 0.7196879\nyU9  0.40514646  0.85925393 1.00000000 0.6677252 0.32863018 0.8576563 0.8308759\nyU10 0.50385545  0.71249274 0.66772521 1.0000000 0.43933329 0.8209003 0.7613887\nyU11 0.40703223  0.24354011 0.32863018 0.4393333 1.00000000 0.3979970 0.3842810\nyU12 0.46493122  0.85894429 0.85765628 0.8209003 0.39799703 1.0000000 0.8647603\nyU13 0.47337047  0.71968790 0.83087586 0.7613887 0.38428102 0.8647603 1.0000000\nyU14 0.39403244  0.55996027 0.58517952 0.8086018 0.50575578 0.8047386 0.7734068\nyU15 0.47280578  0.45377894 0.50942512 0.7438777 0.54581862 0.7299160 0.7238840\nyU16 0.59401759  0.30028230 0.41560578 0.6096355 0.55080422 0.5430776 0.6207888\nyU17 0.62466811  0.26078630 0.34754627 0.6581154 0.56987869 0.5232409 0.6114107\nyU18 0.54039139  0.12183264 0.27951265 0.4594921 0.54399687 0.3484956 0.4663317\nyU19 0.52975433  0.30335332 0.41676124 0.5871081 0.56491750 0.5408127 0.6233692\nyU20 0.55069523  0.37970191 0.49934682 0.6642367 0.56117115 0.6021437 0.6870959\nyU21 0.42350580  0.25280884 0.43371333 0.3784125 0.46411286 0.4025754 0.5288207\nyU22 0.38431158  0.29930408 0.39180729 0.5128730 0.53009909 0.4509522 0.4528984\nyU23 0.41901735  0.20732104 0.37705818 0.3530144 0.51670421 0.3602302 0.4784037\nyU24 0.29531737  0.13365159 0.28964034 0.3669106 0.46629680 0.3745715 0.4024707\nyU25 0.36482287  0.23230502 0.38964337 0.3469125 0.31803460 0.3591472 0.4809163\nyU26 0.06836123  0.09138485 0.25796954 0.2756727 0.26396326 0.2035513 0.3213771\nyU27 0.30193851  0.34037797 0.46126222 0.6402589 0.52869539 0.5392883 0.5583534\nyU28 0.47146085  0.58452211 0.69651927 0.7240816 0.37460521 0.8184629 0.8972789\nyU29 0.22029400 -0.05335386 0.02605197 0.1065278 0.20594558 0.0628074 0.1064381\nyU30 0.15150885  0.20837519 0.27242316 0.1670479 0.21245168 0.2789485 0.3490941\nyU31 0.45827282  0.18191834 0.37094840 0.3481627 0.38238798 0.3427293 0.4964805\nyU32 0.34802006  0.22387067 0.32007523 0.5440963 0.48448973 0.4811179 0.4563504\nyU33 0.34783702  0.30165558 0.42630422 0.5932908 0.49406651 0.5193567 0.5421084\nyU34 0.38447020  0.11987159 0.30172620 0.3056811 0.47271377 0.3130486 0.4300045\nyU35 0.48570315  0.28790898 0.40244516 0.5858554 0.51585318 0.4972777 0.5413888\nyU36 0.38858298  0.11590447 0.29137042 0.3262493 0.49551878 0.3033549 0.4071978\nyU37 0.43196822  0.23940933 0.42117141 0.3931647 0.54702081 0.4301815 0.5119400\nyU38 0.33777557  0.16315804 0.30097317 0.3941636 0.32532134 0.3529404 0.4453401\nyU39 0.30960613  0.14003597 0.30511453 0.3404313 0.32406536 0.3297861 0.4018333\nyU40 0.49694645  0.14929986 0.36216107 0.3673422 0.45054096 0.3734297 0.5220294\nyU41 0.50773465  0.23182140 0.39179183 0.4767100 0.45651961 0.4685148 0.5346194\nyU42 0.40176439  0.22786287 0.36078890 0.4536437 0.36367201 0.3825937 0.5134173\nyU43 0.62647090  0.33985543 0.44316038 0.5925562 0.58928846 0.5265148 0.6393808\nyU44 0.57146323  0.13505506 0.29025526 0.4102267 0.62980806 0.3459244 0.4455258\n          yU14      yU15      yU16      yU17        yU18      yU19      yU20\nyU1  0.5651180 0.5197567 0.4502098 0.4364325  0.22287421 0.4039420 0.4745600\nyU2  0.4551220 0.3731708 0.2954378 0.2534060  0.08746853 0.2685263 0.3144747\nyU3  0.5317052 0.5847341 0.6140391 0.5903495  0.45954714 0.5718450 0.5657679\nyU4  0.5248819 0.4727819 0.4389309 0.4290424  0.19224304 0.3877373 0.4597681\nyU5  0.1729122 0.1287573 0.1613473 0.1392282 -0.02004310 0.1582223 0.1129604\nyU6  0.4448696 0.5545205 0.6542502 0.6735240  0.54197387 0.6033034 0.5960467\nyU7  0.3940324 0.4728058 0.5940176 0.6246681  0.54039139 0.5297543 0.5506952\nyU8  0.5599603 0.4537789 0.3002823 0.2607863  0.12183264 0.3033533 0.3797019\nyU9  0.5851795 0.5094251 0.4156058 0.3475463  0.27951265 0.4167612 0.4993468\nyU10 0.8086018 0.7438777 0.6096355 0.6581154  0.45949208 0.5871081 0.6642367\nyU11 0.5057558 0.5458186 0.5508042 0.5698787  0.54399687 0.5649175 0.5611712\nyU12 0.8047386 0.7299160 0.5430776 0.5232409  0.34849557 0.5408127 0.6021437\nyU13 0.7734068 0.7238840 0.6207888 0.6114107  0.46633165 0.6233692 0.6870959\nyU14 1.0000000 0.9259926 0.6863703 0.6926379  0.46644933 0.6782078 0.7497479\nyU15 0.9259926 1.0000000 0.7997783 0.7871522  0.57109772 0.7758772 0.8282523\nyU16 0.6863703 0.7997783 1.0000000 0.8842294  0.76663653 0.8911249 0.8368418\nyU17 0.6926379 0.7871522 0.8842294 1.0000000  0.74969607 0.8577586 0.7290285\nyU18 0.4664493 0.5710977 0.7666365 0.7496961  1.00000000 0.7877303 0.6852016\nyU19 0.6782078 0.7758772 0.8911249 0.8577586  0.78773030 1.0000000 0.7861898\nyU20 0.7497479 0.8282523 0.8368418 0.7290285  0.68520155 0.7861898 1.0000000\nyU21 0.4642670 0.5475118 0.7332270 0.6124976  0.61368912 0.6837558 0.6193149\nyU22 0.5080854 0.5648882 0.7367379 0.5817907  0.58700116 0.6782711 0.7165111\nyU23 0.4601323 0.5295170 0.6911659 0.5921032  0.54401362 0.6591983 0.6314007\nyU24 0.4977722 0.5753414 0.6409255 0.5396480  0.52136444 0.5878636 0.6127420\nyU25 0.3872521 0.4442464 0.6412742 0.5137880  0.49434792 0.5443262 0.5852381\nyU26 0.3391932 0.2885265 0.3792232 0.3013296  0.27080347 0.2883968 0.3518649\nyU27 0.6629460 0.6657057 0.7261820 0.6075293  0.55486711 0.6083329 0.7319478\nyU28 0.7979968 0.7813554 0.7111284 0.6795641  0.49334007 0.6847731 0.6945899\nyU29 0.2168356 0.3045051 0.4453200 0.3930213  0.43937778 0.3526916 0.4061142\nyU30 0.2690100 0.2756001 0.3130661 0.3149126  0.27647343 0.3161846 0.3402613\nyU31 0.4236736 0.5422930 0.7587694 0.6499717  0.69882563 0.6913089 0.6617904\nyU32 0.6322650 0.7074972 0.7733600 0.6412969  0.58208876 0.6773371 0.7495807\nyU33 0.6510753 0.7186305 0.7567077 0.6326519  0.60378291 0.6840950 0.8032135\nyU34 0.4491010 0.5613359 0.6993866 0.5921704  0.64191345 0.6835339 0.7000019\nyU35 0.6231676 0.7469554 0.8516326 0.7447432  0.67349661 0.7750624 0.8182740\nyU36 0.4322773 0.5515527 0.7266430 0.6314542  0.71907406 0.6781152 0.6713521\nyU37 0.5240264 0.6057564 0.7226941 0.6169899  0.71287903 0.7298851 0.7338353\nyU38 0.4847604 0.5728005 0.7708638 0.6323385  0.64367982 0.6569033 0.6629998\nyU39 0.4490616 0.5586076 0.7126482 0.5674748  0.58202588 0.5830284 0.6410097\nyU40 0.5046950 0.6016847 0.8004590 0.6966594  0.76113108 0.7619221 0.6877506\nyU41 0.6026355 0.7263884 0.8889617 0.7253680  0.70584871 0.7986973 0.7906797\nyU42 0.5065776 0.6078684 0.7533372 0.6695767  0.59868142 0.6723589 0.6753139\nyU43 0.6244936 0.6884410 0.8738939 0.8534415  0.81051030 0.8668130 0.7605613\nyU44 0.4972484 0.6191550 0.8284535 0.7617059  0.86960496 0.8036760 0.7068495\n          yU21       yU22      yU23       yU24      yU25       yU26       yU27\nyU1  0.3563626 0.39991461 0.3379898 0.27421886 0.3273764 0.27743171 0.37820546\nyU2  0.2820240 0.28721421 0.2358304 0.13661864 0.2407404 0.19066581 0.28298612\nyU3  0.4689127 0.46321768 0.4722500 0.32126733 0.4180409 0.19670890 0.34166272\nyU4  0.3514164 0.40146208 0.3271709 0.25442889 0.3335768 0.28055394 0.37347430\nyU5  0.1742254 0.01900241 0.1451872 0.02610688 0.2197905 0.07297593 0.05119852\nyU6  0.4698475 0.40549734 0.4736568 0.30865940 0.4009400 0.05580331 0.32953114\nyU7  0.4235058 0.38431158 0.4190173 0.29531737 0.3648229 0.06836123 0.30193851\nyU8  0.2528088 0.29930408 0.2073210 0.13365159 0.2323050 0.09138485 0.34037797\nyU9  0.4337133 0.39180729 0.3770582 0.28964034 0.3896434 0.25796954 0.46126222\nyU10 0.3784125 0.51287302 0.3530144 0.36691055 0.3469125 0.27567273 0.64025891\nyU11 0.4641129 0.53009909 0.5167042 0.46629680 0.3180346 0.26396326 0.52869539\nyU12 0.4025754 0.45095216 0.3602302 0.37457155 0.3591472 0.20355127 0.53928827\nyU13 0.5288207 0.45289841 0.4784037 0.40247071 0.4809163 0.32137705 0.55835337\nyU14 0.4642670 0.50808541 0.4601323 0.49777223 0.3872521 0.33919315 0.66294604\nyU15 0.5475118 0.56488822 0.5295170 0.57534144 0.4442464 0.28852653 0.66570570\nyU16 0.7332270 0.73673793 0.6911659 0.64092554 0.6412742 0.37922324 0.72618201\nyU17 0.6124976 0.58179069 0.5921032 0.53964798 0.5137880 0.30132961 0.60752931\nyU18 0.6136891 0.58700116 0.5440136 0.52136444 0.4943479 0.27080347 0.55486711\nyU19 0.6837558 0.67827115 0.6591983 0.58786356 0.5443262 0.28839676 0.60833294\nyU20 0.6193149 0.71651107 0.6314007 0.61274202 0.5852381 0.35186492 0.73194776\nyU21 1.0000000 0.70959059 0.9175036 0.62831910 0.8669404 0.50195285 0.62949535\nyU22 0.7095906 1.00000000 0.6692114 0.78151436 0.6994178 0.44643179 0.80021417\nyU23 0.9175036 0.66921138 1.0000000 0.53352467 0.8540222 0.47146107 0.56468062\nyU24 0.6283191 0.78151436 0.5335247 1.00000000 0.6216621 0.49306774 0.76705240\nyU25 0.8669404 0.69941784 0.8540222 0.62166213 1.0000000 0.57252062 0.63040251\nyU26 0.5019529 0.44643179 0.4714611 0.49306774 0.5725206 1.00000000 0.53206529\nyU27 0.6294953 0.80021417 0.5646806 0.76705240 0.6304025 0.53206529 1.00000000\nyU28 0.4983739 0.48932223 0.4239324 0.51742008 0.4523832 0.28775867 0.60127146\nyU29 0.5566781 0.43219891 0.4908198 0.56264486 0.5955633 0.23111319 0.41270308\nyU30 0.5563734 0.39382816 0.5279489 0.46629913 0.5980853 0.27305152 0.34181743\nyU31 0.9054181 0.68280686 0.8474565 0.64381974 0.8654691 0.46311924 0.57922017\nyU32 0.5326570 0.81276012 0.4925766 0.77907690 0.5111239 0.36197192 0.83823213\nyU33 0.6143559 0.79696789 0.5350982 0.81314992 0.5947295 0.44929450 0.90661514\nyU34 0.8246688 0.59793259 0.8350477 0.53237177 0.7199915 0.41118100 0.52885450\nyU35 0.7071444 0.83829091 0.6874458 0.73209714 0.7105218 0.39353337 0.78124158\nyU36 0.8388027 0.65561251 0.7718932 0.56088231 0.7256934 0.38709176 0.60352405\nyU37 0.8606852 0.66691652 0.8407113 0.53073025 0.7200846 0.39465003 0.58496499\nyU38 0.7869071 0.80098280 0.7127230 0.81809889 0.8124384 0.49139322 0.74622384\nyU39 0.7480711 0.77005745 0.6710996 0.83211941 0.7641684 0.48418074 0.69595224\nyU40 0.8832586 0.67718816 0.8130665 0.64248004 0.7965061 0.43932038 0.61236010\nyU41 0.8045300 0.76585067 0.7308739 0.75021006 0.7469012 0.42611680 0.75904964\nyU42 0.8199303 0.71909023 0.8133027 0.64108600 0.8112857 0.48406983 0.64561562\nyU43 0.6709351 0.66980647 0.6500572 0.53168977 0.5850998 0.30863194 0.59996999\nyU44 0.6928421 0.60560958 0.6382281 0.53552909 0.5232503 0.32183260 0.55125936\n          yU28         yU29      yU30      yU31        yU32       yU33\nyU1  0.5987657  0.014287984 0.2801279 0.2723248  0.29717750 0.32433842\nyU2  0.5104006 -0.093435144 0.1968154 0.1806293  0.15641896 0.21118893\nyU3  0.5300233  0.157300010 0.1717752 0.4415774  0.39205110 0.35419364\nyU4  0.5953958  0.002335548 0.2721931 0.2838947  0.27745876 0.31112759\nyU5  0.3873141 -0.056298868 0.2052261 0.1948021 -0.04846779 0.01866693\nyU6  0.5367108  0.217121034 0.1392104 0.4744182  0.39048693 0.38122969\nyU7  0.4714608  0.220294002 0.1515088 0.4582728  0.34802006 0.34783702\nyU8  0.5845221 -0.053353858 0.2083752 0.1819183  0.22387067 0.30165558\nyU9  0.6965193  0.026051975 0.2724232 0.3709484  0.32007523 0.42630422\nyU10 0.7240816  0.106527801 0.1670479 0.3481627  0.54409631 0.59329079\nyU11 0.3746052  0.205945576 0.2124517 0.3823880  0.48448973 0.49406651\nyU12 0.8184629  0.062807395 0.2789485 0.3427293  0.48111795 0.51935674\nyU13 0.8972789  0.106438085 0.3490941 0.4964805  0.45635044 0.54210835\nyU14 0.7979968  0.216835570 0.2690100 0.4236736  0.63226499 0.65107525\nyU15 0.7813554  0.304505073 0.2756001 0.5422930  0.70749719 0.71863054\nyU16 0.7111284  0.445319981 0.3130661 0.7587694  0.77336002 0.75670773\nyU17 0.6795641  0.393021298 0.3149126 0.6499717  0.64129693 0.63265186\nyU18 0.4933401  0.439377785 0.2764734 0.6988256  0.58208876 0.60378291\nyU19 0.6847731  0.352691558 0.3161846 0.6913089  0.67733709 0.68409504\nyU20 0.6945899  0.406114220 0.3402613 0.6617904  0.74958068 0.80321348\nyU21 0.4983739  0.556678128 0.5563734 0.9054181  0.53265700 0.61435593\nyU22 0.4893222  0.432198905 0.3938282 0.6828069  0.81276012 0.79696789\nyU23 0.4239324  0.490819826 0.5279489 0.8474565  0.49257661 0.53509818\nyU24 0.5174201  0.562644862 0.4662991 0.6438197  0.77907690 0.81314992\nyU25 0.4523832  0.595563299 0.5980853 0.8654691  0.51112388 0.59472952\nyU26 0.2877587  0.231113187 0.2730515 0.4631192  0.36197192 0.44929450\nyU27 0.6012715  0.412703079 0.3418174 0.5792202  0.83823213 0.90661514\nyU28 1.0000000  0.143830058 0.2781299 0.4870897  0.60798096 0.62452093\nyU29 0.1438301  1.000000000 0.6592196 0.6428012  0.43243123 0.45685637\nyU30 0.2781299  0.659219603 1.0000000 0.5706041  0.22370022 0.31709128\nyU31 0.4870897  0.642801199 0.5706041 1.0000000  0.56284761 0.61973574\nyU32 0.6079810  0.432431227 0.2237002 0.5628476  1.00000000 0.90071336\nyU33 0.6245209  0.456856367 0.3170913 0.6197357  0.90071336 1.00000000\nyU34 0.4289675  0.447358422 0.4295293 0.8112256  0.49381440 0.58725583\nyU35 0.6009530  0.494597165 0.3703822 0.7438874  0.79841543 0.80041786\nyU36 0.4285523  0.519986580 0.3976158 0.8150806  0.57235710 0.63336838\nyU37 0.4465595  0.503636964 0.4756844 0.7946033  0.52996970 0.60277310\nyU38 0.5233627  0.699056026 0.5131340 0.8464204  0.76178868 0.75822893\nyU39 0.4720063  0.684949443 0.5648275 0.8046678  0.71300393 0.71367508\nyU40 0.5294740  0.612973773 0.5124521 0.9291022  0.57817323 0.64276813\nyU41 0.6156887  0.591181409 0.4355381 0.8403561  0.77299395 0.81840367\nyU42 0.4988230  0.542128111 0.5299673 0.9032819  0.60786926 0.62165191\nyU43 0.6720816  0.390702026 0.3364520 0.7025417  0.66003537 0.64999660\nyU44 0.4917377  0.412909618 0.2123180 0.7213096  0.59835347 0.60526383\n           yU34       yU35         yU36       yU37      yU38       yU39\nyU1  0.20040000 0.41834108  0.191519389 0.31964146 0.2525079 0.26007425\nyU2  0.11883252 0.27507059  0.093032787 0.21956265 0.1397273 0.15935117\nyU3  0.34691445 0.58683870  0.365674497 0.47102098 0.3847394 0.37545087\nyU4  0.18457260 0.41558822  0.171920055 0.28450213 0.2676822 0.25542639\nyU5  0.08785426 0.07175337 -0.009870691 0.06730503 0.0138725 0.00762338\nyU6  0.42109479 0.54213129  0.439332143 0.46008021 0.3668176 0.33293784\nyU7  0.38447020 0.48570315  0.388582975 0.43196822 0.3377756 0.30960613\nyU8  0.11987159 0.28790898  0.115904468 0.23940933 0.1631580 0.14003597\nyU9  0.30172620 0.40244516  0.291370420 0.42117141 0.3009732 0.30511453\nyU10 0.30568108 0.58585543  0.326249289 0.39316468 0.3941636 0.34043129\nyU11 0.47271377 0.51585318  0.495518779 0.54702081 0.3253213 0.32406536\nyU12 0.31304859 0.49727774  0.303354864 0.43018150 0.3529404 0.32978608\nyU13 0.43000448 0.54138875  0.407197754 0.51194001 0.4453401 0.40183335\nyU14 0.44910098 0.62316763  0.432277348 0.52402642 0.4847604 0.44906157\nyU15 0.56133591 0.74695535  0.551552672 0.60575641 0.5728005 0.55860756\nyU16 0.69938665 0.85163259  0.726642950 0.72269405 0.7708638 0.71264821\nyU17 0.59217042 0.74474322  0.631454217 0.61698989 0.6323385 0.56747476\nyU18 0.64191345 0.67349661  0.719074061 0.71287903 0.6436798 0.58202588\nyU19 0.68353393 0.77506245  0.678115170 0.72988512 0.6569033 0.58302844\nyU20 0.70000194 0.81827397  0.671352099 0.73383528 0.6629998 0.64100968\nyU21 0.82466876 0.70714438  0.838802692 0.86068517 0.7869071 0.74807108\nyU22 0.59793259 0.83829091  0.655612512 0.66691652 0.8009828 0.77005745\nyU23 0.83504772 0.68744580  0.771893213 0.84071126 0.7127230 0.67109957\nyU24 0.53237177 0.73209714  0.560882307 0.53073025 0.8180989 0.83211941\nyU25 0.71999152 0.71052181  0.725693371 0.72008457 0.8124384 0.76416843\nyU26 0.41118100 0.39353337  0.387091763 0.39465003 0.4913932 0.48418074\nyU27 0.52885450 0.78124158  0.603524050 0.58496499 0.7462238 0.69595224\nyU28 0.42896751 0.60095295  0.428552252 0.44655954 0.5233627 0.47200628\nyU29 0.44735842 0.49459717  0.519986580 0.50363696 0.6990560 0.68494944\nyU30 0.42952934 0.37038224  0.397615777 0.47568444 0.5131340 0.56482751\nyU31 0.81122563 0.74388739  0.815080627 0.79460334 0.8464204 0.80466777\nyU32 0.49381440 0.79841543  0.572357104 0.52996970 0.7617887 0.71300393\nyU33 0.58725583 0.80041786  0.633368385 0.60277310 0.7582289 0.71367508\nyU34 1.00000000 0.64647565  0.846091000 0.89132602 0.6801790 0.65750642\nyU35 0.64647565 1.00000000  0.683890114 0.70664568 0.8075295 0.77324436\nyU36 0.84609100 0.68389011  1.000000000 0.85386402 0.7476813 0.70661154\nyU37 0.89132602 0.70664568  0.853864020 1.00000000 0.6985994 0.67349318\nyU38 0.68017898 0.80752946  0.747681317 0.69859944 1.0000000 0.90732057\nyU39 0.65750642 0.77324436  0.706611542 0.67349318 0.9073206 1.00000000\nyU40 0.79308935 0.72600370  0.814117882 0.79988760 0.7882111 0.75192446\nyU41 0.73637109 0.85931617  0.763376610 0.75541320 0.8482211 0.79513769\nyU42 0.73636358 0.79314574  0.756816858 0.71309259 0.8430240 0.80279540\nyU43 0.60119052 0.72475250  0.669678061 0.66082239 0.6571954 0.59459564\nyU44 0.73617596 0.69694945  0.772200601 0.77169352 0.6221965 0.57958408\n          yU40      yU41      yU42      yU43       yU44\nyU1  0.2533513 0.3331399 0.3179226 0.4895681 0.24175868\nyU2  0.1492736 0.2051210 0.2343243 0.3288418 0.10990556\nyU3  0.4343121 0.4979875 0.4303973 0.6418807 0.49386046\nyU4  0.2423778 0.3091987 0.3384967 0.4795452 0.19605629\nyU5  0.1810988 0.1369463 0.1540943 0.1470076 0.03608798\nyU6  0.5208768 0.5564873 0.4297837 0.6664540 0.58167912\nyU7  0.4969465 0.5077347 0.4017644 0.6264709 0.57146323\nyU8  0.1492999 0.2318214 0.2278629 0.3398554 0.13505506\nyU9  0.3621611 0.3917918 0.3607889 0.4431604 0.29025526\nyU10 0.3673422 0.4767100 0.4536437 0.5925562 0.41022672\nyU11 0.4505410 0.4565196 0.3636720 0.5892885 0.62980806\nyU12 0.3734297 0.4685148 0.3825937 0.5265148 0.34592441\nyU13 0.5220294 0.5346194 0.5134173 0.6393808 0.44552582\nyU14 0.5046950 0.6026355 0.5065776 0.6244936 0.49724841\nyU15 0.6016847 0.7263884 0.6078684 0.6884410 0.61915504\nyU16 0.8004590 0.8889617 0.7533372 0.8738939 0.82845352\nyU17 0.6966594 0.7253680 0.6695767 0.8534415 0.76170593\nyU18 0.7611311 0.7058487 0.5986814 0.8105103 0.86960496\nyU19 0.7619221 0.7986973 0.6723589 0.8668130 0.80367597\nyU20 0.6877506 0.7906797 0.6753139 0.7605613 0.70684947\nyU21 0.8832586 0.8045300 0.8199303 0.6709351 0.69284215\nyU22 0.6771882 0.7658507 0.7190902 0.6698065 0.60560958\nyU23 0.8130665 0.7308739 0.8133027 0.6500572 0.63822810\nyU24 0.6424800 0.7502101 0.6410860 0.5316898 0.53552909\nyU25 0.7965061 0.7469012 0.8112857 0.5850998 0.52325028\nyU26 0.4393204 0.4261168 0.4840698 0.3086319 0.32183260\nyU27 0.6123601 0.7590496 0.6456156 0.5999700 0.55125936\nyU28 0.5294740 0.6156887 0.4988230 0.6720816 0.49173770\nyU29 0.6129738 0.5911814 0.5421281 0.3907020 0.41290962\nyU30 0.5124521 0.4355381 0.5299673 0.3364520 0.21231798\nyU31 0.9291022 0.8403561 0.9032819 0.7025417 0.72130957\nyU32 0.5781732 0.7729940 0.6078693 0.6600354 0.59835347\nyU33 0.6427681 0.8184037 0.6216519 0.6499966 0.60526383\nyU34 0.7930894 0.7363711 0.7363636 0.6011905 0.73617596\nyU35 0.7260037 0.8593162 0.7931457 0.7247525 0.69694945\nyU36 0.8141179 0.7633766 0.7568169 0.6696781 0.77220060\nyU37 0.7998876 0.7554132 0.7130926 0.6608224 0.77169352\nyU38 0.7882111 0.8482211 0.8430240 0.6571954 0.62219649\nyU39 0.7519245 0.7951377 0.8027954 0.5945956 0.57958408\nyU40 1.0000000 0.8725483 0.8200443 0.7407935 0.77547093\nyU41 0.8725483 1.0000000 0.7905961 0.7436275 0.75333080\nyU42 0.8200443 0.7905961 1.0000000 0.6729642 0.65098630\nyU43 0.7407935 0.7436275 0.6729642 1.0000000 0.80937854\nyU44 0.7754709 0.7533308 0.6509863 0.8093785 1.00000000\n\n\n\n%%R\nwrite.csv(yU_cor, './data2/yU_weight.csv', row.names=FALSE)"
  },
  {
    "objectID": "posts/SOLAR/2023-04-14-데이터수정2.html#create-stgcn-datset",
    "href": "posts/SOLAR/2023-04-14-데이터수정2.html#create-stgcn-datset",
    "title": "[SOLAR] Crate Dataset (data2: 22/06~22/09/15) 재수정",
    "section": "Create STGCN Datset",
    "text": "Create STGCN Datset\n\nimport\n\nimport pandas as pd\nimport numpy as np\n\n\ndf = pd.read_csv('./data2/solar_radiation.csv')\nweight = pd.read_csv('./data2/weight.csv')\nept_weight = pd.read_csv('./data2/yU_weight.csv')\n\n\ndf.head(30)\n\n\n\n\n\n  \n    \n      \n      Unnamed: 0\n      region\n      solar_radiation\n      date\n    \n  \n  \n    \n      0\n      0\n      북춘천\n      0.00\n      2022-06-01-00:00\n    \n    \n      1\n      1\n      북춘천\n      0.00\n      2022-06-01-01:00\n    \n    \n      2\n      2\n      북춘천\n      0.00\n      2022-06-01-02:00\n    \n    \n      3\n      3\n      북춘천\n      0.00\n      2022-06-01-03:00\n    \n    \n      4\n      4\n      북춘천\n      0.00\n      2022-06-01-04:00\n    \n    \n      5\n      5\n      북춘천\n      0.00\n      2022-06-01-05:00\n    \n    \n      6\n      6\n      북춘천\n      0.05\n      2022-06-01-06:00\n    \n    \n      7\n      7\n      북춘천\n      0.52\n      2022-06-01-07:00\n    \n    \n      8\n      8\n      북춘천\n      1.14\n      2022-06-01-08:00\n    \n    \n      9\n      9\n      북춘천\n      1.68\n      2022-06-01-09:00\n    \n    \n      10\n      10\n      북춘천\n      2.51\n      2022-06-01-10:00\n    \n    \n      11\n      11\n      북춘천\n      2.82\n      2022-06-01-11:00\n    \n    \n      12\n      12\n      북춘천\n      3.03\n      2022-06-01-12:00\n    \n    \n      13\n      13\n      북춘천\n      3.38\n      2022-06-01-13:00\n    \n    \n      14\n      14\n      북춘천\n      3.44\n      2022-06-01-14:00\n    \n    \n      15\n      15\n      북춘천\n      3.10\n      2022-06-01-15:00\n    \n    \n      16\n      16\n      북춘천\n      2.62\n      2022-06-01-16:00\n    \n    \n      17\n      17\n      북춘천\n      1.95\n      2022-06-01-17:00\n    \n    \n      18\n      18\n      북춘천\n      1.26\n      2022-06-01-18:00\n    \n    \n      19\n      19\n      북춘천\n      0.53\n      2022-06-01-19:00\n    \n    \n      20\n      20\n      북춘천\n      0.06\n      2022-06-01-20:00\n    \n    \n      21\n      21\n      북춘천\n      0.00\n      2022-06-01-21:00\n    \n    \n      22\n      22\n      북춘천\n      0.00\n      2022-06-01-22:00\n    \n    \n      23\n      23\n      북춘천\n      0.00\n      2022-06-01-23:00\n    \n    \n      24\n      24\n      북춘천\n      0.00\n      2022-06-02-00:00\n    \n    \n      25\n      25\n      북춘천\n      0.00\n      2022-06-02-01:00\n    \n    \n      26\n      26\n      북춘천\n      0.00\n      2022-06-02-02:00\n    \n    \n      27\n      27\n      북춘천\n      0.00\n      2022-06-02-03:00\n    \n    \n      28\n      28\n      북춘천\n      0.00\n      2022-06-02-04:00\n    \n    \n      29\n      29\n      북춘천\n      0.00\n      2022-06-02-05:00\n    \n  \n\n\n\n\n\ndf.tail()\n\n\n\n\n\n  \n    \n      \n      Unnamed: 0\n      region\n      solar_radiation\n      date\n    \n  \n  \n    \n      112987\n      32731\n      경주시\n      0.01\n      2022-09-15-19:00\n    \n    \n      112988\n      32732\n      경주시\n      0.00\n      2022-09-15-20:00\n    \n    \n      112989\n      32733\n      경주시\n      0.00\n      2022-09-15-21:00\n    \n    \n      112990\n      32734\n      경주시\n      0.00\n      2022-09-15-22:00\n    \n    \n      112991\n      32735\n      경주시\n      0.00\n      2022-09-15-23:00\n    \n  \n\n\n\n\n\ndf.duplicated().sum()\n\n0\n\n\n\n# df = df.iloc[:,1:]\n\n\ndf.head()\n\n\n\n\n\n  \n    \n      \n      region\n      solar_radiation\n      date\n    \n  \n  \n    \n      0\n      북춘천\n      0.0\n      2022-06-01-00:00\n    \n    \n      1\n      북춘천\n      0.0\n      2022-06-01-01:00\n    \n    \n      2\n      북춘천\n      0.0\n      2022-06-01-02:00\n    \n    \n      3\n      북춘천\n      0.0\n      2022-06-01-03:00\n    \n    \n      4\n      북춘천\n      0.0\n      2022-06-01-04:00\n    \n  \n\n\n\n\n\n%R -i df\n\n\n%%R\ndf = df |> mutate(date=ymd_hm(date))\ndf <- df %>%\n          group_by(region) %>%\n          mutate(row = row_number()) %>%\n          tidyr::pivot_wider(names_from = region, values_from = solar_radiation) %>%\n          select(-row)\n\n\n%%R\ndf %>% head()\n\n# A tibble: 6 × 45\n  date                북춘천  철원 대관령  춘천 백령도 북강릉  강릉  서울  인천\n  <dttm>               <dbl> <dbl>  <dbl> <dbl>  <dbl>  <dbl> <dbl> <dbl> <dbl>\n1 2022-06-01 00:00:00      0     0      0     0      0      0     0     0     0\n2 2022-06-01 01:00:00      0     0      0     0      0      0     0     0     0\n3 2022-06-01 02:00:00      0     0      0     0      0      0     0     0     0\n4 2022-06-01 03:00:00      0     0      0     0      0      0     0     0     0\n5 2022-06-01 04:00:00      0     0      0     0      0      0     0     0     0\n6 2022-06-01 05:00:00      0     0      0     0      0      0     0     0     0\n# … with 35 more variables: 원주 <dbl>, 울릉도 <dbl>, 수원 <dbl>, 서산 <dbl>,\n#   청주 <dbl>, 대전 <dbl>, 추풍령 <dbl>, 안동 <dbl>, 포항 <dbl>, 대구 <dbl>,\n#   전주 <dbl>, 창원 <dbl>, 광주 <dbl>, 부산 <dbl>, 목포 <dbl>, 여수 <dbl>,\n#   흑산도 <dbl>, 고창 <dbl>, 홍성 <dbl>, 제주 <dbl>, 고산 <dbl>, 진주 <dbl>,\n#   고창군 <dbl>, 영광군 <dbl>, 김해시 <dbl>, 순창군 <dbl>, 북창원 <dbl>,\n#   양산시 <dbl>, 보성군 <dbl>, 강진군 <dbl>, 의령군 <dbl>, 함양군 <dbl>,\n#   광양시 <dbl>, 청송군 <dbl>, 경주시 <dbl>\n# ℹ Use `colnames()` to see all variable names\n\n\n\n%%R\nwrite.csv(df,'./data2/restructuring_data.csv', row.names=FALSE)\n\n\nimport gc\ngc.collect()\n\n419\n\n\n\n\nSTGCN Ver1\n\ndf = pd.read_csv('./data2/restructuring_data.csv')\ndf.head()\n\n\n\n\n\n  \n    \n      \n      date\n      북춘천\n      철원\n      대관령\n      춘천\n      백령도\n      북강릉\n      강릉\n      서울\n      인천\n      ...\n      순창군\n      북창원\n      양산시\n      보성군\n      강진군\n      의령군\n      함양군\n      광양시\n      청송군\n      경주시\n    \n  \n  \n    \n      0\n      2022-06-01 00:00:00\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      ...\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n    \n    \n      1\n      2022-06-01 01:00:00\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      ...\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n    \n    \n      2\n      2022-06-01 02:00:00\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      ...\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n    \n    \n      3\n      2022-06-01 03:00:00\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      ...\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n    \n    \n      4\n      2022-06-01 04:00:00\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      ...\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n    \n  \n\n5 rows × 45 columns\n\n\n\n\ndf.iloc[2116]\n\ndate    2022-08-28 04:00:00\n북춘천                     0.0\n철원                      0.0\n대관령                     0.0\n춘천                      0.0\n백령도                     0.0\n북강릉                     0.0\n강릉                      0.0\n서울                      0.0\n인천                      0.0\n원주                      0.0\n울릉도                     0.0\n수원                      0.0\n서산                      0.0\n청주                      0.0\n대전                      0.0\n추풍령                     0.0\n안동                      0.0\n포항                      0.0\n대구                      0.0\n전주                      0.0\n창원                      0.0\n광주                      0.0\n부산                      0.0\n목포                      0.0\n여수                      0.0\n흑산도                     0.0\n고창                      0.0\n홍성                      0.0\n제주                      0.0\n고산                      0.0\n진주                      0.0\n고창군                     0.0\n영광군                     0.0\n김해시                     0.0\n순창군                     0.0\n북창원                     0.0\n양산시                     0.0\n보성군                     0.0\n강진군                     0.0\n의령군                     0.0\n함양군                     0.0\n광양시                     0.0\n청송군                     0.0\n경주시                     0.0\nName: 2116, dtype: object\n\n\n\ndf2 = df.iloc[:,1:]\n\n\nnode_list =(df2.columns).tolist()\nnode_ids = {node : i for i, node in enumerate(node_list)}\nnode_ids\n\n{'북춘천': 0,\n '철원': 1,\n '대관령': 2,\n '춘천': 3,\n '백령도': 4,\n '북강릉': 5,\n '강릉': 6,\n '서울': 7,\n '인천': 8,\n '원주': 9,\n '울릉도': 10,\n '수원': 11,\n '서산': 12,\n '청주': 13,\n '대전': 14,\n '추풍령': 15,\n '안동': 16,\n '포항': 17,\n '대구': 18,\n '전주': 19,\n '창원': 20,\n '광주': 21,\n '부산': 22,\n '목포': 23,\n '여수': 24,\n '흑산도': 25,\n '고창': 26,\n '홍성': 27,\n '제주': 28,\n '고산': 29,\n '진주': 30,\n '고창군': 31,\n '영광군': 32,\n '김해시': 33,\n '순창군': 34,\n '북창원': 35,\n '양산시': 36,\n '보성군': 37,\n '강진군': 38,\n '의령군': 39,\n '함양군': 40,\n '광양시': 41,\n '청송군': 42,\n '경주시': 43}\n\n\n\nedges = []    \n \nfor i in range(44):\n    for j in range(44):\n        if i != j:\n            edges.append([i,j]) \n# print(edges)\n\n\nweights = []    \n \nfor i in range(44):\n    for j in range(44):\n        if i != j:\n            weights.append(weight.iloc[i,j]) \n\n\nnp.array(weights).shape\n\n(1892,)\n\n\n\nlen(df['date']) # time\n\n2568\n\n\n\nFX = []    \nfor i in range(2568):\n    FX.append(list(df2.iloc[i,:])) \n#FX\n\n\nnp.array(FX).shape\n\n(2568, 44)\n\n\n- weights, edges, node_ids, FX\n\ndata_dict = {'edges':edges, 'node_ids':node_ids, 'weights':weights, 'FX':FX}\n\n\ndata_dict.keys()\n\ndict_keys(['edges', 'node_ids', 'weights', 'FX'])\n\n\n\nfile_path = './data2/stgcn_data1.json'\n\n\nwith open(file_path, 'w') as f:\n    json.dump(data_dict, f)\n\n\nwith open(file_path, 'r') as f:\n    test = json.load(f, encoding='cp949')\n\n\nimport gc\ngc.collect()\n\n0\n\n\n\nnp.array(data_dict['weights']).mean()\n\n0.8305000717570354\n\n\n\n\nSTGCN Ver2\n\n# ept_weight\n\n\nept_weights = []    \n \nfor i in range(44):\n    for j in range(44):\n        if i != j:\n            ept_weights.append(ept_weight.iloc[i,j]) \n\n\nnp.mean(weights), np.mean(ept_weights)\n\n(0.8305000717570354, 0.5184766409749978)\n\n\n\ndata_dict2 = data_dict.copy()\n\n\ndata_dict2['weights'] = ept_weights\n\n\ndata_dict2['weights'][:10]\n\n[0.907759100668583,\n 0.741068831832639,\n 0.968835370647473,\n 0.504767766362897,\n 0.544524976746219,\n 0.527829574702507,\n 0.803172492443386,\n 0.781489079941053,\n 0.712366118080602,\n 0.409662421310778]\n\n\n\nnp.array(data_dict2['weights']).mean()\n\n0.5184766409749978\n\n\n\nfile_path = './data2/stgcn_data2.json'\n\n\n# with open(file_path, 'w') as f:\n#     json.dump(data_dict2, f)\n\n\n# with open(file_path, 'r') as f:\n#     test2 = json.load(f, encoding='cp949')"
  },
  {
    "objectID": "posts/SOLAR/2023-04-14-데이터수정2.html#comparision",
    "href": "posts/SOLAR/2023-04-14-데이터수정2.html#comparision",
    "title": "[SOLAR] Crate Dataset (data2: 22/06~22/09/15) 재수정",
    "section": "Comparision",
    "text": "Comparision\n\nplt.hist(np.array(weights), alpha = 0.5, label = 'weights')\nplt.hist(np.array(ept_weights), alpha = 0.5, label = 'EPT weights')\nplt.legend(loc='upper left')\n\n<matplotlib.legend.Legend at 0x7f8b47a041f0>\n\n\n\n\n\n\n모듈 수정"
  },
  {
    "objectID": "posts/SOLAR/2023-05-03-s-stgcn-ver2-시뮬레이션-10iter.html",
    "href": "posts/SOLAR/2023-05-03-s-stgcn-ver2-시뮬레이션-10iter.html",
    "title": "[SOLAR] STGCN Ver2 (data2, -N +S) 시뮬레이션 (epoch, filter, lag)",
    "section": "",
    "text": "10 iter, 50에폭 돌아가는중 (05-04 밤 start) // 완료!\n\n\n10 iter, 100에폭 돌아가는중 (05-06 오전 11시 57분 start) // 완료! –> 모델 날라감.\n\n\n10 iter, 150에폭 돌아가는중 (05-07 오후2시 32분 start) // 완료! (5월 9일 오전 10시)\n\n10iter 완료\n\n10 iter, 50에폭 돌리기 // 완료\n\n\n10 iter, 100에폭 돌리기(5월 10일 오전 11시 시작) // 완료(5월 11일 오후 2시)\n\n\n150 에폭 돌리기 (5월 11일 오후 4시 42분 시작) // 완료 (5월 13일 오전 11시)\n\n20iter 완료\n\n10 iter, 50에폭 돌리기 시작 (5월 13일 오후 12시 43분) – 파일 날라감\n\n\n50에폭 돌리기 시작 (5월 14일 오전 2시 52분) // 5월 14일 오후6시 완료\n\n\n100 에폭 돌리기 시작(5월 15일 오전 10시14분) –> 진행중\n\n\n\n\nhttps://github.com/miruetoto/yechan3/tree/main/posts/3_Researches/ITSTGCN/itstgcn\nhttps://miruetoto.github.io/yechan3/posts/3_Researches/ITSTGCN/2023-03-18-SimulationPlanner-Tutorial.html#plnr_gnar_block\n\n\n\n\n\ntrain 2022-06-01 00:00:00 ~ 2022-08-14 17:00:00\ntest 2022-08-14 18:00:00 ~ 2022-09-15 23:00:00"
  },
  {
    "objectID": "posts/SOLAR/2023-05-03-s-stgcn-ver2-시뮬레이션-10iter.html#epoch",
    "href": "posts/SOLAR/2023-05-03-s-stgcn-ver2-시뮬레이션-10iter.html#epoch",
    "title": "[SOLAR] STGCN Ver2 (data2, -N +S) 시뮬레이션 (epoch, filter, lag)",
    "section": "50 epoch",
    "text": "50 epoch\n\nplans_stgcn = {\n    'max_iteration': 10,   # 30, \n    'method': ['EPT-STGCN'], \n    'lags': [4, 8, 12, 24],  # [4, 8, 12]\n    'nof_filters': [16, 32, 64], # [16, 32, 64]\n    'epoch': [50] # [50, 100, 150]\n}\n\n\nplans_stgcn\n\n{'max_iteration': 10,\n 'method': ['EPT-STGCN'],\n 'lags': [4, 8, 12, 24],\n 'nof_filters': [16, 32, 64],\n 'epoch': [50]}\n\n\n\nplnr = eptstgcn.planner.PLNR_STGCN(plans_stgcn,loader,dataset_name='data2')\n\n\nplnr.simulate()\neptstgcn.save_data(plnr, './simul_model2/stgcn_v2/third/stgcn_v2_50epoch.pickle')\nsimul_model = eptstgcn.load_data('./simul_model2/stgcn_v2/third/stgcn_v2_50epoch.pickle')\n\n20/50\n\n\n\nsimul_model.simulation_results\n\n\n\n\n\n  \n    \n      \n      dataset\n      method\n      normal\n      lags\n      nof_filters\n      epoch\n      mse(train)\n      mse(test)\n      calculation_time\n    \n  \n  \n    \n      0\n      data2\n      EPT-STGCN\n      X\n      4\n      16\n      50\n      0.190714\n      0.175346\n      409.163005\n    \n    \n      1\n      data2\n      EPT-STGCN\n      X\n      4\n      32\n      50\n      0.203176\n      0.18565\n      413.682942\n    \n    \n      2\n      data2\n      EPT-STGCN\n      X\n      4\n      64\n      50\n      0.191339\n      0.171761\n      423.513701\n    \n    \n      3\n      data2\n      EPT-STGCN\n      X\n      8\n      16\n      50\n      0.199274\n      0.171866\n      417.055229\n    \n    \n      4\n      data2\n      EPT-STGCN\n      X\n      8\n      32\n      50\n      0.197361\n      0.171141\n      420.399146\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      115\n      data2\n      EPT-STGCN\n      X\n      12\n      32\n      50\n      0.197463\n      0.171049\n      573.610863\n    \n    \n      116\n      data2\n      EPT-STGCN\n      X\n      12\n      64\n      50\n      0.205291\n      0.176054\n      587.493403\n    \n    \n      117\n      data2\n      EPT-STGCN\n      X\n      24\n      16\n      50\n      0.246351\n      0.201683\n      533.891202\n    \n    \n      118\n      data2\n      EPT-STGCN\n      X\n      24\n      32\n      50\n      0.255483\n      0.222253\n      400.819432\n    \n    \n      119\n      data2\n      EPT-STGCN\n      X\n      24\n      64\n      50\n      0.351609\n      0.27754\n      416.468699\n    \n  \n\n120 rows × 9 columns\n\n\n\n\n# eptstgcn.save_data(plnr, './simul_model2/stgcn_v2/stgcn_v2_50epoch.pickle')\n\n\n# simul_model = eptstgcn.load_data('./simul_model2/stgcn_v2/stgcn_v2_50epoch.pickle')\n\n\ndf_simul_no = simul_model.simulation_results\ndf_simul_no\n\n\n\n\n\n  \n    \n      \n      dataset\n      method\n      normal\n      lags\n      nof_filters\n      epoch\n      mse(train)\n      mse(test)\n      calculation_time\n    \n  \n  \n    \n      0\n      data2\n      EPT-STGCN\n      NaN\n      4\n      16\n      50\n      0.192152\n      0.173403\n      430.805053\n    \n    \n      1\n      data2\n      EPT-STGCN\n      NaN\n      4\n      32\n      50\n      0.184834\n      0.166629\n      553.995057\n    \n    \n      2\n      data2\n      EPT-STGCN\n      NaN\n      4\n      64\n      50\n      0.186183\n      0.169907\n      568.342531\n    \n    \n      3\n      data2\n      EPT-STGCN\n      NaN\n      8\n      16\n      50\n      0.200127\n      0.171658\n      484.037182\n    \n    \n      4\n      data2\n      EPT-STGCN\n      NaN\n      8\n      32\n      50\n      0.203025\n      0.17327\n      416.375737\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      115\n      data2\n      EPT-STGCN\n      NaN\n      12\n      32\n      50\n      0.198326\n      0.183998\n      431.555464\n    \n    \n      116\n      data2\n      EPT-STGCN\n      NaN\n      12\n      64\n      50\n      0.200407\n      0.173493\n      444.294899\n    \n    \n      117\n      data2\n      EPT-STGCN\n      NaN\n      24\n      16\n      50\n      0.311627\n      0.25768\n      403.552449\n    \n    \n      118\n      data2\n      EPT-STGCN\n      NaN\n      24\n      32\n      50\n      0.25655\n      0.213685\n      539.358858\n    \n    \n      119\n      data2\n      EPT-STGCN\n      NaN\n      24\n      64\n      50\n      0.25666\n      0.207781\n      562.105567\n    \n  \n\n120 rows × 9 columns\n\n\n\n\n# df_simul_no = simul_model.simulation_results\n# df_simul_no"
  },
  {
    "objectID": "posts/SOLAR/2023-05-03-s-stgcn-ver2-시뮬레이션-10iter.html#epoch-1",
    "href": "posts/SOLAR/2023-05-03-s-stgcn-ver2-시뮬레이션-10iter.html#epoch-1",
    "title": "[SOLAR] STGCN Ver2 (data2, -N +S) 시뮬레이션 (epoch, filter, lag)",
    "section": "100epoch",
    "text": "100epoch\n\nplans_stgcn = {\n    'max_iteration': 10,   # 30, \n    'method': ['EPT-STGCN'], \n    'lags': [4, 8, 12, 24],  # [4, 8, 12]\n    'nof_filters': [16, 32, 64], # [16, 32, 64]\n    'epoch': [100] # [50, 100, 150]\n}\n\n\nplans_stgcn\n\n{'max_iteration': 10,\n 'method': ['EPT-STGCN'],\n 'lags': [4, 8, 12, 24],\n 'nof_filters': [16, 32, 64],\n 'epoch': [100]}\n\n\n\nplnr = eptstgcn.planner.PLNR_STGCN(plans_stgcn,loader,dataset_name='data2')\n\n\nplnr.simulate()\neptstgcn.save_data(plnr,'./simul_model2/stgcn_v2/third/stgcn_v2_100epoch.pickle')\nsimul_model_100 = eptstgcn.load_data('./simul_model2/stgcn_v2/third/stgcn_v2_100epoch.pickle')\n\n1/10 is done\n2/10000\n\n\n\nplans_stgcn\n\n{'max_iteration': 10,\n 'method': ['EPT-STGCN'],\n 'lags': [4, 8, 12, 24],\n 'nof_filters': [16, 32, 64],\n 'epoch': [100]}\n\n\n\nsimul_model_100.simulation_results\n\n\n\n\n\n  \n    \n      \n      dataset\n      method\n      normal\n      lags\n      nof_filters\n      epoch\n      mse(train)\n      mse(test)\n      calculation_time\n    \n  \n  \n    \n      0\n      data2\n      EPT-STGCN\n      NaN\n      4\n      16\n      100\n      0.192383\n      0.17238\n      1095.311545\n    \n    \n      1\n      data2\n      EPT-STGCN\n      NaN\n      4\n      32\n      100\n      0.182036\n      0.162083\n      1117.031205\n    \n    \n      2\n      data2\n      EPT-STGCN\n      NaN\n      4\n      64\n      100\n      0.182569\n      0.163465\n      1141.591372\n    \n    \n      3\n      data2\n      EPT-STGCN\n      NaN\n      8\n      16\n      100\n      0.192919\n      0.168806\n      919.13007\n    \n    \n      4\n      data2\n      EPT-STGCN\n      NaN\n      8\n      32\n      100\n      0.199459\n      0.17362\n      839.538126\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      115\n      data2\n      EPT-STGCN\n      NaN\n      12\n      32\n      100\n      0.201038\n      0.179846\n      634.851532\n    \n    \n      116\n      data2\n      EPT-STGCN\n      NaN\n      12\n      64\n      100\n      0.200569\n      0.172256\n      660.412136\n    \n    \n      117\n      data2\n      EPT-STGCN\n      NaN\n      24\n      16\n      100\n      0.250253\n      0.199742\n      594.428839\n    \n    \n      118\n      data2\n      EPT-STGCN\n      NaN\n      24\n      32\n      100\n      0.223538\n      0.195406\n      601.475364\n    \n    \n      119\n      data2\n      EPT-STGCN\n      NaN\n      24\n      64\n      100\n      0.23775\n      0.209232\n      630.741058\n    \n  \n\n120 rows × 9 columns\n\n\n\n\nsimul_model_100.simulation_results\n\n\n\n\n\n  \n    \n      \n      dataset\n      method\n      normal\n      lags\n      nof_filters\n      epoch\n      mse(train)\n      mse(test)\n      calculation_time\n    \n  \n  \n    \n      0\n      data2\n      EPT-STGCN\n      X\n      4\n      16\n      100\n      0.17722\n      0.153878\n      596.881295\n    \n    \n      1\n      data2\n      EPT-STGCN\n      X\n      4\n      32\n      100\n      0.197419\n      0.180425\n      602.239902\n    \n    \n      2\n      data2\n      EPT-STGCN\n      X\n      4\n      64\n      100\n      0.182701\n      0.164736\n      626.37006\n    \n    \n      3\n      data2\n      EPT-STGCN\n      X\n      8\n      16\n      100\n      0.201668\n      0.173668\n      614.472721\n    \n    \n      4\n      data2\n      EPT-STGCN\n      X\n      8\n      32\n      100\n      0.194725\n      0.169411\n      622.566114\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      115\n      data2\n      EPT-STGCN\n      X\n      12\n      32\n      100\n      0.189322\n      0.165408\n      638.128908\n    \n    \n      116\n      data2\n      EPT-STGCN\n      X\n      12\n      64\n      100\n      0.202024\n      0.172773\n      666.259671\n    \n    \n      117\n      data2\n      EPT-STGCN\n      X\n      24\n      16\n      100\n      0.249016\n      0.206701\n      592.889058\n    \n    \n      118\n      data2\n      EPT-STGCN\n      X\n      24\n      32\n      100\n      0.218932\n      0.183241\n      607.23982\n    \n    \n      119\n      data2\n      EPT-STGCN\n      X\n      24\n      64\n      100\n      0.225561\n      0.19306\n      637.986133\n    \n  \n\n120 rows × 9 columns\n\n\n\n\nprint('끝났따! ㅎㅎ')\n\n끝났따! ㅎㅎ"
  },
  {
    "objectID": "posts/SOLAR/2023-05-03-s-stgcn-ver2-시뮬레이션-10iter.html#epoch-2",
    "href": "posts/SOLAR/2023-05-03-s-stgcn-ver2-시뮬레이션-10iter.html#epoch-2",
    "title": "[SOLAR] STGCN Ver2 (data2, -N +S) 시뮬레이션 (epoch, filter, lag)",
    "section": "150epoch",
    "text": "150epoch\n\nplans_stgcn = {\n    'max_iteration': 10,   # 30, \n    'method': ['EPT-STGCN'], \n    'lags': [4, 8, 12, 24],  # [4, 8, 12]\n    'nof_filters': [16, 32, 64], # [16, 32, 64]\n    'epoch': [150] # [50, 100, 150]\n}\n\n\nplans_stgcn\n\n{'max_iteration': 10,\n 'method': ['EPT-STGCN'],\n 'lags': [4, 8, 12, 24],\n 'nof_filters': [16, 32, 64],\n 'epoch': [150]}\n\n\n\nplnr = eptstgcn.planner.PLNR_STGCN(plans_stgcn,loader,dataset_name='data2')\n\n\nplnr.simulate()\neptstgcn.save_data(plnr,'./simul_model2/stgcn_v2/second/stgcn_v2_150epoch.pickle')\nsimul_model_150 = eptstgcn.load_data('./simul_model2/second/stgcn_v2/stgcn_v2_150epoch.pickle')\n\n78/1500\n\n\n\nsimul_model_150.simulation_results\n\n\n\n\n\n  \n    \n      \n      dataset\n      method\n      normal\n      lags\n      nof_filters\n      epoch\n      mse(train)\n      mse(test)\n      calculation_time\n    \n  \n  \n    \n      0\n      data2\n      EPT-STGCN\n      X\n      4\n      16\n      150\n      0.189039\n      0.16644\n      890.523769\n    \n    \n      1\n      data2\n      EPT-STGCN\n      X\n      4\n      32\n      150\n      0.1839\n      0.163163\n      901.624805\n    \n    \n      2\n      data2\n      EPT-STGCN\n      X\n      4\n      64\n      150\n      0.188576\n      0.16788\n      930.632719\n    \n    \n      3\n      data2\n      EPT-STGCN\n      X\n      8\n      16\n      150\n      0.191546\n      0.163098\n      922.549719\n    \n    \n      4\n      data2\n      EPT-STGCN\n      X\n      8\n      32\n      150\n      0.196264\n      0.171726\n      934.935377\n    \n    \n      5\n      data2\n      EPT-STGCN\n      X\n      8\n      64\n      150\n      0.193626\n      0.169606\n      971.07701\n    \n    \n      6\n      data2\n      EPT-STGCN\n      X\n      12\n      16\n      150\n      0.196048\n      0.16558\n      946.160373\n    \n    \n      7\n      data2\n      EPT-STGCN\n      X\n      12\n      32\n      150\n      0.196824\n      0.174657\n      953.823792\n    \n    \n      8\n      data2\n      EPT-STGCN\n      X\n      12\n      64\n      150\n      0.223708\n      0.18818\n      991.851157\n    \n  \n\n\n\n\n\nsimul_model_150.simulation_results\n\n\n\n\n\n  \n    \n      \n      dataset\n      method\n      normal\n      lags\n      nof_filters\n      epoch\n      mse(train)\n      mse(test)\n      calculation_time\n    \n  \n  \n    \n      0\n      data2\n      EPT-STGCN\n      NaN\n      4\n      16\n      150\n      0.192811\n      0.172286\n      1107.788696\n    \n    \n      1\n      data2\n      EPT-STGCN\n      NaN\n      4\n      32\n      150\n      0.196971\n      0.180187\n      1221.65175\n    \n    \n      2\n      data2\n      EPT-STGCN\n      NaN\n      4\n      64\n      150\n      0.180952\n      0.160223\n      1700.991477\n    \n    \n      3\n      data2\n      EPT-STGCN\n      NaN\n      8\n      16\n      150\n      0.206765\n      0.17639\n      1684.464239\n    \n    \n      4\n      data2\n      EPT-STGCN\n      NaN\n      8\n      32\n      150\n      0.196287\n      0.171737\n      1695.175945\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      115\n      data2\n      EPT-STGCN\n      NaN\n      12\n      32\n      150\n      0.196776\n      0.173983\n      1290.014739\n    \n    \n      116\n      data2\n      EPT-STGCN\n      NaN\n      12\n      64\n      150\n      0.197882\n      0.170004\n      1347.436289\n    \n    \n      117\n      data2\n      EPT-STGCN\n      NaN\n      24\n      16\n      150\n      0.222497\n      0.188107\n      1199.523731\n    \n    \n      118\n      data2\n      EPT-STGCN\n      NaN\n      24\n      32\n      150\n      0.25576\n      0.204602\n      1231.037348\n    \n    \n      119\n      data2\n      EPT-STGCN\n      NaN\n      24\n      64\n      150\n      0.222175\n      0.188326\n      1288.791447\n    \n  \n\n120 rows × 9 columns\n\n\n\n\nsimul_model_150 = eptstgcn.load_data('./simul_model2/stgcn_v2/second/stgcn_v2_150epoch.pickle')\nsimul_model_150.simulation_results\n\n\n\n\n\n  \n    \n      \n      dataset\n      method\n      normal\n      lags\n      nof_filters\n      epoch\n      mse(train)\n      mse(test)\n      calculation_time\n    \n  \n  \n    \n      0\n      data2\n      EPT-STGCN\n      X\n      4\n      16\n      150\n      0.178198\n      0.157106\n      1423.730819\n    \n    \n      1\n      data2\n      EPT-STGCN\n      X\n      4\n      32\n      150\n      0.181055\n      0.162908\n      1237.804481\n    \n    \n      2\n      data2\n      EPT-STGCN\n      X\n      4\n      64\n      150\n      0.183514\n      0.162532\n      1266.853936\n    \n    \n      3\n      data2\n      EPT-STGCN\n      X\n      8\n      16\n      150\n      0.196917\n      0.170607\n      1248.808106\n    \n    \n      4\n      data2\n      EPT-STGCN\n      X\n      8\n      32\n      150\n      0.19937\n      0.171157\n      1266.948898\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      115\n      data2\n      EPT-STGCN\n      X\n      12\n      32\n      150\n      0.189644\n      0.165611\n      1301.643343\n    \n    \n      116\n      data2\n      EPT-STGCN\n      X\n      12\n      64\n      150\n      0.232695\n      0.198717\n      1354.209712\n    \n    \n      117\n      data2\n      EPT-STGCN\n      X\n      24\n      16\n      150\n      0.238722\n      0.195829\n      1200.269542\n    \n    \n      118\n      data2\n      EPT-STGCN\n      X\n      24\n      32\n      150\n      0.21136\n      0.183716\n      1226.011955\n    \n    \n      119\n      data2\n      EPT-STGCN\n      X\n      24\n      64\n      150\n      0.223982\n      0.19227\n      1285.877905\n    \n  \n\n120 rows × 9 columns\n\n\n\n\nprint('stgcn ver2 150epoch 시뮬레이션 끄읕!^^')\n\nstgcn ver2 150epoch 시뮬레이션 끄읕!^^\n\n\n\nimport matplotlib.pyplot as plt\nplt.boxplot(df_simul_no['mse(test)'])\nplt.show()"
  },
  {
    "objectID": "posts/SOLAR/2023-03-29-data0.html",
    "href": "posts/SOLAR/2023-03-29-data0.html",
    "title": "Data preprocessing",
    "section": "",
    "text": "raw data\nprep_data\nDownload Link (homepage)\n\n\n\n\n\n\n\n\n\nfile name\ndescription\nnote\n\n\n\n\nOBS_ASOS_TIM_data0.csv\n2021-01-01 ~ 2021-12-31\n21년 데이터셋 (1년씩 다운 가능)\n\n\nOBS_ASOS_TIM_data1.csv\n2022-01-01 ~ 2022-12-31\n22년 데이터셋 (1년씩 다운 가능)\n\n\nraw.csv\n2021-01-01 ~ 2022-12-31\n21~22년 데이터셋 (위의 두개 데이터 합친 것)\n\n\nprep_data.csv\nraw.csv 전처리한 데이터셋\n\n\n\ntest_raw.csv\n2023-01-01 ~ 2023-01-15\n2주간의 데이터셋 for test (확정x)\n\n\nprep_test.csv\ntest_raw.csv 전처리한 데이터셋\nprep_data와 전처리과정 동일\n\n\nrestructuring_prep_data.csv\nprep_data.csv 재구조화, 결측치처리X\ncolumn:지점명, row:일시, value=일사량 으로 재구조화한 데이터셋 (observation number = \\(8030 \\times 45\\) )\n\n\nrestructuring_raw.csv\nraw.csv 재구조화, 결측치처리X\ncolumn:지점명, row:일시, value=일사량 으로 재구조화한 데이터셋 (observation number = \\(10379\\times50\\) )\n\n\n\n\n2021-01-01부터 2022-12-31 약 2년간의 데이터셋\n00시부터 23시까지 1시간 간격으로 측정한 데이터셋 (08시부터 18시까지 관측된 데이터가 대다수)\n총 49개의 지점\n\n\nimport pandas as pd\nimport numpy as np\nimport gc\n\n\ndf0 = pd.read_csv('./data/OBS_ASOS_TIM_data0.csv', encoding='cp949') # 2021-01-01 ~ 2021-12-31\ndf1 = pd.read_csv('./data/OBS_ASOS_TIM_data1.csv') # 2022-01-01 ~ 2023-12-31\ndf2 = pd.read_csv('./data/test_raw.csv', encoding='cp949') # 2023-01-01 ~ 2023-01-15\n\n\n# # dtype 변환 및 hour변수 생성.\n# df1['일시'] = pd.to_datetime(df1['일시'])\n# df1['Datetime'] = df1['일시'].dt.date\n# df1['hour'] = df1['일시'].dt.hour\n# df1.head()\n\n\n# import datetime\n# df1 = df1[df1['Datetime'] != datetime.date(2023, 1, 1)]\n# df1 = df1.drop(['Datetime', 'hour'], axis=1)\n# df1.to_csv('./data/OBS_ASOS_TIM_data1.csv', index=False)\n\n\ndf_raw = pd.concat([df0, df1])\ndf_raw.head()\n\n\n\n\n\n  \n    \n      \n      지점\n      지점명\n      일시\n      일사(MJ/m2)\n    \n  \n  \n    \n      0\n      93\n      북춘천\n      2021-01-01 08:00\n      0.00\n    \n    \n      1\n      93\n      북춘천\n      2021-01-01 09:00\n      0.37\n    \n    \n      2\n      93\n      북춘천\n      2021-01-01 10:00\n      0.96\n    \n    \n      3\n      93\n      북춘천\n      2021-01-01 11:00\n      1.40\n    \n    \n      4\n      93\n      북춘천\n      2021-01-01 12:00\n      1.72\n    \n  \n\n\n\n\n\ndf_raw.shape\n\n(444720, 4)\n\n\n\n# 2021-01-01 ~ 2023-01-01 dataset (2 years)\n# df_raw.to_csv('./data/raw.csv', index=False)"
  },
  {
    "objectID": "posts/SOLAR/2023-03-29-data0.html#데이터-탐색-for-preprocessing",
    "href": "posts/SOLAR/2023-03-29-data0.html#데이터-탐색-for-preprocessing",
    "title": "Data preprocessing",
    "section": "데이터 탐색 (for preprocessing)",
    "text": "데이터 탐색 (for preprocessing)\n\ngc.collect()\n\n38\n\n\n\n관측지점 수\n\n# 관측지점 수\nlen(df0['지점'].unique()), len(df1['지점'].unique())\n\n(48, 49)\n\n\n22년도에 관측지점이 하나 더 추가된 듯하다..\n\nset(df1['지점명'].unique()) - (set(df0['지점명'].unique()) & set(df1['지점명'].unique()))\n\n{'제천'}\n\n\n\ndf1[df1['지점명']=='제천']  # 관측기록이 1회밖에 없다.\n\n\n\n\n\n  \n    \n      \n      지점\n      지점명\n      일시\n      일사(MJ/m2)\n    \n  \n  \n    \n      167426\n      221\n      제천\n      2022-10-27 07:00:00\n      0.0\n    \n  \n\n\n\n\n제천에서 관측된 값이 하나밖에 없으므로 제거해주는 것이 좋을 듯 하다.\n\ndf0['지점명'].unique(),  df1['지점명'].unique()\n\n(array(['북춘천', '철원', '동두천', '파주', '대관령', '춘천', '백령도', '북강릉', '강릉', '서울',\n        '인천', '원주', '울릉도', '수원', '충주', '서산', '청주', '대전', '추풍령', '안동', '상주',\n        '포항', '대구', '전주', '창원', '광주', '부산', '목포', '여수', '흑산도', '고창', '홍성',\n        '제주', '고산', '진주', '고창군', '영광군', '김해시', '순창군', '북창원', '양산시', '보성군',\n        '강진군', '의령군', '함양군', '광양시', '청송군', '경주시'], dtype=object),\n array(['북춘천', '철원', '동두천', '파주', '대관령', '춘천', '백령도', '북강릉', '강릉', '서울',\n        '인천', '원주', '울릉도', '수원', '충주', '서산', '청주', '대전', '추풍령', '안동', '상주',\n        '포항', '대구', '전주', '창원', '광주', '부산', '목포', '여수', '흑산도', '고창', '홍성',\n        '제주', '고산', '진주', '제천', '고창군', '영광군', '김해시', '순창군', '북창원', '양산시',\n        '보성군', '강진군', '의령군', '함양군', '광양시', '청송군', '경주시'], dtype=object))\n\n\n\n\n날짜형 변환 및 Datetime, hour 변수 생성\n\n# dtype 변환 및 hour변수 생성.\ndf_raw['일시'] = pd.to_datetime(df_raw['일시'])\ndf_raw['Datetime'] = df_raw['일시'].dt.date\ndf_raw['hour'] = df_raw['일시'].dt.hour\ndf_raw.head()\n\n\n\n\n\n  \n    \n      \n      지점\n      지점명\n      일시\n      일사(MJ/m2)\n      Datetime\n      hour\n    \n  \n  \n    \n      0\n      93\n      북춘천\n      2021-01-01 08:00:00\n      0.00\n      2021-01-01\n      8\n    \n    \n      1\n      93\n      북춘천\n      2021-01-01 09:00:00\n      0.37\n      2021-01-01\n      9\n    \n    \n      2\n      93\n      북춘천\n      2021-01-01 10:00:00\n      0.96\n      2021-01-01\n      10\n    \n    \n      3\n      93\n      북춘천\n      2021-01-01 11:00:00\n      1.40\n      2021-01-01\n      11\n    \n    \n      4\n      93\n      북춘천\n      2021-01-01 12:00:00\n      1.72\n      2021-01-01\n      12\n    \n  \n\n\n\n\n\ndf_raw.info()\n\n<class 'pandas.core.frame.DataFrame'>\nInt64Index: 444720 entries, 0 to 229676\nData columns (total 6 columns):\n #   Column     Non-Null Count   Dtype         \n---  ------     --------------   -----         \n 0   지점         444720 non-null  int64         \n 1   지점명        444720 non-null  object        \n 2   일시         444720 non-null  datetime64[ns]\n 3   일사(MJ/m2)  444720 non-null  float64       \n 4   Datetime   444720 non-null  object        \n 5   hour       444720 non-null  int64         \ndtypes: datetime64[ns](1), float64(1), int64(2), object(2)\nmemory usage: 23.8+ MB\n\n\n\ndf_raw.shape[0]/df_raw['지점명'].nunique() # 지점하나당 9000개 정도의 관측치가 있음.\n\n9075.918367346938\n\n\n\n\n시간대별 관측치 수\n\ndf_raw['hour'].value_counts().sort_index()\n\n0       114\n1       114\n2       114\n3       114\n4       114\n5       186\n6     12896\n7     23300\n8     33764\n9     33779\n10    33780\n11    33763\n12    33768\n13    33773\n14    33773\n15    33772\n16    33783\n17    33759\n18    33737\n19    22851\n20    13032\n21      206\n22      114\n23      114\nName: hour, dtype: int64\n\n\n00시부터 23시까지 필터링해서 홈페이지에서 다운받아왔지만 대다수 데이터가 08시~18시까지 관측되어있음.\n\n\n지점별 관측치 수 (2021-01-01 ~ 2023-01-01)\n\npd.DataFrame(df_raw['지점명'].value_counts())\n\n\n\n\n\n  \n    \n      \n      지점명\n    \n  \n  \n    \n      백령도\n      9673\n    \n    \n      울릉도\n      9608\n    \n    \n      창원\n      9595\n    \n    \n      의령군\n      9594\n    \n    \n      북강릉\n      9592\n    \n    \n      강진군\n      9591\n    \n    \n      제주\n      9591\n    \n    \n      대구\n      9591\n    \n    \n      목포\n      9587\n    \n    \n      북창원\n      9586\n    \n    \n      포항\n      9585\n    \n    \n      홍성\n      9585\n    \n    \n      여수\n      9585\n    \n    \n      철원\n      9584\n    \n    \n      북춘천\n      9584\n    \n    \n      함양군\n      9583\n    \n    \n      서울\n      9582\n    \n    \n      춘천\n      9581\n    \n    \n      청송군\n      9581\n    \n    \n      고산\n      9581\n    \n    \n      보성군\n      9580\n    \n    \n      경주시\n      9579\n    \n    \n      원주\n      9579\n    \n    \n      대관령\n      9578\n    \n    \n      광양시\n      9576\n    \n    \n      안동\n      9574\n    \n    \n      김해시\n      9574\n    \n    \n      인천\n      9573\n    \n    \n      서산\n      9572\n    \n    \n      고창군\n      9571\n    \n    \n      수원\n      9570\n    \n    \n      전주\n      9566\n    \n    \n      순창군\n      9566\n    \n    \n      청주\n      9565\n    \n    \n      진주\n      9563\n    \n    \n      추풍령\n      9557\n    \n    \n      영광군\n      9554\n    \n    \n      부산\n      9553\n    \n    \n      양산시\n      9547\n    \n    \n      고창\n      9531\n    \n    \n      강릉\n      9478\n    \n    \n      광주\n      9469\n    \n    \n      흑산도\n      9428\n    \n    \n      대전\n      9418\n    \n    \n      파주\n      6172\n    \n    \n      상주\n      6169\n    \n    \n      동두천\n      6164\n    \n    \n      충주\n      5254\n    \n    \n      제천\n      1\n    \n  \n\n\n\n\n\n365*2*11 # 11시간관측을 기준으로 했을 때 지점당 관측치 개수..\n\n8030\n\n\n대다수 지점에서 2년간 약 9500건 관측되었지만, 파주, 상주, 동두천, 충주, 제천(1)은 다른지점에 비해 관측치가 적음.\n\n\n파주, 상주, 동두천\n\ndf_raw.head() ## 북춘천\n\n\n\n\n\n  \n    \n      \n      지점\n      지점명\n      일시\n      일사(MJ/m2)\n      Datetime\n      hour\n    \n  \n  \n    \n      0\n      93\n      북춘천\n      2021-01-01 08:00:00\n      0.00\n      2021-01-01\n      8\n    \n    \n      1\n      93\n      북춘천\n      2021-01-01 09:00:00\n      0.37\n      2021-01-01\n      9\n    \n    \n      2\n      93\n      북춘천\n      2021-01-01 10:00:00\n      0.96\n      2021-01-01\n      10\n    \n    \n      3\n      93\n      북춘천\n      2021-01-01 11:00:00\n      1.40\n      2021-01-01\n      11\n    \n    \n      4\n      93\n      북춘천\n      2021-01-01 12:00:00\n      1.72\n      2021-01-01\n      12\n    \n  \n\n\n\n\n\ndf_raw[df_raw['지점명']=='파주'].iloc[[0]] \n\n\n\n\n\n  \n    \n      \n      지점\n      지점명\n      일시\n      일사(MJ/m2)\n      Datetime\n      hour\n    \n  \n  \n    \n      10961\n      99\n      파주\n      2021-10-12\n      0.0\n      2021-10-12\n      0\n    \n  \n\n\n\n\n\ndf_raw[df_raw['지점명']=='상주'].iloc[[0]]\n\n\n\n\n\n  \n    \n      \n      지점\n      지점명\n      일시\n      일사(MJ/m2)\n      Datetime\n      hour\n    \n  \n  \n    \n      84525\n      137\n      상주\n      2021-10-12\n      0.0\n      2021-10-12\n      0\n    \n  \n\n\n\n\n\ndf_raw[df_raw['지점명']=='동두천'].iloc[[0]]\n\n\n\n\n\n  \n    \n      \n      지점\n      지점명\n      일시\n      일사(MJ/m2)\n      Datetime\n      hour\n    \n  \n  \n    \n      9583\n      98\n      동두천\n      2021-10-12\n      0.0\n      2021-10-12\n      0\n    \n  \n\n\n\n\n\n\n충주\n\ndf_raw[df_raw['지점명']=='충주'].iloc[[0]]\n\n\n\n\n\n  \n    \n      \n      지점\n      지점명\n      일시\n      일사(MJ/m2)\n      Datetime\n      hour\n    \n  \n  \n    \n      60308\n      127\n      충주\n      2021-11-18 18:00:00\n      0.0\n      2021-11-18\n      18\n    \n  \n\n\n\n\n\n\n제천\n\ndf_raw[df_raw['지점명']=='제천']\n\n\n\n\n\n  \n    \n      \n      지점\n      지점명\n      일시\n      일사(MJ/m2)\n      Datetime\n      hour\n    \n  \n  \n    \n      167426\n      221\n      제천\n      2022-10-27 07:00:00\n      0.0\n      2022-10-27\n      7\n    \n  \n\n\n\n\n\n보유기간 1904년 4월 ~ 현재 (지점별 상이함)\n\n\n파주, 상주, 동두천 지점은 2021-10-12일 이전의 기록은 보유하고 있지 않음.\n충주는 2021-11-18일 이전의 기록은 보유하고 있지 않음.\n제천은 2022-10-27일 단 하루만의 기록만 있음.\nref: https://minwon.kma.go.kr/main/obvStn.do\nref: https://data.kma.go.kr/data/grnd/selectAsosRltmList.do?pgmNo=36"
  },
  {
    "objectID": "posts/SOLAR/2023-03-29-data0.html#데이터-처리-및-csv파일로-내보내기",
    "href": "posts/SOLAR/2023-03-29-data0.html#데이터-처리-및-csv파일로-내보내기",
    "title": "Data preprocessing",
    "section": "데이터 처리 및 csv파일로 내보내기",
    "text": "데이터 처리 및 csv파일로 내보내기\n\n제천, 파주, 상주, 동두천 제거\n\ndf_prep1 = df_raw[~df_raw['지점명'].str.contains('제천|파주|상주|동두천|충주')]\n\n\n\n관측시간 08시 ~ 18시\n\ndf_prep1[(df_prep1['hour']>=8) & (df_prep1['hour'] <= 18)]\n\n\n\n\n\n  \n    \n      \n      지점\n      지점명\n      일시\n      일사(MJ/m2)\n      Datetime\n      hour\n    \n  \n  \n    \n      0\n      93\n      북춘천\n      2021-01-01 08:00:00\n      0.00\n      2021-01-01\n      8\n    \n    \n      1\n      93\n      북춘천\n      2021-01-01 09:00:00\n      0.37\n      2021-01-01\n      9\n    \n    \n      2\n      93\n      북춘천\n      2021-01-01 10:00:00\n      0.96\n      2021-01-01\n      10\n    \n    \n      3\n      93\n      북춘천\n      2021-01-01 11:00:00\n      1.40\n      2021-01-01\n      11\n    \n    \n      4\n      93\n      북춘천\n      2021-01-01 12:00:00\n      1.72\n      2021-01-01\n      12\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      229672\n      283\n      경주시\n      2022-12-31 14:00:00\n      1.82\n      2022-12-31\n      14\n    \n    \n      229673\n      283\n      경주시\n      2022-12-31 15:00:00\n      1.52\n      2022-12-31\n      15\n    \n    \n      229674\n      283\n      경주시\n      2022-12-31 16:00:00\n      0.96\n      2022-12-31\n      16\n    \n    \n      229675\n      283\n      경주시\n      2022-12-31 17:00:00\n      0.35\n      2022-12-31\n      17\n    \n    \n      229676\n      283\n      경주시\n      2022-12-31 18:00:00\n      0.01\n      2022-12-31\n      18\n    \n  \n\n352279 rows × 6 columns\n\n\n\n\ndf_prep1[(df_prep1['hour']>=8) & (df_prep1['hour'] <= 18)]['hour'].value_counts().sort_index()\n\n8     32025\n9     32038\n10    32036\n11    32020\n12    32025\n13    32028\n14    32029\n15    32028\n16    32039\n17    32017\n18    31994\nName: hour, dtype: int64\n\n\n\ndf_prep2 = df_prep1[(df_prep1['hour']>=8) & (df_prep1['hour'] <= 18)]\ndf_prep2.head()\n\n\n\n\n\n  \n    \n      \n      지점\n      지점명\n      일시\n      일사(MJ/m2)\n      Datetime\n      hour\n    \n  \n  \n    \n      0\n      93\n      북춘천\n      2021-01-01 08:00:00\n      0.00\n      2021-01-01\n      8\n    \n    \n      1\n      93\n      북춘천\n      2021-01-01 09:00:00\n      0.37\n      2021-01-01\n      9\n    \n    \n      2\n      93\n      북춘천\n      2021-01-01 10:00:00\n      0.96\n      2021-01-01\n      10\n    \n    \n      3\n      93\n      북춘천\n      2021-01-01 11:00:00\n      1.40\n      2021-01-01\n      11\n    \n    \n      4\n      93\n      북춘천\n      2021-01-01 12:00:00\n      1.72\n      2021-01-01\n      12\n    \n  \n\n\n\n\n\ndf_prep2['지점명'].nunique()\n\n44\n\n\n\ndf_prep2['지점명'].value_counts()\n\n북춘천    8030\n북강릉    8030\n철원     8030\n강진군    8030\n백령도    8029\n의령군    8029\n홍성     8029\n목포     8028\n창원     8028\n춘천     8027\n제주     8026\n원주     8026\n대구     8026\n서울     8025\n북창원    8023\n여수     8023\n함양군    8023\n대관령    8022\n포항     8021\n보성군    8021\n인천     8019\n청송군    8019\n서산     8019\n김해시    8018\n고산     8018\n경주시    8018\n수원     8014\n광양시    8012\n안동     8012\n순창군    8012\n고창군    8011\n청주     8009\n추풍령    8007\n전주     8006\n영광군    8001\n진주     7999\n부산     7989\n양산시    7987\n고창     7981\n울릉도    7974\n광주     7925\n강릉     7920\n흑산도    7896\n대전     7887\nName: 지점명, dtype: int64\n\n\n\ndf_prep2.to_csv('./data/prep_data.csv', index=False)"
  },
  {
    "objectID": "posts/SOLAR/2023-03-29-data0.html#테스트용-데이터-전처리",
    "href": "posts/SOLAR/2023-03-29-data0.html#테스트용-데이터-전처리",
    "title": "Data preprocessing",
    "section": "테스트용 데이터 전처리",
    "text": "테스트용 데이터 전처리\n\n# df2 = pd.read_csv('./data/test_raw.csv', encoding='cp949')\ngc.collect()\n\n1258\n\n\n\n# dtype 변환 및 hour변수 생성.\ndf2['일시'] = pd.to_datetime(df2['일시'])\ndf2['Datetime'] = df2['일시'].dt.date\ndf2['hour'] = df2['일시'].dt.hour\ndf2.head()\n\n\n\n\n\n  \n    \n      \n      지점\n      지점명\n      일시\n      일사(MJ/m2)\n      Datetime\n      hour\n    \n  \n  \n    \n      0\n      93\n      북춘천\n      2023-01-01 08:00:00\n      0.00\n      2023-01-01\n      8\n    \n    \n      1\n      93\n      북춘천\n      2023-01-01 09:00:00\n      0.32\n      2023-01-01\n      9\n    \n    \n      2\n      93\n      북춘천\n      2023-01-01 10:00:00\n      0.90\n      2023-01-01\n      10\n    \n    \n      3\n      93\n      북춘천\n      2023-01-01 11:00:00\n      1.73\n      2023-01-01\n      11\n    \n    \n      4\n      93\n      북춘천\n      2023-01-01 12:00:00\n      1.86\n      2023-01-01\n      12\n    \n  \n\n\n\n\n\ndf2 = df2[~df2['지점명'].str.contains('제천|파주|상주|동두천|충주')]\n\n\ndf2 = df2[(df2['hour']>=8) & (df2['hour'] <= 18)]\ndf2.head()\n\n\n\n\n\n  \n    \n      \n      지점\n      지점명\n      일시\n      일사(MJ/m2)\n      Datetime\n      hour\n    \n  \n  \n    \n      0\n      93\n      북춘천\n      2023-01-01 08:00:00\n      0.00\n      2023-01-01\n      8\n    \n    \n      1\n      93\n      북춘천\n      2023-01-01 09:00:00\n      0.32\n      2023-01-01\n      9\n    \n    \n      2\n      93\n      북춘천\n      2023-01-01 10:00:00\n      0.90\n      2023-01-01\n      10\n    \n    \n      3\n      93\n      북춘천\n      2023-01-01 11:00:00\n      1.73\n      2023-01-01\n      11\n    \n    \n      4\n      93\n      북춘천\n      2023-01-01 12:00:00\n      1.86\n      2023-01-01\n      12\n    \n  \n\n\n\n\n\ndf2['hour'].value_counts()\n\n9     660\n10    660\n11    660\n13    660\n14    660\n15    660\n12    659\n16    659\n17    659\n18    659\n8     653\nName: hour, dtype: int64\n\n\n\n# df2.to_csv('./data/prep_test.csv',index=False)"
  },
  {
    "objectID": "posts/SOLAR/2023-04-21-정규화-스케일링-stgcn-ver2--guebin.html",
    "href": "posts/SOLAR/2023-04-21-정규화-스케일링-stgcn-ver2--guebin.html",
    "title": "[SOLAR] STGCN Ver2 (+N +S) (MSE: 0.1801) – guebin",
    "section": "",
    "text": "train 2022-06-01 00:00:00 ~ 2022-08-14 17:00:00\ntest 2022-08-14 18:00:00 ~ 2022-09-15 23:00:00"
  },
  {
    "objectID": "posts/SOLAR/2023-04-21-정규화-스케일링-stgcn-ver2--guebin.html#import",
    "href": "posts/SOLAR/2023-04-21-정규화-스케일링-stgcn-ver2--guebin.html#import",
    "title": "[SOLAR] STGCN Ver2 (+N +S) (MSE: 0.1801) – guebin",
    "section": "import",
    "text": "import\n\nimport pandas as pd\nimport numpy as np\nimport json\nimport urllib\nimport time\n\n\n# 일반적인 모듈 \nimport numpy as np\nimport matplotlib.pyplot as plt \nimport networkx as nx \nfrom tqdm import tqdm \n\n# 파이토치 관련 \nimport torch\nimport torch.nn.functional as F\n\n# PyG 관련 \nfrom torch_geometric.data import Data ## Data: 그래프자료형을 만드는 클래스\n\n# STGCN 관련 \nimport torch_geometric_temporal\nfrom torch_geometric_temporal.nn.recurrent import GConvGRU\nfrom torch_geometric_temporal.signal import temporal_signal_split \n\n\nclass RecurrentGCN(torch.nn.Module):\n    def __init__(self, node_features, filters):\n        super(RecurrentGCN, self).__init__()\n        self.recurrent = GConvGRU(node_features, filters, 2)\n        self.linear = torch.nn.Linear(filters, 1)\n\n    def forward(self, x, edge_index, edge_weight):\n        h = self.recurrent(x, edge_index, edge_weight)\n        h = F.relu(h)\n        h = self.linear(h)\n        return h\n\n\nfrom mysolar2 import SolarDatasetLoader\n\n\nurl = \"https://raw.githubusercontent.com/pinkocto/noteda/main/posts/SOLAR/data2/stgcn_data2.json\"\nloader = SolarDatasetLoader(url)\ndataset = loader.get_dataset(lags=4)\n\n\ndef minmaxscaler(arr):\n    arr = arr - arr.min()\n    arr = arr/arr.max()\n    return arr \n\n\ndataset.edge_weight = minmaxscaler(dataset.edge_weight)\ntrain_dataset, test_dataset = temporal_signal_split(dataset, train_ratio=0.7)"
  },
  {
    "objectID": "posts/SOLAR/2023-04-21-정규화-스케일링-stgcn-ver2--guebin.html#learn",
    "href": "posts/SOLAR/2023-04-21-정규화-스케일링-stgcn-ver2--guebin.html#learn",
    "title": "[SOLAR] STGCN Ver2 (+N +S) (MSE: 0.1801) – guebin",
    "section": "Learn",
    "text": "Learn\n\nmodel = RecurrentGCN(node_features=4, filters=32)\noptimizer = torch.optim.Adam(model.parameters(), lr=0.01)\nmodel.train()\n\nfor epoch in tqdm(range(50)):\n    for t, snapshot in enumerate(train_dataset):\n        yt_hat = model(snapshot.x, snapshot.edge_index, snapshot.edge_attr)\n        cost = torch.mean((yt_hat-snapshot.y)**2)\n        cost.backward()\n        optimizer.step()\n        optimizer.zero_grad()\n\n100%|██████████| 50/50 [05:26<00:00,  6.53s/it]\n\n\n\n# import pickle \n# with open('./model3/normal_stgcn1_lag4_new.pickle','wb') as fw:\n#     pickle.dump(model, fw)\n\n\n# import pickle \n# with open('./model3/normal_stgcn1_lag4_new.pickle', 'rb') as f: \n#     model = pickle.load(f)\n\n- train\n\nMSE: 0.2102 (before normalize)\n\n\nmodel.eval()\ncost = 0\nfor time, snapshot in enumerate(train_dataset):\n    y_hat = model(snapshot.x, snapshot.edge_index, snapshot.edge_attr)\n    cost = cost + torch.mean((y_hat-snapshot.y)**2)\ncost = cost / (time+1)\ncost = cost.item()\nprint(\"MSE: {:.4f}\".format(cost))\n\nMSE: 0.1966\n\n\n- test\n\nMSE: 0.1899 (before normalize)\n\n\nmodel.eval()\ncost = 0\nfor time, snapshot in enumerate(test_dataset):\n    y_hat = model(snapshot.x, snapshot.edge_index, snapshot.edge_attr)\n    cost = cost + torch.mean((y_hat-snapshot.y)**2)\ncost = cost / (time+1)\ncost = cost.item()\nprint(\"MSE: {:.4f}\".format(cost))\n\nMSE: 0.1801"
  },
  {
    "objectID": "posts/SOLAR/2023-04-21-정규화-스케일링-stgcn-ver2--guebin.html#visualization",
    "href": "posts/SOLAR/2023-04-21-정규화-스케일링-stgcn-ver2--guebin.html#visualization",
    "title": "[SOLAR] STGCN Ver2 (+N +S) (MSE: 0.1801) – guebin",
    "section": "Visualization",
    "text": "Visualization\n\nurl = 'https://raw.githubusercontent.com/pinkocto/noteda/main/posts/SOLAR/data2/stgcn_data1.json'\n\n\ndata_dict = json.loads(urllib.request.urlopen(url).read())\nV = list(data_dict['node_ids'].keys())\nf = np.array(data_dict[\"FX\"])\n\n\nyhat_train = torch.stack([model(snapshot.x,snapshot.edge_index, snapshot.edge_attr) for snapshot in train_dataset]).detach().numpy()\nyhat_test = torch.stack([model(snapshot.x,snapshot.edge_index, snapshot.edge_attr) for snapshot in test_dataset]).detach().numpy()\n\n\nf.shape\n\n(2568, 44)\n\n\n\nyhat_test.shape[0] +  yhat_train.shape[0]\n\n2564\n\n\n\nyhat_test.shape, yhat_train.shape\n\n((770, 44, 1), (1794, 44, 1))\n\n\n\nimport matplotlib.pyplot as plt\nplt.rcParams['font.family'] = 'NanumGothic'\n\n\ntrain\n\nfig,ax = plt.subplots(44,1,figsize=(10,50))\nlag= 0 \nT = 100 \nfor k in range(44):\n    ax[k].plot(np.array(train_dataset.targets)[lag:(lag+T),k],'--',alpha=0.5,label='observed', color='green')\n    ax[k].set_title('node: {}'.format(V[k]))\n    ax[k].plot(yhat_train[:T,k],label='predicted (tr)', color = 'orange')\n#    ax[k].plot(range(yhat_train.shape[0],yhat_train.shape[0]+yhat_test.shape[0]),yhat_test[:,k],label='predicted (test)')\n    ax[k].legend()\nfig.tight_layout()\n\n# plt.savefig('stgcn-ver2-lag4-vis.png')\n\n\n\n\n\nnp.array(dataset.features).shape\n\n(2564, 44, 4)\n\n\n\nnp.array(dataset.targets).shape\n\n(2564, 44)\n\n\n\nnp.array(train_dataset.targets).shape\n\n(1794, 44)\n\n\n\nnp.array(test_dataset.targets).shape\n\n(770, 44)\n\n\n\n\ntest\n\nfig,ax = plt.subplots(44,1,figsize=(10,50))\nlag= 0\nT = 100 \nfor k in range(44):\n    ax[k].plot(np.array(test_dataset.targets)[lag:(lag+T),k],'--',alpha=0.5,label='observed')\n    ax[k].set_title('node: {}'.format(V[k]))\n    ax[k].plot(yhat_test[:T,k],label='predicted (test)', color='red')\n#    ax[k].plot(range(yhat_train.shape[0],yhat_train.shape[0]+yhat_test.shape[0]),yhat_test[:,k],label='predicted (test)')\n    ax[k].legend()\nfig.tight_layout()\n\n# plt.savefig('stgcn-ver2-lag4-vis.png')"
  },
  {
    "objectID": "posts/SOLAR/2023-04-17-정규화-stgcn-ver1-.html",
    "href": "posts/SOLAR/2023-04-17-정규화-stgcn-ver1-.html",
    "title": "[SOLAR] STGCN Ver1 (data2, +N) (MSE: 0.1705)",
    "section": "",
    "text": "train 2022-06-01 00:00:00 ~ 2022-08-14 17:00:00\ntest 2022-08-14 18:00:00 ~ 2022-09-15 23:00:00"
  },
  {
    "objectID": "posts/SOLAR/2023-04-17-정규화-stgcn-ver1-.html#import",
    "href": "posts/SOLAR/2023-04-17-정규화-stgcn-ver1-.html#import",
    "title": "[SOLAR] STGCN Ver1 (data2, +N) (MSE: 0.1705)",
    "section": "import",
    "text": "import\n\nimport pandas as pd\nimport numpy as np\nimport json\nimport urllib\nimport time\n\n\n# 일반적인 모듈 \nimport numpy as np\nimport matplotlib.pyplot as plt \nimport networkx as nx \nfrom tqdm import tqdm \n\n# 파이토치 관련 \nimport torch\nimport torch.nn.functional as F\n\n# PyG 관련 \nfrom torch_geometric.data import Data ## Data: 그래프자료형을 만드는 클래스\n\n# STGCN 관련 \nimport torch_geometric_temporal\nfrom torch_geometric_temporal.nn.recurrent import GConvGRU\nfrom torch_geometric_temporal.signal import temporal_signal_split \n\n\nclass RecurrentGCN(torch.nn.Module):\n    def __init__(self, node_features, filters):\n        super(RecurrentGCN, self).__init__()\n        self.recurrent = GConvGRU(node_features, filters, 2)\n        self.linear = torch.nn.Linear(filters, 1)\n\n    def forward(self, x, edge_index, edge_weight):\n        h = self.recurrent(x, edge_index, edge_weight)\n        h = F.relu(h)\n        h = self.linear(h)\n        return h\n\n\nfrom mysolar2 import NormalSolarDatasetLoader\n\n\nloader = NormalSolarDatasetLoader()\ndataset = loader.get_dataset(lags=4)\ntrain_dataset, test_dataset = temporal_signal_split(dataset, train_ratio=0.7)\n\n\nprint(np.array(train_dataset.targets).shape)\nprint(np.array(test_dataset.targets).shape)\n\n(1794, 44)\n(770, 44)\n\n\n\ntrain 2022-06-01 00:00:00 ~ 2022-08-14 17:00:00\ntest 2022-08-14 18:00:00 ~ 2022-09-15 23:00:00"
  },
  {
    "objectID": "posts/SOLAR/2023-04-17-정규화-stgcn-ver1-.html#learn",
    "href": "posts/SOLAR/2023-04-17-정규화-stgcn-ver1-.html#learn",
    "title": "[SOLAR] STGCN Ver1 (data2, +N) (MSE: 0.1705)",
    "section": "Learn",
    "text": "Learn\n\nmodel = RecurrentGCN(node_features=4, filters=32)\noptimizer = torch.optim.Adam(model.parameters(), lr=0.01)\nmodel.train()\n\nfor epoch in tqdm(range(50)):\n    for t, snapshot in enumerate(train_dataset):\n        yt_hat = model(snapshot.x, snapshot.edge_index, snapshot.edge_attr)\n        cost = torch.mean((yt_hat-snapshot.y)**2)\n        cost.backward()\n        optimizer.step()\n        optimizer.zero_grad()\n\n100%|██████████| 50/50 [05:00<00:00,  6.02s/it]\n\n\n\nimport pickle \nwith open('./model3/normal_stgcn1_lag4_new.pickle','wb') as fw:\n    pickle.dump(model, fw)\n\n\nimport pickle \nwith open('./model3/normal_stgcn1_lag4_new.pickle', 'rb') as f: \n    model = pickle.load(f)\n\n\nmodel\n\nRecurrentGCN(\n  (recurrent): GConvGRU(\n    (conv_x_z): ChebConv(4, 32, K=2, normalization=sym)\n    (conv_h_z): ChebConv(32, 32, K=2, normalization=sym)\n    (conv_x_r): ChebConv(4, 32, K=2, normalization=sym)\n    (conv_h_r): ChebConv(32, 32, K=2, normalization=sym)\n    (conv_x_h): ChebConv(4, 32, K=2, normalization=sym)\n    (conv_h_h): ChebConv(32, 32, K=2, normalization=sym)\n  )\n  (linear): Linear(in_features=32, out_features=1, bias=True)\n)"
  },
  {
    "objectID": "posts/SOLAR/2023-04-17-정규화-stgcn-ver1-.html#모델평가",
    "href": "posts/SOLAR/2023-04-17-정규화-stgcn-ver1-.html#모델평가",
    "title": "[SOLAR] STGCN Ver1 (data2, +N) (MSE: 0.1705)",
    "section": "모델평가",
    "text": "모델평가\n- train\n\nMSE: 0.2102 (before normalize)\n\n\nmodel.eval()\ncost = 0\nfor time, snapshot in enumerate(train_dataset):\n    y_hat = model(snapshot.x, snapshot.edge_index, snapshot.edge_attr)\n    cost = cost + torch.mean((y_hat-snapshot.y)**2)\ncost = cost / (time+1)\ncost = cost.item()\nprint(\"MSE: {:.4f}\".format(cost))\n\nMSE: 0.1846\n\n\n- test\n\nMSE: 0.1899 (before normalize)\n\n\nmodel.eval()\ncost = 0\nfor time, snapshot in enumerate(test_dataset):\n    y_hat = model(snapshot.x, snapshot.edge_index, snapshot.edge_attr)\n    cost = cost + torch.mean((y_hat-snapshot.y)**2)\ncost = cost / (time+1)\ncost = cost.item()\nprint(\"MSE: {:.4f}\".format(cost))\n\nMSE: 0.1705"
  },
  {
    "objectID": "posts/SOLAR/2023-04-17-정규화-stgcn-ver1-.html#visualization",
    "href": "posts/SOLAR/2023-04-17-정규화-stgcn-ver1-.html#visualization",
    "title": "[SOLAR] STGCN Ver1 (data2, +N) (MSE: 0.1705)",
    "section": "Visualization",
    "text": "Visualization\n\nurl = 'https://raw.githubusercontent.com/pinkocto/noteda/main/posts/SOLAR/data2/stgcn_data1.json'\n\n\ndata_dict = json.loads(urllib.request.urlopen(url).read())\nV = list(data_dict['node_ids'].keys())\nf = np.array(data_dict[\"FX\"])\n\n\nyhat_train = torch.stack([model(snapshot.x,snapshot.edge_index, snapshot.edge_attr) for snapshot in train_dataset]).detach().numpy()\nyhat_test = torch.stack([model(snapshot.x,snapshot.edge_index, snapshot.edge_attr) for snapshot in test_dataset]).detach().numpy()\n\n\nf.shape\n\n(2568, 44)\n\n\n\nyhat_test.shape[0] +  yhat_train.shape[0]\n\n2564\n\n\n\nyhat_test.shape, yhat_train.shape\n\n((770, 44, 1), (1794, 44, 1))\n\n\n\nimport matplotlib.pyplot as plt\nplt.rcParams['font.family'] = 'NanumGothic'\n\n\ntrain\n\nfig,ax = plt.subplots(44,1,figsize=(10,50))\nlag= 0 \nT = 100 \nfor k in range(44):\n    ax[k].plot(np.array(train_dataset.targets)[lag:(lag+T),k],'--',alpha=0.5,label='observed', color='green')\n    ax[k].set_title('node: {}'.format(V[k]))\n    ax[k].plot(yhat_train[:T,k],label='predicted (tr)', color = 'orange')\n#    ax[k].plot(range(yhat_train.shape[0],yhat_train.shape[0]+yhat_test.shape[0]),yhat_test[:,k],label='predicted (test)')\n    ax[k].legend()\nfig.tight_layout()\n\n# plt.savefig('stgcn-ver2-lag4-vis.png')\n\n\n\n\n\nnp.array(dataset.features).shape\n\n(2350, 44, 4)\n\n\n\nnp.array(dataset.targets).shape\n\n(2350, 44)\n\n\n\nnp.array(train_dataset.targets).shape\n\n(1645, 44)\n\n\n\nnp.array(test_dataset.targets).shape\n\n(705, 44)\n\n\n\n\ntest\n\nfig,ax = plt.subplots(44,1,figsize=(10,50))\nlag= 0\nT = 100 \nfor k in range(44):\n    ax[k].plot(np.array(test_dataset.targets)[lag:(lag+T),k],'--',alpha=0.5,label='observed')\n    ax[k].set_title('node: {}'.format(V[k]))\n    ax[k].plot(yhat_test[:T,k],label='predicted (test)', color='red')\n#    ax[k].plot(range(yhat_train.shape[0],yhat_train.shape[0]+yhat_test.shape[0]),yhat_test[:,k],label='predicted (test)')\n    ax[k].legend()\nfig.tight_layout()\n\n# plt.savefig('stgcn-ver2-lag4-vis.png')"
  },
  {
    "objectID": "posts/SOLAR/2023-04-07-soloar-stgcn-ver1-lag4.html",
    "href": "posts/SOLAR/2023-04-07-soloar-stgcn-ver1-lag4.html",
    "title": "[SOLAR] STGCN Ver1 lag4",
    "section": "",
    "text": "import pandas as pd\nimport numpy as np\nimport json\nimport urllib\n\n\n# 일반적인 모듈 \nimport numpy as np\nimport matplotlib.pyplot as plt \nimport networkx as nx \nfrom tqdm import tqdm \n\n# 파이토치 관련 \nimport torch\nimport torch.nn.functional as F\n\n# PyG 관련 \nfrom torch_geometric.data import Data ## Data: 그래프자료형을 만드는 클래스\n\n# STGCN 관련 \nimport torch_geometric_temporal\nfrom torch_geometric_temporal.nn.recurrent import GConvGRU\nfrom torch_geometric_temporal.signal import temporal_signal_split \n\n\nclass RecurrentGCN(torch.nn.Module):\n    def __init__(self, node_features, filters):\n        super(RecurrentGCN, self).__init__()\n        self.recurrent = GConvGRU(node_features, filters, 2)\n        self.linear = torch.nn.Linear(filters, 1)\n\n    def forward(self, x, edge_index, edge_weight):\n        h = self.recurrent(x, edge_index, edge_weight)\n        h = F.relu(h)\n        h = self.linear(h)\n        return h\n\n\nimport pickle \nwith open('stgcn.pickle', 'rb') as f: \n    model = pickle.load(f)\n\n\nmodel\n\nRecurrentGCN(\n  (recurrent): GConvGRU(\n    (conv_x_z): ChebConv(4, 32, K=2, normalization=sym)\n    (conv_h_z): ChebConv(32, 32, K=2, normalization=sym)\n    (conv_x_r): ChebConv(4, 32, K=2, normalization=sym)\n    (conv_h_r): ChebConv(32, 32, K=2, normalization=sym)\n    (conv_x_h): ChebConv(4, 32, K=2, normalization=sym)\n    (conv_h_h): ChebConv(32, 32, K=2, normalization=sym)\n  )\n  (linear): Linear(in_features=32, out_features=1, bias=True)\n)\n\n\n\nfrom mysolar import SolarDatasetLoader\n\n\nloader = SolarDatasetLoader()\ndataset = loader.get_dataset(lags=4)\ntrain_dataset, test_dataset = temporal_signal_split(dataset, train_ratio=0.8)\n\n\nnp.array(dataset.features).shape\n\n(18246, 44, 4)"
  },
  {
    "objectID": "posts/SOLAR/2023-04-07-soloar-stgcn-ver1-lag4.html#모델평가",
    "href": "posts/SOLAR/2023-04-07-soloar-stgcn-ver1-lag4.html#모델평가",
    "title": "[SOLAR] STGCN Ver1 lag4",
    "section": "모델평가",
    "text": "모델평가\n\nmodel.eval()\ncost = 0\nfor time, snapshot in enumerate(train_dataset):\n    y_hat = model(snapshot.x, snapshot.edge_index, snapshot.edge_attr)\n    cost = cost + torch.mean((y_hat-snapshot.y)**2)\ncost = cost / (time+1)\ncost = cost.item()\nprint(\"MSE: {:.4f}\".format(cost))\n\nMSE: 0.1041\n\n\n\nmodel.eval()\ncost = 0\nfor time, snapshot in enumerate(test_dataset):\n    y_hat = model(snapshot.x, snapshot.edge_index, snapshot.edge_attr)\n    cost = cost + torch.mean((y_hat-snapshot.y)**2)\ncost = cost / (time+1)\ncost = cost.item()\nprint(\"MSE: {:.4f}\".format(cost))\n\nMSE: 0.0934\n\n\n\nyhat_train = torch.stack([model(snapshot.x,snapshot.edge_index, snapshot.edge_attr) for snapshot in train_dataset]).detach().numpy()\nyhat_test = torch.stack([model(snapshot.x,snapshot.edge_index, snapshot.edge_attr) for snapshot in test_dataset]).detach().numpy()\n\n\nurl = 'https://raw.githubusercontent.com/pinkocto/noteda/main/posts/SOLAR/data/solar.json'\ndata_dict = json.loads(urllib.request.urlopen(url).read())\nV = list(data_dict['node_ids'].keys())\nf = np.array(data_dict[\"FX\"])"
  },
  {
    "objectID": "posts/SOLAR/2023-04-07-soloar-stgcn-ver1-lag4.html#visualization",
    "href": "posts/SOLAR/2023-04-07-soloar-stgcn-ver1-lag4.html#visualization",
    "title": "[SOLAR] STGCN Ver1 lag4",
    "section": "Visualization",
    "text": "Visualization\n\nimport matplotlib.pyplot as plt\nplt.rcParams['font.family'] = 'NanumGothic'\n\n\nfig,ax = plt.subplots(44,1,figsize=(10,50))\nfor k in range(44):\n    ax[k].plot(f[4:104,k],'--',alpha=0.5,label='observed')\n    # ax[k].set_title('node: {}'.format(V[k]))\n    ax[k].plot(yhat_train[:100,k],label='predicted (tr)')\n    # ax[k].plot(range(yhat_train.shape[0],yhat_train.shape[0]+yhat_test.shape[0]),yhat_test[:,k],label='predicted (test)')\n    ax[k].legend()\nfig.tight_layout()"
  },
  {
    "objectID": "posts/SOLAR/2023-05-07-정리.html",
    "href": "posts/SOLAR/2023-05-07-정리.html",
    "title": "[SOLAR] 0508 정리중",
    "section": "",
    "text": "author’s code repo: https://github.com/VeritasYin/STGCN_IJCAI-18\npytorch : https://github.com/dmlc/dgl/tree/master/examples/pytorch/stgcn_wave\nhttps://arxiv.org/abs/1906.00121"
  },
  {
    "objectID": "posts/SOLAR/2023-05-07-정리.html#introduction",
    "href": "posts/SOLAR/2023-05-07-정리.html#introduction",
    "title": "[SOLAR] 0508 정리중",
    "section": "Introduction",
    "text": "Introduction"
  },
  {
    "objectID": "posts/SOLAR/2023-05-07-정리.html#review-of-existing-studies",
    "href": "posts/SOLAR/2023-05-07-정리.html#review-of-existing-studies",
    "title": "[SOLAR] 0508 정리중",
    "section": "Review of Existing Studies",
    "text": "Review of Existing Studies\nSTGCN: Spatio-Temporal Graph Convolutional Networks: A Deep Learning Framework for Traffic Forecasting 논문에서 시/공간을 고려하는 gcn 모델로 처음 제안된 방법론 (2018년 Yu와 Yin, Zhu가 제안한 모델)\n\n\n\nSpatio-Temporal Graph Convolutional Networks: A Deep Learning Framework for Traffic Forecasting_2018(IJCAI) cited : 2290\n\n\n[Figure1] Graph-structured traffic data. Each \\(v_t\\) indicates a frame of current traffic status at time step \\(t\\), which is recorded in a graph-structured data matrix\n입력 데이터는 시간 경과에 따라 촬용동니 도로 구간 교통정보 관련 스냅샷과 도로망 그래프로 구성.\n공간적 측면과 시간적 측면은 ‘샌드위치’ 로 묘사되는 방식으로 결합된다. (Temporal 사이에 시간적 특징을 추출하는 첫번째 레이어가 공간적 특징을 추출하는 두 번째 레이어로 전달된다. 그리고 이 레이터는 또 다른 시간 레이어로 전달되는 것이다."
  },
  {
    "objectID": "posts/SOLAR/2023-05-07-정리.html#proposed-method",
    "href": "posts/SOLAR/2023-05-07-정리.html#proposed-method",
    "title": "[SOLAR] 0508 정리중",
    "section": "Proposed Method",
    "text": "Proposed Method\n\nSTGCN + EPT weights\n\nSTGCN Adjacency matrix에 지역별 일사량 ept correlation을 가중치로 준것.\nEPT: the ensemble process makes it possible to design various filters, icluding nonlinear filters, which are suitable for extracting some meaningful features such as global trend, volatility, seasonality, and intervention.\n\n기존 weight : \\(W_{ij}\\)\nARIMA 등 기존모델의 한계점을 언급하면서, Time과 Spatial 방법을 모두 고려한 모델들 소개.\nMulti scale (ept 언급 꼭 안해도 됨)"
  },
  {
    "objectID": "posts/SOLAR/2023-05-07-정리.html#experiments",
    "href": "posts/SOLAR/2023-05-07-정리.html#experiments",
    "title": "[SOLAR] 0508 정리중",
    "section": "Experiments",
    "text": "Experiments\n\nSOLAR DATA 정리\n\nIn this example, we analyze the soloar radiation data that were hourly observed at 44 cities in South Korea1 for about four months from June 1, 2022 to September 15, 2022.\n\n\n\n\n\n\n\n\n\n\n수학기호\n코드에 저장된 변수\n자료형\n차원\n설명\n\n\n\n\n\\({\\cal V}\\)\ndata_dict['node_ids']\ndict\n44\n44개의 노드에 대한 설명이 있음\n\n\n\\({\\cal E}\\)\ndata_dict['edges']\nlist(double list)\n(1892, 2)\n노드들에 대한 1892개의 연결을 정의함\n\n\n\\({\\mathbf f}\\)\ndata_dict['FX']\nlist(double list)\n(2568,44)\n\\(v \\in {\\cal V}\\) for \\(v\\in{\\cal V}\\)and \\(t=1,\\dots,T\\)\n\n\n\n\n\\({\\bf f}=\\begin{bmatrix} {\\bf f}_1\\\\ {\\bf f}_2\\\\ \\dots \\\\ {\\bf f}_{2568} \\end{bmatrix}=\\begin{bmatrix} f(t=1,v=\\tt{북춘천}) & \\dots & f(t=1,v=\\tt{경주시}) \\\\ f(t=2,v=\\tt{북춘천}) & \\dots & f(t=2,v=\\tt{경주시}) \\\\ \\dots & \\dots & \\dots \\\\ f(t=2568,v=\\tt{북춘천}) & \\dots & f(t=2568,v=\\tt{경주시}) \\end{bmatrix}\\)\nno weights >> X\ncorrelation by region\nept correlation\n\n- weights\nThe standard time interval in dataset is set to 1 hour. In SOLAR, the adjacency matrix of the ??graph is computed based on the correlation coefficient among solar radiation observed in 44 cities, including Bukchunchueon, Cheolwon, etc.\n\n\\((t, X_t)\\) : observation at time step \\(t\\).\n\\(\\cal\\gamma\\): scale factor\n\\(U_t^\\tau(X_t)\\): upper envelope of ensemble path transform for size parameter \\(\\tau\\)\n\n\\(U_t^\\tau(X_t) = \\underset{k\\in[-\\tau/2, \\tau/2]}{\\max}\\{X_{t+k}\\}-0.5\\cal \\gamma \\tau\\)\nThe weighted adjacency matrix \\(W\\) can be formed as,\n\\(w_{ij} = \\begin{cases} \\\\ 0 & ,\\text{otherwise}\\end{cases}\\)\nwhere \\(w_{ij}\\) is the weight of edge which is decided by ept correlation (the ept correlation between 44 cities)\ncorrelation by region\nHourly solar radiation of observatories from South Korean for 4 months. Vertices represent 44 cities and the weighted edges represent the strength of the relationship. The target variable allows regression operations. (The weight is the correlation coefficient of solar radiation by region.)\nept correlation\nHourly solar radiation of observatories from South Korean for 4 months. Vertices represent 44 cities and the weighted edges represent the strength of the relationship. The target variable allows regression operations. The weight is the EPT correlation coefficient of solar radiation by region\n\n10 iter rslt\n\nimport pandas as pd\nimport numpy as np\n\n\nv1_50 = pd.read_csv('./simulation_results/A/stgcn/50.csv')\nv1_100 = pd.read_csv('./simulation_results/A/stgcn/100.csv')\nv1_150 = pd.read_csv('./simulation_results/A/stgcn/150.csv')\n\n\nv1 = pd.concat([v1_50, v1_100, v1_150])\nv1\n\n\n\n\n\n  \n    \n      \n      dataset\n      method\n      normal\n      lags\n      nof_filters\n      epoch\n      mse(train)\n      mse(test)\n      calculation_time\n    \n  \n  \n    \n      0\n      data2\n      STGCN\n      X\n      4\n      16\n      50\n      0.184666\n      0.168772\n      298.709778\n    \n    \n      1\n      data2\n      STGCN\n      X\n      4\n      32\n      50\n      0.184967\n      0.170560\n      302.935171\n    \n    \n      2\n      data2\n      STGCN\n      X\n      4\n      64\n      50\n      0.183801\n      0.169246\n      315.828636\n    \n    \n      3\n      data2\n      STGCN\n      X\n      8\n      16\n      50\n      0.189229\n      0.165215\n      309.634520\n    \n    \n      4\n      data2\n      STGCN\n      X\n      8\n      32\n      50\n      0.193490\n      0.167097\n      311.973553\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      115\n      data2\n      STGCN\n      X\n      12\n      32\n      150\n      0.201391\n      0.177662\n      1306.056505\n    \n    \n      116\n      data2\n      STGCN\n      X\n      12\n      64\n      150\n      0.188375\n      0.165186\n      1348.935959\n    \n    \n      117\n      data2\n      STGCN\n      X\n      24\n      16\n      150\n      0.225323\n      0.195045\n      1199.328551\n    \n    \n      118\n      data2\n      STGCN\n      X\n      24\n      32\n      150\n      0.217955\n      0.194223\n      1223.021271\n    \n    \n      119\n      data2\n      STGCN\n      X\n      24\n      64\n      150\n      0.227995\n      0.206702\n      1302.931912\n    \n  \n\n360 rows × 9 columns\n\n\n\n\nv2_50 = pd.read_csv('./simulation_results/A/eptstgcn/50.csv')\nv2_100 = pd.read_csv('./simulation_results/A/eptstgcn/100.csv')\nv2_150 = pd.read_csv('./simulation_results/A/eptstgcn/150.csv')\n\n\nv2 = pd.concat([v2_50, v2_100, v2_150])\nv2\n\n\n\n\n\n  \n    \n      \n      dataset\n      method\n      normal\n      lags\n      nof_filters\n      epoch\n      mse(train)\n      mse(test)\n      calculation_time\n    \n  \n  \n    \n      0\n      data2\n      EPT-STGCN\n      NaN\n      4\n      16\n      50\n      0.192152\n      0.173403\n      430.805053\n    \n    \n      1\n      data2\n      EPT-STGCN\n      NaN\n      4\n      32\n      50\n      0.184834\n      0.166629\n      553.995057\n    \n    \n      2\n      data2\n      EPT-STGCN\n      NaN\n      4\n      64\n      50\n      0.186183\n      0.169907\n      568.342531\n    \n    \n      3\n      data2\n      EPT-STGCN\n      NaN\n      8\n      16\n      50\n      0.200127\n      0.171658\n      484.037182\n    \n    \n      4\n      data2\n      EPT-STGCN\n      NaN\n      8\n      32\n      50\n      0.203025\n      0.173270\n      416.375737\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      115\n      data2\n      EPT-STGCN\n      NaN\n      12\n      32\n      150\n      0.196776\n      0.173983\n      1290.014739\n    \n    \n      116\n      data2\n      EPT-STGCN\n      NaN\n      12\n      64\n      150\n      0.197882\n      0.170004\n      1347.436289\n    \n    \n      117\n      data2\n      EPT-STGCN\n      NaN\n      24\n      16\n      150\n      0.222497\n      0.188107\n      1199.523731\n    \n    \n      118\n      data2\n      EPT-STGCN\n      NaN\n      24\n      32\n      150\n      0.255760\n      0.204602\n      1231.037348\n    \n    \n      119\n      data2\n      EPT-STGCN\n      NaN\n      24\n      64\n      150\n      0.222175\n      0.188326\n      1288.791447\n    \n  \n\n360 rows × 9 columns"
  },
  {
    "objectID": "posts/SOLAR/2023-04-12-stgcn-ver1.html",
    "href": "posts/SOLAR/2023-04-12-stgcn-ver1.html",
    "title": "[SOLAR] STGCN Ver1 (MSE: 0.1899)",
    "section": "",
    "text": "import pandas as pd\nimport numpy as np\nimport json\nimport urllib\nimport time\n\n\n# 일반적인 모듈 \nimport numpy as np\nimport matplotlib.pyplot as plt \nimport networkx as nx \nfrom tqdm import tqdm \n\n# 파이토치 관련 \nimport torch\nimport torch.nn.functional as F\n\n# PyG 관련 \nfrom torch_geometric.data import Data ## Data: 그래프자료형을 만드는 클래스\n\n# STGCN 관련 \nimport torch_geometric_temporal\nfrom torch_geometric_temporal.nn.recurrent import GConvGRU\nfrom torch_geometric_temporal.signal import temporal_signal_split \n\n\nclass RecurrentGCN(torch.nn.Module):\n    def __init__(self, node_features, filters):\n        super(RecurrentGCN, self).__init__()\n        self.recurrent = GConvGRU(node_features, filters, 2)\n        self.linear = torch.nn.Linear(filters, 1)\n\n    def forward(self, x, edge_index, edge_weight):\n        h = self.recurrent(x, edge_index, edge_weight)\n        h = F.relu(h)\n        h = self.linear(h)\n        return h\n\n\nfrom mysolar import SolarDatasetLoader\n\n\nloader = SolarDatasetLoader()\ndataset = loader.get_dataset(lags=4)\ntrain_dataset, test_dataset = temporal_signal_split(dataset, train_ratio=0.7)\n\n\nprint(np.array(train_dataset.targets).shape)\nprint(np.array(test_dataset.targets).shape)\n\n(1645, 44)\n(705, 44)\n\n\n\ntrain: 2022-06-01 00:00:00 ~ 2022-08-14 17:00:00\ntest: 2022-08-14 18:00:00 ~ 2022-09-15 21:00:00"
  },
  {
    "objectID": "posts/SOLAR/2023-04-12-stgcn-ver1.html#learn",
    "href": "posts/SOLAR/2023-04-12-stgcn-ver1.html#learn",
    "title": "[SOLAR] STGCN Ver1 (MSE: 0.1899)",
    "section": "Learn",
    "text": "Learn\n\nmodel = RecurrentGCN(node_features=4, filters=32)\noptimizer = torch.optim.Adam(model.parameters(), lr=0.01)\nmodel.train()\n\nfor epoch in tqdm(range(50)):\n    for t, snapshot in enumerate(train_dataset):\n        yt_hat = model(snapshot.x, snapshot.edge_index, snapshot.edge_attr)\n        cost = torch.mean((yt_hat-snapshot.y)**2)\n        cost.backward()\n        optimizer.step()\n        optimizer.zero_grad()\n\n100%|██████████| 50/50 [04:33<00:00,  5.48s/it]\n\n\n\nprint(271.29201/60, '분')\n\n4.5215335 분\n\n\n\n# import pickle \n# with open('./model/stgcn1_lag4_new.pickle','wb') as fw:\n#     pickle.dump(model, fw)\n\n\n# import pickle \n# with open('./model/stgcn1_lag4_new.pickle', 'rb') as f: \n#     model = pickle.load(f)\n\n\nmodel\n\nRecurrentGCN(\n  (recurrent): GConvGRU(\n    (conv_x_z): ChebConv(4, 32, K=2, normalization=sym)\n    (conv_h_z): ChebConv(32, 32, K=2, normalization=sym)\n    (conv_x_r): ChebConv(4, 32, K=2, normalization=sym)\n    (conv_h_r): ChebConv(32, 32, K=2, normalization=sym)\n    (conv_x_h): ChebConv(4, 32, K=2, normalization=sym)\n    (conv_h_h): ChebConv(32, 32, K=2, normalization=sym)\n  )\n  (linear): Linear(in_features=32, out_features=1, bias=True)\n)"
  },
  {
    "objectID": "posts/SOLAR/2023-04-12-stgcn-ver1.html#모델평가",
    "href": "posts/SOLAR/2023-04-12-stgcn-ver1.html#모델평가",
    "title": "[SOLAR] STGCN Ver1 (MSE: 0.1899)",
    "section": "모델평가",
    "text": "모델평가\n- train\n\nMSE: 0.2102\n\n\nmodel.eval()\ncost = 0\nfor time, snapshot in enumerate(train_dataset):\n    y_hat = model(snapshot.x, snapshot.edge_index, snapshot.edge_attr)\n    cost = cost + torch.mean((y_hat-snapshot.y)**2)\ncost = cost / (time+1)\ncost = cost.item()\nprint(\"MSE: {:.4f}\".format(cost))\n\nMSE: 0.2048\n\n\n- test\n\nMSE: 0.1899\n\n\nmodel.eval()\ncost = 0\nfor time, snapshot in enumerate(test_dataset):\n    y_hat = model(snapshot.x, snapshot.edge_index, snapshot.edge_attr)\n    cost = cost + torch.mean((y_hat-snapshot.y)**2)\ncost = cost / (time+1)\ncost = cost.item()\nprint(\"MSE: {:.4f}\".format(cost))\n\nMSE: 0.1868"
  },
  {
    "objectID": "posts/SOLAR/2023-04-12-stgcn-ver1.html#visualization",
    "href": "posts/SOLAR/2023-04-12-stgcn-ver1.html#visualization",
    "title": "[SOLAR] STGCN Ver1 (MSE: 0.1899)",
    "section": "Visualization",
    "text": "Visualization\n\nurl = 'https://raw.githubusercontent.com/pinkocto/noteda/main/posts/SOLAR/data2/stgcn_data1.json'\n\n\ndata_dict = json.loads(urllib.request.urlopen(url).read())\nV = list(data_dict['node_ids'].keys())\nf = np.array(data_dict[\"FX\"])\n\n\nyhat_train = torch.stack([model(snapshot.x,snapshot.edge_index, snapshot.edge_attr) for snapshot in train_dataset]).detach().numpy()\nyhat_test = torch.stack([model(snapshot.x,snapshot.edge_index, snapshot.edge_attr) for snapshot in test_dataset]).detach().numpy()\n\n\nf.shape\n\n(2354, 44)\n\n\n\n705 + 1645\n\n2350\n\n\n\nyhat_test.shape, yhat_train.shape\n\n((705, 44, 1), (1645, 44, 1))\n\n\n\nimport matplotlib.pyplot as plt\nplt.rcParams['font.family'] = 'NanumGothic'\n\n\nfig,ax = plt.subplots(44,1,figsize=(10,50))\nlag= 0 \nT = 100 \nfor k in range(44):\n    ax[k].plot(np.array(train_dataset.targets)[lag:(lag+T),k],'--',alpha=0.5,label='observed')\n    ax[k].set_title('node: {}'.format(V[k]))\n    ax[k].plot(yhat_train[:T,k],label='predicted (tr)')\n#    ax[k].plot(range(yhat_train.shape[0],yhat_train.shape[0]+yhat_test.shape[0]),yhat_test[:,k],label='predicted (test)')\n    ax[k].legend()\nfig.tight_layout()\n\n# plt.savefig('stgcn-ver2-lag4-vis.png')\n\n\n\n\n\nnp.array(dataset.features).shape\n\n(2350, 44, 4)\n\n\n\nnp.array(dataset.targets).shape\n\n(2350, 44)\n\n\n\nnp.array(train_dataset.targets).shape\n\n(1645, 44)\n\n\n\nnp.array(test_dataset.targets).shape\n\n(705, 44)\n\n\n\nfig,ax = plt.subplots(44,1,figsize=(10,50))\nlag= 0\nT = 100 \nfor k in range(44):\n    ax[k].plot(np.array(test_dataset.targets)[lag:(lag+T),k],'--',alpha=0.5,label='observed')\n    ax[k].set_title('node: {}'.format(V[k]))\n    ax[k].plot(yhat_test[:T,k],label='predicted (test)')\n#    ax[k].plot(range(yhat_train.shape[0],yhat_train.shape[0]+yhat_test.shape[0]),yhat_test[:,k],label='predicted (test)')\n    ax[k].legend()\nfig.tight_layout()\n\n# plt.savefig('stgcn-ver2-lag4-vis.png')"
  },
  {
    "objectID": "posts/SOLAR/2023-04-07-yu.html",
    "href": "posts/SOLAR/2023-04-07-yu.html",
    "title": "[SOLAR] yU",
    "section": "",
    "text": "ref: https://www.sciencedirect.com/science/article/pii/S2352711021000492"
  },
  {
    "objectID": "posts/SOLAR/2023-04-07-yu.html#데이터-처리",
    "href": "posts/SOLAR/2023-04-07-yu.html#데이터-처리",
    "title": "[SOLAR] yU",
    "section": "데이터 처리",
    "text": "데이터 처리\n\ndf = df |> mutate(date=ymd_hm(date))\ndf %>% head()\n\n\n\nA tibble: 6 × 3\n\n    regionsolar_radiationdate\n    <chr><dbl><dttm>\n\n\n    북춘천02021-01-01 00:00:00\n    북춘천02021-01-01 01:00:00\n    북춘천02021-01-01 02:00:00\n    북춘천02021-01-01 03:00:00\n    북춘천02021-01-01 04:00:00\n    북춘천02021-01-01 05:00:00\n\n\n\n\n\ndim(df)\n\n\n8030003\n\n\n\nunique(df$region) %>% length()\n\n44"
  },
  {
    "objectID": "posts/SOLAR/2023-04-07-yu.html#plot",
    "href": "posts/SOLAR/2023-04-07-yu.html#plot",
    "title": "[SOLAR] yU",
    "section": "Plot",
    "text": "Plot\n\nfor (i in 1:44){\n     assign(paste0('data',1:44)[i],df |> filter(region == unique(df$region)[i]))\n     assign(paste0('data',1:44)[i],eval(parse(text=paste0('data',i)))[order(eval(parse(text=paste0('data',i)))$date),])\n     assign(paste0('y',1:44)[i], eval(parse(text=paste0('data',i)))$solar_radiation)\n}\n\n\nfor (i in 1:44){\n    plot(eval(parse(text=paste0('y',i)))[1:500], ann=FALSE)\n    lines(eval(parse(text=paste0('y',i))),lty=2)\n    title(main = as.character(unique(df$region)[i]), xlab='time', ylab='solar radiation')\n    }"
  },
  {
    "objectID": "posts/SOLAR/2023-04-07-yu.html#etp-수행",
    "href": "posts/SOLAR/2023-04-07-yu.html#etp-수행",
    "title": "[SOLAR] yU",
    "section": "ETP 수행",
    "text": "ETP 수행\n\nept = function(y){\n    EpM = eptransf(signal=y,tau=24,process=c(\"envelope\",\"average\"))$EpM\n    EpM*2\n}\n\n\n아래 코드 오래걸림 주의\n\n\nlibrary(tictoc)\n\n\ntic('지역별 yU계산')\nfor (i in 1:44){\n    assign(paste0('yU',1:44)[i], ept(eval(parse(text=paste0('y',i)))))\n}\ntoc()\n\n지역별 yU계산: 353.519 sec elapsed\n\n\n\nlength(yU1)\n\n18250\n\n\n\nyU1\n\n\n1.6661.6661.6661.6661.6661.6661.6661.6661.6661.6661.67081.68841.72361.78241.81761.83521.841.84281.84561.84841.85121.8541.85681.85961.86241.86521.8681.87081.87361.87641.87921.8821.88481.88761.89041.89321.8961.89881.90161.90441.90721.911.90641.90041.89441.88841.88241.87641.87041.86441.85841.85241.84641.84041.83441.82841.82241.81641.81041.80441.79841.79241.78641.78041.77441.76841.76241.75641.75281.74921.74561.7421.73841.73481.73121.72761.7241.72041.71681.71321.70961.7061.70241.69881.69521.69161.6881.68441.68081.67721.67361.67361.6841.69441.70481.71521.72561.7361.74641.75681.76721.77761.7881.79841.80881.81921.82961.841.85041.86081.87121.88161.8921.90241.91281.92321.931.931.931.931.931.931.931.931.931.931.931.931.931.931.931.931.931.931.931.931.931.931.931.931.931.931.9321.9341.9361.9381.941.9421.9441.9461.9481.951.9521.9541.9561.9581.961.9621.9641.9661.9681.971.9721.9741.9761.9781.981.98081.98161.98241.98321.9841.98481.98561.98641.98721.9881.98881.98961.99041.99121.9921.99281.99361.99441.99521.9961.99681.99761.99841.999221.9981.9961.9941.9921.991.9881.9861.984⋯1.85561.85721.85881.86041.8621.86361.86521.86681.86841.871.87161.87321.87481.87641.8781.87961.881.89241.90481.91721.92961.9421.95441.96681.97921.99162.0042.01642.02882.04122.05362.0662.07842.09082.10322.11562.1282.14042.15282.16522.17762.192.1782.14562.10522.06482.02441.9841.94361.90321.86281.82241.7821.74161.70121.66081.62041.581.53961.49921.45881.41841.3781.33761.29721.25681.21641.19681.21521.24161.2681.29441.32081.34721.37361.41.42641.45281.47921.50561.5321.55841.58481.61121.63761.6641.69041.71681.74321.76961.7961.82561.84641.84961.85281.8561.85921.86241.86561.86881.8721.87521.87841.88161.88481.8881.89121.89441.89761.90081.9041.90721.91041.91361.91681.921.91721.91441.91161.90881.9061.90321.90041.89761.89481.8921.88921.88641.88361.88081.8781.87521.87241.86961.86681.8641.86121.85841.85561.85281.851.851.86081.87161.88241.89321.9041.91481.92561.93641.94721.9581.96881.97961.99042.00122.0122.02282.03362.04442.05522.0662.07682.08762.09842.10922.12042.12082.12122.12162.1222.12242.12282.12322.12362.1242.12442.12482.12522.12562.1262.12642.12682.12722.12762.1282.12842.12882.12922.12962.132.132.132.132.132.132.132.132.132.13"
  },
  {
    "objectID": "posts/SOLAR/2023-04-07-yu.html#yu-저장",
    "href": "posts/SOLAR/2023-04-07-yu.html#yu-저장",
    "title": "[SOLAR] yU",
    "section": "yU 저장",
    "text": "yU 저장\n\ndf_yU = do.call(cbind.data.frame, mget(paste0('yU', 1:44)))\n\n\nwrite.csv(df_yU, './df_yU.csv', row.names=FALSE)\n\n\n# for (i in 1:44){\n#     print(length(eval(parse(text=paste0('yU',i)))))}"
  },
  {
    "objectID": "posts/SOLAR/2023-04-07-yu.html#시각화",
    "href": "posts/SOLAR/2023-04-07-yu.html#시각화",
    "title": "[SOLAR] yU",
    "section": "시각화",
    "text": "시각화\n\nfor (i in 1:44){\n    plot(eval(parse(text=paste0('y',i)))[1:500], ann=FALSE)\n    lines(eval(parse(text=paste0('yU',i))),col = 2, lty=2)\n    title(main = as.character(unique(df$region)[i]), xlab='time', ylab='solar radiation')\n    }"
  },
  {
    "objectID": "posts/SOLAR/2023-04-07-yu.html#yu-correlation",
    "href": "posts/SOLAR/2023-04-07-yu.html#yu-correlation",
    "title": "[SOLAR] yU",
    "section": "yU Correlation",
    "text": "yU Correlation\n\ndf_yU = read_csv('./data/df_yU.csv')\n\nRows: 18250 Columns: 44\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\ndbl (44): yU1, yU2, yU3, yU4, yU5, yU6, yU7, yU8, yU9, yU10, yU11, yU12, yU1...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\nyU_cor = cor(df_yU)\n\n\nwrite.csv(yU_cor, './data/yU_weight.csv', row.names=FALSE)\n\n\nref : https://jobmanager1.tistory.com/84\nref : https://rbasall.tistory.com/101"
  },
  {
    "objectID": "posts/SOLAR/2099.html",
    "href": "posts/SOLAR/2099.html",
    "title": "noteda",
    "section": "",
    "text": "import eptstgcn\nimport torch\nimport eptstgcn.planner\nimport warnings\nwarnings.filterwarnings('ignore')\nimport torch_geometric_temporal\n\n\nurl = \"https://raw.githubusercontent.com/pinkocto/noteda/main/posts/SOLAR/data2/stgcn_data1.json\"\nloader = eptstgcn.DatasetLoader(url)\ndataset = loader.get_dataset(lags=4)\n\n\ntrain_dataset, test_dataset = eptstgcn.utils.temporal_signal_split(dataset, train_ratio = 0.7)\n\n\ntrain_dataset.url\n\n'https://raw.githubusercontent.com/pinkocto/noteda/main/posts/SOLAR/data2/stgcn_data1.json'"
  },
  {
    "objectID": "posts/SOLAR/2023-04-06-corr.html",
    "href": "posts/SOLAR/2023-04-06-corr.html",
    "title": "[SOLAR] Correlation coefficient by region",
    "section": "",
    "text": "library(data.table)\nlibrary(tidyverse)\nlibrary(dplyr)\nlibrary(lubridate)\nlibrary(recipes)\nlibrary(corrplot)\nlibrary(GGally)"
  },
  {
    "objectID": "posts/SOLAR/2023-04-06-corr.html#correlation",
    "href": "posts/SOLAR/2023-04-06-corr.html#correlation",
    "title": "[SOLAR] Correlation coefficient by region",
    "section": "Correlation",
    "text": "Correlation\n\nnum_vars <- df %>% select(-date)\nweight <- cor(num_vars)\nweight\n\n\n\nA matrix: 44 × 44 of type dbl\n\n    북춘천철원대관령춘천백령도북강릉강릉서울인천원주⋯순창군북창원양산시보성군강진군의령군함양군광양시청송군경주시\n\n\n    북춘천1.00000000.96236670.90982560.98565660.87168090.90065860.89092680.94308110.93689940.9444727⋯0.87913650.85348270.85816940.86397400.85968520.86678300.87559780.86517210.88310080.8486414\n    철원0.96236671.00000000.89069610.96005730.88626390.88416100.87476390.94552730.94129330.9308258⋯0.86860650.84108620.84603560.85575580.85543860.85131030.86368900.85417160.86679450.8344436\n    대관령0.90982560.89069611.00000000.90551540.81928340.95308830.94734110.88496130.88252510.9211512⋯0.87752430.87260890.87710470.86825570.85759790.87901550.89007090.87039760.91696970.8885608\n    춘천0.98565660.96005730.90551541.00000000.87421090.89863900.88813890.94350840.93843420.9429720⋯0.88093960.85227160.85702130.86463310.86069420.86629430.87510420.86478200.88234000.8463213\n    백령도0.87168090.88626390.81928340.87421091.00000000.82074610.81376870.87548680.89881400.8418373⋯0.83297100.80321980.80368260.82838960.83019960.81600460.82579820.82429720.80596250.7860864\n    북강릉0.90065860.88416100.95308830.89863900.82074611.00000000.97705220.87656040.87876870.9086585⋯0.87454730.87007270.87343620.86707600.85600760.87818790.88095300.86536680.90730610.8865896\n    강릉0.89092680.87476390.94734110.88813890.81376870.97705221.00000000.86762730.86977540.9006898⋯0.86706830.86360820.86544780.86130960.84839180.87122730.87461980.85886820.90092040.8777924\n    서울0.94308110.94552730.88496130.94350840.87548680.87656040.86762731.00000000.95945320.9345457⋯0.87638220.84780500.84722070.85738280.85809660.85502020.86572900.85817450.86778110.8344653\n    인천0.93689940.94129330.88252510.93843420.89881400.87876870.86977540.95945321.00000000.9236006⋯0.88403320.85426900.85546320.87403700.87092110.86725670.87857780.87018520.87075620.8437449\n    원주0.94447270.93082580.92115120.94297200.84183730.90865850.90068980.93454570.92360061.0000000⋯0.89894230.86961050.87262400.87934750.87497280.88166300.89350010.87852450.90533450.8674754\n    울릉도0.84085800.82891050.85855730.83914710.77270460.85816420.84823670.82059290.82701560.8532737⋯0.85595070.86356200.86813290.84728260.84423100.86360510.86316810.85036490.87725990.8705571\n    수원0.94256350.93950890.89943540.94306860.87738880.89261660.88462970.96384220.96141710.9467150⋯0.89727820.86728520.86717250.88162390.88044850.87815030.88969430.88014170.88622850.8577320\n    서산0.92202230.91892300.88810520.92069530.88259030.88269370.87522970.93419210.94723710.9294862⋯0.90437160.86862550.86925630.88834560.88765280.88050100.89487730.88554230.88484430.8578193\n    청주0.91823670.90504900.90343090.91790840.84107890.89687110.88942760.91892550.91547610.9444102⋯0.92492170.88868400.88882410.90121590.89966250.89936120.91548140.90113790.91181540.8833474\n    대전0.89849000.88265250.89105100.89817380.82709280.88541310.87895300.89855360.89851640.9232921⋯0.92871910.89298370.89158130.90660020.90390680.90538850.92289340.90476430.91024320.8837027\n    추풍령0.89006050.87620400.90545220.89027500.82115400.90080260.89422750.88090660.88637170.9150908⋯0.93773670.92328680.92286330.92485190.91704750.93231370.94937880.92447280.94599950.9246200\n    안동0.90359100.88521710.91838630.90375460.82501810.91341890.90654600.88871830.89097730.9272982⋯0.92702150.92246470.92296570.91773800.90762730.92863650.93794690.91916080.96139130.9292945\n    포항0.85466180.83896090.89135600.85482100.79060870.89188400.88385830.84080040.84885050.8729144⋯0.89773430.93255090.93770070.90218680.88758650.93322840.92192480.90866860.94564880.9624291\n    대구0.88049760.86613860.90077360.87874960.82137280.89739960.88881930.86796520.87410670.8979111⋯0.93129020.94769840.94790040.93255740.92068280.95557090.95285090.93592820.95231160.9529934\n    전주0.88831450.87735680.88453240.88720240.82756220.88049190.87303740.88940530.89116110.9166516⋯0.95061010.90956070.90708410.92708070.92764880.91950440.93813760.92221060.91505040.8943981\n    창원0.86079630.84779010.87440680.86016990.80875120.87152050.86383460.84829660.86215790.8745101⋯0.92395270.97690180.96344420.94455470.92847980.96839080.94072460.95240460.92691300.9390504\n    광주0.85942370.85250110.85968650.86033290.81278460.85674520.84878970.86130310.86738400.8810247⋯0.95423770.91104900.90466160.93790630.93973800.91791490.92826810.92591540.90190950.8896842\n    부산0.85447880.84190870.87140320.85362290.80102510.86699390.85802330.84344060.85383820.8675622⋯0.91299840.96006960.96598170.93357000.91884180.95057310.92920540.93965770.92209300.9367743\n    목포0.86633740.86147620.86061270.86735670.83891680.85831300.85206650.86424250.88178560.8803827⋯0.94374800.90968720.90545510.94887360.95764670.92284550.92555600.93279790.89680090.8876638\n    여수0.85700350.84581090.86570560.85672800.81732710.85974890.85464620.84907260.86352030.8689917⋯0.92813560.94420000.93715530.96219770.94303670.95318040.93699560.96585720.90925800.9091946\n    흑산도0.82282580.82214030.80848140.82661570.82540140.81149830.80648380.82171010.84490930.8304114⋯0.88310310.85684140.85740710.89259770.89853220.86903390.87279490.87910700.83957940.8372829\n    고창0.87908340.87102610.86564930.88095600.83527630.86251080.85580080.87833740.88910040.8954195⋯0.95422990.90690180.90482820.93497520.93847400.91780220.92969910.92301780.90471720.8864325\n    홍성0.91704440.90910770.89306150.91830500.86733490.88921860.88224880.92604690.93383050.9297931⋯0.91452880.87906210.88020480.89874840.89786130.89129370.90580570.89412650.89556400.8688941\n    제주0.79767390.79445210.80816520.80047300.78782940.80411950.80035320.78487990.80516480.8102970⋯0.87030270.87024130.86730040.89229960.89521970.87457120.87294140.87859680.84743550.8538871\n    고산0.82326700.82143810.81854910.82609000.81067530.81299230.80859920.81786800.83478470.8321734⋯0.88442410.87592320.87250750.90350960.90758850.88336860.87846910.89477450.85391030.8524065\n    진주0.86052260.84694180.87741080.86009420.81787450.87303670.86673860.85237070.86558940.8758120⋯0.93157060.95900030.94635240.95239080.93495400.97175160.94899010.96103410.92389590.9320667\n    고창군0.87477910.86584960.86902380.87418820.82784790.86461250.85698680.87455600.88142480.8944722⋯0.95634670.90621030.90335760.93232190.93592950.91499480.92925500.92159380.90413300.8867928\n    영광군0.87216160.86535240.86206570.87295770.83683740.86124230.85414870.87267750.88637020.8886936⋯0.94891400.90359000.90162680.93365960.93802830.91534840.92557200.92183030.89834380.8827982\n    김해시0.85344840.84087600.87304980.85168270.80250670.86922090.86129060.84612690.85392520.8688775⋯0.91450680.97368310.97388080.93286690.91722590.95641720.93324380.94100440.92669110.9440780\n    순창군0.87913650.86860650.87752430.88093960.83297100.87454730.86706830.87638220.88403320.8989423⋯1.00000000.91874540.91695800.94576540.94677970.93258530.94948170.93881320.91738570.8984046\n    북창원0.85348270.84108620.87260890.85227160.80321980.87007270.86360820.84780500.85426900.8696105⋯0.91874541.00000000.96530020.93721720.92142390.96252270.93836910.94559180.92750890.9442955\n    양산시0.85816940.84603560.87710470.85702130.80368260.87343620.86544780.84722070.85546320.8726240⋯0.91695800.96530021.00000000.92979220.91516460.95358900.93408790.93731890.92848620.9451212\n    보성군0.86397400.85575580.86825570.86463310.82838960.86707600.86130960.85738280.87403700.8793475⋯0.94576540.93721720.92979221.00000000.96814880.94880620.94426150.96412040.91124690.9081843\n    강진군0.85968520.85543860.85759790.86069420.83019960.85600760.84839180.85809660.87092110.8749728⋯0.94677970.92142390.91516460.96814881.00000000.93153300.93262120.94796680.90211470.8929973\n    의령군0.86678300.85131030.87901550.86629430.81600460.87818790.87122730.85502020.86725670.8816630⋯0.93258530.96252270.95358900.94880620.93153301.00000000.95239100.95593960.93041170.9402360\n    함양군0.87559780.86368900.89007090.87510420.82579820.88095300.87461980.86572900.87857780.8935001⋯0.94948170.93836910.93408790.94426150.93262120.95239101.00000000.94214040.93475910.9279347\n    광양시0.86517210.85417160.87039760.86478200.82429720.86536680.85886820.85817450.87018520.8785245⋯0.93881320.94559180.93731890.96412040.94796680.95593960.94214041.00000000.91540760.9141593\n    청송군0.88310080.86679450.91696970.88234000.80596250.90730610.90092040.86778110.87075620.9053345⋯0.91738570.92750890.92848620.91124690.90211470.93041170.93475910.91540761.00000000.9439168\n    경주시0.84864140.83444360.88856080.84632130.78608640.88658960.87779240.83446530.84374490.8674754⋯0.89840460.94429550.94512120.90818430.89299730.94023600.92793470.91415930.94391681.0000000\n\n\n\n\n\n# write.csv(weight, './data/weight.csv', row.names=FALSE)\n\n\nweight |> dim()\n\n\n4444"
  },
  {
    "objectID": "posts/SOLAR/2023-04-06-corr.html#corrplot",
    "href": "posts/SOLAR/2023-04-06-corr.html#corrplot",
    "title": "[SOLAR] Correlation coefficient by region",
    "section": "Corrplot",
    "text": "Corrplot\n\noptions(repr.plot.width=30, repr.plot.height=30, repr.plot.res=300)\n\n\ncorrplot(round(weight,2), method = 'number')"
  },
  {
    "objectID": "posts/SOLAR/2023-05-02-s-stgcn-ver1-정규화-시뮬레이션.html",
    "href": "posts/SOLAR/2023-05-02-s-stgcn-ver1-정규화-시뮬레이션.html",
    "title": "[SOLAR] STGCN Ver1 (data2, +N +S) 시뮬레이션(epoch, filter, lag)",
    "section": "",
    "text": "train 2022-06-01 00:00:00 ~ 2022-08-14 17:00:00\ntest 2022-08-14 18:00:00 ~ 2022-09-15 23:00:00"
  },
  {
    "objectID": "posts/SOLAR/2023-05-02-s-stgcn-ver1-정규화-시뮬레이션.html#epoch",
    "href": "posts/SOLAR/2023-05-02-s-stgcn-ver1-정규화-시뮬레이션.html#epoch",
    "title": "[SOLAR] STGCN Ver1 (data2, +N +S) 시뮬레이션(epoch, filter, lag)",
    "section": "50 epoch",
    "text": "50 epoch\n\nplans_stgcn = {\n    'max_iteration': 1, # 30 \n    'method': ['STGCN'], \n    'lags': [4, 8, 12], \n    'nof_filters': [16, 32, 64], \n    'epoch': [50] # [50, 100, 150]\n}\n\n\nplnr = eptstgcn.planner.NORMAL_PLNR_STGCN(plans_stgcn, data_dict, dataset_name='data2')\n\n\nplnr.simulate()\n\n1/1 is done\nAll results are stored in ./simulation_results/2023-05-02_16-19-40.csv\n\n\n\neptstgcn.save_data(plnr,'./simul_model2/normal/stgcn_v1_50epoch.pickle')\n\n\nsimul_model_50 = eptstgcn.load_data('./simul_model2/normal/stgcn_v1_50epoch.pickle')\n\n\nsimul_model_50.simulation_results\n\n\n\n\n\n  \n    \n      \n      dataset\n      method\n      normal\n      lags\n      nof_filters\n      epoch\n      mse(train)\n      mse(test)\n      calculation_time\n    \n  \n  \n    \n      0\n      data2\n      STGCN\n      O\n      4\n      16\n      50\n      0.181886\n      0.170189\n      301.377795\n    \n    \n      1\n      data2\n      STGCN\n      O\n      4\n      32\n      50\n      0.198904\n      0.190715\n      296.4576\n    \n    \n      2\n      data2\n      STGCN\n      O\n      4\n      64\n      50\n      0.195493\n      0.188309\n      308.646654\n    \n    \n      3\n      data2\n      STGCN\n      O\n      8\n      16\n      50\n      0.189424\n      0.177908\n      303.527294\n    \n    \n      4\n      data2\n      STGCN\n      O\n      8\n      32\n      50\n      0.213567\n      0.208104\n      307.255326\n    \n    \n      5\n      data2\n      STGCN\n      O\n      8\n      64\n      50\n      0.190067\n      0.175568\n      319.699453\n    \n    \n      6\n      data2\n      STGCN\n      O\n      12\n      16\n      50\n      0.189747\n      0.180983\n      315.89522\n    \n    \n      7\n      data2\n      STGCN\n      O\n      12\n      32\n      50\n      0.201539\n      0.201505\n      320.217695\n    \n    \n      8\n      data2\n      STGCN\n      O\n      12\n      64\n      50\n      0.193679\n      0.187321\n      322.39595\n    \n  \n\n\n\n\n\nprint('stgcn ver1 50epoch 시뮬레이션 끝!')\n\nstgcn ver1 50epoch 시뮬레이션 끝!\n\n\n\nimport matplotlib.pyplot as plt\nplt.boxplot(simul_model_50.simulation_results['mse(test)'])\nplt.show()"
  },
  {
    "objectID": "posts/SOLAR/2023-05-02-s-stgcn-ver1-정규화-시뮬레이션.html#epoch-1",
    "href": "posts/SOLAR/2023-05-02-s-stgcn-ver1-정규화-시뮬레이션.html#epoch-1",
    "title": "[SOLAR] STGCN Ver1 (data2, +N +S) 시뮬레이션(epoch, filter, lag)",
    "section": "100 epoch",
    "text": "100 epoch\n\nplans_stgcn = {\n    'max_iteration': 1, # 30 \n    'method': ['STGCN'], \n    'lags': [4, 8, 12], \n    'nof_filters': [16, 32, 64], \n    'epoch': [100] # [50, 100, 150]\n}\n\n\nplnr = eptstgcn.planner.NORMAL_PLNR_STGCN(plans_stgcn, data_dict, dataset_name='data2')\n\n\nplnr.simulate()\n\n1/1 is done\nAll results are stored in ./simulation_results/2023-05-02_17-53-27.csv\n\n\n\neptstgcn.save_data(plnr, './simul_model2/normal/stgcn_v1_100epoch.pickle')\n\n\nsimul_model_100 = eptstgcn.load_data('./simul_model2/normal/stgcn_v1_100epoch.pickle')\n\n\nsimul_model_100.simulation_results\n\n\n\n\n\n  \n    \n      \n      dataset\n      method\n      normal\n      lags\n      nof_filters\n      epoch\n      mse(train)\n      mse(test)\n      calculation_time\n    \n  \n  \n    \n      0\n      data2\n      STGCN\n      O\n      4\n      16\n      100\n      0.184018\n      0.176352\n      591.468639\n    \n    \n      1\n      data2\n      STGCN\n      O\n      4\n      32\n      100\n      0.18008\n      0.166548\n      596.956525\n    \n    \n      2\n      data2\n      STGCN\n      O\n      4\n      64\n      100\n      0.183982\n      0.173036\n      619.508867\n    \n    \n      3\n      data2\n      STGCN\n      O\n      8\n      16\n      100\n      0.182058\n      0.172347\n      609.206819\n    \n    \n      4\n      data2\n      STGCN\n      O\n      8\n      32\n      100\n      0.191687\n      0.177967\n      620.305754\n    \n    \n      5\n      data2\n      STGCN\n      O\n      8\n      64\n      100\n      0.196819\n      0.188639\n      637.897624\n    \n    \n      6\n      data2\n      STGCN\n      O\n      12\n      16\n      100\n      0.186397\n      0.177353\n      620.586107\n    \n    \n      7\n      data2\n      STGCN\n      O\n      12\n      32\n      100\n      0.194325\n      0.188517\n      627.757534\n    \n    \n      8\n      data2\n      STGCN\n      O\n      12\n      64\n      100\n      0.183982\n      0.175041\n      645.52017\n    \n  \n\n\n\n\n\nprint('100에폭 끝')\n\n100에폭 끝"
  },
  {
    "objectID": "posts/SOLAR/2023-05-02-s-stgcn-ver1-정규화-시뮬레이션.html#epoch-2",
    "href": "posts/SOLAR/2023-05-02-s-stgcn-ver1-정규화-시뮬레이션.html#epoch-2",
    "title": "[SOLAR] STGCN Ver1 (data2, +N +S) 시뮬레이션(epoch, filter, lag)",
    "section": "150 epoch",
    "text": "150 epoch\n\nplans_stgcn = {\n    'max_iteration': 1, # 30 \n    'method': ['STGCN'], \n    'lags': [4, 8, 12], \n    'nof_filters': [16, 32, 64], \n    'epoch': [150] # [50, 100, 150]\n}\n\n\nplnr = eptstgcn.planner.NORMAL_PLNR_STGCN(plans_stgcn, data_dict, dataset_name='data2')\n\n\nplnr.simulate()\n\n1/1 is done\nAll results are stored in ./simulation_results/2023-05-02_20-14-40.csv\n\n\n\neptstgcn.save_data(plnr,'./simul_model2/normal/stgcn_v1_150epoch.pickle')\n\n\nsimul_model_150 = eptstgcn.load_data('./simul_model2/normal/stgcn_v1_150epoch.pickle')\n\n\nsimul_model_150.simulation_results\n\n\n\n\n\n  \n    \n      \n      dataset\n      method\n      normal\n      lags\n      nof_filters\n      epoch\n      mse(train)\n      mse(test)\n      calculation_time\n    \n  \n  \n    \n      0\n      data2\n      STGCN\n      O\n      4\n      16\n      150\n      0.178521\n      0.167069\n      893.5531\n    \n    \n      1\n      data2\n      STGCN\n      O\n      4\n      32\n      150\n      0.196559\n      0.188793\n      904.754509\n    \n    \n      2\n      data2\n      STGCN\n      O\n      4\n      64\n      150\n      0.182324\n      0.169113\n      945.174071\n    \n    \n      3\n      data2\n      STGCN\n      O\n      8\n      16\n      150\n      0.18494\n      0.174159\n      918.975577\n    \n    \n      4\n      data2\n      STGCN\n      O\n      8\n      32\n      150\n      0.193189\n      0.182417\n      938.209813\n    \n    \n      5\n      data2\n      STGCN\n      O\n      8\n      64\n      150\n      0.195476\n      0.18993\n      957.47494\n    \n    \n      6\n      data2\n      STGCN\n      O\n      12\n      16\n      150\n      0.194128\n      0.186243\n      931.000848\n    \n    \n      7\n      data2\n      STGCN\n      O\n      12\n      32\n      150\n      0.183539\n      0.175252\n      945.265863\n    \n    \n      8\n      data2\n      STGCN\n      O\n      12\n      64\n      150\n      0.203312\n      0.199971\n      980.781949\n    \n  \n\n\n\n\n\nprint('150에폭 끝!')\n\n150에폭 끝!"
  },
  {
    "objectID": "posts/SOLAR/2023-04-26-s-stgcn-ver2-150에폭.html",
    "href": "posts/SOLAR/2023-04-26-s-stgcn-ver2-150에폭.html",
    "title": "[SOLAR] STGCN Ver2 (data2, -N +S) 30회 150 epoch",
    "section": "",
    "text": "https://github.com/miruetoto/yechan3/tree/main/posts/3_Researches/ITSTGCN/itstgcn\nhttps://miruetoto.github.io/yechan3/posts/3_Researches/ITSTGCN/2023-03-18-SimulationPlanner-Tutorial.html#plnr_gnar_block\n\n\n\n\n\ntrain 2022-06-01 00:00:00 ~ 2022-08-14 17:00:00\ntest 2022-08-14 18:00:00 ~ 2022-09-15 23:00:00\n\n\n\n\n\nimport eptstgcn\nimport torch\nimport eptstgcn.planner\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\n\n\n\n\nurl = \"https://raw.githubusercontent.com/pinkocto/noteda/main/posts/SOLAR/data2/stgcn_data2.json\"\nloader = eptstgcn.DatasetLoader(url)\ndataset = loader.get_dataset(lags=4)\n\n\ntrain_dataset, test_dataset = eptstgcn.utils.temporal_signal_split(dataset, train_ratio = 0.7)\n\n\n\n\n\nref: https://seoyeonc.github.io/blog/posts/GCN/2023-03-17-ITSTGCN-Tutorial.html\n\n\nlrnr = eptstgcn.StgcnLearner(train_dataset, dataset_name = 'data2(2022/06/01 ~ 2022/09/15)')\n\n\nlrnr.learn(filters=32, epoch=150)\n\n150/150\n\n\n\nimport pickle \nwith open('./lrnr_model/stgcn_ver2_data2_cancel_normal_150epoch.pickle','wb') as fw:\n    pickle.dump(lrnr, fw)\n\n\nimport pickle \nwith open('./lrnr_model/stgcn_ver2_data2_cancel_normal_150epoch.pickle', 'rb') as f: \n    model = pickle.load(f)\n\n\n\n\n\nevtor = eptstgcn.Evaluator(model, train_dataset, test_dataset)\n\n\n# fig = evtor.plot('--', label='observed data')\n# fig.tight_layout()\n# fig\n\n\n\n\nevtor.tr_plot(t=150, label='observed data')\n\n\n\n\n\n\n\n\nevtor.test_plot(t=150, label='observed data')\n\n\n\n\n\n\n\n\n\nplans_stgcn = {\n    'max_iteration': 30, \n    'method': ['EPT-STGCN'], \n    'lags': [4], \n    'nof_filters': [32], \n    'epoch': [150]\n}\n\n\nplnr = eptstgcn.planner.PLNR_STGCN(plans_stgcn,loader,dataset_name='data2')\n\n\nplnr.simulate()\n\n1/30 is done\n2/30 is done\n3/30 is done\n4/30 is done\n5/30 is done\n6/30 is done\n7/30 is done\n8/30 is done\n9/30 is done\n10/30 is done\n11/30 is done\n12/30 is done\n13/30 is done\n14/30 is done\n15/30 is done\n16/30 is done\n17/30 is done\n18/30 is done\n19/30 is done\n20/30 is done\n21/30 is done\n22/30 is done\n23/30 is done\n24/30 is done\n25/30 is done\n26/30 is done\n27/30 is done\n28/30 is done\n29/30 is done\n30/30 is done\nAll results are stored in ./simulation_results/2023-04-27_22-16-11.csv\n\n\n\nimport pickle\nwith open('./simul_model/stgcn_ver2_data2_cancel_normal_150epoch.pickle', 'wb') as fw:\n    pickle.dump(plnr, fw)\n\n\nwith open('./simul_model/stgcn_ver2_data2_cancel_normal_150epoch.pickle', 'rb') as f:\n    simul_model = pickle.load(f)\n\n\ndf_simul_no = simul_model.simulation_results\ndf_simul_no\n\n\n\n\n\n  \n    \n      \n      dataset\n      method\n      lags\n      nof_filters\n      epoch\n      mse(train)\n      mse(test)\n      calculation_time\n    \n  \n  \n    \n      0\n      data2\n      EPT-STGCN\n      4\n      32\n      150\n      0.185434\n      0.167638\n      3469.144449\n    \n    \n      1\n      data2\n      EPT-STGCN\n      4\n      32\n      150\n      0.193655\n      0.177747\n      3484.422505\n    \n    \n      2\n      data2\n      EPT-STGCN\n      4\n      32\n      150\n      0.184885\n      0.166774\n      3117.519283\n    \n    \n      3\n      data2\n      EPT-STGCN\n      4\n      32\n      150\n      0.182733\n      0.165493\n      3578.09566\n    \n    \n      4\n      data2\n      EPT-STGCN\n      4\n      32\n      150\n      0.19472\n      0.179478\n      3367.387573\n    \n    \n      5\n      data2\n      EPT-STGCN\n      4\n      32\n      150\n      0.189369\n      0.173464\n      3462.885302\n    \n    \n      6\n      data2\n      EPT-STGCN\n      4\n      32\n      150\n      0.188635\n      0.172912\n      3383.795394\n    \n    \n      7\n      data2\n      EPT-STGCN\n      4\n      32\n      150\n      0.189322\n      0.173068\n      3309.909593\n    \n    \n      8\n      data2\n      EPT-STGCN\n      4\n      32\n      150\n      0.201105\n      0.18462\n      3457.644482\n    \n    \n      9\n      data2\n      EPT-STGCN\n      4\n      32\n      150\n      0.191193\n      0.17579\n      3350.393971\n    \n    \n      10\n      data2\n      EPT-STGCN\n      4\n      32\n      150\n      0.192512\n      0.175854\n      3049.338518\n    \n    \n      11\n      data2\n      EPT-STGCN\n      4\n      32\n      150\n      0.184679\n      0.167099\n      1396.975266\n    \n    \n      12\n      data2\n      EPT-STGCN\n      4\n      32\n      150\n      0.202852\n      0.18948\n      1221.331869\n    \n    \n      13\n      data2\n      EPT-STGCN\n      4\n      32\n      150\n      0.188402\n      0.166038\n      1219.885355\n    \n    \n      14\n      data2\n      EPT-STGCN\n      4\n      32\n      150\n      0.191666\n      0.175607\n      1221.502784\n    \n    \n      15\n      data2\n      EPT-STGCN\n      4\n      32\n      150\n      0.194334\n      0.177816\n      1222.205302\n    \n    \n      16\n      data2\n      EPT-STGCN\n      4\n      32\n      150\n      0.185386\n      0.165209\n      1222.540227\n    \n    \n      17\n      data2\n      EPT-STGCN\n      4\n      32\n      150\n      0.184355\n      0.165018\n      1225.328879\n    \n    \n      18\n      data2\n      EPT-STGCN\n      4\n      32\n      150\n      0.189528\n      0.168143\n      1223.233369\n    \n    \n      19\n      data2\n      EPT-STGCN\n      4\n      32\n      150\n      0.189098\n      0.166917\n      1227.838187\n    \n    \n      20\n      data2\n      EPT-STGCN\n      4\n      32\n      150\n      0.191017\n      0.174641\n      1225.812665\n    \n    \n      21\n      data2\n      EPT-STGCN\n      4\n      32\n      150\n      0.189909\n      0.174315\n      1227.123315\n    \n    \n      22\n      data2\n      EPT-STGCN\n      4\n      32\n      150\n      0.188329\n      0.169955\n      1227.044582\n    \n    \n      23\n      data2\n      EPT-STGCN\n      4\n      32\n      150\n      0.19075\n      0.169495\n      1229.764893\n    \n    \n      24\n      data2\n      EPT-STGCN\n      4\n      32\n      150\n      0.190843\n      0.175025\n      1229.049209\n    \n    \n      25\n      data2\n      EPT-STGCN\n      4\n      32\n      150\n      0.189308\n      0.167444\n      1530.840858\n    \n    \n      26\n      data2\n      EPT-STGCN\n      4\n      32\n      150\n      0.190253\n      0.174134\n      3743.438032\n    \n    \n      27\n      data2\n      EPT-STGCN\n      4\n      32\n      150\n      0.188167\n      0.169744\n      4029.448345\n    \n    \n      28\n      data2\n      EPT-STGCN\n      4\n      32\n      150\n      0.194325\n      0.177916\n      4092.016257\n    \n    \n      29\n      data2\n      EPT-STGCN\n      4\n      32\n      150\n      0.190294\n      0.169708\n      4100.476865\n    \n  \n\n\n\n\n\ndf_simul_no['mse(test)'].mean()\n\n0.17255143771568934\n\n\n\nprint('끝')\n\n끝\n\n\n\nimport matplotlib.pyplot as plt\nplt.boxplot(df_simul_no['mse(test)'])\nplt.show()"
  },
  {
    "objectID": "posts/SOLAR/2023-04-29-s-stgcn-ver1-시뮬레이션.html",
    "href": "posts/SOLAR/2023-04-29-s-stgcn-ver1-시뮬레이션.html",
    "title": "[SOLAR] STGCN Ver1 (data2, -N +S) 시뮬레이션(epoch, filter, lag)",
    "section": "",
    "text": "https://github.com/miruetoto/yechan3/tree/main/posts/3_Researches/ITSTGCN/itstgcn\nhttps://miruetoto.github.io/yechan3/posts/3_Researches/ITSTGCN/2023-03-18-SimulationPlanner-Tutorial.html#plnr_gnar_block\n\n\n\n\n\ntrain 2022-06-01 00:00:00 ~ 2022-08-14 17:00:00\ntest 2022-08-14 18:00:00 ~ 2022-09-15 23:00:00"
  },
  {
    "objectID": "posts/SOLAR/2023-04-29-s-stgcn-ver1-시뮬레이션.html#epoch",
    "href": "posts/SOLAR/2023-04-29-s-stgcn-ver1-시뮬레이션.html#epoch",
    "title": "[SOLAR] STGCN Ver1 (data2, -N +S) 시뮬레이션(epoch, filter, lag)",
    "section": "50 epoch",
    "text": "50 epoch\n\nplans_stgcn = {\n    'max_iteration': 1, # 30 \n    'method': ['STGCN'], \n    'lags': [4, 8, 12], \n    'nof_filters': [16, 32, 64], \n    'epoch': [50] # [50, 100, 150]\n}\n\n\nplnr = eptstgcn.planner.PLNR_STGCN(plans_stgcn,loader,dataset_name='data2')\n\n\nplnr.simulate()\n\n1/1 is done\nAll results are stored in ./simulation_results/2023-05-01_21-13-58.csv\n\n\n\neptstgcn.save_data(plnr,'./simul_model2/stgcn_v1_50epoch.pickle')\n\n\nsimul_model_50 = eptstgcn.load_data('./simul_model2/stgcn_v1_50epoch.pickle')\n\n\nsimul_model_50.simulation_results\n\n\n\n\n\n  \n    \n      \n      dataset\n      method\n      lags\n      nof_filters\n      epoch\n      mse(train)\n      mse(test)\n      calculation_time\n    \n  \n  \n    \n      0\n      data2\n      STGCN\n      4\n      16\n      50\n      0.182058\n      0.167798\n      299.051996\n    \n    \n      1\n      data2\n      STGCN\n      4\n      32\n      50\n      0.201436\n      0.188044\n      305.62022\n    \n    \n      2\n      data2\n      STGCN\n      4\n      64\n      50\n      0.191472\n      0.174166\n      316.454904\n    \n    \n      3\n      data2\n      STGCN\n      8\n      16\n      50\n      0.192159\n      0.17396\n      304.476469\n    \n    \n      4\n      data2\n      STGCN\n      8\n      32\n      50\n      0.205647\n      0.177749\n      309.493689\n    \n    \n      5\n      data2\n      STGCN\n      8\n      64\n      50\n      0.193967\n      0.170748\n      320.984409\n    \n    \n      6\n      data2\n      STGCN\n      12\n      16\n      50\n      0.201442\n      0.177695\n      315.960462\n    \n    \n      7\n      data2\n      STGCN\n      12\n      32\n      50\n      0.191433\n      0.177609\n      317.608783\n    \n    \n      8\n      data2\n      STGCN\n      12\n      64\n      50\n      0.195411\n      0.177827\n      327.97184\n    \n  \n\n\n\n\n\nprint('stgcn ver1 50epoch 시뮬레이션 끝!')\n\nstgcn ver1 50epoch 시뮬레이션 끝!\n\n\n\nimport matplotlib.pyplot as plt\nplt.boxplot(simul_model_50.simulation_results['mse(test)'])\nplt.show()"
  },
  {
    "objectID": "posts/SOLAR/2023-04-29-s-stgcn-ver1-시뮬레이션.html#epoch-1",
    "href": "posts/SOLAR/2023-04-29-s-stgcn-ver1-시뮬레이션.html#epoch-1",
    "title": "[SOLAR] STGCN Ver1 (data2, -N +S) 시뮬레이션(epoch, filter, lag)",
    "section": "100 epoch",
    "text": "100 epoch\n\nplans_stgcn = {\n    'max_iteration': 1, # 30 \n    'method': ['STGCN'], \n    'lags': [4, 8, 12], \n    'nof_filters': [16, 32, 64], \n    'epoch': [100] # [50, 100, 150]\n}\n\n\nplnr = eptstgcn.planner.PLNR_STGCN(plans_stgcn,loader,dataset_name='data2')\n\n\nplnr.simulate()\n\n1/1 is done\nAll results are stored in ./simulation_results/2023-05-02_00-43-59.csv\n\n\n\neptstgcn.save_data(plnr, './simul_model2/stgcn_v1_100epoch.pickle')\n\n\nsimul_model_100 = eptstgcn.load_data('./simul_model2/stgcn_v1_100epoch.pickle')"
  },
  {
    "objectID": "posts/SOLAR/2023-04-29-s-stgcn-ver1-시뮬레이션.html#epoch-2",
    "href": "posts/SOLAR/2023-04-29-s-stgcn-ver1-시뮬레이션.html#epoch-2",
    "title": "[SOLAR] STGCN Ver1 (data2, -N +S) 시뮬레이션(epoch, filter, lag)",
    "section": "150 epoch",
    "text": "150 epoch\n\nplans_stgcn = {\n    'max_iteration': 1, # 30 \n    'method': ['STGCN'], \n    'lags': [4, 8, 12], \n    'nof_filters': [16, 32, 64], \n    'epoch': [150] # [50, 100, 150]\n}\n\n\nplnr = eptstgcn.planner.PLNR_STGCN(plans_stgcn,loader,dataset_name='data2')\n\n\nplnr.simulate()\n\n1/1 is done\nAll results are stored in ./simulation_results/2023-05-02_03-05-45.csv\n\n\n\neptstgcn.save_data(plnr,'./simul_model2/stgcn_v1_150epoch.pickle')\n\n\nsimul_model_150 = eptstgcn.load_data('./simul_model2/stgcn_v1_150epoch.pickle')"
  },
  {
    "objectID": "posts/SOLAR/2023-04-25-s-stgcn-ver2-100에폭.html",
    "href": "posts/SOLAR/2023-04-25-s-stgcn-ver2-100에폭.html",
    "title": "[SOLAR] STGCN Ver2 (data2, -N +S) 30회 100 epoch",
    "section": "",
    "text": "https://github.com/miruetoto/yechan3/tree/main/posts/3_Researches/ITSTGCN/itstgcn\nhttps://miruetoto.github.io/yechan3/posts/3_Researches/ITSTGCN/2023-03-18-SimulationPlanner-Tutorial.html#plnr_gnar_block\n\n\n\n\n\ntrain 2022-06-01 00:00:00 ~ 2022-08-14 17:00:00\ntest 2022-08-14 18:00:00 ~ 2022-09-15 23:00:00\n\n\n\n\n\nimport eptstgcn\nimport torch\nimport eptstgcn.planner\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\n\n\n\n\nurl = \"https://raw.githubusercontent.com/pinkocto/noteda/main/posts/SOLAR/data2/stgcn_data2.json\"\nloader = eptstgcn.DatasetLoader(url)\ndataset = loader.get_dataset(lags=4)\n\n\ntrain_dataset, test_dataset = eptstgcn.utils.temporal_signal_split(dataset, train_ratio = 0.7)\n\n\n\n\n\nref: https://seoyeonc.github.io/blog/posts/GCN/2023-03-17-ITSTGCN-Tutorial.html\n\n\nlrnr = eptstgcn.StgcnLearner(train_dataset, dataset_name = 'data2(2022/06/01 ~ 2022/09/15)')\n\n\nlrnr.learn(filters=32, epoch=100)\n\n100/100\n\n\n\nimport pickle \nwith open('./lrnr_model/stgcn_ver2_data2_cancel_normal_100epoch.pickle','wb') as fw:\n    pickle.dump(lrnr, fw)\n\n\nimport pickle \nwith open('./lrnr_model/stgcn_ver2_data2_cancel_normal_100epoch.pickle', 'rb') as f: \n    model = pickle.load(f)\n\n\n\n\n\nevtor = eptstgcn.Evaluator(model, train_dataset, test_dataset)\n\n\n# fig = evtor.plot('--', label='observed data')\n# fig.tight_layout()\n# fig\n\n\n\n\nevtor.tr_plot(t=150, label='observed data')\n\n\n\n\n\n\n\n\nevtor.test_plot(t=150, label='observed data')\n\n\n\n\n\n\n\n\n\nplans_stgcn = {\n    'max_iteration': 30, \n    'method': ['EPT-STGCN'], \n    'lags': [4], \n    'nof_filters': [32], \n    'epoch': [100]\n}\n\n\nplnr = eptstgcn.planner.PLNR_STGCN(plans_stgcn,loader,dataset_name='data2')\n\n\nplnr.simulate()\n\n1/30 is done\n2/30 is done\n3/30 is done\n4/30 is done\n5/30 is done\n6/30 is done\n7/30 is done\n8/30 is done\n9/30 is done\n10/30 is done\n11/30 is done\n12/30 is done\n13/30 is done\n14/30 is done\n15/30 is done\n16/30 is done\n17/30 is done\n18/30 is done\n19/30 is done\n20/30 is done\n21/30 is done\n22/30 is done\n23/30 is done\n24/30 is done\n25/30 is done\n26/30 is done\n27/30 is done\n28/30 is done\n29/30 is done\n30/30 is done\nAll results are stored in ./simulation_results/2023-04-27_12-15-15.csv\n\n\n\nimport pickle\nwith open('./simul_model/stgcn_ver2_data2_cancel_normal_100epoch.pickle', 'wb') as fw:\n    pickle.dump(plnr, fw)\n\n\nwith open('./simul_model/stgcn_ver2_data2_cancel_normal_100epoch.pickle', 'rb') as f:\n    simul_model = pickle.load(f)\n\n\ndf_simul_no = simul_model.simulation_results\ndf_simul_no\n\n\n\n\n\n  \n    \n      \n      dataset\n      method\n      lags\n      nof_filters\n      epoch\n      mse(train)\n      mse(test)\n      calculation_time\n    \n  \n  \n    \n      0\n      data2\n      EPT-STGCN\n      4\n      32\n      100\n      0.184624\n      0.166554\n      806.291872\n    \n    \n      1\n      data2\n      EPT-STGCN\n      4\n      32\n      100\n      0.191821\n      0.174335\n      809.761688\n    \n    \n      2\n      data2\n      EPT-STGCN\n      4\n      32\n      100\n      0.189864\n      0.172401\n      812.575872\n    \n    \n      3\n      data2\n      EPT-STGCN\n      4\n      32\n      100\n      0.184429\n      0.165976\n      813.223254\n    \n    \n      4\n      data2\n      EPT-STGCN\n      4\n      32\n      100\n      0.195412\n      0.179954\n      813.411208\n    \n    \n      5\n      data2\n      EPT-STGCN\n      4\n      32\n      100\n      0.189516\n      0.167228\n      802.375919\n    \n    \n      6\n      data2\n      EPT-STGCN\n      4\n      32\n      100\n      0.193522\n      0.173043\n      805.097764\n    \n    \n      7\n      data2\n      EPT-STGCN\n      4\n      32\n      100\n      0.191042\n      0.175756\n      811.814163\n    \n    \n      8\n      data2\n      EPT-STGCN\n      4\n      32\n      100\n      0.190697\n      0.173998\n      863.916972\n    \n    \n      9\n      data2\n      EPT-STGCN\n      4\n      32\n      100\n      0.192474\n      0.176019\n      874.849521\n    \n    \n      10\n      data2\n      EPT-STGCN\n      4\n      32\n      100\n      0.190868\n      0.171752\n      1087.609615\n    \n    \n      11\n      data2\n      EPT-STGCN\n      4\n      32\n      100\n      0.190033\n      0.171047\n      1025.377339\n    \n    \n      12\n      data2\n      EPT-STGCN\n      4\n      32\n      100\n      0.190472\n      0.172028\n      1041.937325\n    \n    \n      13\n      data2\n      EPT-STGCN\n      4\n      32\n      100\n      0.19148\n      0.175484\n      2193.973796\n    \n    \n      14\n      data2\n      EPT-STGCN\n      4\n      32\n      100\n      0.19964\n      0.184739\n      2024.050035\n    \n    \n      15\n      data2\n      EPT-STGCN\n      4\n      32\n      100\n      0.182046\n      0.164116\n      2261.503337\n    \n    \n      16\n      data2\n      EPT-STGCN\n      4\n      32\n      100\n      0.184723\n      0.165917\n      2353.211124\n    \n    \n      17\n      data2\n      EPT-STGCN\n      4\n      32\n      100\n      0.20017\n      0.184031\n      2246.013008\n    \n    \n      18\n      data2\n      EPT-STGCN\n      4\n      32\n      100\n      0.20381\n      0.189657\n      2153.198691\n    \n    \n      19\n      data2\n      EPT-STGCN\n      4\n      32\n      100\n      0.190219\n      0.172672\n      2594.615245\n    \n    \n      20\n      data2\n      EPT-STGCN\n      4\n      32\n      100\n      0.185853\n      0.165922\n      2058.042647\n    \n    \n      21\n      data2\n      EPT-STGCN\n      4\n      32\n      100\n      0.206896\n      0.190757\n      2394.984007\n    \n    \n      22\n      data2\n      EPT-STGCN\n      4\n      32\n      100\n      0.191237\n      0.174569\n      2212.408073\n    \n    \n      23\n      data2\n      EPT-STGCN\n      4\n      32\n      100\n      0.19208\n      0.175278\n      2294.681623\n    \n    \n      24\n      data2\n      EPT-STGCN\n      4\n      32\n      100\n      0.190018\n      0.174164\n      2555.400719\n    \n    \n      25\n      data2\n      EPT-STGCN\n      4\n      32\n      100\n      0.194303\n      0.178379\n      2388.160844\n    \n    \n      26\n      data2\n      EPT-STGCN\n      4\n      32\n      100\n      0.191164\n      0.175594\n      2372.384897\n    \n    \n      27\n      data2\n      EPT-STGCN\n      4\n      32\n      100\n      0.19249\n      0.175679\n      2252.741733\n    \n    \n      28\n      data2\n      EPT-STGCN\n      4\n      32\n      100\n      0.194278\n      0.179537\n      2190.178894\n    \n    \n      29\n      data2\n      EPT-STGCN\n      4\n      32\n      100\n      0.19047\n      0.174702\n      2534.951102\n    \n  \n\n\n\n\n\ndf_simul_no['mse(test)'].mean()\n\n0.17470959573984146\n\n\n\nprint('stgcn ver2 100에폭 끝')\n\nstgcn ver2 100에폭 끝\n\n\n\nimport matplotlib.pyplot as plt\nplt.boxplot(df_simul_no['mse(test)'])\nplt.show()"
  },
  {
    "objectID": "posts/SOLAR/2023-04-09-solar-stgcn-ver2-lag1.html",
    "href": "posts/SOLAR/2023-04-09-solar-stgcn-ver2-lag1.html",
    "title": "[SOLAR] STGCN Ver2 lag1",
    "section": "",
    "text": "import pandas as pd\nimport numpy as np\nimport json\nimport urllib\n\nimport matplotlib.pyplot as plt\nimport time\n\n\n# 일반적인 모듈 \nimport numpy as np\nimport matplotlib.pyplot as plt \nimport networkx as nx \nfrom tqdm import tqdm \n\n# 파이토치 관련 \nimport torch\nimport torch.nn.functional as F\n\n# PyG 관련 \nfrom torch_geometric.data import Data ## Data: 그래프자료형을 만드는 클래스\n\n# STGCN 관련 \nimport torch_geometric_temporal\nfrom torch_geometric_temporal.nn.recurrent import GConvGRU\nfrom torch_geometric_temporal.signal import temporal_signal_split \n\n\nclass RecurrentGCN(torch.nn.Module):\n    def __init__(self, node_features, filters):\n        super(RecurrentGCN, self).__init__()\n        self.recurrent = GConvGRU(node_features, filters, 2)\n        self.linear = torch.nn.Linear(filters, 1)\n\n    def forward(self, x, edge_index, edge_weight):\n        h = self.recurrent(x, edge_index, edge_weight)\n        h = F.relu(h)\n        h = self.linear(h)\n        return h\n\n\nfrom mysolar import SolarEPTDatasetLoader\n\n\nloader = SolarEPTDatasetLoader()\ndataset = loader.get_dataset(lags=1)\ntrain_dataset, test_dataset = temporal_signal_split(dataset, train_ratio=0.8)"
  },
  {
    "objectID": "posts/SOLAR/2023-04-09-solar-stgcn-ver2-lag1.html#learn",
    "href": "posts/SOLAR/2023-04-09-solar-stgcn-ver2-lag1.html#learn",
    "title": "[SOLAR] STGCN Ver2 lag1",
    "section": "Learn",
    "text": "Learn\n\nmodel = RecurrentGCN(node_features=1, filters=32)\noptimizer = torch.optim.Adam(model.parameters(), lr=0.01)\nmodel.train()\n\nRecurrentGCN(\n  (recurrent): GConvGRU(\n    (conv_x_z): ChebConv(1, 32, K=2, normalization=sym)\n    (conv_h_z): ChebConv(32, 32, K=2, normalization=sym)\n    (conv_x_r): ChebConv(1, 32, K=2, normalization=sym)\n    (conv_h_r): ChebConv(32, 32, K=2, normalization=sym)\n    (conv_x_h): ChebConv(1, 32, K=2, normalization=sym)\n    (conv_h_h): ChebConv(32, 32, K=2, normalization=sym)\n  )\n  (linear): Linear(in_features=32, out_features=1, bias=True)\n)\n\n\n\nstart = time.time()\nfor epoch in tqdm(range(50)):\n    for t, snapshot in enumerate(train_dataset):\n        yt_hat = model(snapshot.x, snapshot.edge_index, snapshot.edge_attr)\n        cost = torch.mean((yt_hat-snapshot.y)**2)\n        cost.backward()\n        optimizer.step()\n        optimizer.zero_grad()\nend = time.time()\nprint(f\"{end-start:.5f} sec\")\n\n100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [48:08<00:00, 57.77s/it]\n\n\n2888.63086 sec\n\n\n\n\n\n\nprint(2888.63086/60, '분')\n\n48.14384766666667 분\n\n\n\nimport pickle \nwith open('stgcn2_lag1.pickle','wb') as fw:\n    pickle.dump(model, fw)\n\n\nimport pickle \nwith open('stgcn2_lag1.pickle', 'rb') as f: \n    model = pickle.load(f)\n\n\nmodel\n\nRecurrentGCN(\n  (recurrent): GConvGRU(\n    (conv_x_z): ChebConv(1, 32, K=2, normalization=sym)\n    (conv_h_z): ChebConv(32, 32, K=2, normalization=sym)\n    (conv_x_r): ChebConv(1, 32, K=2, normalization=sym)\n    (conv_h_r): ChebConv(32, 32, K=2, normalization=sym)\n    (conv_x_h): ChebConv(1, 32, K=2, normalization=sym)\n    (conv_h_h): ChebConv(32, 32, K=2, normalization=sym)\n  )\n  (linear): Linear(in_features=32, out_features=1, bias=True)\n)"
  },
  {
    "objectID": "posts/SOLAR/2023-04-09-solar-stgcn-ver2-lag1.html#모델평가",
    "href": "posts/SOLAR/2023-04-09-solar-stgcn-ver2-lag1.html#모델평가",
    "title": "[SOLAR] STGCN Ver2 lag1",
    "section": "모델평가",
    "text": "모델평가\n\nmodel.eval()\ncost = 0\nfor time, snapshot in enumerate(train_dataset):\n    y_hat = model(snapshot.x, snapshot.edge_index, snapshot.edge_attr)\n    cost = cost + torch.mean((y_hat-snapshot.y)**2)\ncost = cost / (time+1)\ncost = cost.item()\nprint(\"MSE: {:.4f}\".format(cost))\n\nMSE: 0.1711\n\n\n\nmodel.eval()\ncost = 0\nfor time, snapshot in enumerate(test_dataset):\n    y_hat = model(snapshot.x, snapshot.edge_index, snapshot.edge_attr)\n    cost = cost + torch.mean((y_hat-snapshot.y)**2)\ncost = cost / (time+1)\ncost = cost.item()\nprint(\"MSE: {:.4f}\".format(cost))\n\nMSE: 0.1452"
  },
  {
    "objectID": "posts/SOLAR/2023-04-09-solar-stgcn-ver2-lag1.html#visualization",
    "href": "posts/SOLAR/2023-04-09-solar-stgcn-ver2-lag1.html#visualization",
    "title": "[SOLAR] STGCN Ver2 lag1",
    "section": "Visualization",
    "text": "Visualization\n\nyhat_train = torch.stack([model(snapshot.x,snapshot.edge_index, snapshot.edge_attr) for snapshot in train_dataset]).detach().numpy()\nyhat_test = torch.stack([model(snapshot.x,snapshot.edge_index, snapshot.edge_attr) for snapshot in test_dataset]).detach().numpy()\n\n\nurl = 'https://raw.githubusercontent.com/pinkocto/noteda/main/posts/SOLAR/data/solar2.json'\n\n\ndata_dict = json.loads(urllib.request.urlopen(url).read())\nV = list(data_dict['node_ids'].keys())\nf = np.array(data_dict[\"FX\"])\n\n\nimport matplotlib.pyplot as plt\nplt.rcParams['font.family'] = 'NanumGothic'\n\n\nfig,ax = plt.subplots(44,1,figsize=(10,50))\nfor k in range(44):\n    ax[k].plot(f[:,k],'--',alpha=0.5,label='observed')\n    ax[k].set_title('node: {}'.format(V[k]))\n    ax[k].plot(yhat_train[:,k],label='predicted (tr)')\n    ax[k].plot(range(yhat_train.shape[0],yhat_train.shape[0]+yhat_test.shape[0]),yhat_test[:,k],label='predicted (test)')\n    ax[k].legend()\nfig.tight_layout()\n\n\n\n\n\n깃헙 메모리문제(100MB 초과)"
  },
  {
    "objectID": "posts/SOLAR/2023-04-10-lstm.html",
    "href": "posts/SOLAR/2023-04-10-lstm.html",
    "title": "[SOLAR] LSTM",
    "section": "",
    "text": "Data\n\n\n\n\nimport pandas as pd\nimport numpy as np\nimport json\nimport urllib\nimport gc\n\nimport matplotlib.pyplot as plt\n\n\nurl = 'https://raw.githubusercontent.com/pinkocto/noteda/main/posts/SOLAR/data/df_new.csv'\ndf = pd.read_csv(url)"
  },
  {
    "objectID": "posts/SOLAR/2023-04-03-일사량.html",
    "href": "posts/SOLAR/2023-04-03-일사량.html",
    "title": "일사량자료정리",
    "section": "",
    "text": "import pandas as pd\nimport numpy as np\nimport itertools\n\n\ndf0 = pd.read_csv('https://raw.githubusercontent.com/pinkocto/noteda/main/posts/SOLAR/data/OBS_ASOS_TIM_data0.csv', encoding='cp949') # 2021-01-01 ~ 2021-12-31\ndf1 = pd.read_csv('https://raw.githubusercontent.com/pinkocto/noteda/main/posts/SOLAR/data/OBS_ASOS_TIM_data1.csv') # 2022-01-01 ~ 2023-12-31\ndf2 = pd.read_csv('https://raw.githubusercontent.com/pinkocto/noteda/main/posts/SOLAR/data/test_raw.csv', encoding='cp949') # 2023-01-01 ~ 2023-01-15\n\n- df_raw\n\ndf_raw = pd.concat([df0, df1])\ndf_raw\n\n\n\n\n\n  \n    \n      \n      지점\n      지점명\n      일시\n      일사(MJ/m2)\n    \n  \n  \n    \n      0\n      93\n      북춘천\n      2021-01-01 08:00\n      0.00\n    \n    \n      1\n      93\n      북춘천\n      2021-01-01 09:00\n      0.37\n    \n    \n      2\n      93\n      북춘천\n      2021-01-01 10:00\n      0.96\n    \n    \n      3\n      93\n      북춘천\n      2021-01-01 11:00\n      1.40\n    \n    \n      4\n      93\n      북춘천\n      2021-01-01 12:00\n      1.72\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      229672\n      283\n      경주시\n      2022-12-31 14:00:00\n      1.82\n    \n    \n      229673\n      283\n      경주시\n      2022-12-31 15:00:00\n      1.52\n    \n    \n      229674\n      283\n      경주시\n      2022-12-31 16:00:00\n      0.96\n    \n    \n      229675\n      283\n      경주시\n      2022-12-31 17:00:00\n      0.35\n    \n    \n      229676\n      283\n      경주시\n      2022-12-31 18:00:00\n      0.01\n    \n  \n\n444720 rows × 4 columns\n\n\n\n- 지점칼럼 삭제 // 일시 \\(\\to\\) 날짜, 시간으로 분리\n\ndf_temp = df_raw.assign(날짜= list(map(lambda x: x[:10],df_raw['일시'])))\\\n.assign(시간 = list(map(lambda x: x[11:16], df_raw['일시'])))\\\n.drop(['일시','지점'], axis=1).rename({'일사(MJ/m2)':'일사'},axis=1).reset_index(drop=True)\ndf_temp\n\n\n\n\n\n  \n    \n      \n      지점명\n      일사\n      날짜\n      시간\n    \n  \n  \n    \n      0\n      북춘천\n      0.00\n      2021-01-01\n      08:00\n    \n    \n      1\n      북춘천\n      0.37\n      2021-01-01\n      09:00\n    \n    \n      2\n      북춘천\n      0.96\n      2021-01-01\n      10:00\n    \n    \n      3\n      북춘천\n      1.40\n      2021-01-01\n      11:00\n    \n    \n      4\n      북춘천\n      1.72\n      2021-01-01\n      12:00\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      444715\n      경주시\n      1.82\n      2022-12-31\n      14:00\n    \n    \n      444716\n      경주시\n      1.52\n      2022-12-31\n      15:00\n    \n    \n      444717\n      경주시\n      0.96\n      2022-12-31\n      16:00\n    \n    \n      444718\n      경주시\n      0.35\n      2022-12-31\n      17:00\n    \n    \n      444719\n      경주시\n      0.01\n      2022-12-31\n      18:00\n    \n  \n\n444720 rows × 4 columns\n\n\n\n- 파주, 상주, 동두천, 충주, 제천은 삭제\n\ndf_temp = df_temp.query(\"지점명 not in ['파주','상주','동두천','충주','제천']\").reset_index(drop=True)\ndf_temp\n\n\n\n\n\n  \n    \n      \n      지점명\n      일사\n      날짜\n      시간\n    \n  \n  \n    \n      0\n      북춘천\n      0.00\n      2021-01-01\n      08:00\n    \n    \n      1\n      북춘천\n      0.37\n      2021-01-01\n      09:00\n    \n    \n      2\n      북춘천\n      0.96\n      2021-01-01\n      10:00\n    \n    \n      3\n      북춘천\n      1.40\n      2021-01-01\n      11:00\n    \n    \n      4\n      북춘천\n      1.72\n      2021-01-01\n      12:00\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      420955\n      경주시\n      1.82\n      2022-12-31\n      14:00\n    \n    \n      420956\n      경주시\n      1.52\n      2022-12-31\n      15:00\n    \n    \n      420957\n      경주시\n      0.96\n      2022-12-31\n      16:00\n    \n    \n      420958\n      경주시\n      0.35\n      2022-12-31\n      17:00\n    \n    \n      420959\n      경주시\n      0.01\n      2022-12-31\n      18:00\n    \n  \n\n420960 rows × 4 columns\n\n\n\n- 시간이 비어있지 않도록…\n\nreg = df_temp['지점명'].unique().tolist() \nday = df_temp['날짜'].unique().tolist() \ntime = list(df_temp['시간'].unique())\ntime = ['0{}:00'.format(i) for i in range(0,8)] + time\n\n\ntime\n\n['00:00',\n '01:00',\n '02:00',\n '03:00',\n '04:00',\n '05:00',\n '05:00',\n '06:00',\n '06:00',\n '07:00',\n '07:00',\n '08:00',\n '09:00',\n '10:00',\n '11:00',\n '12:00',\n '13:00',\n '14:00',\n '15:00',\n '16:00',\n '17:00',\n '18:00',\n '19:00',\n '20:00',\n '21:00']\n\n\n\ndf_temp2 = pd.DataFrame(itertools.product(reg,day,time)).rename({0:'지점명',1:'날짜',2:'시간'},axis=1).merge(df_temp,how='left').fillna(0)\ndf_temp2\n\n\n\n\n\n  \n    \n      \n      지점명\n      날짜\n      시간\n      일사\n    \n  \n  \n    \n      0\n      북춘천\n      2021-01-01\n      00:00\n      0.0\n    \n    \n      1\n      북춘천\n      2021-01-01\n      01:00\n      0.0\n    \n    \n      2\n      북춘천\n      2021-01-01\n      02:00\n      0.0\n    \n    \n      3\n      북춘천\n      2021-01-01\n      03:00\n      0.0\n    \n    \n      4\n      북춘천\n      2021-01-01\n      04:00\n      0.0\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      802995\n      경주시\n      2022-12-31\n      07:00\n      0.0\n    \n    \n      802996\n      경주시\n      2022-12-31\n      20:00\n      0.0\n    \n    \n      802997\n      경주시\n      2022-12-31\n      06:00\n      0.0\n    \n    \n      802998\n      경주시\n      2022-12-31\n      21:00\n      0.0\n    \n    \n      802999\n      경주시\n      2022-12-31\n      05:00\n      0.0\n    \n  \n\n803000 rows × 4 columns\n\n\n\n\ndf_temp2[:10]\n\n\n\n\n\n  \n    \n      \n      지점명\n      날짜\n      시간\n      일사\n    \n  \n  \n    \n      0\n      북춘천\n      2021-01-01\n      00:00\n      0.00\n    \n    \n      1\n      북춘천\n      2021-01-01\n      01:00\n      0.00\n    \n    \n      2\n      북춘천\n      2021-01-01\n      02:00\n      0.00\n    \n    \n      3\n      북춘천\n      2021-01-01\n      03:00\n      0.00\n    \n    \n      4\n      북춘천\n      2021-01-01\n      04:00\n      0.00\n    \n    \n      5\n      북춘천\n      2021-01-01\n      05:00\n      0.00\n    \n    \n      6\n      북춘천\n      2021-01-01\n      06:00\n      0.00\n    \n    \n      7\n      북춘천\n      2021-01-01\n      07:00\n      0.00\n    \n    \n      8\n      북춘천\n      2021-01-01\n      08:00\n      0.00\n    \n    \n      9\n      북춘천\n      2021-01-01\n      09:00\n      0.37\n    \n  \n\n\n\n\n\ndf_temp2[:-10]\n\n\n\n\n\n  \n    \n      \n      지점명\n      날짜\n      시간\n      일사\n    \n  \n  \n    \n      0\n      북춘천\n      2021-01-01\n      00:00\n      0.00\n    \n    \n      1\n      북춘천\n      2021-01-01\n      01:00\n      0.00\n    \n    \n      2\n      북춘천\n      2021-01-01\n      02:00\n      0.00\n    \n    \n      3\n      북춘천\n      2021-01-01\n      03:00\n      0.00\n    \n    \n      4\n      북춘천\n      2021-01-01\n      04:00\n      0.00\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      802985\n      경주시\n      2022-12-31\n      10:00\n      1.05\n    \n    \n      802986\n      경주시\n      2022-12-31\n      11:00\n      1.52\n    \n    \n      802987\n      경주시\n      2022-12-31\n      12:00\n      1.86\n    \n    \n      802988\n      경주시\n      2022-12-31\n      13:00\n      1.93\n    \n    \n      802989\n      경주시\n      2022-12-31\n      14:00\n      1.82\n    \n  \n\n802990 rows × 4 columns\n\n\n\n- 시간,날짜 \\(\\to\\) 일시\n\ndf_temp3=df_temp2.assign(일시 = list(map(lambda x,y: x+'-'+y,df_temp2['날짜'],df_temp2['시간'])))\\\n.drop(['날짜','시간'],axis=1)\ndf_temp3\n\n\n\n\n\n  \n    \n      \n      지점명\n      일사\n      일시\n    \n  \n  \n    \n      0\n      북춘천\n      0.0\n      2021-01-01-00:00\n    \n    \n      1\n      북춘천\n      0.0\n      2021-01-01-01:00\n    \n    \n      2\n      북춘천\n      0.0\n      2021-01-01-02:00\n    \n    \n      3\n      북춘천\n      0.0\n      2021-01-01-03:00\n    \n    \n      4\n      북춘천\n      0.0\n      2021-01-01-04:00\n    \n    \n      ...\n      ...\n      ...\n      ...\n    \n    \n      802995\n      경주시\n      0.0\n      2022-12-31-07:00\n    \n    \n      802996\n      경주시\n      0.0\n      2022-12-31-20:00\n    \n    \n      802997\n      경주시\n      0.0\n      2022-12-31-06:00\n    \n    \n      802998\n      경주시\n      0.0\n      2022-12-31-21:00\n    \n    \n      802999\n      경주시\n      0.0\n      2022-12-31-05:00\n    \n  \n\n803000 rows × 3 columns\n\n\n\n- 저장\n\ndf_temp3.rename({'지점명':'region','일사':'solar_radiation','일시':'date'},axis=1)\n\n\n\n\n\n  \n    \n      \n      region\n      solar_radiation\n      date\n    \n  \n  \n    \n      0\n      북춘천\n      0.0\n      2021-01-01-00:00\n    \n    \n      1\n      북춘천\n      0.0\n      2021-01-01-01:00\n    \n    \n      2\n      북춘천\n      0.0\n      2021-01-01-02:00\n    \n    \n      3\n      북춘천\n      0.0\n      2021-01-01-03:00\n    \n    \n      4\n      북춘천\n      0.0\n      2021-01-01-04:00\n    \n    \n      ...\n      ...\n      ...\n      ...\n    \n    \n      802995\n      경주시\n      0.0\n      2022-12-31-07:00\n    \n    \n      802996\n      경주시\n      0.0\n      2022-12-31-20:00\n    \n    \n      802997\n      경주시\n      0.0\n      2022-12-31-06:00\n    \n    \n      802998\n      경주시\n      0.0\n      2022-12-31-21:00\n    \n    \n      802999\n      경주시\n      0.0\n      2022-12-31-05:00\n    \n  \n\n803000 rows × 3 columns\n\n\n\n\ndf = df_temp3.rename({'지점명':'region','일사':'solar_radiation','일시':'date'},axis=1)\ndf.to_csv(\"solar_radiation.csv\",index=False)\n!git add .\n!git commit -m .\n!git push \n\n[main 553559d] .\n 3 files changed, 804001 insertions(+)\n create mode 100644 posts/2_Research/SOLAR/.ipynb_checkpoints/Untitled-checkpoint.ipynb\n create mode 100644 posts/2_Research/SOLAR/Untitled.ipynb\n create mode 100644 posts/2_Research/SOLAR/solar_radiation.csv\nEnumerating objects: 12, done.\nCounting objects: 100% (12/12), done.\nDelta compression using up to 16 threads\nCompressing objects: 100% (8/8), done.\nWriting objects: 100% (9/9), 2.72 MiB | 2.41 MiB/s, done.\nTotal 9 (delta 0), reused 0 (delta 0), pack-reused 0\nTo https://github.com/pinkocto/mm\n   7468929..553559d  main -> main\n\n\n- 불러오기\n\ndf = pd.read_csv(\"https://raw.githubusercontent.com/pinkocto/mm/main/posts/2_Research/SOLAR/solar_radiation.csv\")\ndf\n\n\n\n\n\n  \n    \n      \n      region\n      solar_radiation\n      date\n    \n  \n  \n    \n      0\n      북춘천\n      0.0\n      2021-01-01-00:00\n    \n    \n      1\n      북춘천\n      0.0\n      2021-01-01-01:00\n    \n    \n      2\n      북춘천\n      0.0\n      2021-01-01-02:00\n    \n    \n      3\n      북춘천\n      0.0\n      2021-01-01-03:00\n    \n    \n      4\n      북춘천\n      0.0\n      2021-01-01-04:00\n    \n    \n      ...\n      ...\n      ...\n      ...\n    \n    \n      802995\n      경주시\n      0.0\n      2022-12-31-07:00\n    \n    \n      802996\n      경주시\n      0.0\n      2022-12-31-20:00\n    \n    \n      802997\n      경주시\n      0.0\n      2022-12-31-06:00\n    \n    \n      802998\n      경주시\n      0.0\n      2022-12-31-21:00\n    \n    \n      802999\n      경주시\n      0.0\n      2022-12-31-05:00\n    \n  \n\n803000 rows × 3 columns\n\n\n\n- 다운로드\n\n# !wget https://raw.githubusercontent.com/miruetoto/yechan3/main/posts/3_Researches/SOLAR/solar_radiation.csv"
  },
  {
    "objectID": "posts/SOLAR/2023-04-06-solar-class.html",
    "href": "posts/SOLAR/2023-04-06-solar-class.html",
    "title": "[SOLAR] WindmillOutputLargeDatasetLoader",
    "section": "",
    "text": "ref: https://pytorch-geometric-temporal.readthedocs.io/en/latest/modules/dataset.html#torch_geometric_temporal.dataset.windmilllarge.WindmillOutputLargeDatasetLoader\n\n\nimport pandas as pd\nimport numpy as np\nimport json\nimport urllib\n\n\n# 일반적인 모듈 \nimport numpy as np\nimport matplotlib.pyplot as plt \nimport networkx as nx \nfrom tqdm import tqdm \n\n# 파이토치 관련 \nimport torch\nimport torch.nn.functional as F\n\n# PyG 관련 \nfrom torch_geometric.data import Data ## Data: 그래프자료형을 만드는 클래스\n\n# STGCN 관련 \nimport torch_geometric_temporal\nfrom torch_geometric_temporal.nn.recurrent import GConvGRU\nfrom torch_geometric_temporal.signal import temporal_signal_split \n\n\nurl = \"https://graphmining.ai/temporal_datasets/windmill_output.json\"\ndata_dict = json.loads(urllib.request.urlopen(url).read())\ndata_dict.keys()\n\ndict_keys(['block', 'time_periods', 'weights', 'edges'])\n\n\n\ntype(data_dict['weights']) # list 형태로 들어가있음.\n\nlist\n\n\n\ntype(data_dict['block']) # list 형태로 들어가 있음.\n\nlist\n\n\n\nnp.array(data_dict['block'])\n\narray([[0.1287, 0.1167, 0.0812, ..., 0.027 , 0.0201, 0.0228],\n       [0.0817, 0.1078, 0.1054, ..., 0.0439, 0.0262, 0.021 ],\n       [0.9418, 0.9589, 0.9447, ..., 0.7815, 0.8621, 0.2498],\n       ...,\n       [0.1391, 0.1829, 0.1383, ..., 0.0359, 0.0335, 0.0219],\n       [0.5972, 0.6057, 0.6123, ..., 0.2606, 0.4203, 0.1954],\n       [0.1298, 0.1504, 0.1442, ..., 0.0256, 0.093 , 0.0158]])\n\n\n\nnp.array(data_dict['block']).shape\n\n(17472, 319)\n\n\n\ntype(data_dict['block'])\n\nlist\n\n\n\nnp.array(data_dict['weights']).shape\n\n(101761,)\n\n\n\n# data_dict['block']\n\n\n# data_dict['edges']"
  },
  {
    "objectID": "posts/SOLAR/2023-04-06-solar-class.html#source-code-for-torch_geometric_temporal.dataset.windmillmedium",
    "href": "posts/SOLAR/2023-04-06-solar-class.html#source-code-for-torch_geometric_temporal.dataset.windmillmedium",
    "title": "[SOLAR] WindmillOutputLargeDatasetLoader",
    "section": "Source code for torch_geometric_temporal.dataset.windmillmedium",
    "text": "Source code for torch_geometric_temporal.dataset.windmillmedium\nimport json\nimport urllib\nimport numpy as np\nfrom ..signal import StaticGraphTemporalSignal\n\n\nclass WindmillOutputLargeDatasetLoader(object):\n    \"\"\"Hourly energy output of windmills from a European country\n    for more than 2 years. Vertices represent 319 windmills and\n    weighted edges describe the strength of relationships. The target\n    variable allows for regression tasks.\n    \"\"\"\n\n    def __init__(self):\n        self._read_web_data()\n\n    def _read_web_data(self):\n        url = \"https://graphmining.ai/temporal_datasets/windmill_output.json\"\n        self._dataset = json.loads(urllib.request.urlopen(url).read().decode())\n\n    def _get_edges(self):\n        self._edges = np.array(self._dataset[\"edges\"]).T\n\n    def _get_edge_weights(self):\n        self._edge_weights = np.array(self._dataset[\"weights\"]).T\n\n    def _get_targets_and_features(self):\n        stacked_target = np.stack(self._dataset[\"block\"])\n        standardized_target = (stacked_target - np.mean(stacked_target, axis=0)) / (\n            np.std(stacked_target, axis=0) + 10 ** -10\n        )\n        self.features = [\n            standardized_target[i : i + self.lags, :].T\n            for i in range(standardized_target.shape[0] - self.lags)\n        ]\n        self.targets = [\n            standardized_target[i + self.lags, :].T\n            for i in range(standardized_target.shape[0] - self.lags)\n        ]\n\n    def get_dataset(self, lags: int = 8) -> StaticGraphTemporalSignal:\n        \"\"\"Returning the Windmill Output data iterator.\n\n        Args types:\n            * **lags** *(int)* - The number of time lags.\n        Return types:\n            * **dataset** *(StaticGraphTemporalSignal)* - The Windmill Output dataset.\n        \"\"\"\n        self.lags = lags\n        self._get_edges()\n        self._get_edge_weights()\n        self._get_targets_and_features()\n        dataset = StaticGraphTemporalSignal(\n            self._edges, self._edge_weights, self.features, self.targets\n        )\n        return dataset\n\ntorch_geometric_temporal.signal.StaticGraphTemporalSignal"
  },
  {
    "objectID": "posts/SOLAR/2023-04-06-solar-class.html#source-code-for-solardatasetloader",
    "href": "posts/SOLAR/2023-04-06-solar-class.html#source-code-for-solardatasetloader",
    "title": "[SOLAR] WindmillOutputLargeDatasetLoader",
    "section": "Source code for SolarDatasetLoader",
    "text": "Source code for SolarDatasetLoader\n\nimport json\nimport urllib\nimport numpy as np\nfrom torch_geometric_temporal.signal.static_graph_temporal_signal import StaticGraphTemporalSignal\n\n\nclass SolarDatasetLoader(object):\n    \"\"\"Hourly energy output of windmills from a European country\n    for more than 2 years. Vertices represent 319 windmills and\n    weighted edges describe the strength of relationships. The target\n    variable allows for regression tasks.\n    \"\"\"\n\n    def __init__(self):\n        self._read_web_data()\n\n    def _read_web_data(self):\n        url = \"https://raw.githubusercontent.com/pinkocto/noteda/main/posts/SOLAR/data/solar.json\"\n        self._dataset = json.loads(urllib.request.urlopen(url).read().decode())\n\n    def _get_edges(self):\n        self._edges = np.array(self._dataset[\"edges\"]).T\n\n    def _get_edge_weights(self):\n        self._edge_weights = np.array(self._dataset[\"weights\"]).T\n\n    def _get_targets_and_features(self):\n        stacked_target = np.stack(self._dataset[\"FX\"])\n        self.features = [\n            stacked_target[i : i + self.lags, :].T\n            for i in range(stacked_target.shape[0] - self.lags)\n        ]\n        self.targets = [\n            stacked_target[i + self.lags, :].T\n            for i in range(stacked_target.shape[0] - self.lags)\n        ]\n\n    def get_dataset(self, lags: int = 4) -> StaticGraphTemporalSignal:\n        \"\"\"Returning the Windmill Output data iterator.\n\n        Args types:\n            * **lags** *(int)* - The number of time lags.\n        Return types:\n            * **dataset** *(StaticGraphTemporalSignal)* - The Windmill Output dataset.\n        \"\"\"\n        self.lags = lags\n        self._get_edges()\n        self._get_edge_weights()\n        self._get_targets_and_features()\n        dataset = StaticGraphTemporalSignal(\n            self._edges, self._edge_weights, self.features, self.targets\n        )\n        return dataset\n\n\nloader = SolarDatasetLoader()\ndataset = loader.get_dataset(lags=4)\ntrain_dataset, test_dataset = temporal_signal_split(dataset, train_ratio=0.8)\n\n\ndataset\n\n<torch_geometric_temporal.signal.static_graph_temporal_signal.StaticGraphTemporalSignal at 0x7f82258d5f40>\n\n\n\nmodel = RecurrentGCN(node_features=4, filters=32)\noptimizer = torch.optim.Adam(model.parameters(), lr=0.01)\nmodel.train()\n\nfor epoch in tqdm(range(50)):\n    for t, snapshot in enumerate(train_dataset):\n        yt_hat = model(snapshot.x, snapshot.edge_index, snapshot.edge_attr)\n        cost = torch.mean((yt_hat-snapshot.y)**2)\n        cost.backward()\n        optimizer.step()\n        optimizer.zero_grad()\n\n\nimport mysolar"
  },
  {
    "objectID": "posts/SOLAR/2023-03-30-restructure-data.html",
    "href": "posts/SOLAR/2023-03-30-restructure-data.html",
    "title": "[R]데이터 재구조화",
    "section": "",
    "text": "library(data.table)\nlibrary(tidyverse)\n\n\nfile_path <- './data/'\nlist.files(file_path)\n\n [1] \"df_arima.csv\"                \"df_new.csv\"                 \n [3] \"df_yU.csv\"                   \"OBS_ASOS_TIM_data0.csv\"     \n [5] \"OBS_ASOS_TIM_data1.csv\"      \"prep_data.csv\"              \n [7] \"prep_test.csv\"               \"raw.csv\"                    \n [9] \"restructuring_prep_data.csv\" \"restructuring_raw.csv\"      \n[11] \"solar_radiation.csv\"         \"solar_radiation2.csv\"       \n[13] \"solar.json\"                  \"solar2.json\"                \n[15] \"test_raw.csv\"                \"weight.csv\"                 \n[17] \"yU_weight.csv\"              \n\n\n\ndf_raw <- fread(file.path(file_path, 'raw.csv'))\nhead(df_raw)\n\n   지점 지점명             일시 일사(MJ/m2)\n1:   93 북춘천 2021-01-01 08:00        0.00\n2:   93 북춘천 2021-01-01 09:00        0.37\n3:   93 북춘천 2021-01-01 10:00        0.96\n4:   93 북춘천 2021-01-01 11:00        1.40\n5:   93 북춘천 2021-01-01 12:00        1.72\n6:   93 북춘천 2021-01-01 13:00        1.84\n\n\n\ndf_raw <- df_raw %>% dcast(일시 + '일사(MJ/m2)' ~ 지점명)\n\nUsing '일사(MJ/m2)' as value column. Use 'value.var' to override\n\ndf_raw %>% head()\n\n               일시 강릉 강진군 경주시 고산 고창 고창군 광양시 광주 김해시\n1: 2021-01-01 08:00 0.01   0.01   0.02 0.00 0.01   0.01   0.01 0.06   0.01\n2: 2021-01-01 09:00 0.37   0.17   0.45 0.05 0.14   0.22   0.25 0.19   0.41\n3: 2021-01-01 10:00 0.97   0.78   0.92 0.15 0.58   0.36   0.86 0.33   1.07\n4: 2021-01-01 11:00 1.48   1.75   1.14 0.15 0.61   0.30   1.31 0.66   1.49\n5: 2021-01-01 12:00 1.76   1.40   1.40 0.28 1.37   0.73   1.52 1.73   1.64\n6: 2021-01-01 13:00 1.92   1.16   1.38 0.17 1.31   1.26   1.13 1.75   1.98\n   대관령 대구 대전 동두천 목포 백령도 보성군 부산 북강릉 북창원 북춘천 상주\n1:   0.00 0.03 0.01     NA 0.01   0.00   0.02 0.03   0.01   0.01   0.00   NA\n2:   0.29 0.45 0.53     NA 0.30   0.13   0.35 0.47   0.35   0.27   0.37   NA\n3:   1.02 1.03 0.80     NA 1.01   0.65   0.88 1.10   0.92   0.92   0.96   NA\n4:   1.61 1.51 0.81     NA 0.96   1.04   1.38 1.62   1.39   1.22   1.40   NA\n5:   1.96 1.75 0.57     NA 1.01   1.71   1.63 1.94   1.71   1.86   1.72   NA\n6:   2.06 1.74 0.62     NA 1.01   1.87   1.31 2.11   1.82   1.99   1.84   NA\n   서산 서울 수원 순창군 안동 양산시 여수 영광군 울릉도 원주 의령군 인천 전주\n1: 0.00 0.00 0.00   0.00 0.01   0.01 0.00   0.00   0.00 0.00   0.03 0.00 0.01\n2: 0.06 0.27 0.18   0.24 0.40   0.27 0.30   0.23   0.24 0.35   0.51 0.15 0.51\n3: 0.18 0.76 0.60   0.45 0.99   1.07 0.97   0.34   0.68 1.15   1.37 0.65 1.19\n4: 0.31 1.40 1.22   0.76 0.96   1.60 1.34   1.00   0.51 1.59   1.69 1.20 1.13\n5: 0.46 1.74 1.69   0.65 1.85   1.91 1.40   1.35   0.47 2.02   2.04 1.48 1.19\n6: 0.36 1.61 1.78   1.70 1.99   2.02 1.98   1.65   0.89 1.91   1.64 1.70 1.28\n   제주 제천 진주 창원 철원 청송군 청주 추풍령 춘천 충주 파주 포항 함양군 홍성\n1: 0.00   NA 0.01 0.00 0.00   0.02 0.00   0.00 0.00   NA   NA 0.02   0.00 0.00\n2: 0.14   NA 0.54 0.29 0.11   0.46 0.27   0.27 0.31   NA   NA 0.38   0.25 0.07\n3: 0.27   NA 1.25 0.87 0.74   1.05 0.85   0.56 0.96   NA   NA 1.03   1.05 0.26\n4: 0.47   NA 1.59 1.41 1.37   1.26 0.75   0.69 1.46   NA   NA 1.53   1.65 0.43\n5: 0.26   NA 1.89 1.73 1.74   1.92 0.96   0.63 1.68   NA   NA 1.81   1.52 0.49\n6: 0.34   NA 1.80 1.83 1.98   1.85 0.87   1.26 1.78   NA   NA 1.86   1.13 0.52\n   흑산도\n1:   0.02\n2:   0.15\n3:   0.61\n4:   0.56\n5:   0.57\n6:   0.48\n\n\n\nwrite.csv(df_raw, './data/restructuring_raw.csv', row.names = FALSE)"
  },
  {
    "objectID": "posts/SOLAR/2023-04-06-stgcn-data-ver1.html",
    "href": "posts/SOLAR/2023-04-06-stgcn-data-ver1.html",
    "title": "[SOLAR] Dataset for STGCN Ver1",
    "section": "",
    "text": "# !pip install torch-geometric\n# !pip install torch-geometric-temporal\n\n\n\n\n- 필요한 패키지 임포트\n\nimport pandas as pd\nimport numpy as np\nimport json\nimport urllib\n\n\n# 일반적인 모듈 \nimport numpy as np\nimport matplotlib.pyplot as plt \nimport networkx as nx \nfrom tqdm import tqdm \n\n# 파이토치 관련 \nimport torch\nimport torch.nn.functional as F\n\n# PyG 관련 \nfrom torch_geometric.data import Data\n\n# STGCN 관련 \nimport torch_geometric_temporal\nfrom torch_geometric_temporal.nn.recurrent import GConvGRU\nfrom torch_geometric_temporal.signal import temporal_signal_split \n\n\ntqdm: for문의 진행상태를 확인하기 위한 패키지\nnetworkx: 그래프 시그널 시각화를 위한 모듈\ntorch : 파이토치 (STGCN은 파이토치 기반으로 만들어짐) 모듈\ntorch.nn.functional: relu 등의 활성화함수를 불러오기 위한 모듈\nData : 그래프 자료를 만들기 위한 클래스\nGConvGRU : STGCN layer를 만드는 클래스\ntemporal_signal_split : STGCN dataset을 train/test 형태로 분리하는 기능이 있는 “함수”\n\n- STGCN 학습을 위한 클래스 선언\n\nclass RecurrentGCN(torch.nn.Module):\n    def __init__(self, node_features, filters):\n        super(RecurrentGCN, self).__init__()\n        self.recurrent = GConvGRU(node_features, filters, 2)\n        self.linear = torch.nn.Linear(filters, 1)\n\n    def forward(self, x, edge_index, edge_weight):\n        h = self.recurrent(x, edge_index, edge_weight)\n        h = F.relu(h)\n        h = self.linear(h)\n        return h\n\n\n\n\n\nimport pandas as pd\nimport numpy as np\n\n\n\n\nurl = 'https://raw.githubusercontent.com/pinkocto/noteda/main/posts/SOLAR/data/df_new.csv'\ndf = pd.read_csv(url)\n\n\nurl2 = 'https://raw.githubusercontent.com/pinkocto/noteda/main/posts/SOLAR/data/weight.csv'\ndf2 = pd.read_csv(url2)\n\n\ndf = df.iloc[:,1:]\n\n\nnode_list =(df.columns).tolist()\nnode_ids = {node : i for i, node in enumerate(node_list)}\nnode_ids\n\n{'북춘천': 0,\n '철원': 1,\n '대관령': 2,\n '춘천': 3,\n '백령도': 4,\n '북강릉': 5,\n '강릉': 6,\n '서울': 7,\n '인천': 8,\n '원주': 9,\n '울릉도': 10,\n '수원': 11,\n '서산': 12,\n '청주': 13,\n '대전': 14,\n '추풍령': 15,\n '안동': 16,\n '포항': 17,\n '대구': 18,\n '전주': 19,\n '창원': 20,\n '광주': 21,\n '부산': 22,\n '목포': 23,\n '여수': 24,\n '흑산도': 25,\n '고창': 26,\n '홍성': 27,\n '제주': 28,\n '고산': 29,\n '진주': 30,\n '고창군': 31,\n '영광군': 32,\n '김해시': 33,\n '순창군': 34,\n '북창원': 35,\n '양산시': 36,\n '보성군': 37,\n '강진군': 38,\n '의령군': 39,\n '함양군': 40,\n '광양시': 41,\n '청송군': 42,\n '경주시': 43}\n\n\n\nedges = []    \n \nfor i in range(44):\n    for j in range(44):\n        if i != j:\n            edges.append([i,j]) \n# print(edges)\n\n\nnp.array(edges).shape\n\n(1892, 2)\n\n\n\n# from itertools import permutations\n# list(permutations(list(node_ids.values()), 2))\n\n\nlen(df['date']) # time\n\n18250\n\n\n\ndf2\n\n\n\n\n\n  \n    \n      \n      북춘천\n      철원\n      대관령\n      춘천\n      백령도\n      북강릉\n      강릉\n      서울\n      인천\n      원주\n      ...\n      순창군\n      북창원\n      양산시\n      보성군\n      강진군\n      의령군\n      함양군\n      광양시\n      청송군\n      경주시\n    \n  \n  \n    \n      0\n      1.000000\n      0.962367\n      0.909826\n      0.985657\n      0.871681\n      0.900659\n      0.890927\n      0.943081\n      0.936899\n      0.944473\n      ...\n      0.879136\n      0.853483\n      0.858169\n      0.863974\n      0.859685\n      0.866783\n      0.875598\n      0.865172\n      0.883101\n      0.848641\n    \n    \n      1\n      0.962367\n      1.000000\n      0.890696\n      0.960057\n      0.886264\n      0.884161\n      0.874764\n      0.945527\n      0.941293\n      0.930826\n      ...\n      0.868607\n      0.841086\n      0.846036\n      0.855756\n      0.855439\n      0.851310\n      0.863689\n      0.854172\n      0.866795\n      0.834444\n    \n    \n      2\n      0.909826\n      0.890696\n      1.000000\n      0.905515\n      0.819283\n      0.953088\n      0.947341\n      0.884961\n      0.882525\n      0.921151\n      ...\n      0.877524\n      0.872609\n      0.877105\n      0.868256\n      0.857598\n      0.879016\n      0.890071\n      0.870398\n      0.916970\n      0.888561\n    \n    \n      3\n      0.985657\n      0.960057\n      0.905515\n      1.000000\n      0.874211\n      0.898639\n      0.888139\n      0.943508\n      0.938434\n      0.942972\n      ...\n      0.880940\n      0.852272\n      0.857021\n      0.864633\n      0.860694\n      0.866294\n      0.875104\n      0.864782\n      0.882340\n      0.846321\n    \n    \n      4\n      0.871681\n      0.886264\n      0.819283\n      0.874211\n      1.000000\n      0.820746\n      0.813769\n      0.875487\n      0.898814\n      0.841837\n      ...\n      0.832971\n      0.803220\n      0.803683\n      0.828390\n      0.830200\n      0.816005\n      0.825798\n      0.824297\n      0.805963\n      0.786086\n    \n    \n      5\n      0.900659\n      0.884161\n      0.953088\n      0.898639\n      0.820746\n      1.000000\n      0.977052\n      0.876560\n      0.878769\n      0.908658\n      ...\n      0.874547\n      0.870073\n      0.873436\n      0.867076\n      0.856008\n      0.878188\n      0.880953\n      0.865367\n      0.907306\n      0.886590\n    \n    \n      6\n      0.890927\n      0.874764\n      0.947341\n      0.888139\n      0.813769\n      0.977052\n      1.000000\n      0.867627\n      0.869775\n      0.900690\n      ...\n      0.867068\n      0.863608\n      0.865448\n      0.861310\n      0.848392\n      0.871227\n      0.874620\n      0.858868\n      0.900920\n      0.877792\n    \n    \n      7\n      0.943081\n      0.945527\n      0.884961\n      0.943508\n      0.875487\n      0.876560\n      0.867627\n      1.000000\n      0.959453\n      0.934546\n      ...\n      0.876382\n      0.847805\n      0.847221\n      0.857383\n      0.858097\n      0.855020\n      0.865729\n      0.858174\n      0.867781\n      0.834465\n    \n    \n      8\n      0.936899\n      0.941293\n      0.882525\n      0.938434\n      0.898814\n      0.878769\n      0.869775\n      0.959453\n      1.000000\n      0.923601\n      ...\n      0.884033\n      0.854269\n      0.855463\n      0.874037\n      0.870921\n      0.867257\n      0.878578\n      0.870185\n      0.870756\n      0.843745\n    \n    \n      9\n      0.944473\n      0.930826\n      0.921151\n      0.942972\n      0.841837\n      0.908658\n      0.900690\n      0.934546\n      0.923601\n      1.000000\n      ...\n      0.898942\n      0.869611\n      0.872624\n      0.879347\n      0.874973\n      0.881663\n      0.893500\n      0.878524\n      0.905335\n      0.867475\n    \n    \n      10\n      0.840858\n      0.828910\n      0.858557\n      0.839147\n      0.772705\n      0.858164\n      0.848237\n      0.820593\n      0.827016\n      0.853274\n      ...\n      0.855951\n      0.863562\n      0.868133\n      0.847283\n      0.844231\n      0.863605\n      0.863168\n      0.850365\n      0.877260\n      0.870557\n    \n    \n      11\n      0.942564\n      0.939509\n      0.899435\n      0.943069\n      0.877389\n      0.892617\n      0.884630\n      0.963842\n      0.961417\n      0.946715\n      ...\n      0.897278\n      0.867285\n      0.867173\n      0.881624\n      0.880449\n      0.878150\n      0.889694\n      0.880142\n      0.886229\n      0.857732\n    \n    \n      12\n      0.922022\n      0.918923\n      0.888105\n      0.920695\n      0.882590\n      0.882694\n      0.875230\n      0.934192\n      0.947237\n      0.929486\n      ...\n      0.904372\n      0.868625\n      0.869256\n      0.888346\n      0.887653\n      0.880501\n      0.894877\n      0.885542\n      0.884844\n      0.857819\n    \n    \n      13\n      0.918237\n      0.905049\n      0.903431\n      0.917908\n      0.841079\n      0.896871\n      0.889428\n      0.918926\n      0.915476\n      0.944410\n      ...\n      0.924922\n      0.888684\n      0.888824\n      0.901216\n      0.899662\n      0.899361\n      0.915481\n      0.901138\n      0.911815\n      0.883347\n    \n    \n      14\n      0.898490\n      0.882652\n      0.891051\n      0.898174\n      0.827093\n      0.885413\n      0.878953\n      0.898554\n      0.898516\n      0.923292\n      ...\n      0.928719\n      0.892984\n      0.891581\n      0.906600\n      0.903907\n      0.905388\n      0.922893\n      0.904764\n      0.910243\n      0.883703\n    \n    \n      15\n      0.890061\n      0.876204\n      0.905452\n      0.890275\n      0.821154\n      0.900803\n      0.894228\n      0.880907\n      0.886372\n      0.915091\n      ...\n      0.937737\n      0.923287\n      0.922863\n      0.924852\n      0.917048\n      0.932314\n      0.949379\n      0.924473\n      0.945999\n      0.924620\n    \n    \n      16\n      0.903591\n      0.885217\n      0.918386\n      0.903755\n      0.825018\n      0.913419\n      0.906546\n      0.888718\n      0.890977\n      0.927298\n      ...\n      0.927022\n      0.922465\n      0.922966\n      0.917738\n      0.907627\n      0.928637\n      0.937947\n      0.919161\n      0.961391\n      0.929294\n    \n    \n      17\n      0.854662\n      0.838961\n      0.891356\n      0.854821\n      0.790609\n      0.891884\n      0.883858\n      0.840800\n      0.848850\n      0.872914\n      ...\n      0.897734\n      0.932551\n      0.937701\n      0.902187\n      0.887587\n      0.933228\n      0.921925\n      0.908669\n      0.945649\n      0.962429\n    \n    \n      18\n      0.880498\n      0.866139\n      0.900774\n      0.878750\n      0.821373\n      0.897400\n      0.888819\n      0.867965\n      0.874107\n      0.897911\n      ...\n      0.931290\n      0.947698\n      0.947900\n      0.932557\n      0.920683\n      0.955571\n      0.952851\n      0.935928\n      0.952312\n      0.952993\n    \n    \n      19\n      0.888314\n      0.877357\n      0.884532\n      0.887202\n      0.827562\n      0.880492\n      0.873037\n      0.889405\n      0.891161\n      0.916652\n      ...\n      0.950610\n      0.909561\n      0.907084\n      0.927081\n      0.927649\n      0.919504\n      0.938138\n      0.922211\n      0.915050\n      0.894398\n    \n    \n      20\n      0.860796\n      0.847790\n      0.874407\n      0.860170\n      0.808751\n      0.871520\n      0.863835\n      0.848297\n      0.862158\n      0.874510\n      ...\n      0.923953\n      0.976902\n      0.963444\n      0.944555\n      0.928480\n      0.968391\n      0.940725\n      0.952405\n      0.926913\n      0.939050\n    \n    \n      21\n      0.859424\n      0.852501\n      0.859687\n      0.860333\n      0.812785\n      0.856745\n      0.848790\n      0.861303\n      0.867384\n      0.881025\n      ...\n      0.954238\n      0.911049\n      0.904662\n      0.937906\n      0.939738\n      0.917915\n      0.928268\n      0.925915\n      0.901910\n      0.889684\n    \n    \n      22\n      0.854479\n      0.841909\n      0.871403\n      0.853623\n      0.801025\n      0.866994\n      0.858023\n      0.843441\n      0.853838\n      0.867562\n      ...\n      0.912998\n      0.960070\n      0.965982\n      0.933570\n      0.918842\n      0.950573\n      0.929205\n      0.939658\n      0.922093\n      0.936774\n    \n    \n      23\n      0.866337\n      0.861476\n      0.860613\n      0.867357\n      0.838917\n      0.858313\n      0.852067\n      0.864243\n      0.881786\n      0.880383\n      ...\n      0.943748\n      0.909687\n      0.905455\n      0.948874\n      0.957647\n      0.922845\n      0.925556\n      0.932798\n      0.896801\n      0.887664\n    \n    \n      24\n      0.857004\n      0.845811\n      0.865706\n      0.856728\n      0.817327\n      0.859749\n      0.854646\n      0.849073\n      0.863520\n      0.868992\n      ...\n      0.928136\n      0.944200\n      0.937155\n      0.962198\n      0.943037\n      0.953180\n      0.936996\n      0.965857\n      0.909258\n      0.909195\n    \n    \n      25\n      0.822826\n      0.822140\n      0.808481\n      0.826616\n      0.825401\n      0.811498\n      0.806484\n      0.821710\n      0.844909\n      0.830411\n      ...\n      0.883103\n      0.856841\n      0.857407\n      0.892598\n      0.898532\n      0.869034\n      0.872795\n      0.879107\n      0.839579\n      0.837283\n    \n    \n      26\n      0.879083\n      0.871026\n      0.865649\n      0.880956\n      0.835276\n      0.862511\n      0.855801\n      0.878337\n      0.889100\n      0.895420\n      ...\n      0.954230\n      0.906902\n      0.904828\n      0.934975\n      0.938474\n      0.917802\n      0.929699\n      0.923018\n      0.904717\n      0.886433\n    \n    \n      27\n      0.917044\n      0.909108\n      0.893061\n      0.918305\n      0.867335\n      0.889219\n      0.882249\n      0.926047\n      0.933830\n      0.929793\n      ...\n      0.914529\n      0.879062\n      0.880205\n      0.898748\n      0.897861\n      0.891294\n      0.905806\n      0.894126\n      0.895564\n      0.868894\n    \n    \n      28\n      0.797674\n      0.794452\n      0.808165\n      0.800473\n      0.787829\n      0.804120\n      0.800353\n      0.784880\n      0.805165\n      0.810297\n      ...\n      0.870303\n      0.870241\n      0.867300\n      0.892300\n      0.895220\n      0.874571\n      0.872941\n      0.878597\n      0.847435\n      0.853887\n    \n    \n      29\n      0.823267\n      0.821438\n      0.818549\n      0.826090\n      0.810675\n      0.812992\n      0.808599\n      0.817868\n      0.834785\n      0.832173\n      ...\n      0.884424\n      0.875923\n      0.872508\n      0.903510\n      0.907588\n      0.883369\n      0.878469\n      0.894774\n      0.853910\n      0.852406\n    \n    \n      30\n      0.860523\n      0.846942\n      0.877411\n      0.860094\n      0.817874\n      0.873037\n      0.866739\n      0.852371\n      0.865589\n      0.875812\n      ...\n      0.931571\n      0.959000\n      0.946352\n      0.952391\n      0.934954\n      0.971752\n      0.948990\n      0.961034\n      0.923896\n      0.932067\n    \n    \n      31\n      0.874779\n      0.865850\n      0.869024\n      0.874188\n      0.827848\n      0.864613\n      0.856987\n      0.874556\n      0.881425\n      0.894472\n      ...\n      0.956347\n      0.906210\n      0.903358\n      0.932322\n      0.935929\n      0.914995\n      0.929255\n      0.921594\n      0.904133\n      0.886793\n    \n    \n      32\n      0.872162\n      0.865352\n      0.862066\n      0.872958\n      0.836837\n      0.861242\n      0.854149\n      0.872677\n      0.886370\n      0.888694\n      ...\n      0.948914\n      0.903590\n      0.901627\n      0.933660\n      0.938028\n      0.915348\n      0.925572\n      0.921830\n      0.898344\n      0.882798\n    \n    \n      33\n      0.853448\n      0.840876\n      0.873050\n      0.851683\n      0.802507\n      0.869221\n      0.861291\n      0.846127\n      0.853925\n      0.868877\n      ...\n      0.914507\n      0.973683\n      0.973881\n      0.932867\n      0.917226\n      0.956417\n      0.933244\n      0.941004\n      0.926691\n      0.944078\n    \n    \n      34\n      0.879136\n      0.868607\n      0.877524\n      0.880940\n      0.832971\n      0.874547\n      0.867068\n      0.876382\n      0.884033\n      0.898942\n      ...\n      1.000000\n      0.918745\n      0.916958\n      0.945765\n      0.946780\n      0.932585\n      0.949482\n      0.938813\n      0.917386\n      0.898405\n    \n    \n      35\n      0.853483\n      0.841086\n      0.872609\n      0.852272\n      0.803220\n      0.870073\n      0.863608\n      0.847805\n      0.854269\n      0.869611\n      ...\n      0.918745\n      1.000000\n      0.965300\n      0.937217\n      0.921424\n      0.962523\n      0.938369\n      0.945592\n      0.927509\n      0.944296\n    \n    \n      36\n      0.858169\n      0.846036\n      0.877105\n      0.857021\n      0.803683\n      0.873436\n      0.865448\n      0.847221\n      0.855463\n      0.872624\n      ...\n      0.916958\n      0.965300\n      1.000000\n      0.929792\n      0.915165\n      0.953589\n      0.934088\n      0.937319\n      0.928486\n      0.945121\n    \n    \n      37\n      0.863974\n      0.855756\n      0.868256\n      0.864633\n      0.828390\n      0.867076\n      0.861310\n      0.857383\n      0.874037\n      0.879347\n      ...\n      0.945765\n      0.937217\n      0.929792\n      1.000000\n      0.968149\n      0.948806\n      0.944262\n      0.964120\n      0.911247\n      0.908184\n    \n    \n      38\n      0.859685\n      0.855439\n      0.857598\n      0.860694\n      0.830200\n      0.856008\n      0.848392\n      0.858097\n      0.870921\n      0.874973\n      ...\n      0.946780\n      0.921424\n      0.915165\n      0.968149\n      1.000000\n      0.931533\n      0.932621\n      0.947967\n      0.902115\n      0.892997\n    \n    \n      39\n      0.866783\n      0.851310\n      0.879016\n      0.866294\n      0.816005\n      0.878188\n      0.871227\n      0.855020\n      0.867257\n      0.881663\n      ...\n      0.932585\n      0.962523\n      0.953589\n      0.948806\n      0.931533\n      1.000000\n      0.952391\n      0.955940\n      0.930412\n      0.940236\n    \n    \n      40\n      0.875598\n      0.863689\n      0.890071\n      0.875104\n      0.825798\n      0.880953\n      0.874620\n      0.865729\n      0.878578\n      0.893500\n      ...\n      0.949482\n      0.938369\n      0.934088\n      0.944262\n      0.932621\n      0.952391\n      1.000000\n      0.942140\n      0.934759\n      0.927935\n    \n    \n      41\n      0.865172\n      0.854172\n      0.870398\n      0.864782\n      0.824297\n      0.865367\n      0.858868\n      0.858174\n      0.870185\n      0.878524\n      ...\n      0.938813\n      0.945592\n      0.937319\n      0.964120\n      0.947967\n      0.955940\n      0.942140\n      1.000000\n      0.915408\n      0.914159\n    \n    \n      42\n      0.883101\n      0.866795\n      0.916970\n      0.882340\n      0.805963\n      0.907306\n      0.900920\n      0.867781\n      0.870756\n      0.905335\n      ...\n      0.917386\n      0.927509\n      0.928486\n      0.911247\n      0.902115\n      0.930412\n      0.934759\n      0.915408\n      1.000000\n      0.943917\n    \n    \n      43\n      0.848641\n      0.834444\n      0.888561\n      0.846321\n      0.786086\n      0.886590\n      0.877792\n      0.834465\n      0.843745\n      0.867475\n      ...\n      0.898405\n      0.944296\n      0.945121\n      0.908184\n      0.892997\n      0.940236\n      0.927935\n      0.914159\n      0.943917\n      1.000000\n    \n  \n\n44 rows × 44 columns\n\n\n\n\nweights = []    \n \nfor i in range(44):\n    for j in range(44):\n        if i != j:\n            weights.append(df2.iloc[i,j]) \n\n\nnp.array(weights).shape\n\n(1892,)\n\n\n\nFX = []    \nfor i in range(18250):\n    FX.append(list(df.iloc[i,:])) \n#FX\n\n\nnp.array(FX).shape\n\n(18250, 44)\n\n\n- weights, edges, node_ids, FX\n\ndata_dict = {'edges':edges, 'node_ids':node_ids, 'weights':weights, 'FX':FX}\n\n\ndata_dict.keys()\n\ndict_keys(['edges', 'node_ids', 'weights', 'FX'])\n\n\n\nfile_path = './data/solar.json'\n\n\nwith open(file_path, 'w') as f:\n    json.dump(data_dict, f)\n\n\nwith open(file_path, 'r') as f:\n    test = json.load(f, encoding='cp949')\n\n\n# json_data = json.dumps(data_dict, ensure_ascii=False)\n# json_data\n\n\n\\({\\bf f}=\\begin{bmatrix} {\\bf f}_1\\\\ {\\bf f}_2\\\\ \\dots \\\\ {\\bf f}_{521} \\end{bmatrix}=\\begin{bmatrix} f(t=1,v=\\tt{BACS}) & \\dots & f(t=1,v=\\tt{ZALA}) \\\\ f(t=2,v=\\tt{BACS}) & \\dots & f(t=2,v=\\tt{ZALA}) \\\\ \\dots & \\dots & \\dots \\\\ f(t=521,v=\\tt{BACS}) & \\dots & f(t=521,v=\\tt{ZALA}) \\end{bmatrix}\\)"
  },
  {
    "objectID": "posts/SOLAR/2023-04-09-ft.html",
    "href": "posts/SOLAR/2023-04-09-ft.html",
    "title": "푸리에 변환",
    "section": "",
    "text": "ref: 파이썬으로 배우는 음성인식\nref: 퓨리에변환 교수님 버전\nref: wiki"
  },
  {
    "objectID": "posts/SOLAR/2023-04-09-ft.html#위키버전",
    "href": "posts/SOLAR/2023-04-09-ft.html#위키버전",
    "title": "푸리에 변환",
    "section": "위키버전",
    "text": "위키버전\n푸리에 변환(Fourier transform, FT) 은 시간이나 공간에 대한 함수를 시간 또는 공간 주파수 성분으로 분해하는 변환을 말한다. 종종 이 변환으로 나타난 주파수 영역에서 함수를 표현한 결과물을 가리키는 용어로도 사용된다. 조제프 푸리에가 열전도에 대한 연구에서 열 방정식의 해를 구할 때 처음 사용되었다.\n시간에 대한 함수를 푸리에 변환했을 때 얻어지는 복소함수에서 각 주파수에서의 진폭은 원래 함수를 구성하던 그 주파수 성분의 크기를, 편각은 기본 사인 곡선과의 위상차(phase offset)를 나타낸다. 푸리에 변환된 결과물로부터 피변환함수를 복원할 수도 있다. 이를 증명하는 정리를 푸리에 역변환 정리 라고 한다.\n시간 영역에서는 좁은 지역에서 표현되는 함수를 주파수 영역으로 푸리에 변환하면 함수가 넓게 퍼지게 된다. 이를 불확정성 원리라 한다. 그러나 가우스 함수는 푸리에 변환을 해도 똑같이 가우스 함수로 나타난다. 이 가우스 함수는 확률 이론과 통계학에서 뿐만 아니라 정규 분포를 나타내는 물리 현상에 대한 연구에서 매우 중요하게 다뤄진다. 조제프 푸리에가 푸리에 변환을 통해 구한 열 방정식의 해가 바로 가우스 함수의 꼴을 띄었다.\n엄밀히 말하자면 푸리에 변환은 일종의 적분 변환 으로, 리만 이상적분이어서 더 복잡한 적분 이론을 요구하는 응용분야에서는 적합하지 않을 수 있다. 대표적으로 많은 경우 디랙 델타 함수를 일종의 함수로 푸리에 변환에 응용하지만, 수학적으로 엄밀한 관점을 취하자면 더 심도있는 고찰이 필요한 것이다."
  },
  {
    "objectID": "posts/SOLAR/2023-04-09-ft.html#주파수-영역",
    "href": "posts/SOLAR/2023-04-09-ft.html#주파수-영역",
    "title": "푸리에 변환",
    "section": "주파수 영역",
    "text": "주파수 영역\n\n\n\nimage.png\n\n\n\nfrom IPython.display import IFrame\nIFrame(\"https://upload.wikimedia.org/wikipedia/commons/7/72/Fourier_transform_time_and_frequency_domains_%28small%29.gif\", width=\"300\" ,height = \"240\",frameborder=\"0\")"
  },
  {
    "objectID": "posts/SOLAR/2023-04-09-ft.html#푸리에-변환의-단점",
    "href": "posts/SOLAR/2023-04-09-ft.html#푸리에-변환의-단점",
    "title": "푸리에 변환",
    "section": "푸리에 변환의 단점",
    "text": "푸리에 변환의 단점\n시간에 대한 연속성이 고려되지 않음으로써 많은 문제가 야기된다. 이러한 단점을 보완하기 위해 DTFT, STFT, 웨이블릿 변환, 가버변환, MFCCs 등등이 연구되어 나왔다.\n\n와닿지가 않아.. 웨이블릿 변환? 가버변환?"
  },
  {
    "objectID": "posts/SOLAR/2023-04-09-ft.html#예비학습-모델링이란",
    "href": "posts/SOLAR/2023-04-09-ft.html#예비학습-모델링이란",
    "title": "푸리에 변환",
    "section": "예비학습: 모델링이란?",
    "text": "예비학습: 모델링이란?\n- 모델링이란?\n\\[y_i = f(x_i) + \\epsilon_i\\]\n의 꼴에서 \\(f\\)의 모양을 결정하는 과정을 의미한다.\n- 파라메트릭 모델링\n\\(f\\)의 모양을 결정할 때 데이터에 대한 확실한 사전정보가 있는 경우가 있다. 예를들어 “\\(f(x)\\)는 \\(x\\)에 선형변환으로 만들어질 수 있다. (즉, \\(f(x) = \\beta_0 + \\beta_1x\\))”라는 사실을 알고 있는 경우이다. 이는\n\\[y_i = f(x_i) + \\epsilon_i\\]\n와 같은 모델에서 \\(f\\)가 어떠한 형태를 가질것인지를 미리 알고있다고 생각한다는 말과 같다. 이처럼 \\(f\\)가 어떤 모양인지 미리 알고 접근하는 방법을 파라메트릭 모델링 이라고 한다.\n- 세미파라메트릭 모델링\n사전정보가 없어서 \\(f\\)를 어떻게 모델링할지 감이 안 올수도 있다. 즉 자료를 봤는데 선형의 모양을 가지는지 어떤지 감을 못잡겠는 경우이다. 이것을 바꾸어 말하면 \\(\\{ y_i\\}\\)가 \\(\\{x_i\\}\\)의 어떤 space에 있는지 감을 못잡겠다는 뜻이다. 혹은 모델링이 귀찮을 수도 있다. 이럴 경우 \\(f(x)\\)가 \\(x\\)의 어떤 특정스페이스 \\(\\cal{A}\\)의 부분공간에 존재한다고 가정하고 그 특정 스페이스 \\(\\cal{A}\\)를 생성할 수 있는 베이시스를 선택하여 문제를 풀 수 있다. 가령 예를들면 “\\(f(x)\\)가 어떤 공간에 있는지 모르겠는데 최소한 비숍스페이스의 부분공간에 있는 것 같아”라고 생각한다면 웨이블릿 베이시스를 선택하여 모델링 하는 것이다. 보통 위와 같은 접근법은 무한대의 basis를 활용한다. 많은 수학자들이 “이런식으로 무한개의 basis를 활용하면 특정공간에 있는 어떠한 함수도 표현할 수 있어요~” 이런식의 증명을 많이 해놓았는데 이런 증명결과들을 적극적으로 활용하는 셈이다. 이렇게 \\(f\\)를 표현하는게 무한개의 basis를 활용하는 모델링을 semi-parametric modeling 이라고 한다.\n- 웨이블릿과 푸리에변동으로 \\(f(x)\\)를 추론하는 것이 대표적인 세미파라메트릭 모델링이다."
  },
  {
    "objectID": "posts/SOLAR/2023-04-09-ft.html#import",
    "href": "posts/SOLAR/2023-04-09-ft.html#import",
    "title": "푸리에 변환",
    "section": "import",
    "text": "import\n\nimport numpy as np\nimport matplotlib.pyplot as plt \nimport rpy2\n%load_ext rpy2.ipython"
  },
  {
    "objectID": "posts/SOLAR/2023-04-09-ft.html#예제신호-소개",
    "href": "posts/SOLAR/2023-04-09-ft.html#예제신호-소개",
    "title": "푸리에 변환",
    "section": "예제신호 소개",
    "text": "예제신호 소개\n- 아래와 같은 신호를 고려하자.\n\nn=100\nt=np.linspace(0,0.99,n)\nf_true =3+ 1.5*np.sin(2*np.pi*t)+2*np.sin(10*np.pi*t)\nϵ=np.random.normal(scale=0.2,size=n)\nf = f_true + ϵ\nplt.plot(t,f,'.')\nplt.plot(t,f_true)\n\n\n\n\n\n목표 : 파란점을 관찰 \\(\\to\\) 주황선을 추론\n\n- 수식화하면 아래와 같다.\n\\[f_i = 3 + 1.5\\times \\sin(2\\pi t_i) + 2\\times \\sin(10\\pi t_i) + \\epsilon_i, \\quad t_i = \\frac{i}{100}\\]\n회귀분석 느낌으로 표현하면 아래와 같이 표현가능하다.\n\\[y_i = \\beta_0 + \\beta_1x_{i1} + \\beta_2x_{i2} + \\epsilon_i\\]\n단, \\(x_{i1} = \\sin(2\\pi t_i)\\)이고 \\(x_{i2} = \\sin(10\\pi t_i).\\)\n우리의 목표는 이제 아래와 같이 정리할 수 있다.\n\n주어진 것: \\((y_i, x_{i1}, x_{i2})\\)\n목표: \\(\\beta_0, \\beta_1, \\beta_2\\)를 추론"
  },
  {
    "objectID": "posts/SOLAR/2023-04-09-ft.html#방법1-회귀분석",
    "href": "posts/SOLAR/2023-04-09-ft.html#방법1-회귀분석",
    "title": "푸리에 변환",
    "section": "방법1: 회귀분석",
    "text": "방법1: 회귀분석\n- x1, x2, y를 아래와 같이 col-vector로 선언\n\n# t=np.linspace(0,0.99,n)\nx1 = np.sin(2*np.pi*t)\nx2 = np.sin(10*np.pi*t)\n\n\\(\\bf{X} = [1, x1, x2]\\) 라고 생각하고 회귀분석을 수행한다.\n\n# n=100\n# f = f_true + ϵ\nX=np.ones((n,3))\nX[:,1] = x1\nX[:,2] = x2\nX = np.matrix(X)\ny = np.matrix(f).T # y는 col-vec로 선언\nβhat = (X.T*X).I*X.T*y\nβhat\n\nmatrix([[3.00673254],\n        [1.47090366],\n        [2.06163848]])\n\n\n- R을 이용해서 구해볼 수도 있음.\n\n%R -i f,x1,x2\n\n\n%%R \nlm(f~x1+x2)\n\n\nCall:\nlm(formula = f ~ x1 + x2)\n\nCoefficients:\n(Intercept)           x1           x2  \n      3.007        1.471        2.062"
  },
  {
    "objectID": "posts/SOLAR/2023-04-09-ft.html#방법2",
    "href": "posts/SOLAR/2023-04-09-ft.html#방법2",
    "title": "푸리에 변환",
    "section": "방법2",
    "text": "방법2\nx1, x2을 모른다면? 우리가 \\(f=y\\) 만을 알고있다면?\n그러니까 \\(x_{i1}=\\sin(2\\pi t_i)\\)이고 \\(x_{i2} = \\sin(10\\pi t_i)\\) 인지 모른다면? (구체적으로 2와 10과 같은 숫자를 모른다면? = 주파수를 모른다면?)\n잘은 모르겠지만 아래의 베이시스중에 하나는 걸릴 것 같다.\n\nx1=np.sin(2*np.pi*t)\nx2=np.sin(4*np.pi*t)\nx3=np.sin(6*np.pi*t)\nx4=np.sin(8*np.pi*t)\nx5=np.sin(10*np.pi*t)\n\n\nX=np.ones((n,6))\nX[:,1]=x1\nX[:,2]=x2\nX[:,3]=x3\nX[:,4]=x4\nX[:,5]=x5\nX=np.matrix(X)\nβhat= (X.T*X).I*X.T*y\nβhat\n\nmatrix([[ 3.00673254e+00],\n        [ 1.47090366e+00],\n        [-2.51527234e-02],\n        [-8.29437604e-04],\n        [ 5.00178446e-02],\n        [ 2.06163848e+00]])\n\n\n그럴듯함\n적합해보자..\n\nplt.plot(f, '.')\nplt.plot(X*βhat)\n\n\n\n\n비판1: 베이시스를 막 추가했는데 (\\(=p\\)가 늘어났는데) 오버피팅이 생기는것이 아닌가? \\(\\to\\) 절대안생김\n비판2: 저 베이시스중에서 안걸리면 어떻게 할것임? \\(\\to\\) 무한대의 베이시스를 쓰겠음 \\(\\Rightarrow\\) 이게 퓨리에 변환\n\nx1=np.sin(2*np.pi*t)\nx2=np.cos(2*np.pi*t)\nx3=np.sin(4*np.pi*t)\nx4=np.cos(4*np.pi*t)\nx5=np.sin(6*np.pi*t)\nx6=np.cos(6*np.pi*t)\nx7=np.sin(8*np.pi*t)\nx8=np.cos(8*np.pi*t)\n... \n# 수틀리면 베이시스 더 쓸수도 있다 --> 무한대까지 쓸 수 있지만 무한대까지 쓸 필요는 없음.. (나아퀴스트 정리)\n\nEllipsis"
  },
  {
    "objectID": "posts/SOLAR/2023-04-09-ft.html#방법3-퓨리에-변환",
    "href": "posts/SOLAR/2023-04-09-ft.html#방법3-퓨리에-변환",
    "title": "푸리에 변환",
    "section": "방법3: 퓨리에 변환",
    "text": "방법3: 퓨리에 변환\n- 퓨리에 변환 결과\n\nfbar = np.abs(np.fft.fft(f))/100\nplt.plot(fbar,'.')\n\n\n\n\n- 세부적인 이론이 있지만 실수인 경우는 fbar는 아래의 특징을 가짐\n\nfbar[0]을 제외하고 나머지는 대칭임.\n\n- 따라서 그림을 아래와 같이 그려도 정보손실없음\n\nfbar2=np.zeros(50)\nfbar2[0] = fbar[0] \nfbar2[1:50] = 2*fbar[1:50]\nplt.plot(fbar2,'.')\n\n\n\n\n대충보면 인덱스 10이전까지의 값만 살펴보면 될것 같도 나머지는 \\(0\\) 근처임\n\nfbar2[[0,1,5]]\n\narray([3.00673254, 1.47117598, 2.06163854])\n\n\n이것은 각각 1, x1, x2에 대한 베이시스임을 알 수 있다.\n- 퓨리에 변환요약: 아무런 생각없이 무한대의 베이시스를 넣고 계수값을 구하면 잘 적합된다.\n- 퓨리에의 통찰: 어지간한 함수는 저주파부터 고주파의 cos함수 (혹은 sin함수)에 적당한 계수를 곱한뒤 합치면 표현가능하다."
  },
  {
    "objectID": "posts/SOLAR/2023-04-09-ft.html#pca",
    "href": "posts/SOLAR/2023-04-09-ft.html#pca",
    "title": "푸리에 변환",
    "section": "PCA",
    "text": "PCA\n- 생각해보니까 베이시스를 무한대로 넣는것이 매우 통쾌해보임\n- 종종 \\(p\\)가 너무 커서 곤란한 상황이 많음. \\(\\to\\) 공부해야할 것도 많음.\n\n다중공선성\n오버피팅\n변수선택\n\\(\\dots\\)\n\n- 베이시스가 직교였더라면.. \\(\\to\\) 기존 베이시스를 변환하여 직교 베이시스로 만들자!\n- 기존 베이시스를 변환하여 직교 베이시스로 만드는 방법: Eigen-value decomposition, SVD"
  },
  {
    "objectID": "posts/SOLAR/2023-04-27-s-stgcn-ver1-50에폭-64필터.html",
    "href": "posts/SOLAR/2023-04-27-s-stgcn-ver1-50에폭-64필터.html",
    "title": "[SOLAR] STGCN Ver1 (data2, -N +S) 30회 50epoch 64filter",
    "section": "",
    "text": "https://github.com/miruetoto/yechan3/tree/main/posts/3_Researches/ITSTGCN/itstgcn\nhttps://miruetoto.github.io/yechan3/posts/3_Researches/ITSTGCN/2023-03-18-SimulationPlanner-Tutorial.html#plnr_gnar_block\n\n\n\n\n\ntrain 2022-06-01 00:00:00 ~ 2022-08-14 17:00:00\ntest 2022-08-14 18:00:00 ~ 2022-09-15 23:00:00\n\n\n\n\n\nimport eptstgcn\nimport torch\nimport eptstgcn.planner\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\n\n\n\n\nurl = \"https://raw.githubusercontent.com/pinkocto/noteda/main/posts/SOLAR/data2/stgcn_data1.json\"\nloader = eptstgcn.DatasetLoader(url)\ndataset = loader.get_dataset(lags=4)\n\n\ntrain_dataset, test_dataset = eptstgcn.utils.temporal_signal_split(dataset, train_ratio = 0.7)\n\n\n\n\n\nlrnr = eptstgcn.StgcnLearner(train_dataset, dataset_name = 'data2(2022/06/01 ~ 2022/09/15)')\n\n\nlrnr.learn(filters=64, epoch=50)\n\n50/50\n\n\n\nimport pickle \nwith open('./lrnr_model/stgcn_ver1_data2_cancel_normal_64fil_50_epoch.pickle','wb') as fw:\n    pickle.dump(lrnr, fw)\n\n\nimport pickle \nwith open('./lrnr_model/stgcn_ver1_data2_cancel_normal_64fil_50_epoch.pickle', 'rb') as f: \n    lrnr_model = pickle.load(f)\n\n\n\n\n\n\n\nevtor = eptstgcn.Evaluator(lrnr_model, train_dataset, test_dataset)\n\n\nevtor.tr_plot(t=150, label='observed data')\n\n\n\n\n\n\n\n\nevtor.test_plot(t=150, label='observed data')\n\n\n\n\n\n\n\n\n\nplans_stgcn = {\n    'max_iteration': 30, \n    'method': ['STGCN'], \n    'lags': [4], \n    'nof_filters': [64], \n    'epoch': [50]\n}\n\n\nplnr = eptstgcn.planner.PLNR_STGCN(plans_stgcn,loader,dataset_name='data2')\n\n\nplnr.simulate()\n\n1/30 is done\n2/30 is done\n3/30 is done\n4/30 is done\n5/30 is done\n6/30 is done\n7/30 is done\n8/30 is done\n9/30 is done\n10/30 is done\n11/30 is done\n12/30 is done\n13/30 is done\n14/30 is done\n15/30 is done\n16/30 is done\n17/30 is done\n18/30 is done\n19/30 is done\n20/30 is done\n21/30 is done\n22/30 is done\n23/30 is done\n24/30 is done\n25/30 is done\n26/30 is done\n27/30 is done\n28/30 is done\n29/30 is done\n30/30 is done\nAll results are stored in ./simulation_results/2023-04-28_00-30-34.csv\n\n\n\nimport pickle\nwith open('./simul_model/stgcn_ver1_data2_cancel_normal_64fil_50epoch.pickle','wb') as fw:\n         pickle.dump(plnr, fw)\n\n\nimport pickle\nwith open('./simul_model/stgcn_ver1_data2_cancel_normal_64fil_50epoch.pickle','rb') as f:\n         simul_model = pickle.load(f)\n\n\ndf_simul_no = simul_model.simulation_results\ndf_simul_no\n\n\n\n\n\n  \n    \n      \n      dataset\n      method\n      lags\n      nof_filters\n      epoch\n      mse(train)\n      mse(test)\n      calculation_time\n    \n  \n  \n    \n      0\n      data2\n      STGCN\n      4\n      64\n      50\n      0.191362\n      0.177325\n      1295.943912\n    \n    \n      1\n      data2\n      STGCN\n      4\n      64\n      50\n      0.192469\n      0.181441\n      1167.687822\n    \n    \n      2\n      data2\n      STGCN\n      4\n      64\n      50\n      0.186016\n      0.170659\n      1198.141087\n    \n    \n      3\n      data2\n      STGCN\n      4\n      64\n      50\n      0.193183\n      0.178462\n      1125.773396\n    \n    \n      4\n      data2\n      STGCN\n      4\n      64\n      50\n      0.191952\n      0.179335\n      1048.083814\n    \n    \n      5\n      data2\n      STGCN\n      4\n      64\n      50\n      0.193967\n      0.181968\n      1027.186577\n    \n    \n      6\n      data2\n      STGCN\n      4\n      64\n      50\n      0.194936\n      0.182994\n      1111.670336\n    \n    \n      7\n      data2\n      STGCN\n      4\n      64\n      50\n      0.189526\n      0.17169\n      1136.746021\n    \n    \n      8\n      data2\n      STGCN\n      4\n      64\n      50\n      0.189038\n      0.174021\n      1122.651814\n    \n    \n      9\n      data2\n      STGCN\n      4\n      64\n      50\n      0.189971\n      0.172886\n      959.683786\n    \n    \n      10\n      data2\n      STGCN\n      4\n      64\n      50\n      0.193519\n      0.180539\n      1006.969697\n    \n    \n      11\n      data2\n      STGCN\n      4\n      64\n      50\n      0.195559\n      0.183155\n      1099.276521\n    \n    \n      12\n      data2\n      STGCN\n      4\n      64\n      50\n      0.19046\n      0.177095\n      1159.008835\n    \n    \n      13\n      data2\n      STGCN\n      4\n      64\n      50\n      0.193731\n      0.180649\n      795.682773\n    \n    \n      14\n      data2\n      STGCN\n      4\n      64\n      50\n      0.19746\n      0.18563\n      418.992473\n    \n    \n      15\n      data2\n      STGCN\n      4\n      64\n      50\n      0.190527\n      0.177849\n      418.652911\n    \n    \n      16\n      data2\n      STGCN\n      4\n      64\n      50\n      0.189349\n      0.171285\n      460.293338\n    \n    \n      17\n      data2\n      STGCN\n      4\n      64\n      50\n      0.186201\n      0.171583\n      522.558877\n    \n    \n      18\n      data2\n      STGCN\n      4\n      64\n      50\n      0.18616\n      0.170812\n      560.117258\n    \n    \n      19\n      data2\n      STGCN\n      4\n      64\n      50\n      0.184117\n      0.170089\n      560.118513\n    \n    \n      20\n      data2\n      STGCN\n      4\n      64\n      50\n      0.190282\n      0.175846\n      559.028552\n    \n    \n      21\n      data2\n      STGCN\n      4\n      64\n      50\n      0.196327\n      0.183477\n      559.161665\n    \n    \n      22\n      data2\n      STGCN\n      4\n      64\n      50\n      0.194578\n      0.181951\n      560.53973\n    \n    \n      23\n      data2\n      STGCN\n      4\n      64\n      50\n      0.192624\n      0.17909\n      561.462616\n    \n    \n      24\n      data2\n      STGCN\n      4\n      64\n      50\n      0.201977\n      0.191076\n      441.949286\n    \n    \n      25\n      data2\n      STGCN\n      4\n      64\n      50\n      0.190822\n      0.17375\n      473.617449\n    \n    \n      26\n      data2\n      STGCN\n      4\n      64\n      50\n      0.189557\n      0.17323\n      419.907709\n    \n    \n      27\n      data2\n      STGCN\n      4\n      64\n      50\n      0.190529\n      0.173975\n      418.957462\n    \n    \n      28\n      data2\n      STGCN\n      4\n      64\n      50\n      0.19635\n      0.18454\n      419.596368\n    \n    \n      29\n      data2\n      STGCN\n      4\n      64\n      50\n      0.190731\n      0.174071\n      420.817851\n    \n  \n\n\n\n\n\ndf_simul_no['mse(test)'].mean()\n\n0.17768246829509735\n\n\n\nprint('stgcn ver1 50에폭 64filter 끝!')\n\nstgcn ver1 50에폭 64filter 끝!\n\n\n\nimport matplotlib.pyplot as plt\nplt.boxplot(df_simul_no['mse(test)'])\nplt.show()"
  },
  {
    "objectID": "posts/SOLAR/2023-04-23-스케일링-stgcn-ver2-정규화취소.html",
    "href": "posts/SOLAR/2023-04-23-스케일링-stgcn-ver2-정규화취소.html",
    "title": "[SOLAR] STGCN Ver2 (data2, -N +S) 30회",
    "section": "",
    "text": "https://github.com/miruetoto/yechan3/tree/main/posts/3_Researches/ITSTGCN/itstgcn\nhttps://miruetoto.github.io/yechan3/posts/3_Researches/ITSTGCN/2023-03-18-SimulationPlanner-Tutorial.html#plnr_gnar_block\n\n\n\n\n\ntrain 2022-06-01 00:00:00 ~ 2022-08-14 17:00:00\ntest 2022-08-14 18:00:00 ~ 2022-09-15 23:00:00\n\n\n\n\n\nimport eptstgcn\nimport torch\nimport eptstgcn.planner\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\n\n\n\n\nurl = \"https://raw.githubusercontent.com/pinkocto/noteda/main/posts/SOLAR/data2/stgcn_data2.json\"\nloader = eptstgcn.DatasetLoader(url)\ndataset = loader.get_dataset(lags=4)\n\n\ntrain_dataset, test_dataset = eptstgcn.utils.temporal_signal_split(dataset, train_ratio = 0.7)\n\n\n\n\n\nref: https://seoyeonc.github.io/blog/posts/GCN/2023-03-17-ITSTGCN-Tutorial.html\n\n\nlrnr = eptstgcn.StgcnLearner(train_dataset, dataset_name = 'data2(2022/06/01 ~ 2022/09/15)')\n\n\nlrnr.learn(filters=32, epoch=50)\n\n50/50\n\n\n\n# import pickle \n# with open('./lrnr_model/stgcn_ver2_data2_cancel_normal.pickle','wb') as fw:\n#     pickle.dump(lrnr, fw)\n\n\nimport pickle \nwith open('./lrnr_model/stgcn_ver2_data2_cancel_normal.pickle', 'rb') as f: \n    model = pickle.load(f)\n\n\n\n\n\nevtor = eptstgcn.Evaluator(model, train_dataset, test_dataset)\n\n\n# fig = evtor.plot('--', label='observed data')\n# fig.tight_layout()\n# fig\n\n\n\n\nevtor.tr_plot(t=150, label='observed data')\n\n\n\n\n\n\n\n\nevtor.test_plot(t=150, label='observed data')\n\n\n\n\n\n\n\n\n\nplans_stgcn = {\n    'max_iteration': 30, \n    'method': ['EPT-STGCN'], \n    'lags': [4], \n    'nof_filters': [32], \n    'epoch': [50]\n}\n\n\n# plnr = eptstgcn.planner.PLNR_STGCN(plans_stgcn,loader,dataset_name='data2')\n\n\n# plnr.simulate()\n\n1/30 is done\n2/30 is done\n3/30 is done\n4/30 is done\n5/30 is done\n6/30 is done\n7/30 is done\n8/30 is done\n9/30 is done\n10/30 is done\n11/30 is done\n12/30 is done\n13/30 is done\n14/30 is done\n15/30 is done\n16/30 is done\n17/30 is done\n18/30 is done\n19/30 is done\n20/30 is done\n21/30 is done\n22/30 is done\n23/30 is done\n24/30 is done\n25/30 is done\n26/30 is done\n27/30 is done\n28/30 is done\n29/30 is done\n30/30 is done\nAll results are stored in ./simulation_results/2023-04-23_01-41-09.csv\n\n\n\n# import pickle\n# with open('./simul_model/stgcn_ver2_data2_cancel_normal.pickle', 'wb') as fw:\n#     pickle.dump(plnr, fw)\n\n\nwith open('./simul_model/stgcn_ver2_data2_cancel_normal.pickle', 'rb') as f:\n    simul_model = pickle.load(f)\n\n\ndf_simul_no = simul_model.simulation_results\ndf_simul_no\n\n\n\n\n\n  \n    \n      \n      dataset\n      method\n      lags\n      nof_filters\n      epoch\n      mse(train)\n      mse(test)\n      calculation_time\n    \n  \n  \n    \n      0\n      data2\n      EPT-STGCN\n      4\n      32\n      50\n      0.207058\n      0.192318\n      405.406879\n    \n    \n      1\n      data2\n      EPT-STGCN\n      4\n      32\n      50\n      0.183151\n      0.166525\n      406.358098\n    \n    \n      2\n      data2\n      EPT-STGCN\n      4\n      32\n      50\n      0.187727\n      0.170964\n      405.92099\n    \n    \n      3\n      data2\n      EPT-STGCN\n      4\n      32\n      50\n      0.183493\n      0.165333\n      405.771331\n    \n    \n      4\n      data2\n      EPT-STGCN\n      4\n      32\n      50\n      0.183788\n      0.163304\n      406.80101\n    \n    \n      5\n      data2\n      EPT-STGCN\n      4\n      32\n      50\n      0.184463\n      0.166215\n      404.526357\n    \n    \n      6\n      data2\n      EPT-STGCN\n      4\n      32\n      50\n      0.184557\n      0.168805\n      404.531185\n    \n    \n      7\n      data2\n      EPT-STGCN\n      4\n      32\n      50\n      0.182589\n      0.16412\n      403.679201\n    \n    \n      8\n      data2\n      EPT-STGCN\n      4\n      32\n      50\n      0.18965\n      0.168722\n      404.699471\n    \n    \n      9\n      data2\n      EPT-STGCN\n      4\n      32\n      50\n      0.181751\n      0.161628\n      404.820747\n    \n    \n      10\n      data2\n      EPT-STGCN\n      4\n      32\n      50\n      0.193702\n      0.174698\n      404.747668\n    \n    \n      11\n      data2\n      EPT-STGCN\n      4\n      32\n      50\n      0.186056\n      0.169208\n      405.390504\n    \n    \n      12\n      data2\n      EPT-STGCN\n      4\n      32\n      50\n      0.183449\n      0.164652\n      418.454221\n    \n    \n      13\n      data2\n      EPT-STGCN\n      4\n      32\n      50\n      0.181829\n      0.164456\n      431.528654\n    \n    \n      14\n      data2\n      EPT-STGCN\n      4\n      32\n      50\n      0.181213\n      0.162173\n      407.844052\n    \n    \n      15\n      data2\n      EPT-STGCN\n      4\n      32\n      50\n      0.185801\n      0.163754\n      411.968251\n    \n    \n      16\n      data2\n      EPT-STGCN\n      4\n      32\n      50\n      0.180674\n      0.162226\n      409.180396\n    \n    \n      17\n      data2\n      EPT-STGCN\n      4\n      32\n      50\n      0.183327\n      0.165314\n      410.445006\n    \n    \n      18\n      data2\n      EPT-STGCN\n      4\n      32\n      50\n      0.188633\n      0.171534\n      410.336946\n    \n    \n      19\n      data2\n      EPT-STGCN\n      4\n      32\n      50\n      0.183651\n      0.162947\n      407.536792\n    \n    \n      20\n      data2\n      EPT-STGCN\n      4\n      32\n      50\n      0.181314\n      0.16315\n      407.53003\n    \n    \n      21\n      data2\n      EPT-STGCN\n      4\n      32\n      50\n      0.189536\n      0.173027\n      407.360921\n    \n    \n      22\n      data2\n      EPT-STGCN\n      4\n      32\n      50\n      0.194188\n      0.180879\n      407.03145\n    \n    \n      23\n      data2\n      EPT-STGCN\n      4\n      32\n      50\n      0.19195\n      0.173795\n      406.137764\n    \n    \n      24\n      data2\n      EPT-STGCN\n      4\n      32\n      50\n      0.201777\n      0.183143\n      409.344015\n    \n    \n      25\n      data2\n      EPT-STGCN\n      4\n      32\n      50\n      0.188091\n      0.170836\n      408.617722\n    \n    \n      26\n      data2\n      EPT-STGCN\n      4\n      32\n      50\n      0.184508\n      0.163219\n      407.710896\n    \n    \n      27\n      data2\n      EPT-STGCN\n      4\n      32\n      50\n      0.187269\n      0.170395\n      408.118827\n    \n    \n      28\n      data2\n      EPT-STGCN\n      4\n      32\n      50\n      0.184121\n      0.163209\n      407.103555\n    \n    \n      29\n      data2\n      EPT-STGCN\n      4\n      32\n      50\n      0.195845\n      0.175516\n      373.846944\n    \n  \n\n\n\n\n\nimport matplotlib.pyplot as plt\nplt.boxplot(df_simul_no['mse(test)'])\nplt.show()"
  },
  {
    "objectID": "posts/SOLAR/2023-04-23-결과비교.html",
    "href": "posts/SOLAR/2023-04-23-결과비교.html",
    "title": "[SOLAR] Comparison of 30 simulation results (+N)",
    "section": "",
    "text": "데이터 정규화 시행후 결과 비교 (Data Leakage 문제로 XXX)"
  },
  {
    "objectID": "posts/SOLAR/2023-04-23-결과비교.html#import",
    "href": "posts/SOLAR/2023-04-23-결과비교.html#import",
    "title": "[SOLAR] Comparison of 30 simulation results (+N)",
    "section": "IMPORT",
    "text": "IMPORT\n\nimport eptstgcn\nimport torch\nimport eptstgcn.planner \n\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n\nstgcn_ver1 = eptstgcn.load_data('./simul_model/stgcn_ver1_data2_수정본.pickle')\nstgcn_ver2 = eptstgcn.load_data('./simul_model/stgcn_ver2_data2.pickle')"
  },
  {
    "objectID": "posts/SOLAR/2023-04-23-결과비교.html#simul-stgcn-rslt",
    "href": "posts/SOLAR/2023-04-23-결과비교.html#simul-stgcn-rslt",
    "title": "[SOLAR] Comparison of 30 simulation results (+N)",
    "section": "SIMUL STGCN RSLT",
    "text": "SIMUL STGCN RSLT\n\nstgcn_ver1.simulation_results\n\n\n\n\n\n  \n    \n      \n      dataset\n      method\n      lags\n      nof_filters\n      epoch\n      mse(train)\n      mse(test)\n      calculation_time\n    \n  \n  \n    \n      0\n      data2\n      STGCN\n      4\n      32\n      50\n      0.19253\n      0.178813\n      299.506482\n    \n    \n      1\n      data2\n      STGCN\n      4\n      32\n      50\n      0.207814\n      0.194699\n      301.152882\n    \n    \n      2\n      data2\n      STGCN\n      4\n      32\n      50\n      0.211491\n      0.199109\n      300.802653\n    \n    \n      3\n      data2\n      STGCN\n      4\n      32\n      50\n      0.197654\n      0.184594\n      300.746954\n    \n    \n      4\n      data2\n      STGCN\n      4\n      32\n      50\n      0.195077\n      0.181618\n      299.451799\n    \n    \n      5\n      data2\n      STGCN\n      4\n      32\n      50\n      0.193239\n      0.179953\n      300.354728\n    \n    \n      6\n      data2\n      STGCN\n      4\n      32\n      50\n      0.196659\n      0.185346\n      299.26752\n    \n    \n      7\n      data2\n      STGCN\n      4\n      32\n      50\n      0.193781\n      0.18058\n      302.380001\n    \n    \n      8\n      data2\n      STGCN\n      4\n      32\n      50\n      0.208838\n      0.195911\n      299.447903\n    \n    \n      9\n      data2\n      STGCN\n      4\n      32\n      50\n      0.189922\n      0.17138\n      300.263546\n    \n    \n      10\n      data2\n      STGCN\n      4\n      32\n      50\n      0.187192\n      0.169113\n      303.470774\n    \n    \n      11\n      data2\n      STGCN\n      4\n      32\n      50\n      0.193115\n      0.179827\n      302.080011\n    \n    \n      12\n      data2\n      STGCN\n      4\n      32\n      50\n      0.1858\n      0.170334\n      303.651782\n    \n    \n      13\n      data2\n      STGCN\n      4\n      32\n      50\n      0.19476\n      0.183161\n      303.882288\n    \n    \n      14\n      data2\n      STGCN\n      4\n      32\n      50\n      0.193405\n      0.181564\n      302.608904\n    \n    \n      15\n      data2\n      STGCN\n      4\n      32\n      50\n      0.202983\n      0.191953\n      303.581119\n    \n    \n      16\n      data2\n      STGCN\n      4\n      32\n      50\n      0.191977\n      0.176434\n      303.073734\n    \n    \n      17\n      data2\n      STGCN\n      4\n      32\n      50\n      0.208281\n      0.197348\n      302.28101\n    \n    \n      18\n      data2\n      STGCN\n      4\n      32\n      50\n      0.188831\n      0.172268\n      303.441188\n    \n    \n      19\n      data2\n      STGCN\n      4\n      32\n      50\n      0.197277\n      0.184311\n      300.513449\n    \n    \n      20\n      data2\n      STGCN\n      4\n      32\n      50\n      0.210896\n      0.200388\n      298.272825\n    \n    \n      21\n      data2\n      STGCN\n      4\n      32\n      50\n      0.192973\n      0.176103\n      296.521845\n    \n    \n      22\n      data2\n      STGCN\n      4\n      32\n      50\n      0.19158\n      0.175037\n      298.292416\n    \n    \n      23\n      data2\n      STGCN\n      4\n      32\n      50\n      0.195284\n      0.182071\n      298.253546\n    \n    \n      24\n      data2\n      STGCN\n      4\n      32\n      50\n      0.194003\n      0.18216\n      298.014387\n    \n    \n      25\n      data2\n      STGCN\n      4\n      32\n      50\n      0.188042\n      0.169741\n      296.891701\n    \n    \n      26\n      data2\n      STGCN\n      4\n      32\n      50\n      0.190116\n      0.173018\n      299.238075\n    \n    \n      27\n      data2\n      STGCN\n      4\n      32\n      50\n      0.190899\n      0.17734\n      304.243038\n    \n    \n      28\n      data2\n      STGCN\n      4\n      32\n      50\n      0.193679\n      0.179784\n      297.256639\n    \n    \n      29\n      data2\n      STGCN\n      4\n      32\n      50\n      0.216928\n      0.206055\n      297.618324"
  },
  {
    "objectID": "posts/SOLAR/2023-04-23-결과비교.html#simul-ept-stgcn-rslt",
    "href": "posts/SOLAR/2023-04-23-결과비교.html#simul-ept-stgcn-rslt",
    "title": "[SOLAR] Comparison of 30 simulation results (+N)",
    "section": "SIMUL EPT-STGCN RSLT",
    "text": "SIMUL EPT-STGCN RSLT\n\nstgcn_ver2.simulation_results\n\n\n\n\n\n  \n    \n      \n      dataset\n      method\n      lags\n      nof_filters\n      epoch\n      mse(train)\n      mse(test)\n      calculation_time\n    \n  \n  \n    \n      0\n      data2\n      EPT-STGCN\n      4\n      32\n      50\n      0.191743\n      0.174037\n      308.999537\n    \n    \n      1\n      data2\n      EPT-STGCN\n      4\n      32\n      50\n      0.188173\n      0.171402\n      310.277773\n    \n    \n      2\n      data2\n      EPT-STGCN\n      4\n      32\n      50\n      0.193801\n      0.177204\n      308.135715\n    \n    \n      3\n      data2\n      EPT-STGCN\n      4\n      32\n      50\n      0.193846\n      0.177513\n      307.202175\n    \n    \n      4\n      data2\n      EPT-STGCN\n      4\n      32\n      50\n      0.192977\n      0.172927\n      301.829093\n    \n    \n      5\n      data2\n      EPT-STGCN\n      4\n      32\n      50\n      0.192712\n      0.176857\n      301.443737\n    \n    \n      6\n      data2\n      EPT-STGCN\n      4\n      32\n      50\n      0.195432\n      0.179403\n      303.030302\n    \n    \n      7\n      data2\n      EPT-STGCN\n      4\n      32\n      50\n      0.193558\n      0.17668\n      302.182927\n    \n    \n      8\n      data2\n      EPT-STGCN\n      4\n      32\n      50\n      0.188431\n      0.170934\n      300.978617\n    \n    \n      9\n      data2\n      EPT-STGCN\n      4\n      32\n      50\n      0.194312\n      0.178338\n      301.406438\n    \n    \n      10\n      data2\n      EPT-STGCN\n      4\n      32\n      50\n      0.192146\n      0.17524\n      310.645684\n    \n    \n      11\n      data2\n      EPT-STGCN\n      4\n      32\n      50\n      0.21723\n      0.202964\n      309.016529\n    \n    \n      12\n      data2\n      EPT-STGCN\n      4\n      32\n      50\n      0.191419\n      0.175272\n      301.719725\n    \n    \n      13\n      data2\n      EPT-STGCN\n      4\n      32\n      50\n      0.189603\n      0.16854\n      298.208967\n    \n    \n      14\n      data2\n      EPT-STGCN\n      4\n      32\n      50\n      0.192472\n      0.175902\n      298.160489\n    \n    \n      15\n      data2\n      EPT-STGCN\n      4\n      32\n      50\n      0.195813\n      0.180936\n      298.502372\n    \n    \n      16\n      data2\n      EPT-STGCN\n      4\n      32\n      50\n      0.192051\n      0.172564\n      303.121567\n    \n    \n      17\n      data2\n      EPT-STGCN\n      4\n      32\n      50\n      0.186588\n      0.169016\n      298.217363\n    \n    \n      18\n      data2\n      EPT-STGCN\n      4\n      32\n      50\n      0.188448\n      0.17067\n      308.988231\n    \n    \n      19\n      data2\n      EPT-STGCN\n      4\n      32\n      50\n      0.192218\n      0.174493\n      314.624435\n    \n    \n      20\n      data2\n      EPT-STGCN\n      4\n      32\n      50\n      0.194702\n      0.178929\n      312.727251\n    \n    \n      21\n      data2\n      EPT-STGCN\n      4\n      32\n      50\n      0.191139\n      0.171002\n      307.64198\n    \n    \n      22\n      data2\n      EPT-STGCN\n      4\n      32\n      50\n      0.193083\n      0.176349\n      308.692932\n    \n    \n      23\n      data2\n      EPT-STGCN\n      4\n      32\n      50\n      0.188758\n      0.168046\n      298.516863\n    \n    \n      24\n      data2\n      EPT-STGCN\n      4\n      32\n      50\n      0.193287\n      0.176689\n      300.613522\n    \n    \n      25\n      data2\n      EPT-STGCN\n      4\n      32\n      50\n      0.196557\n      0.182426\n      300.518729\n    \n    \n      26\n      data2\n      EPT-STGCN\n      4\n      32\n      50\n      0.197129\n      0.17901\n      303.639919\n    \n    \n      27\n      data2\n      EPT-STGCN\n      4\n      32\n      50\n      0.188209\n      0.170222\n      305.739781\n    \n    \n      28\n      data2\n      EPT-STGCN\n      4\n      32\n      50\n      0.19453\n      0.17823\n      316.576063\n    \n    \n      29\n      data2\n      EPT-STGCN\n      4\n      32\n      50\n      0.194562\n      0.178458\n      304.878169"
  },
  {
    "objectID": "posts/SOLAR/2023-04-23-결과비교.html#visualization",
    "href": "posts/SOLAR/2023-04-23-결과비교.html#visualization",
    "title": "[SOLAR] Comparison of 30 simulation results (+N)",
    "section": "VISUALIZATION",
    "text": "VISUALIZATION\n\nrslt1 = stgcn_ver1.simulation_results[['method', 'mse(train)', 'mse(test)']]\nrslt2 = stgcn_ver2.simulation_results[['method', 'mse(train)', 'mse(test)']]\n\n\nrslt = pd.concat([rslt1, rslt2], axis=0)\n# rslt\n\n\nrslt.groupby('method').agg(['mean', 'median', 'var']).reset_index()\n\n\n\n\n\n  \n    \n      \n      method\n      mse(train)\n      mse(test)\n    \n    \n      \n      \n      mean\n      median\n      var\n      mean\n      median\n      var\n    \n  \n  \n    \n      0\n      EPT-STGCN\n      0.193164\n      0.192844\n      0.000028\n      0.176008\n      0.176125\n      0.000040\n    \n    \n      1\n      STGCN\n      0.196501\n      0.193730\n      0.000065\n      0.182667\n      0.181072\n      0.000097\n    \n  \n\n\n\n\n- train\n\nsns.boxplot(x = rslt['method'],\n            y = rslt['mse(train)'])\nplt.title('Comparison of 30 simulation results(tr_mse)')\nplt.show()\n\n\n\n\n- test\n\nsns.boxplot(x = rslt['method'],\n            y = rslt['mse(test)'])\nplt.title('Comparison of 30 simulation results(test_mse)')\nplt.show()\n\n\n\n\n- histogram (test)\n\nrslt1['mse(test)'].hist(alpha=.5, label='STGCN', color='blue')\nrslt2['mse(test)'].hist(alpha=.5, label = 'EPT-STGCN', color='red')\nplt.title('Comparison of 30 simulation results(test_mse)')\nplt.legend()\nplt.show()"
  },
  {
    "objectID": "posts/SOLAR/2023-04-23-결과비교.html#lrnr-stgcn",
    "href": "posts/SOLAR/2023-04-23-결과비교.html#lrnr-stgcn",
    "title": "[SOLAR] Comparison of 30 simulation results (+N)",
    "section": "LRNR (STGCN)",
    "text": "LRNR (STGCN)\n\nurl = \"https://raw.githubusercontent.com/pinkocto/noteda/main/posts/SOLAR/data2/stgcn_data1.json\"\nloader = eptstgcn.DatasetLoader(url)\ndataset = loader.get_dataset(lags=4)\ntrain_dataset, test_dataset = eptstgcn.utils.temporal_signal_split(dataset, train_ratio = 0.7)\n\n\nlrnr1 = eptstgcn.load_data('./lrnr_model/stgcn_ver1_data2.pickle')\n\n\nevtor = eptstgcn.Evaluator(lrnr1, train_dataset, test_dataset)\n\n/home/jy/Dropbox/noteda/posts/SOLAR/eptstgcn/learners.py:70: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /opt/conda/conda-bld/pytorch_1678402421473/work/torch/csrc/utils/tensor_new.cpp:245.)\n  X = torch.tensor(dataset.features).float()\n\n\n\nTRAIN\n\nevtor.tr_plot(t=150, label='observed data')\n\n\n\n\n\n\nTEST\n\nevtor.test_plot(t=150, label='observed data')"
  },
  {
    "objectID": "posts/SOLAR/2023-04-23-결과비교.html#lrnr-ept-stgcn",
    "href": "posts/SOLAR/2023-04-23-결과비교.html#lrnr-ept-stgcn",
    "title": "[SOLAR] Comparison of 30 simulation results (+N)",
    "section": "LRNR (EPT-STGCN)",
    "text": "LRNR (EPT-STGCN)\n\nurl = \"https://raw.githubusercontent.com/pinkocto/noteda/main/posts/SOLAR/data2/stgcn_data2.json\"\nloader = eptstgcn.DatasetLoader(url)\ndataset = loader.get_dataset(lags=4)\ntrain_dataset, test_dataset = eptstgcn.utils.temporal_signal_split(dataset, train_ratio = 0.7)\n\n\nlrnr2 = eptstgcn.load_data('./lrnr_model/stgcn_ver2_data2.pickle')\n\n\nevtor2 = eptstgcn.Evaluator(lrnr2, train_dataset, test_dataset)\n\n\nTRAIN\n\nevtor2.tr_plot(t=150, label='observed data')\n\n\n\n\n\n\nTEST\n\nevtor2.test_plot(t=150, label='observed data')"
  },
  {
    "objectID": "posts/SOLAR/2023-03-30-correlation.html",
    "href": "posts/SOLAR/2023-03-30-correlation.html",
    "title": "[R]Correlation coefficient by region",
    "section": "",
    "text": "library(data.table)\nlibrary(tidyverse)\nlibrary(recipes)\nlibrary(corrplot)\nlibrary(GGally)\n\n\nfile_path <- './data/'\nlist.files(file_path)\n\n [1] \"df_arima.csv\"                \"df_new.csv\"                 \n [3] \"df_yU.csv\"                   \"OBS_ASOS_TIM_data0.csv\"     \n [5] \"OBS_ASOS_TIM_data1.csv\"      \"prep_data.csv\"              \n [7] \"prep_test.csv\"               \"raw.csv\"                    \n [9] \"restructuring_prep_data.csv\" \"restructuring_raw.csv\"      \n[11] \"solar_radiation.csv\"         \"solar_radiation2.csv\"       \n[13] \"solar.json\"                  \"solar2.json\"                \n[15] \"test_raw.csv\"                \"weight.csv\"                 \n[17] \"yU_weight.csv\"              \n\n\n\ndf1 <- fread(file.path(file_path, 'prep_data.csv'))\nhead(df1)\n\n   지점 지점명                일시 일사(MJ/m2)   Datetime hour\n1:   93 북춘천 2021-01-01 08:00:00        0.00 2021-01-01    8\n2:   93 북춘천 2021-01-01 09:00:00        0.37 2021-01-01    9\n3:   93 북춘천 2021-01-01 10:00:00        0.96 2021-01-01   10\n4:   93 북춘천 2021-01-01 11:00:00        1.40 2021-01-01   11\n5:   93 북춘천 2021-01-01 12:00:00        1.72 2021-01-01   12\n6:   93 북춘천 2021-01-01 13:00:00        1.84 2021-01-01   13\n\n\n\nglimpse(df1)\n\nRows: 352,279\nColumns: 6\n$ 지점          <int> 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, …\n$ 지점명        <chr> \"북춘천\", \"북춘천\", \"북춘천\", \"북춘천\", \"북춘천\", \"북춘…\n$ 일시          <dttm> 2021-01-01 08:00:00, 2021-01-01 09:00:00, 2021-01-01 10…\n$ `일사(MJ/m2)` <dbl> 0.00, 0.37, 0.96, 1.40, 1.72, 1.84, 1.74, 1.30, 0.93, 0.…\n$ Datetime      <IDate> 2021-01-01, 2021-01-01, 2021-01-01, 2021-01-01, 2021-0…\n$ hour          <int> 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 8, 9, 10, 11, …"
  },
  {
    "objectID": "posts/SOLAR/2023-03-30-correlation.html#지역별-일사량-correlation",
    "href": "posts/SOLAR/2023-03-30-correlation.html#지역별-일사량-correlation",
    "title": "[R]Correlation coefficient by region",
    "section": "지역별 일사량 correlation",
    "text": "지역별 일사량 correlation\n\ndf1 <- subset(df1, select = -c(Datetime,hour))\ndf1 %>% head()\n\n   지점 지점명                일시 일사(MJ/m2)\n1:   93 북춘천 2021-01-01 08:00:00        0.00\n2:   93 북춘천 2021-01-01 09:00:00        0.37\n3:   93 북춘천 2021-01-01 10:00:00        0.96\n4:   93 북춘천 2021-01-01 11:00:00        1.40\n5:   93 북춘천 2021-01-01 12:00:00        1.72\n6:   93 북춘천 2021-01-01 13:00:00        1.84\n\n\n\ndf1 <- df1 %>% dcast(일시 + '일사(MJ/m2)' ~ 지점명)\n\nUsing '일사(MJ/m2)' as value column. Use 'value.var' to override\n\ndf1 %>% head()\n\n                  일시 강릉 강진군 경주시 고산 고창 고창군 광양시 광주 김해시\n1: 2021-01-01 08:00:00 0.01   0.01   0.02 0.00 0.01   0.01   0.01 0.06   0.01\n2: 2021-01-01 09:00:00 0.37   0.17   0.45 0.05 0.14   0.22   0.25 0.19   0.41\n3: 2021-01-01 10:00:00 0.97   0.78   0.92 0.15 0.58   0.36   0.86 0.33   1.07\n4: 2021-01-01 11:00:00 1.48   1.75   1.14 0.15 0.61   0.30   1.31 0.66   1.49\n5: 2021-01-01 12:00:00 1.76   1.40   1.40 0.28 1.37   0.73   1.52 1.73   1.64\n6: 2021-01-01 13:00:00 1.92   1.16   1.38 0.17 1.31   1.26   1.13 1.75   1.98\n   대관령 대구 대전 목포 백령도 보성군 부산 북강릉 북창원 북춘천 서산 서울 수원\n1:   0.00 0.03 0.01 0.01   0.00   0.02 0.03   0.01   0.01   0.00 0.00 0.00 0.00\n2:   0.29 0.45 0.53 0.30   0.13   0.35 0.47   0.35   0.27   0.37 0.06 0.27 0.18\n3:   1.02 1.03 0.80 1.01   0.65   0.88 1.10   0.92   0.92   0.96 0.18 0.76 0.60\n4:   1.61 1.51 0.81 0.96   1.04   1.38 1.62   1.39   1.22   1.40 0.31 1.40 1.22\n5:   1.96 1.75 0.57 1.01   1.71   1.63 1.94   1.71   1.86   1.72 0.46 1.74 1.69\n6:   2.06 1.74 0.62 1.01   1.87   1.31 2.11   1.82   1.99   1.84 0.36 1.61 1.78\n   순창군 안동 양산시 여수 영광군 울릉도 원주 의령군 인천 전주 제주 진주 창원\n1:   0.00 0.01   0.01 0.00   0.00   0.00 0.00   0.03 0.00 0.01 0.00 0.01 0.00\n2:   0.24 0.40   0.27 0.30   0.23   0.24 0.35   0.51 0.15 0.51 0.14 0.54 0.29\n3:   0.45 0.99   1.07 0.97   0.34   0.68 1.15   1.37 0.65 1.19 0.27 1.25 0.87\n4:   0.76 0.96   1.60 1.34   1.00   0.51 1.59   1.69 1.20 1.13 0.47 1.59 1.41\n5:   0.65 1.85   1.91 1.40   1.35   0.47 2.02   2.04 1.48 1.19 0.26 1.89 1.73\n6:   1.70 1.99   2.02 1.98   1.65   0.89 1.91   1.64 1.70 1.28 0.34 1.80 1.83\n   철원 청송군 청주 추풍령 춘천 포항 함양군 홍성 흑산도\n1: 0.00   0.02 0.00   0.00 0.00 0.02   0.00 0.00   0.02\n2: 0.11   0.46 0.27   0.27 0.31 0.38   0.25 0.07   0.15\n3: 0.74   1.05 0.85   0.56 0.96 1.03   1.05 0.26   0.61\n4: 1.37   1.26 0.75   0.69 1.46 1.53   1.65 0.43   0.56\n5: 1.74   1.92 0.96   0.63 1.68 1.81   1.52 0.49   0.57\n6: 1.98   1.85 0.87   1.26 1.78 1.86   1.13 0.52   0.48\n\n\n\ndf1 %>% dim()\n\n[1] 8030   45\n\n\n\nnum_vars <- df1 %>% select(-일시)\nweight <- cor(num_vars, use = 'pairwise.complete.obs')\nweight\n\n            강릉    강진군    경주시      고산      고창    고창군    광양시\n강릉   1.0000000 0.7044017 0.7703514 0.6312139 0.7271388 0.7274934 0.7274176\n강진군 0.7044017 1.0000000 0.7871212 0.8176767 0.8834400 0.8764382 0.8971808\n경주시 0.7703514 0.7871212 1.0000000 0.7099020 0.7799916 0.7784246 0.8319129\n고산   0.6312139 0.8176767 0.7099020 1.0000000 0.7921017 0.7795135 0.7932090\n고창   0.7271388 0.8834400 0.7799916 0.7921017 1.0000000 0.9636801 0.8544049\n고창군 0.7274934 0.8764382 0.7784246 0.7795135 0.9636801 1.0000000 0.8486326\n광양시 0.7274176 0.8971808 0.8319129 0.7932090 0.8544049 0.8486326 1.0000000\n광주   0.7170920 0.8914366 0.7876565 0.7827690 0.9146688 0.9194130 0.8646192\n김해시 0.7300587 0.8298323 0.8884789 0.7437849 0.8087741 0.8033153 0.8822539\n대관령 0.9096524 0.7151957 0.7830542 0.6468294 0.7392306 0.7430812 0.7428423\n대구   0.7819328 0.8349168 0.9057791 0.7419595 0.8402181 0.8374690 0.8696729\n대전   0.7877771 0.8254926 0.7894997 0.7319483 0.8703778 0.8717858 0.8306825\n목포   0.7089408 0.9132795 0.7733647 0.8247665 0.9118592 0.8988462 0.8636433\n백령도 0.6416767 0.6633466 0.5821691 0.6347485 0.6769029 0.6643130 0.6525396\n보성군 0.7255909 0.9352029 0.8147853 0.8078128 0.8760113 0.8668396 0.9300403\n부산   0.7257286 0.8372601 0.8794130 0.7617967 0.8139354 0.8044084 0.8836403\n북강릉 0.9679702 0.7130858 0.7787018 0.6373739 0.7346559 0.7357016 0.7335184\n북창원 0.7343323 0.8400905 0.8902254 0.7544385 0.8178678 0.8134796 0.8933071\n북춘천 0.7934575 0.7164055 0.6997703 0.6530018 0.7611288 0.7533824 0.7298274\n서산   0.7602535 0.7739392 0.7187583 0.7145626 0.8221190 0.8170089 0.7726253\n서울   0.7497483 0.7169152 0.6754826 0.6466854 0.7611490 0.7564272 0.7202050\n수원   0.7783023 0.7568028 0.7172262 0.6803819 0.8051685 0.7995755 0.7589846\n순창군 0.7477589 0.8975007 0.8024646 0.7772885 0.9201761 0.9223830 0.8847395\n안동   0.8229087 0.8124436 0.8620901 0.7209146 0.8361734 0.8326433 0.8380486\n양산시 0.7420517 0.8297895 0.8982046 0.7489133 0.8166139 0.8102864 0.8794260\n여수   0.7224022 0.8869236 0.8229676 0.8053798 0.8417374 0.8333109 0.9373270\n영광군 0.7199346 0.8802219 0.7709653 0.7998266 0.9641461 0.9451684 0.8482541\n울릉도 0.7249746 0.7068337 0.7591943 0.6533281 0.7212534 0.7202619 0.7193463\n원주   0.8140140 0.7470349 0.7367868 0.6706000 0.7940990 0.7931988 0.7567017\n의령군 0.7482024 0.8586170 0.8799885 0.7668327 0.8383795 0.8297413 0.9122636\n인천   0.7528825 0.7408405 0.6909296 0.6769771 0.7819980 0.7702349 0.7411685\n전주   0.7559655 0.8532850 0.7884779 0.7517062 0.9090750 0.9179114 0.8453850\n제주   0.6288149 0.8025710 0.7278624 0.8944810 0.7713076 0.7571275 0.7723644\n진주   0.7360999 0.8707244 0.8665368 0.7781282 0.8413993 0.8361220 0.9289161\n창원   0.7359527 0.8550384 0.8796000 0.7711443 0.8308083 0.8192160 0.9070658\n철원   0.7613446 0.7099067 0.6728015 0.6511250 0.7463221 0.7376000 0.7094024\n청송군 0.8119685 0.8001702 0.8917156 0.7111140 0.8110318 0.8101408 0.8313951\n청주   0.7906018 0.7990762 0.7691019 0.7160675 0.8455261 0.8479594 0.8049821\n추풍령 0.7994430 0.8366508 0.8551957 0.7404377 0.8598107 0.8605002 0.8527017\n춘천   0.7901031 0.7224999 0.6979233 0.6616856 0.7671444 0.7562610 0.7326951\n포항   0.7800426 0.7743982 0.9299494 0.6950692 0.7746035 0.7687438 0.8202247\n함양군 0.7573195 0.8647581 0.8575342 0.7611798 0.8670402 0.8639479 0.8876091\n홍성   0.7739988 0.7936477 0.7400062 0.7120808 0.8396157 0.8379117 0.7897796\n흑산도 0.6521117 0.8186882 0.7064828 0.7694346 0.8178804 0.7992953 0.7803099\n            광주    김해시    대관령      대구      대전      목포    백령도\n강릉   0.7170920 0.7300587 0.9096524 0.7819328 0.7877771 0.7089408 0.6416767\n강진군 0.8914366 0.8298323 0.7151957 0.8349168 0.8254926 0.9132795 0.6633466\n경주시 0.7876565 0.8884789 0.7830542 0.9057791 0.7894997 0.7733647 0.5821691\n고산   0.7827690 0.7437849 0.6468294 0.7419595 0.7319483 0.8247665 0.6347485\n고창   0.9146688 0.8087741 0.7392306 0.8402181 0.8703778 0.9118592 0.6769029\n고창군 0.9194130 0.8033153 0.7430812 0.8374690 0.8717858 0.8988462 0.6643130\n광양시 0.8646192 0.8822539 0.7428423 0.8696729 0.8306825 0.8636433 0.6525396\n광주   1.0000000 0.8158252 0.7287727 0.8403959 0.8495617 0.8965627 0.6407831\n김해시 0.8158252 1.0000000 0.7453142 0.8887980 0.7995963 0.8046722 0.6070276\n대관령 0.7287727 0.7453142 1.0000000 0.7979967 0.8065325 0.7187562 0.6486741\n대구   0.8403959 0.8887980 0.7979967 1.0000000 0.8506620 0.8210361 0.6376003\n대전   0.8495617 0.7995963 0.8065325 0.8506620 1.0000000 0.8314861 0.6798361\n목포   0.8965627 0.8046722 0.7187562 0.8210361 0.8314861 1.0000000 0.6780046\n백령도 0.6407831 0.6070276 0.6486741 0.6376003 0.6798361 0.6780046 1.0000000\n보성군 0.8845403 0.8600309 0.7327299 0.8569582 0.8299595 0.8942154 0.6569948\n부산   0.8135183 0.9416264 0.7442714 0.8808684 0.7944530 0.8090207 0.6050058\n북강릉 0.7254612 0.7381310 0.9101192 0.7919992 0.7953191 0.7153731 0.6528630\n북창원 0.8291321 0.9478310 0.7446947 0.8916729 0.8034837 0.8140079 0.6083347\n북춘천 0.7252158 0.7024307 0.8228481 0.7529493 0.8213730 0.7268557 0.7488592\n서산   0.7879468 0.7305079 0.7799326 0.7733257 0.8704259 0.7968942 0.7699792\n서울   0.7339461 0.6916416 0.7758534 0.7310587 0.8213377 0.7271795 0.7578969\n수원   0.7737683 0.7260335 0.8012578 0.7700634 0.8652538 0.7720480 0.7594207\n순창군 0.9272002 0.8289053 0.7593288 0.8619748 0.8794022 0.8893603 0.6721664\n안동   0.8283607 0.8429188 0.8384814 0.8925808 0.8807708 0.8055843 0.6524766\n양산시 0.8177595 0.9521355 0.7577321 0.8970682 0.8062842 0.8069924 0.6097318\n여수   0.8493501 0.8819975 0.7367787 0.8583893 0.8134349 0.8548388 0.6442821\n영광군 0.9057378 0.7998990 0.7304388 0.8286563 0.8597324 0.9188443 0.6817800\n울릉도 0.7132909 0.7400635 0.7387259 0.7683306 0.7448819 0.7094023 0.5787507\n원주   0.7708492 0.7337471 0.8453858 0.7896731 0.8717413 0.7559130 0.6905395\n의령군 0.8420095 0.9095451 0.7554448 0.9060476 0.8269171 0.8389763 0.6318475\n인천   0.7447416 0.7045141 0.7703520 0.7412998 0.8222485 0.7609958 0.8040668\n전주   0.8888634 0.8112366 0.7722900 0.8523081 0.9133086 0.8622079 0.6592059\n제주   0.7596200 0.7419911 0.6407150 0.7406006 0.7082283 0.8051050 0.6046135\n진주   0.8525976 0.9057840 0.7510854 0.8919844 0.8243969 0.8485560 0.6387758\n창원   0.8314682 0.9390908 0.7502029 0.8896739 0.8128315 0.8293878 0.6228163\n철원   0.7141419 0.6791410 0.7858886 0.7253687 0.7919180 0.7195667 0.7786030\n청송군 0.8116415 0.8518849 0.8355435 0.9033966 0.8409124 0.7873538 0.6156391\n청주   0.8225686 0.7730950 0.8121126 0.8217519 0.9340775 0.8073679 0.6890909\n추풍령 0.8482247 0.8438536 0.8160104 0.9001672 0.8990270 0.8302442 0.6497277\n춘천   0.7305449 0.7020522 0.8162753 0.7528873 0.8238574 0.7337111 0.7573548\n포항   0.7778093 0.8596690 0.7870301 0.8946346 0.7903350 0.7591535 0.5899988\n함양군 0.8701505 0.8646009 0.7805615 0.9048076 0.8635005 0.8491819 0.6557867\n홍성   0.8075240 0.7518216 0.7897041 0.7956803 0.8969670 0.8068467 0.7400695\n흑산도 0.7870179 0.7320231 0.6528066 0.7385520 0.7535020 0.8404021 0.6941095\n          보성군      부산    북강릉    북창원    북춘천      서산      서울\n강릉   0.7255909 0.7257286 0.9679702 0.7343323 0.7934575 0.7602535 0.7497483\n강진군 0.9352029 0.8372601 0.7130858 0.8400905 0.7164055 0.7739392 0.7169152\n경주시 0.8147853 0.8794130 0.7787018 0.8902254 0.6997703 0.7187583 0.6754826\n고산   0.8078128 0.7617967 0.6373739 0.7544385 0.6530018 0.7145626 0.6466854\n고창   0.8760113 0.8139354 0.7346559 0.8178678 0.7611288 0.8221190 0.7611490\n고창군 0.8668396 0.8044084 0.7357016 0.8134796 0.7533824 0.8170089 0.7564272\n광양시 0.9300403 0.8836403 0.7335184 0.8933071 0.7298274 0.7726253 0.7202050\n광주   0.8845403 0.8135183 0.7254612 0.8291321 0.7252158 0.7879468 0.7339461\n김해시 0.8600309 0.9416264 0.7381310 0.9478310 0.7024307 0.7305079 0.6916416\n대관령 0.7327299 0.7442714 0.9101192 0.7446947 0.8228481 0.7799326 0.7758534\n대구   0.8569582 0.8808684 0.7919992 0.8916729 0.7529493 0.7733257 0.7310587\n대전   0.8299595 0.7944530 0.7953191 0.8034837 0.8213730 0.8704259 0.8213377\n목포   0.8942154 0.8090207 0.7153731 0.8140079 0.7268557 0.7968942 0.7271795\n백령도 0.6569948 0.6050058 0.6528630 0.6083347 0.7488592 0.7699792 0.7578969\n보성군 1.0000000 0.8653985 0.7314723 0.8705693 0.7214366 0.7724279 0.7120614\n부산   0.8653985 1.0000000 0.7360026 0.9244689 0.7053734 0.7304751 0.6877386\n북강릉 0.7314723 0.7360026 1.0000000 0.7398839 0.8043851 0.7695153 0.7591225\n북창원 0.8705693 0.9244689 0.7398839 1.0000000 0.7014921 0.7345072 0.6953645\n북춘천 0.7214366 0.7053734 0.8043851 0.7014921 1.0000000 0.8464304 0.8880320\n서산   0.7724279 0.7304751 0.7695153 0.7345072 0.8464304 1.0000000 0.8712843\n서울   0.7120614 0.6877386 0.7591225 0.6953645 0.8880320 0.8712843 1.0000000\n수원   0.7561238 0.7237300 0.7878541 0.7301601 0.8852839 0.9103966 0.9294995\n순창군 0.8942576 0.8320893 0.7552090 0.8391475 0.7614330 0.8123020 0.7569485\n안동   0.8300610 0.8337583 0.8292302 0.8440515 0.8065327 0.8132446 0.7781851\n양산시 0.8585161 0.9411281 0.7512068 0.9362627 0.7165714 0.7385374 0.6980767\n여수   0.9260953 0.8928121 0.7257559 0.8905387 0.7162523 0.7568196 0.7044715\n영광군 0.8700168 0.8028268 0.7281906 0.8095866 0.7482024 0.8202048 0.7523703\n울릉도 0.7099740 0.7471160 0.7369568 0.7435075 0.7046652 0.7065594 0.6669393\n원주   0.7523637 0.7330975 0.8201516 0.7353742 0.8893776 0.8609313 0.8716929\n의령군 0.8928065 0.9020603 0.7543172 0.9237839 0.7274792 0.7574265 0.7079273\n인천   0.7437245 0.7054006 0.7634885 0.7061770 0.8776439 0.9001509 0.9251643\n전주   0.8502945 0.8077149 0.7640608 0.8173279 0.7769179 0.8383011 0.7811974\n제주   0.7959999 0.7647027 0.6343205 0.7553778 0.6176302 0.6668662 0.5969400\n진주   0.9057814 0.9008628 0.7426414 0.9217478 0.7172328 0.7602648 0.7066561\n창원   0.8864386 0.9321884 0.7449116 0.9553970 0.7199012 0.7514318 0.6986658\n철원   0.7072997 0.6818365 0.7730390 0.6789079 0.9255283 0.8408882 0.8933250\n청송군 0.8164553 0.8458486 0.8175297 0.8546239 0.7650954 0.7701954 0.7380262\n청주   0.7994026 0.7665014 0.7982529 0.7769299 0.8385112 0.8855845 0.8415998\n추풍령 0.8496216 0.8397673 0.8059089 0.8475369 0.7835218 0.8120067 0.7664872\n춘천   0.7274171 0.7070234 0.8031310 0.7027904 0.9731768 0.8471127 0.8912841\n포항   0.8008197 0.8636413 0.7878648 0.8658308 0.7105419 0.7226261 0.6859115\n함양군 0.8869784 0.8606665 0.7627671 0.8766537 0.7485743 0.7891970 0.7329445\n홍성   0.7928560 0.7478028 0.7820003 0.7557474 0.8345775 0.9434424 0.8540948\n흑산도 0.8049325 0.7432957 0.6578724 0.7381646 0.6802003 0.7603084 0.6815248\n            수원    순창군      안동    양산시      여수    영광군    울릉도\n강릉   0.7783023 0.7477589 0.8229087 0.7420517 0.7224022 0.7199346 0.7249746\n강진군 0.7568028 0.8975007 0.8124436 0.8297895 0.8869236 0.8802219 0.7068337\n경주시 0.7172262 0.8024646 0.8620901 0.8982046 0.8229676 0.7709653 0.7591943\n고산   0.6803819 0.7772885 0.7209146 0.7489133 0.8053798 0.7998266 0.6533281\n고창   0.8051685 0.9201761 0.8361734 0.8166139 0.8417374 0.9641461 0.7212534\n고창군 0.7995755 0.9223830 0.8326433 0.8102864 0.8333109 0.9451684 0.7202619\n광양시 0.7589846 0.8847395 0.8380486 0.8794260 0.9373270 0.8482541 0.7193463\n광주   0.7737683 0.9272002 0.8283607 0.8177595 0.8493501 0.9057378 0.7132909\n김해시 0.7260335 0.8289053 0.8429188 0.9521355 0.8819975 0.7998990 0.7400635\n대관령 0.8012578 0.7593288 0.8384814 0.7577321 0.7367787 0.7304388 0.7387259\n대구   0.7700634 0.8619748 0.8925808 0.8970682 0.8583893 0.8286563 0.7683306\n대전   0.8652538 0.8794022 0.8807708 0.8062842 0.8134349 0.8597324 0.7448819\n목포   0.7720480 0.8893603 0.8055843 0.8069924 0.8548388 0.9188443 0.7094023\n백령도 0.7594207 0.6721664 0.6524766 0.6097318 0.6442821 0.6817800 0.5787507\n보성군 0.7561238 0.8942576 0.8300610 0.8585161 0.9260953 0.8700168 0.7099740\n부산   0.7237300 0.8320893 0.8337583 0.9411281 0.8928121 0.8028268 0.7471160\n북강릉 0.7878541 0.7552090 0.8292302 0.7512068 0.7257559 0.7281906 0.7369568\n북창원 0.7301601 0.8391475 0.8440515 0.9362627 0.8905387 0.8095866 0.7435075\n북춘천 0.8852839 0.7614330 0.8065327 0.7165714 0.7162523 0.7482024 0.7046652\n서산   0.9103966 0.8123020 0.8132446 0.7385374 0.7568196 0.8202048 0.7065594\n서울   0.9294995 0.7569485 0.7781851 0.6980767 0.7044715 0.7523703 0.6669393\n수원   1.0000000 0.7963496 0.8152007 0.7325813 0.7450592 0.7978568 0.7018066\n순창군 0.7963496 1.0000000 0.8571997 0.8384777 0.8624229 0.9055046 0.7358091\n안동   0.8152007 0.8571997 1.0000000 0.8492824 0.8257826 0.8247471 0.7778509\n양산시 0.7325813 0.8384777 0.8492824 1.0000000 0.8788297 0.8068656 0.7520630\n여수   0.7450592 0.8624229 0.8257826 0.8788297 1.0000000 0.8369935 0.7083689\n영광군 0.7978568 0.9055046 0.8247471 0.8068656 0.8369935 1.0000000 0.7240009\n울릉도 0.7018066 0.7358091 0.7778509 0.7520630 0.7083689 0.7240009 1.0000000\n원주   0.8932862 0.7995618 0.8543312 0.7450469 0.7404038 0.7818861 0.7275374\n의령군 0.7498167 0.8660499 0.8546061 0.9093550 0.9069745 0.8311861 0.7416053\n인천   0.9277949 0.7722378 0.7820094 0.7111549 0.7312228 0.7794496 0.6793449\n전주   0.8245585 0.9059995 0.8588714 0.8154674 0.8271208 0.8955517 0.7351030\n제주   0.6397318 0.7616506 0.7110714 0.7488517 0.7885493 0.7795366 0.6754414\n진주   0.7474439 0.8691255 0.8473833 0.8990435 0.9184982 0.8375318 0.7309659\n창원   0.7378704 0.8515362 0.8480343 0.9309611 0.9077339 0.8219253 0.7501301\n철원   0.8798808 0.7417757 0.7699446 0.6935911 0.6957997 0.7361521 0.6830782\n청송군 0.7706801 0.8376779 0.9264677 0.8601384 0.8210849 0.7987202 0.7721911\n청주   0.8834187 0.8540764 0.8672225 0.7796850 0.7861436 0.8368720 0.7466784\n추풍령 0.8084938 0.8841590 0.9119007 0.8518558 0.8362716 0.8477300 0.7629999\n춘천   0.8895352 0.7683245 0.8092655 0.7175429 0.7194752 0.7534400 0.7044135\n포항   0.7217079 0.7999456 0.8637574 0.8797223 0.8139715 0.7668033 0.7646536\n함양군 0.7766888 0.9041378 0.8747375 0.8710237 0.8771199 0.8562663 0.7440533\n홍성   0.9031126 0.8320726 0.8342946 0.7598523 0.7731670 0.8341619 0.7174028\n흑산도 0.7291019 0.7936983 0.7299876 0.7391625 0.7747905 0.8281585 0.6667363\n            원주    의령군      인천      전주      제주      진주      창원\n강릉   0.8140140 0.7482024 0.7528825 0.7559655 0.6288149 0.7360999 0.7359527\n강진군 0.7470349 0.8586170 0.7408405 0.8532850 0.8025710 0.8707244 0.8550384\n경주시 0.7367868 0.8799885 0.6909296 0.7884779 0.7278624 0.8665368 0.8796000\n고산   0.6706000 0.7668327 0.6769771 0.7517062 0.8944810 0.7781282 0.7711443\n고창   0.7940990 0.8383795 0.7819980 0.9090750 0.7713076 0.8413993 0.8308083\n고창군 0.7931988 0.8297413 0.7702349 0.9179114 0.7571275 0.8361220 0.8192160\n광양시 0.7567017 0.9122636 0.7411685 0.8453850 0.7723644 0.9289161 0.9070658\n광주   0.7708492 0.8420095 0.7447416 0.8888634 0.7596200 0.8525976 0.8314682\n김해시 0.7337471 0.9095451 0.7045141 0.8112366 0.7419911 0.9057840 0.9390908\n대관령 0.8453858 0.7554448 0.7703520 0.7722900 0.6407150 0.7510854 0.7502029\n대구   0.7896731 0.9060476 0.7412998 0.8523081 0.7406006 0.8919844 0.8896739\n대전   0.8717413 0.8269171 0.8222485 0.9133086 0.7082283 0.8243969 0.8128315\n목포   0.7559130 0.8389763 0.7609958 0.8622079 0.8051050 0.8485560 0.8293878\n백령도 0.6905395 0.6318475 0.8040668 0.6592059 0.6046135 0.6387758 0.6228163\n보성군 0.7523637 0.8928065 0.7437245 0.8502945 0.7959999 0.9057814 0.8864386\n부산   0.7330975 0.9020603 0.7054006 0.8077149 0.7647027 0.9008628 0.9321884\n북강릉 0.8201516 0.7543172 0.7634885 0.7640608 0.6343205 0.7426414 0.7449116\n북창원 0.7353742 0.9237839 0.7061770 0.8173279 0.7553778 0.9217478 0.9553970\n북춘천 0.8893776 0.7274792 0.8776439 0.7769179 0.6176302 0.7172328 0.7199012\n서산   0.8609313 0.7574265 0.9001509 0.8383011 0.6668662 0.7602648 0.7514318\n서울   0.8716929 0.7079273 0.9251643 0.7811974 0.5969400 0.7066561 0.6986658\n수원   0.8932862 0.7498167 0.9277949 0.8245585 0.6397318 0.7474439 0.7378704\n순창군 0.7995618 0.8660499 0.7722378 0.9059995 0.7616506 0.8691255 0.8515362\n안동   0.8543312 0.8546061 0.7820094 0.8588714 0.7110714 0.8473833 0.8480343\n양산시 0.7450469 0.9093550 0.7111549 0.8154674 0.7488517 0.8990435 0.9309611\n여수   0.7404038 0.9069745 0.7312228 0.8271208 0.7885493 0.9184982 0.9077339\n영광군 0.7818861 0.8311861 0.7794496 0.8955517 0.7795366 0.8375318 0.8219253\n울릉도 0.7275374 0.7416053 0.6793449 0.7351030 0.6754414 0.7309659 0.7501301\n원주   1.0000000 0.7577556 0.8514177 0.8337043 0.6416255 0.7484442 0.7474502\n의령군 0.7577556 1.0000000 0.7300582 0.8351702 0.7619990 0.9462497 0.9355706\n인천   0.8514177 0.7300582 1.0000000 0.7847122 0.6334885 0.7307739 0.7243945\n전주   0.8337043 0.8351702 0.7847122 1.0000000 0.7276156 0.8384768 0.8222323\n제주   0.6416255 0.7619990 0.6334885 0.7276156 1.0000000 0.7731759 0.7730517\n진주   0.7484442 0.9462497 0.7307739 0.8384768 0.7731759 1.0000000 0.9325524\n창원   0.7474502 0.9355706 0.7243945 0.8222323 0.7730517 0.9325524 1.0000000\n철원   0.8634073 0.6982029 0.8874605 0.7560478 0.6132508 0.6922773 0.6958414\n청송군 0.8102739 0.8580750 0.7407527 0.8302317 0.7115593 0.8479342 0.8533791\n청주   0.8911557 0.7962606 0.8365598 0.8843604 0.6859250 0.7954768 0.7876874\n추풍령 0.8339665 0.8649878 0.7770587 0.8886191 0.7341553 0.8611533 0.8539492\n춘천   0.8887503 0.7304621 0.8839953 0.7780728 0.6258659 0.7205106 0.7222870\n포항   0.7470316 0.8650930 0.6997455 0.7838372 0.7128223 0.8506123 0.8611485\n함양군 0.7852669 0.9035722 0.7567638 0.8767203 0.7625222 0.9016603 0.8816933\n홍성   0.8600133 0.7780833 0.8718450 0.8638290 0.6740860 0.7773982 0.7699036\n흑산도 0.6964196 0.7585652 0.7266833 0.7716874 0.7560648 0.7680741 0.7599527\n            철원    청송군      청주    추풍령      춘천      포항    함양군\n강릉   0.7613446 0.8119685 0.7906018 0.7994430 0.7901031 0.7800426 0.7573195\n강진군 0.7099067 0.8001702 0.7990762 0.8366508 0.7224999 0.7743982 0.8647581\n경주시 0.6728015 0.8917156 0.7691019 0.8551957 0.6979233 0.9299494 0.8575342\n고산   0.6511250 0.7111140 0.7160675 0.7404377 0.6616856 0.6950692 0.7611798\n고창   0.7463221 0.8110318 0.8455261 0.8598107 0.7671444 0.7746035 0.8670402\n고창군 0.7376000 0.8101408 0.8479594 0.8605002 0.7562610 0.7687438 0.8639479\n광양시 0.7094024 0.8313951 0.8049821 0.8527017 0.7326951 0.8202247 0.8876091\n광주   0.7141419 0.8116415 0.8225686 0.8482247 0.7305449 0.7778093 0.8701505\n김해시 0.6791410 0.8518849 0.7730950 0.8438536 0.7020522 0.8596690 0.8646009\n대관령 0.7858886 0.8355435 0.8121126 0.8160104 0.8162753 0.7870301 0.7805615\n대구   0.7253687 0.9033966 0.8217519 0.9001672 0.7528873 0.8946346 0.9048076\n대전   0.7919180 0.8409124 0.9340775 0.8990270 0.8238574 0.7903350 0.8635005\n목포   0.7195667 0.7873538 0.8073679 0.8302442 0.7337111 0.7591535 0.8491819\n백령도 0.7786030 0.6156391 0.6890909 0.6497277 0.7573548 0.5899988 0.6557867\n보성군 0.7072997 0.8164553 0.7994026 0.8496216 0.7274171 0.8008197 0.8869784\n부산   0.6818365 0.8458486 0.7665014 0.8397673 0.7070234 0.8636413 0.8606665\n북강릉 0.7730390 0.8175297 0.7982529 0.8059089 0.8031310 0.7878648 0.7627671\n북창원 0.6789079 0.8546239 0.7769299 0.8475369 0.7027904 0.8658308 0.8766537\n북춘천 0.9255283 0.7650954 0.8385112 0.7835218 0.9731768 0.7105419 0.7485743\n서산   0.8408882 0.7701954 0.8855845 0.8120067 0.8471127 0.7226261 0.7891970\n서울   0.8933250 0.7380262 0.8415998 0.7664872 0.8912841 0.6859115 0.7329445\n수원   0.8798808 0.7706801 0.8834187 0.8084938 0.8895352 0.7217079 0.7766888\n순창군 0.7417757 0.8376779 0.8540764 0.8841590 0.7683245 0.7999456 0.9041378\n안동   0.7699446 0.9264677 0.8672225 0.9119007 0.8092655 0.8637574 0.8747375\n양산시 0.6935911 0.8601384 0.7796850 0.8518558 0.7175429 0.8797223 0.8710237\n여수   0.6957997 0.8210849 0.7861436 0.8362716 0.7194752 0.8139715 0.8771199\n영광군 0.7361521 0.7987202 0.8368720 0.8477300 0.7534400 0.7668033 0.8562663\n울릉도 0.6830782 0.7721911 0.7466784 0.7629999 0.7044135 0.7646536 0.7440533\n원주   0.8634073 0.8102739 0.8911557 0.8339665 0.8887503 0.7470316 0.7852669\n의령군 0.6982029 0.8580750 0.7962606 0.8649878 0.7304621 0.8650930 0.9035722\n인천   0.8874605 0.7407527 0.8365598 0.7770587 0.8839953 0.6997455 0.7567638\n전주   0.7560478 0.8302317 0.8843604 0.8886191 0.7780728 0.7838372 0.8767203\n제주   0.6132508 0.7115593 0.6859250 0.7341553 0.6258659 0.7128223 0.7625222\n진주   0.6922773 0.8479342 0.7954768 0.8611533 0.7205106 0.8506123 0.9016603\n창원   0.6958414 0.8533791 0.7876874 0.8539492 0.7222870 0.8611485 0.8816933\n철원   1.0000000 0.7343021 0.8133196 0.7573181 0.9232183 0.6811928 0.7266237\n청송군 0.7343021 1.0000000 0.8260340 0.8971555 0.7659701 0.8941903 0.8691234\n청주   0.8133196 0.8260340 1.0000000 0.8773984 0.8408750 0.7681914 0.8314643\n추풍령 0.7573181 0.8971555 0.8773984 1.0000000 0.7862335 0.8528547 0.9021148\n춘천   0.9232183 0.7659701 0.8408750 0.7862335 1.0000000 0.7134771 0.7513840\n포항   0.6811928 0.8941903 0.7681914 0.8528547 0.7134771 1.0000000 0.8442816\n함양군 0.7266237 0.8691234 0.8314643 0.9021148 0.7513840 0.8442816 1.0000000\n홍성   0.8196972 0.7909038 0.9026294 0.8342819 0.8404144 0.7409981 0.8102419\n흑산도 0.6798892 0.7072905 0.7423761 0.7510629 0.6921622 0.6976962 0.7705203\n            홍성    흑산도\n강릉   0.7739988 0.6521117\n강진군 0.7936477 0.8186882\n경주시 0.7400062 0.7064828\n고산   0.7120808 0.7694346\n고창   0.8396157 0.8178804\n고창군 0.8379117 0.7992953\n광양시 0.7897796 0.7803099\n광주   0.8075240 0.7870179\n김해시 0.7518216 0.7320231\n대관령 0.7897041 0.6528066\n대구   0.7956803 0.7385520\n대전   0.8969670 0.7535020\n목포   0.8068467 0.8404021\n백령도 0.7400695 0.6941095\n보성군 0.7928560 0.8049325\n부산   0.7478028 0.7432957\n북강릉 0.7820003 0.6578724\n북창원 0.7557474 0.7381646\n북춘천 0.8345775 0.6802003\n서산   0.9434424 0.7603084\n서울   0.8540948 0.6815248\n수원   0.9031126 0.7291019\n순창군 0.8320726 0.7936983\n안동   0.8342946 0.7299876\n양산시 0.7598523 0.7391625\n여수   0.7731670 0.7747905\n영광군 0.8341619 0.8281585\n울릉도 0.7174028 0.6667363\n원주   0.8600133 0.6964196\n의령군 0.7780833 0.7585652\n인천   0.8718450 0.7266833\n전주   0.8638290 0.7716874\n제주   0.6740860 0.7560648\n진주   0.7773982 0.7680741\n창원   0.7699036 0.7599527\n철원   0.8196972 0.6798892\n청송군 0.7909038 0.7072905\n청주   0.9026294 0.7423761\n추풍령 0.8342819 0.7510629\n춘천   0.8404144 0.6921622\n포항   0.7409981 0.6976962\n함양군 0.8102419 0.7705203\n홍성   1.0000000 0.7597044\n흑산도 0.7597044 1.0000000\n\n\n\ncorrplot(round(weight,2), method = 'number')\n\n\n\n\n\nwrite.csv(df1, './data/restructuring_prep_data.csv', row.names = FALSE)\n\n\n\n\n\n\n\n\n\n\n\n\n요인\n제곱합\n자유도\n평균제곱\n\\(F_0\\)\n유의확률\n\n\n\n\n회귀\n\\(SSR\\)\n\\(1\\)\n\\(MSR = \\frac{SSR}{1}\\)\n\\(\\frac{MSR}{MSE}\\)\n\\(P(F\\geq F_0)\\)\n\n\n잔차\n\\(SSE\\)\n\\(n-1\\)\n\\(MSE=\\frac{SSE}{n-1}\\)\n\n\n\n\n계\n\\(SST\\)\n\\(n\\)"
  },
  {
    "objectID": "posts/SOLAR/2023-04-08-solar-stgcn-ver2-lag4.html",
    "href": "posts/SOLAR/2023-04-08-solar-stgcn-ver2-lag4.html",
    "title": "[SOLAR] STGCN Ver2 lag4",
    "section": "",
    "text": "import pandas as pd\nimport numpy as np\nimport json\nimport urllib\n\nimport matplotlib.pyplot as plt\nimport time\n\n\n# 일반적인 모듈 \nimport numpy as np\nimport matplotlib.pyplot as plt \nimport networkx as nx \nfrom tqdm import tqdm \n\n# 파이토치 관련 \nimport torch\nimport torch.nn.functional as F\n\n# PyG 관련 \nfrom torch_geometric.data import Data ## Data: 그래프자료형을 만드는 클래스\n\n# STGCN 관련 \nimport torch_geometric_temporal\nfrom torch_geometric_temporal.nn.recurrent import GConvGRU\nfrom torch_geometric_temporal.signal import temporal_signal_split \n\n\nclass RecurrentGCN(torch.nn.Module):\n    def __init__(self, node_features, filters):\n        super(RecurrentGCN, self).__init__()\n        self.recurrent = GConvGRU(node_features, filters, 2)\n        self.linear = torch.nn.Linear(filters, 1)\n\n    def forward(self, x, edge_index, edge_weight):\n        h = self.recurrent(x, edge_index, edge_weight)\n        h = F.relu(h)\n        h = self.linear(h)\n        return h\n\n\nfrom mysolar import SolarEPTDatasetLoader\n\n\nloader = SolarEPTDatasetLoader()\ndataset = loader.get_dataset(lags=4)\ntrain_dataset, test_dataset = temporal_signal_split(dataset, train_ratio=0.8)\n\n\ndataset.edge_index.shape\n\n(2, 1892)"
  },
  {
    "objectID": "posts/SOLAR/2023-04-08-solar-stgcn-ver2-lag4.html#learn",
    "href": "posts/SOLAR/2023-04-08-solar-stgcn-ver2-lag4.html#learn",
    "title": "[SOLAR] STGCN Ver2 lag4",
    "section": "Learn",
    "text": "Learn\n\nmodel = RecurrentGCN(node_features=4, filters=32)\noptimizer = torch.optim.Adam(model.parameters(), lr=0.01)\nmodel.train()\n\nRecurrentGCN(\n  (recurrent): GConvGRU(\n    (conv_x_z): ChebConv(4, 32, K=2, normalization=sym)\n    (conv_h_z): ChebConv(32, 32, K=2, normalization=sym)\n    (conv_x_r): ChebConv(4, 32, K=2, normalization=sym)\n    (conv_h_r): ChebConv(32, 32, K=2, normalization=sym)\n    (conv_x_h): ChebConv(4, 32, K=2, normalization=sym)\n    (conv_h_h): ChebConv(32, 32, K=2, normalization=sym)\n  )\n  (linear): Linear(in_features=32, out_features=1, bias=True)\n)\n\n\n\n# start = time.time()\n# for epoch in tqdm(range(50)):\n#     for t, snapshot in enumerate(train_dataset):\n#         yt_hat = model(snapshot.x, snapshot.edge_index, snapshot.edge_attr)\n#         cost = torch.mean((yt_hat-snapshot.y)**2)\n#         cost.backward()\n#         optimizer.step()\n#         optimizer.zero_grad()\n# end = time.time()\n# print(f\"{end-start:.5f} sec\")\n\n100%|█████████████████████████████████████████████████████████████████| 50/50 [40:30<00:00, 48.61s/it]\n\n\n2430.25206 sec\n\n\n\n\n\n\nimport pickle \nwith open('stgcn2.pickle','wb') as fw:\n    pickle.dump(model, fw)\n\n\nimport pickle \nwith open('stgcn2.pickle', 'rb') as f: \n    model = pickle.load(f)\n\n\nmodel\n\nRecurrentGCN(\n  (recurrent): GConvGRU(\n    (conv_x_z): ChebConv(4, 32, K=2, normalization=sym)\n    (conv_h_z): ChebConv(32, 32, K=2, normalization=sym)\n    (conv_x_r): ChebConv(4, 32, K=2, normalization=sym)\n    (conv_h_r): ChebConv(32, 32, K=2, normalization=sym)\n    (conv_x_h): ChebConv(4, 32, K=2, normalization=sym)\n    (conv_h_h): ChebConv(32, 32, K=2, normalization=sym)\n  )\n  (linear): Linear(in_features=32, out_features=1, bias=True)\n)"
  },
  {
    "objectID": "posts/SOLAR/2023-04-08-solar-stgcn-ver2-lag4.html#모델평가",
    "href": "posts/SOLAR/2023-04-08-solar-stgcn-ver2-lag4.html#모델평가",
    "title": "[SOLAR] STGCN Ver2 lag4",
    "section": "모델평가",
    "text": "모델평가\n\nmodel.eval()\ncost = 0\nfor time, snapshot in enumerate(train_dataset):\n    y_hat = model(snapshot.x, snapshot.edge_index, snapshot.edge_attr)\n    cost = cost + torch.mean((y_hat-snapshot.y)**2)\ncost = cost / (time+1)\ncost = cost.item()\nprint(\"MSE: {:.4f}\".format(cost))\n\nMSE: 0.1069\n\n\n\nmodel.eval()\ncost = 0\nfor time, snapshot in enumerate(test_dataset):\n    y_hat = model(snapshot.x, snapshot.edge_index, snapshot.edge_attr)\n    cost = cost + torch.mean((y_hat-snapshot.y)**2)\ncost = cost / (time+1)\ncost = cost.item()\nprint(\"MSE: {:.4f}\".format(cost))\n\nMSE: 0.0938"
  },
  {
    "objectID": "posts/SOLAR/2023-04-08-solar-stgcn-ver2-lag4.html#visualization",
    "href": "posts/SOLAR/2023-04-08-solar-stgcn-ver2-lag4.html#visualization",
    "title": "[SOLAR] STGCN Ver2 lag4",
    "section": "Visualization",
    "text": "Visualization\n\nyhat_train = torch.stack([model(snapshot.x,snapshot.edge_index, snapshot.edge_attr) for snapshot in train_dataset]).detach().numpy()\nyhat_test = torch.stack([model(snapshot.x,snapshot.edge_index, snapshot.edge_attr) for snapshot in test_dataset]).detach().numpy()\n\n\nyhat_train.shape\n\n(14596, 44, 1)\n\n\n\nf.shape\n\n(18250, 44)\n\n\n\ntime\n\n14595\n\n\n\ndf = pd.read_csv(\"./data/solar_radiation.csv\")\n\n\ndf['date'][0]>= '2021-01-01-00:00'\n\nTrue\n\n\n\ndf.region.unique()\n\narray(['북춘천', '철원', '대관령', '춘천', '백령도', '북강릉', '강릉', '서울', '인천', '원주',\n       '울릉도', '수원', '서산', '청주', '대전', '추풍령', '안동', '포항', '대구', '전주', '창원',\n       '광주', '부산', '목포', '여수', '흑산도', '고창', '홍성', '제주', '고산', '진주', '고창군',\n       '영광군', '김해시', '순창군', '북창원', '양산시', '보성군', '강진군', '의령군', '함양군',\n       '광양시', '청송군', '경주시'], dtype=object)\n\n\n\nreg=['부산','창원','김해시','서울','인천','울릉도','고창','포항','대구','창원','북창원']\nreg2=['부산','김해시','서울','인천']\n\n\ndf.query(\"date >= '2022-07-01-01:00' and date <= '2022-07-20-23:00' and region in @reg2\").drop_duplicates()\\\n.plot(backend='plotly',x='date',y='solar_radiation',color='region')"
  },
  {
    "objectID": "posts/SOLAR/2023-04-08-solar-stgcn-ver2-lag4.html#월-8월15-8월15-9월15",
    "href": "posts/SOLAR/2023-04-08-solar-stgcn-ver2-lag4.html#월-8월15-8월15-9월15",
    "title": "[SOLAR] STGCN Ver2 lag4",
    "section": "6월-8월15 // 8월15 ~9월15",
    "text": "6월-8월15 // 8월15 ~9월15\n\ndf.query(\"date >= '2022-09-01-01:00' and date <= '2022-09-01-23:00' and ( region=='부산')\").drop_duplicates()\n\n\n\n\n\n  \n    \n      \n      region\n      solar_radiation\n      date\n    \n  \n  \n    \n      416701\n      부산\n      0.00\n      2022-09-01-01:00\n    \n    \n      416702\n      부산\n      0.00\n      2022-09-01-02:00\n    \n    \n      416703\n      부산\n      0.00\n      2022-09-01-03:00\n    \n    \n      416704\n      부산\n      0.00\n      2022-09-01-04:00\n    \n    \n      416705\n      부산\n      0.00\n      2022-09-01-05:00\n    \n    \n      416706\n      부산\n      0.00\n      2022-09-01-06:00\n    \n    \n      416707\n      부산\n      0.11\n      2022-09-01-07:00\n    \n    \n      416708\n      부산\n      0.44\n      2022-09-01-08:00\n    \n    \n      416709\n      부산\n      0.48\n      2022-09-01-09:00\n    \n    \n      416710\n      부산\n      0.29\n      2022-09-01-10:00\n    \n    \n      416711\n      부산\n      0.50\n      2022-09-01-11:00\n    \n    \n      416712\n      부산\n      0.35\n      2022-09-01-12:00\n    \n    \n      416713\n      부산\n      0.35\n      2022-09-01-13:00\n    \n    \n      416714\n      부산\n      0.46\n      2022-09-01-14:00\n    \n    \n      416715\n      부산\n      0.64\n      2022-09-01-15:00\n    \n    \n      416716\n      부산\n      0.59\n      2022-09-01-16:00\n    \n    \n      416717\n      부산\n      0.30\n      2022-09-01-17:00\n    \n    \n      416718\n      부산\n      0.18\n      2022-09-01-18:00\n    \n    \n      416719\n      부산\n      0.02\n      2022-09-01-19:00\n    \n    \n      416721\n      부산\n      0.00\n      2022-09-01-20:00\n    \n    \n      416723\n      부산\n      0.00\n      2022-09-01-21:00\n    \n  \n\n\n\n\n\nurl = 'https://raw.githubusercontent.com/pinkocto/noteda/main/posts/SOLAR/data/solar2.json'\n\n\ndata_dict = json.loads(urllib.request.urlopen(url).read())\nV = list(data_dict['node_ids'].keys())\nf = np.array(data_dict[\"FX\"])\n\n\nimport matplotlib.pyplot as plt\nplt.rcParams['font.family'] = 'NanumGothic'\n\n\nfig,ax = plt.subplots(44,1,figsize=(10,50))\nlag= 4 \nT = 100 \nfor k in range(44):\n    ax[k].plot(f[lag:(lag+T),k],'--',alpha=0.5,label='observed')\n#    ax[k].set_title('node: {}'.format(V[k]))\n    ax[k].plot(yhat_train[:T,k],label='predicted (tr)')\n#    ax[k].plot(range(yhat_train.shape[0],yhat_train.shape[0]+yhat_test.shape[0]),yhat_test[:,k],label='predicted (test)')\n    ax[k].legend()\nfig.tight_layout()\n\n# plt.savefig('stgcn-ver2-lag4-vis.png')\n\n\n\n\n\n깃헙 메모리문제(100MB 초과)"
  },
  {
    "objectID": "posts/SOLAR/2023-05-02-s-stgcn-ver2-정규화-시뮬레이션.html",
    "href": "posts/SOLAR/2023-05-02-s-stgcn-ver2-정규화-시뮬레이션.html",
    "title": "[SOLAR] STGCN Ver2 (data2, +N +S) 시뮬레이션 (epoch, filter, lag)",
    "section": "",
    "text": "train 2022-06-01 00:00:00 ~ 2022-08-14 17:00:00\ntest 2022-08-14 18:00:00 ~ 2022-09-15 23:00:00"
  },
  {
    "objectID": "posts/SOLAR/2023-05-02-s-stgcn-ver2-정규화-시뮬레이션.html#epoch",
    "href": "posts/SOLAR/2023-05-02-s-stgcn-ver2-정규화-시뮬레이션.html#epoch",
    "title": "[SOLAR] STGCN Ver2 (data2, +N +S) 시뮬레이션 (epoch, filter, lag)",
    "section": "50 epoch",
    "text": "50 epoch\n\nplans_stgcn = {\n    'max_iteration': 1,   # 30, \n    'method': ['EPT-STGCN'], \n    'lags': [4, 8, 12],  # [4, 8, 12]\n    'nof_filters': [16, 32, 64], # [16, 32, 64]\n    'epoch': [50] # [50, 100, 150]\n}\n\n\nplnr = eptstgcn.planner.NORMAL_PLNR_STGCN(plans_stgcn, data_dict, dataset_name='data2')\n\n\nplnr.simulate()\n\n1/1 is done\nAll results are stored in ./simulation_results/2023-05-02_23-15-22.csv\n\n\n\neptstgcn.save_data(plnr, './simul_model2/normal/stgcn_v2_50epoch_.pickle')\n\n\nsimul_model = eptstgcn.load_data('./simul_model2/normal/stgcn_v2_50epoch_.pickle')\n\n\ndf_simul_no = simul_model.simulation_results\ndf_simul_no\n\n\n\n\n\n  \n    \n      \n      dataset\n      method\n      normal\n      lags\n      nof_filters\n      epoch\n      mse(train)\n      mse(test)\n      calculation_time\n    \n  \n  \n    \n      0\n      data2\n      EPT-STGCN\n      O\n      4\n      16\n      50\n      0.191065\n      0.178842\n      295.075789\n    \n    \n      1\n      data2\n      EPT-STGCN\n      O\n      4\n      32\n      50\n      0.180618\n      0.166902\n      298.276487\n    \n    \n      2\n      data2\n      EPT-STGCN\n      O\n      4\n      64\n      50\n      0.185092\n      0.174121\n      307.609691\n    \n    \n      3\n      data2\n      EPT-STGCN\n      O\n      8\n      16\n      50\n      0.18884\n      0.17383\n      304.973405\n    \n    \n      4\n      data2\n      EPT-STGCN\n      O\n      8\n      32\n      50\n      0.21352\n      0.206142\n      308.73471\n    \n    \n      5\n      data2\n      EPT-STGCN\n      O\n      8\n      64\n      50\n      0.19473\n      0.184389\n      317.388223\n    \n    \n      6\n      data2\n      EPT-STGCN\n      O\n      12\n      16\n      50\n      0.184434\n      0.175556\n      311.789555\n    \n    \n      7\n      data2\n      EPT-STGCN\n      O\n      12\n      32\n      50\n      0.200415\n      0.192586\n      316.290751\n    \n    \n      8\n      data2\n      EPT-STGCN\n      O\n      12\n      64\n      50\n      0.189591\n      0.177227\n      325.705265\n    \n  \n\n\n\n\n\nprint('50에폭 끝')\n\n50에폭 끝"
  },
  {
    "objectID": "posts/SOLAR/2023-05-02-s-stgcn-ver2-정규화-시뮬레이션.html#epoch-1",
    "href": "posts/SOLAR/2023-05-02-s-stgcn-ver2-정규화-시뮬레이션.html#epoch-1",
    "title": "[SOLAR] STGCN Ver2 (data2, +N +S) 시뮬레이션 (epoch, filter, lag)",
    "section": "100epoch",
    "text": "100epoch\n\nplans_stgcn = {\n    'max_iteration': 1,   # 30, \n    'method': ['EPT-STGCN'], \n    'lags': [4, 8, 12],  # [4, 8, 12]\n    'nof_filters': [16, 32, 64], # [16, 32, 64]\n    'epoch': [100] # [50, 100, 150]\n}\n\n\nplnr = eptstgcn.planner.NORMAL_PLNR_STGCN(plans_stgcn, data_dict, dataset_name='data2')\n\n\nplnr.simulate()\n\n1/1 is done\nAll results are stored in ./simulation_results/2023-05-03_01-15-13.csv\n\n\n\neptstgcn.save_data(plnr,'./simul_model2/normal/stgcn_v2_100epoch.pickle')\n\n\nsimul_model_100 = eptstgcn.load_data('./simul_model2/normal/stgcn_v2_100epoch.pickle')\n\n\nsimul_model_100.simulation_results\n\n\n\n\n\n  \n    \n      \n      dataset\n      method\n      normal\n      lags\n      nof_filters\n      epoch\n      mse(train)\n      mse(test)\n      calculation_time\n    \n  \n  \n    \n      0\n      data2\n      EPT-STGCN\n      O\n      4\n      16\n      100\n      0.182457\n      0.168873\n      596.517389\n    \n    \n      1\n      data2\n      EPT-STGCN\n      O\n      4\n      32\n      100\n      0.193543\n      0.18523\n      600.148345\n    \n    \n      2\n      data2\n      EPT-STGCN\n      O\n      4\n      64\n      100\n      0.183424\n      0.172943\n      618.539936\n    \n    \n      3\n      data2\n      EPT-STGCN\n      O\n      8\n      16\n      100\n      0.196233\n      0.187182\n      610.896952\n    \n    \n      4\n      data2\n      EPT-STGCN\n      O\n      8\n      32\n      100\n      0.197261\n      0.188859\n      617.301779\n    \n    \n      5\n      data2\n      EPT-STGCN\n      O\n      8\n      64\n      100\n      0.200183\n      0.191655\n      641.214275\n    \n    \n      6\n      data2\n      EPT-STGCN\n      O\n      12\n      16\n      100\n      0.194866\n      0.188829\n      626.573932\n    \n    \n      7\n      data2\n      EPT-STGCN\n      O\n      12\n      32\n      100\n      0.184337\n      0.174792\n      629.810274\n    \n    \n      8\n      data2\n      EPT-STGCN\n      O\n      12\n      64\n      100\n      0.190618\n      0.183905\n      654.698985\n    \n  \n\n\n\n\n\nprint('100에폭 끝 ㅎㅎ')\n\n100에폭 끝 ㅎㅎ"
  },
  {
    "objectID": "posts/SOLAR/2023-05-02-s-stgcn-ver2-정규화-시뮬레이션.html#epoch-2",
    "href": "posts/SOLAR/2023-05-02-s-stgcn-ver2-정규화-시뮬레이션.html#epoch-2",
    "title": "[SOLAR] STGCN Ver2 (data2, +N +S) 시뮬레이션 (epoch, filter, lag)",
    "section": "150epoch",
    "text": "150epoch\n\nplans_stgcn = {\n    'max_iteration': 1,   # 30, \n    'method': ['EPT-STGCN'], \n    'lags': [4, 8, 12],  # [4, 8, 12]\n    'nof_filters': [16, 32, 64], # [16, 32, 64]\n    'epoch': [150] # [50, 100, 150]\n}\n\n\nplnr = eptstgcn.planner.NORMAL_PLNR_STGCN(plans_stgcn, data_dict, dataset_name='data2')\n\n\nplnr.simulate()\n\n1/1 is done\nAll results are stored in ./simulation_results/2023-05-03_04-19-37.csv\n\n\n\neptstgcn.save_data(plnr,'./simul_model2/normal/stgcn_v2_150epoch.pickle')\n\n\nsimul_model_150 = eptstgcn.load_data('./simul_model2/normal/stgcn_v2_150epoch.pickle')\n\n\nsimul_model_150.simulation_results\n\n\n\n\n\n  \n    \n      \n      dataset\n      method\n      normal\n      lags\n      nof_filters\n      epoch\n      mse(train)\n      mse(test)\n      calculation_time\n    \n  \n  \n    \n      0\n      data2\n      EPT-STGCN\n      O\n      4\n      16\n      150\n      0.183898\n      0.169314\n      888.254045\n    \n    \n      1\n      data2\n      EPT-STGCN\n      O\n      4\n      32\n      150\n      0.175188\n      0.162054\n      902.462598\n    \n    \n      2\n      data2\n      EPT-STGCN\n      O\n      4\n      64\n      150\n      0.185554\n      0.174865\n      931.726822\n    \n    \n      3\n      data2\n      EPT-STGCN\n      O\n      8\n      16\n      150\n      0.190883\n      0.178519\n      919.577805\n    \n    \n      4\n      data2\n      EPT-STGCN\n      O\n      8\n      32\n      150\n      0.196512\n      0.188642\n      931.657403\n    \n    \n      5\n      data2\n      EPT-STGCN\n      O\n      8\n      64\n      150\n      0.184796\n      0.175644\n      962.80743\n    \n    \n      6\n      data2\n      EPT-STGCN\n      O\n      12\n      16\n      150\n      0.183245\n      0.17361\n      937.009531\n    \n    \n      7\n      data2\n      EPT-STGCN\n      O\n      12\n      32\n      150\n      0.184576\n      0.173852\n      972.509811\n    \n    \n      8\n      data2\n      EPT-STGCN\n      O\n      12\n      64\n      150\n      0.182424\n      0.172484\n      1004.384947\n    \n  \n\n\n\n\n\nprint('stgcn ver2 150epoch 끝^.^')\n\nstgcn ver2 150epoch 끝^.^\n\n\n\nimport matplotlib.pyplot as plt\nplt.boxplot(df_simul_no['mse(test)'])\nplt.show()"
  },
  {
    "objectID": "posts/SOLAR/2023-04-09-lstm-prac.html",
    "href": "posts/SOLAR/2023-04-09-lstm-prac.html",
    "title": "LSTM for Time Series Prediction (연습)",
    "section": "",
    "text": "연습용, LSTM을 사용하여 시계열 예측 신경망 구축\n\n\nlookback이 의미하는바를 정확히 모르겠음.\n\nLet’s see how LSTM can be used to build a time series prediction neural network with an example.\nThe problem you will look at in this post is the international airline passengers prediction problem. This is a problem where, given a year and a month, the task is to predict the number of international airline passengers in units of 1,000. The data ranges from January 1949 to December 1960, or 12 years, with 144 observations.\nIt is a regression problem. That is, given the number of passengers (in unit of 1,000) the recent months, what is the number of passengers the next month. The dataset has only one feature: The number of passengers.\n\n국제 항공사 승객 수(1000명 단위)를 예측하는 문제\n데이터 범위는 1949년 1월부터 1960년 12월까지이며 1달단위로 관측된 데이터이며, 관측치는 \\(144(12\\times 12)\\)개\n\n\n\n\nimport matplotlib.pyplot as plt\nimport pandas as pd\n\n\ndf = pd.read_csv('https://raw.githubusercontent.com/jbrownlee/Datasets/master/airline-passengers.csv')\ndf.head()\n\n\n\n\n\n  \n    \n      \n      Month\n      Passengers\n    \n  \n  \n    \n      0\n      1949-01\n      112\n    \n    \n      1\n      1949-02\n      118\n    \n    \n      2\n      1949-03\n      132\n    \n    \n      3\n      1949-04\n      129\n    \n    \n      4\n      1949-05\n      121\n    \n  \n\n\n\n\n\ndf.info()\n\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 144 entries, 0 to 143\nData columns (total 2 columns):\n #   Column      Non-Null Count  Dtype \n---  ------      --------------  ----- \n 0   Month       144 non-null    object\n 1   Passengers  144 non-null    int64 \ndtypes: int64(1), object(1)\nmemory usage: 2.4+ KB\n\n\n\ntimeseries = df[['Passengers']].values.astype('float32')\n\nplt.plot(timeseries)\nplt.show()\n\n\n\n\nThis time series has 144 time steps. You can see from the plot that there is an upward trend. There are also some periodicity in the dataset that corresponds to the summer holiday period in the northern hemisphere. Usually a time series should be “detrended” to remove the linear trend component and normalized before processing. For simplicity, these are skipped in this projectc\n\n증가하는 추세를 보이지만 여기서는 따로 처리하지 않았음.\n\n\n\n\n\n# train-test split for time series\ntrain_size = int(len(timeseries) * 0.67) # train ratio = 67%\ntest_size = len(timeseries) - train_size\ntrain_size, test_size\n\n(96, 48)\n\n\n\ntrain, test = timeseries[:train_size], timeseries[train_size:]\n\n\ntrain.shape, test.shape\n\n((96, 1), (48, 1))\n\n\n\nimport torch\n\ndef create_dataset(dataset, lookback):\n    \"\"\"Transform a time series into a prediction dataset\n    \n    Args:\n        dataset: A numpy array of time series, first dimension is the time steps\n        lookback: Size of window for prediction\n    \"\"\"\n    X, y = [], []\n    for i in range(len(dataset)-lookback):\n        feature = dataset[i:i+lookback]\n        target = dataset[i+1:i+lookback+1]\n        X.append(feature)\n        y.append(target)\n    return torch.tensor(X), torch.tensor(y)\n\nThis function is designed to apply windows on the time series. It is assumed to predict for one time step into the immediate future. It is designed to convert a time series into a tensor of dimensions (window sample, time steps, features). A time series of time steps can produce roughly windows (because a window can start from any time step as long as the window does not go beyond the boundary of the time series). Within one window, there are multiple consecutive time steps of values. In each time step, there can be multiple features. In this dataset, there is only one.\n\n\n\n\nlookback = 1\nX_train, y_train = create_dataset(train, lookback=lookback)\nX_test, y_test = create_dataset(test, lookback=lookback)\nprint(X_train.shape, y_train.shape)\nprint(X_test.shape, y_test.shape)\n\ntorch.Size([95, 1, 1]) torch.Size([95, 1, 1])\ntorch.Size([47, 1, 1]) torch.Size([47, 1, 1])\n\n\n\nX_train[:5]\n\ntensor([[[112.]],\n\n        [[118.]],\n\n        [[132.]],\n\n        [[129.]],\n\n        [[121.]]])\n\n\n\ny_train[:5]\n\ntensor([[[118.]],\n\n        [[132.]],\n\n        [[129.]],\n\n        [[121.]],\n\n        [[135.]]])\n\n\nNow you can build the LSTM model to predict the time series. With lookback=1, it is quite surely that the accuracy would not be good for too little clues to predict. But this is a good example to demonstrate the structure of the LSTM model.\n\n\n\nThe model is created as a class, in which a LSTM layer and a fully-connected layer is used.\n\nimport torch.nn as nn\n \nclass AirModel(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.lstm = nn.LSTM(input_size=1, hidden_size=50, num_layers=1, batch_first=True)\n        self.linear = nn.Linear(50, 1)\n    def forward(self, x):\n        x, _ = self.lstm(x)\n        x = self.linear(x)\n        return x\n\nThe output of nn.LSTM() is a tuple. The first element is the generated hidden states, one for each time step of the input. The second element is the LSTM cell’s memory and hidden states, which is not used here.\n\n\n\nBecause it is a regression problem, MSE is chosen as the loss function, which is to be minimized by Adam optimizer. In the code below, the PyTorch tensors are combined into a dataset using torch.utils.data.TensorDataset() and batch for training is provided by a DataLoader. The model performance is evaluated once per 100 epochs, on both the trainning set and the test set:\n\nimport numpy as np\nimport torch.optim as optim\nimport torch.utils.data as data\n \nmodel = AirModel()\noptimizer = optim.Adam(model.parameters())\nloss_fn = nn.MSELoss()\nloader = data.DataLoader(data.TensorDataset(X_train, y_train), shuffle=True, batch_size=8)\n \nn_epochs = 2000\nfor epoch in range(n_epochs):\n    model.train()\n    for X_batch, y_batch in loader:\n        y_pred = model(X_batch)\n        loss = loss_fn(y_pred, y_batch)\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n    # Validation\n    if epoch % 100 != 0:\n        continue\n    model.eval()\n    with torch.no_grad():\n        y_pred = model(X_train)\n        train_rmse = np.sqrt(loss_fn(y_pred, y_train))\n        y_pred = model(X_test)\n        test_rmse = np.sqrt(loss_fn(y_pred, y_test))\n    print(\"Epoch %d: train RMSE %.4f, test RMSE %.4f\" % (epoch, train_rmse, test_rmse))\n\nEpoch 0: train RMSE 225.9365, test RMSE 422.3676\nEpoch 100: train RMSE 184.9790, test RMSE 379.4668\nEpoch 200: train RMSE 152.4027, test RMSE 344.3236\nEpoch 300: train RMSE 124.2188, test RMSE 312.2975\nEpoch 400: train RMSE 101.0204, test RMSE 283.2189\nEpoch 500: train RMSE 82.6843, test RMSE 257.0794\nEpoch 600: train RMSE 66.4356, test RMSE 231.9688\nEpoch 700: train RMSE 54.0870, test RMSE 208.9810\nEpoch 800: train RMSE 44.0830, test RMSE 188.2280\nEpoch 900: train RMSE 37.0532, test RMSE 169.9665\nEpoch 1000: train RMSE 32.5043, test RMSE 154.2343\nEpoch 1100: train RMSE 28.9322, test RMSE 141.3780\nEpoch 1200: train RMSE 27.4202, test RMSE 131.0028\nEpoch 1300: train RMSE 25.8251, test RMSE 122.6009\nEpoch 1400: train RMSE 25.7696, test RMSE 116.9653\nEpoch 1500: train RMSE 24.2167, test RMSE 111.3310\nEpoch 1600: train RMSE 24.6531, test RMSE 106.7048\nEpoch 1700: train RMSE 24.3270, test RMSE 103.3886\nEpoch 1800: train RMSE 23.5308, test RMSE 101.1581\nEpoch 1900: train RMSE 23.3630, test RMSE 99.4288\n\n\nAs the dataset is small, the model should be trained for long enough to learn about the pattern. Over these 2000 epochs trained, you should see the RMSE on both training set and test set decreasing:\nIt is expected to see the RMSE of test set is an order of magnitude larger. The RMSE of 100 means the prediction and the actual target would be in average off by 100 in value (i.e., 100,000 passengers in this dataset).\n\nimport matplotlib.pyplot as plt\nplt.rcParams['font.family'] = 'NanumGothic'\n\n\nwith torch.no_grad():\n    # shift train predictions for plotting\n    train_plot = np.ones_like(timeseries) * np.nan\n    y_pred = model(X_train)\n    y_pred = y_pred[:, -1, :]\n    train_plot[lookback:train_size] = model(X_train)[:, -1, :]\n    # shift test predictions for plotting\n    test_plot = np.ones_like(timeseries) * np.nan\n    test_plot[train_size+lookback:len(timeseries)] = model(X_test)[:, -1, :]\n# plot\nplt.plot(timeseries, c='b', label = '실제관측치')\nplt.plot(train_plot, c='r', label = 'train')\nplt.plot(test_plot, c='g', label = 'test')\nplt.legend()\nplt.show()\n\n\n\n\nThe training set is plotted in red while the test set is plotted in green. The blue curve is what the actual data looks like. You can see that the model can fit well to the training set but not very well on the test set.\n\ntraining set 에 대해서는 잘 맞추는 것 같은데 test set에 대해서는 잘 맞추지 못한다.\n\nTying together, below is the complete code, except the parameter lookback is set to 4 this time:\n\n\n\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.utils.data as data\n \ndf = pd.read_csv('https://raw.githubusercontent.com/jbrownlee/Datasets/master/airline-passengers.csv')\ntimeseries = df[[\"Passengers\"]].values.astype('float32')\n \n# train-test split for time series\ntrain_size = int(len(timeseries) * 0.67)\ntest_size = len(timeseries) - train_size\ntrain, test = timeseries[:train_size], timeseries[train_size:]\n \ndef create_dataset(dataset, lookback):\n    \"\"\"Transform a time series into a prediction dataset\n    \n    Args:\n        dataset: A numpy array of time series, first dimension is the time steps\n        lookback: Size of window for prediction\n    \"\"\"\n    X, y = [], []\n    for i in range(len(dataset)-lookback):\n        feature = dataset[i:i+lookback]\n        target = dataset[i+1:i+lookback+1]\n        X.append(feature)\n        y.append(target)\n    return torch.tensor(X), torch.tensor(y)\n \n## 이번에는 lookback을 4로 놓을 것.    \nlookback = 4\nX_train, y_train = create_dataset(train, lookback=lookback)\nX_test, y_test = create_dataset(test, lookback=lookback)\n \nclass AirModel(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.lstm = nn.LSTM(input_size=1, hidden_size=50, num_layers=1, batch_first=True)\n        self.linear = nn.Linear(50, 1)\n    def forward(self, x):\n        x, _ = self.lstm(x)\n        x = self.linear(x)\n        return x\n \nmodel = AirModel()\noptimizer = optim.Adam(model.parameters())\nloss_fn = nn.MSELoss()\nloader = data.DataLoader(data.TensorDataset(X_train, y_train), shuffle=True, batch_size=8) # shuffle: 샘플을 섞을지 시간 순서대로 추출할지 결정\n \nn_epochs = 2000\nfor epoch in range(n_epochs):\n    model.train()\n    for X_batch, y_batch in loader:\n        y_pred = model(X_batch)\n        loss = loss_fn(y_pred, y_batch)\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n    # Validation\n    if epoch % 100 != 0:\n        continue\n    model.eval()\n    with torch.no_grad():\n        y_pred = model(X_train)\n        train_rmse = np.sqrt(loss_fn(y_pred, y_train))\n        y_pred = model(X_test)\n        test_rmse = np.sqrt(loss_fn(y_pred, y_test))\n    print(\"Epoch %d: train RMSE %.4f, test RMSE %.4f\" % (epoch, train_rmse, test_rmse))\n \nwith torch.no_grad():\n    # shift train predictions for plotting\n    train_plot = np.ones_like(timeseries) * np.nan\n    y_pred = model(X_train)\n    y_pred = y_pred[:, -1, :]\n    train_plot[lookback:train_size] = model(X_train)[:, -1, :]\n    # shift test predictions for plotting\n    test_plot = np.ones_like(timeseries) * np.nan\n    test_plot[train_size+lookback:len(timeseries)] = model(X_test)[:, -1, :]\n\nEpoch 0: train RMSE 225.5574, test RMSE 424.7804\nEpoch 100: train RMSE 177.5963, test RMSE 374.4650\nEpoch 200: train RMSE 138.9036, test RMSE 332.0411\nEpoch 300: train RMSE 108.2241, test RMSE 295.1660\nEpoch 400: train RMSE 86.0366, test RMSE 263.5869\nEpoch 500: train RMSE 65.9311, test RMSE 232.4372\nEpoch 600: train RMSE 51.7861, test RMSE 204.3946\nEpoch 700: train RMSE 41.5776, test RMSE 180.0017\nEpoch 800: train RMSE 34.7810, test RMSE 159.1152\nEpoch 900: train RMSE 29.9309, test RMSE 141.1872\nEpoch 1000: train RMSE 26.6003, test RMSE 126.3749\nEpoch 1100: train RMSE 24.6251, test RMSE 114.9184\nEpoch 1200: train RMSE 23.2474, test RMSE 105.3578\nEpoch 1300: train RMSE 22.2368, test RMSE 98.2287\nEpoch 1400: train RMSE 21.5524, test RMSE 92.6251\nEpoch 1500: train RMSE 21.1995, test RMSE 87.6587\nEpoch 1600: train RMSE 20.5447, test RMSE 84.6245\nEpoch 1700: train RMSE 20.1870, test RMSE 81.5615\nEpoch 1800: train RMSE 20.0715, test RMSE 79.2392\nEpoch 1900: train RMSE 19.9252, test RMSE 78.4828\n\n\n\n# plot\nplt.plot(timeseries, label='실제관측치')\nplt.plot(train_plot, c='r', label='train')\nplt.plot(test_plot, c='g', label='test')\nplt.legend()\nplt.show()\n\n\n\n\n\n이전보다(lookback=1) 테스트 데이터에 대해 훨씬 잘 맞춘다.\n\nRunning the above code will produce the plot below. From both the RMSE measure printed and the plot, you can notice that the model can now do better on the test set.\nThis is also why the create_dataset() function is designed in such way: When the model is given a time series of time \\(t\\) to \\(t+3\\)(as lookback=4), its output is the prediction of \\(t+1\\) to \\(t+4\\). However, \\(t+1\\) to \\(t+3\\) are also known from the input. By using these in the loss function, the model effectively was provided with more clues to train. This design is not always suitable but you can see it is helpful in this particular example\n\n\n\n- lookback 살펴보기\n\nlookback: 입력으로 사용하기 위해 거슬러 올라갈 타임스텝\ndelay : 타깃으로 사용할 미래의 타임스텝\nshuffle: 샘플을 섞을지 시간 순서대로 추출할지 결정\n\n\nlookback = 4\nX_train, y_train = create_dataset(train, lookback=lookback)\nX_test, y_test = create_dataset(test, lookback=lookback)\n\n\nX_train.shape, y_train.shape\n\n(torch.Size([92, 4, 1]), torch.Size([92, 4, 1]))\n\n\n\ndf[:10]\n\n\n\n\n\n  \n    \n      \n      Month\n      Passengers\n    \n  \n  \n    \n      0\n      1949-01\n      112\n    \n    \n      1\n      1949-02\n      118\n    \n    \n      2\n      1949-03\n      132\n    \n    \n      3\n      1949-04\n      129\n    \n    \n      4\n      1949-05\n      121\n    \n    \n      5\n      1949-06\n      135\n    \n    \n      6\n      1949-07\n      148\n    \n    \n      7\n      1949-08\n      148\n    \n    \n      8\n      1949-09\n      136\n    \n    \n      9\n      1949-10\n      119\n    \n  \n\n\n\n\n\nX_train.T\n\ntensor([[[112., 118., 132., 129., 121., 135., 148., 148., 136., 119., 104.,\n          118., 115., 126., 141., 135., 125., 149., 170., 170., 158., 133.,\n          114., 140., 145., 150., 178., 163., 172., 178., 199., 199., 184.,\n          162., 146., 166., 171., 180., 193., 181., 183., 218., 230., 242.,\n          209., 191., 172., 194., 196., 196., 236., 235., 229., 243., 264.,\n          272., 237., 211., 180., 201., 204., 188., 235., 227., 234., 264.,\n          302., 293., 259., 229., 203., 229., 242., 233., 267., 269., 270.,\n          315., 364., 347., 312., 274., 237., 278., 284., 277., 317., 313.,\n          318., 374., 413., 405.],\n         [118., 132., 129., 121., 135., 148., 148., 136., 119., 104., 118.,\n          115., 126., 141., 135., 125., 149., 170., 170., 158., 133., 114.,\n          140., 145., 150., 178., 163., 172., 178., 199., 199., 184., 162.,\n          146., 166., 171., 180., 193., 181., 183., 218., 230., 242., 209.,\n          191., 172., 194., 196., 196., 236., 235., 229., 243., 264., 272.,\n          237., 211., 180., 201., 204., 188., 235., 227., 234., 264., 302.,\n          293., 259., 229., 203., 229., 242., 233., 267., 269., 270., 315.,\n          364., 347., 312., 274., 237., 278., 284., 277., 317., 313., 318.,\n          374., 413., 405., 355.],\n         [132., 129., 121., 135., 148., 148., 136., 119., 104., 118., 115.,\n          126., 141., 135., 125., 149., 170., 170., 158., 133., 114., 140.,\n          145., 150., 178., 163., 172., 178., 199., 199., 184., 162., 146.,\n          166., 171., 180., 193., 181., 183., 218., 230., 242., 209., 191.,\n          172., 194., 196., 196., 236., 235., 229., 243., 264., 272., 237.,\n          211., 180., 201., 204., 188., 235., 227., 234., 264., 302., 293.,\n          259., 229., 203., 229., 242., 233., 267., 269., 270., 315., 364.,\n          347., 312., 274., 237., 278., 284., 277., 317., 313., 318., 374.,\n          413., 405., 355., 306.],\n         [129., 121., 135., 148., 148., 136., 119., 104., 118., 115., 126.,\n          141., 135., 125., 149., 170., 170., 158., 133., 114., 140., 145.,\n          150., 178., 163., 172., 178., 199., 199., 184., 162., 146., 166.,\n          171., 180., 193., 181., 183., 218., 230., 242., 209., 191., 172.,\n          194., 196., 196., 236., 235., 229., 243., 264., 272., 237., 211.,\n          180., 201., 204., 188., 235., 227., 234., 264., 302., 293., 259.,\n          229., 203., 229., 242., 233., 267., 269., 270., 315., 364., 347.,\n          312., 274., 237., 278., 284., 277., 317., 313., 318., 374., 413.,\n          405., 355., 306., 271.]]])\n\n\n\ny_train.T\n\ntensor([[[118., 132., 129., 121., 135., 148., 148., 136., 119., 104., 118.,\n          115., 126., 141., 135., 125., 149., 170., 170., 158., 133., 114.,\n          140., 145., 150., 178., 163., 172., 178., 199., 199., 184., 162.,\n          146., 166., 171., 180., 193., 181., 183., 218., 230., 242., 209.,\n          191., 172., 194., 196., 196., 236., 235., 229., 243., 264., 272.,\n          237., 211., 180., 201., 204., 188., 235., 227., 234., 264., 302.,\n          293., 259., 229., 203., 229., 242., 233., 267., 269., 270., 315.,\n          364., 347., 312., 274., 237., 278., 284., 277., 317., 313., 318.,\n          374., 413., 405., 355.],\n         [132., 129., 121., 135., 148., 148., 136., 119., 104., 118., 115.,\n          126., 141., 135., 125., 149., 170., 170., 158., 133., 114., 140.,\n          145., 150., 178., 163., 172., 178., 199., 199., 184., 162., 146.,\n          166., 171., 180., 193., 181., 183., 218., 230., 242., 209., 191.,\n          172., 194., 196., 196., 236., 235., 229., 243., 264., 272., 237.,\n          211., 180., 201., 204., 188., 235., 227., 234., 264., 302., 293.,\n          259., 229., 203., 229., 242., 233., 267., 269., 270., 315., 364.,\n          347., 312., 274., 237., 278., 284., 277., 317., 313., 318., 374.,\n          413., 405., 355., 306.],\n         [129., 121., 135., 148., 148., 136., 119., 104., 118., 115., 126.,\n          141., 135., 125., 149., 170., 170., 158., 133., 114., 140., 145.,\n          150., 178., 163., 172., 178., 199., 199., 184., 162., 146., 166.,\n          171., 180., 193., 181., 183., 218., 230., 242., 209., 191., 172.,\n          194., 196., 196., 236., 235., 229., 243., 264., 272., 237., 211.,\n          180., 201., 204., 188., 235., 227., 234., 264., 302., 293., 259.,\n          229., 203., 229., 242., 233., 267., 269., 270., 315., 364., 347.,\n          312., 274., 237., 278., 284., 277., 317., 313., 318., 374., 413.,\n          405., 355., 306., 271.],\n         [121., 135., 148., 148., 136., 119., 104., 118., 115., 126., 141.,\n          135., 125., 149., 170., 170., 158., 133., 114., 140., 145., 150.,\n          178., 163., 172., 178., 199., 199., 184., 162., 146., 166., 171.,\n          180., 193., 181., 183., 218., 230., 242., 209., 191., 172., 194.,\n          196., 196., 236., 235., 229., 243., 264., 272., 237., 211., 180.,\n          201., 204., 188., 235., 227., 234., 264., 302., 293., 259., 229.,\n          203., 229., 242., 233., 267., 269., 270., 315., 364., 347., 312.,\n          274., 237., 278., 284., 277., 317., 313., 318., 374., 413., 405.,\n          355., 306., 271., 306.]]])\n\n\n\nhttps://miruetoto.github.io/yechan3/posts/3_Researches/ITSTGCN/2022-12-29-STGCN-tutorial.html#pytorch-geometric-temporal-%EC%9D%98-%EC%9E%90%EB%A3%8C%ED%98%95\n\nlag=4라고 생각하면 될 것같은데 각각 한달 후의 데이터를 예측하는 것이라 \\(y\\)의 차원이 전에 했던거랑 다름."
  },
  {
    "objectID": "posts/SOLAR/2023-04-12-데이터수정.html",
    "href": "posts/SOLAR/2023-04-12-데이터수정.html",
    "title": "[SOLAR] Crate Dataset (22/06~22/09/15)",
    "section": "",
    "text": "import pandas as pd\nimport numpy as np\nimport json\nimport urllib\n\nimport matplotlib.pyplot as plt\nimport time"
  },
  {
    "objectID": "posts/SOLAR/2023-04-12-데이터수정.html#solar_radiation",
    "href": "posts/SOLAR/2023-04-12-데이터수정.html#solar_radiation",
    "title": "[SOLAR] Crate Dataset (22/06~22/09/15)",
    "section": "solar_radiation",
    "text": "solar_radiation\n\ndf = pd.read_csv(\"./data/solar_radiation.csv\")\n\n\ndf.shape\n\n(803000, 3)\n\n\n\ndf.duplicated().sum()\n\n96360\n\n\n\ndf_ = df.drop_duplicates()\n\n\ndf_.shape\n\n(706640, 3)\n\n\n\ndf_.to_csv('./data/solar_radiation.csv', index=False)\n\n\nsolar 데이터 수정완료"
  },
  {
    "objectID": "posts/SOLAR/2023-04-12-데이터수정.html#날짜-재설정-train-test",
    "href": "posts/SOLAR/2023-04-12-데이터수정.html#날짜-재설정-train-test",
    "title": "[SOLAR] Crate Dataset (22/06~22/09/15)",
    "section": "날짜 재설정, train / test",
    "text": "날짜 재설정, train / test\n\nimport gc\ngc.collect()\n\n1050\n\n\n\ndf = pd.read_csv('./data/solar_radiation.csv')\n\n\ndf_.duplicated().sum()\n\n0\n\n\n\ntrain = df.query(\"date >= '2022-06-01-00:00' and date <= '2022-08-15-23:00'\")\ntest = df.query(\"date >= '2022-08-16-00:00' and date <= '2022-09-15-23:00'\")\n\n\ntrain.shape, test.shape, \n\n((73568, 3), (30008, 3))\n\n\n\nprint(train.shape[0]/(train.shape[0]+test.shape[0]))\nprint(test.shape[0]/(train.shape[0]+test.shape[0]))\n\n0.7102803738317757\n0.2897196261682243\n\n\n\ntrain.plot(backend='plotly',x='date',y='solar_radiation',color='region')\n\n\n                                                \n\n\n\n중복되는 것 잘 처리된 듯.\n\n\n# train = train.reset_index(drop=True)\n# test = test.reset_index(drop=True)\n\n\n# train.to_csv('./data/train.csv', index=False)\n# test.to_csv('./data/test.csv', index=False)\n\n\n# solar_radiation = pd.concat([train, test])\n# solar_radiation.to_csv('./data2/solar_radiation.csv')"
  },
  {
    "objectID": "posts/SOLAR/2023-04-12-데이터수정.html#weight",
    "href": "posts/SOLAR/2023-04-12-데이터수정.html#weight",
    "title": "[SOLAR] Crate Dataset (22/06~22/09/15)",
    "section": "Weight",
    "text": "Weight\n\nimport rpy2\n%load_ext rpy2.ipython \n\nThe rpy2.ipython extension is already loaded. To reload it, use:\n  %reload_ext rpy2.ipython\n\n\n\n%R -i train\n\n\n%%R\nlibrary(data.table)\nlibrary(tidyverse)\nlibrary(dplyr)\nlibrary(corrplot)\nlibrary(lubridate)\n\n\n%%R\nhead(train)\n\n  region solar_radiation             date\n0 북춘천               0 2022-06-01-00:00\n1 북춘천               0 2022-06-01-01:00\n2 북춘천               0 2022-06-01-02:00\n3 북춘천               0 2022-06-01-03:00\n4 북춘천               0 2022-06-01-04:00\n5 북춘천               0 2022-06-01-05:00\n\n\n\n%%R\ntrain = train |> mutate(date = ymd_hm(date))\n\n\n%%R\ntrain <- train %>%\n              group_by(region) %>%\n              mutate(row = row_number()) %>%\n              tidyr::pivot_wider(names_from = region, values_from = solar_radiation) %>%\n              select(-row)\n\n\n%%R\nnum_vars <- train %>% select(-date)\nweight <- cor(num_vars)\nweight\n\n          북춘천      철원    대관령      춘천    백령도    북강릉      강릉\n북춘천 1.0000000 0.9324551 0.8413954 0.9795542 0.7683023 0.8009526 0.7861866\n철원   0.9324551 1.0000000 0.7956493 0.9286610 0.7818931 0.7541274 0.7373221\n대관령 0.8413954 0.7956493 1.0000000 0.8386966 0.7188297 0.9138333 0.9137933\n춘천   0.9795542 0.9286610 0.8386966 1.0000000 0.7759241 0.8019631 0.7846640\n백령도 0.7683023 0.7818931 0.7188297 0.7759241 1.0000000 0.7061263 0.6966470\n북강릉 0.8009526 0.7541274 0.9138333 0.8019631 0.7061263 1.0000000 0.9756847\n강릉   0.7861866 0.7373221 0.9137933 0.7846640 0.6966470 0.9756847 1.0000000\n서울   0.8903725 0.8876319 0.7750668 0.8902224 0.7439507 0.7341812 0.7149580\n인천   0.8744700 0.8781875 0.7756263 0.8829605 0.8175882 0.7527663 0.7318706\n원주   0.8818392 0.8502791 0.8491816 0.8878122 0.6968532 0.8167416 0.8101265\n울릉도 0.7595506 0.7189272 0.7990941 0.7635617 0.6354091 0.7795962 0.7709971\n수원   0.8820296 0.8693470 0.8059918 0.8848755 0.7609338 0.7906997 0.7745101\n서산   0.8488350 0.8249927 0.7964682 0.8468232 0.7652919 0.7941227 0.7762608\n청주   0.8307579 0.7855263 0.8221282 0.8348436 0.6822019 0.8148382 0.8010720\n대전   0.8117429 0.7712529 0.8246968 0.8173543 0.6938830 0.8270681 0.8070489\n추풍령 0.7960143 0.7539013 0.8435533 0.8055568 0.6979995 0.8511858 0.8364496\n안동   0.8111964 0.7648565 0.8662600 0.8215898 0.6962950 0.8705724 0.8594888\n포항   0.7256428 0.6844198 0.8058277 0.7365150 0.6518686 0.8046299 0.7996858\n대구   0.7918798 0.7587116 0.8434322 0.8011658 0.6988136 0.8314655 0.8162024\n전주   0.7811925 0.7440809 0.8050267 0.7878076 0.6829282 0.8045137 0.7915923\n창원   0.7565177 0.7151796 0.7979057 0.7624217 0.6870270 0.7819169 0.7735388\n광주   0.7873227 0.7553035 0.7951151 0.7935236 0.6725768 0.7790663 0.7688906\n부산   0.7533812 0.7225822 0.7948010 0.7571069 0.6806941 0.7825222 0.7736873\n목포   0.7661873 0.7337243 0.7737296 0.7732826 0.7140119 0.7596418 0.7484550\n여수   0.7633536 0.7307870 0.7903944 0.7693580 0.7068930 0.7751322 0.7677728\n흑산도 0.6993936 0.6728543 0.6807131 0.7150437 0.6839297 0.6629199 0.6630222\n고창   0.7925044 0.7652972 0.7831101 0.8016362 0.6958330 0.7713971 0.7636234\n홍성   0.8256934 0.7969195 0.7952289 0.8291781 0.7379403 0.8018168 0.7872580\n제주   0.7091296 0.6879107 0.7389474 0.7170028 0.6848686 0.7277671 0.7267009\n고산   0.7449083 0.7306428 0.7393850 0.7508272 0.7299169 0.7236955 0.7193154\n진주   0.7489826 0.7138415 0.8013164 0.7617733 0.7116293 0.7922470 0.7843872\n고창군 0.7805575 0.7413899 0.7884387 0.7870453 0.6840555 0.7828055 0.7670954\n영광군 0.7856301 0.7575025 0.7894362 0.7931970 0.7049749 0.7766498 0.7679711\n김해시 0.7465908 0.7116206 0.7881967 0.7493537 0.6895253 0.7769105 0.7689769\n순창군 0.7943097 0.7505764 0.8160578 0.8019902 0.6802432 0.8074319 0.7920895\n북창원 0.7269668 0.6884748 0.7883019 0.7349089 0.6675491 0.7820283 0.7788529\n양산시 0.7510175 0.7133782 0.8053604 0.7556350 0.6654975 0.7957811 0.7849245\n보성군 0.7704942 0.7420699 0.7950918 0.7839360 0.7141459 0.7853251 0.7764681\n강진군 0.7566174 0.7314532 0.7653234 0.7659525 0.6981070 0.7475696 0.7393672\n의령군 0.7612855 0.7190958 0.8089384 0.7690708 0.7000047 0.8105361 0.8038976\n함양군 0.7796817 0.7394196 0.8166946 0.7869499 0.7173924 0.8155327 0.8052922\n광양시 0.7592679 0.7261431 0.7934692 0.7683094 0.7022263 0.7704416 0.7641724\n청송군 0.7907397 0.7476890 0.8596892 0.8010432 0.6748956 0.8432934 0.8330011\n경주시 0.7300684 0.6859699 0.8178307 0.7338574 0.6582473 0.8199419 0.8096752\n            서울      인천      원주    울릉도      수원      서산      청주\n북춘천 0.8903725 0.8744700 0.8818392 0.7595506 0.8820296 0.8488350 0.8307579\n철원   0.8876319 0.8781875 0.8502791 0.7189272 0.8693470 0.8249927 0.7855263\n대관령 0.7750668 0.7756263 0.8491816 0.7990941 0.8059918 0.7964682 0.8221282\n춘천   0.8902224 0.8829605 0.8878122 0.7635617 0.8848755 0.8468232 0.8348436\n백령도 0.7439507 0.8175882 0.6968532 0.6354091 0.7609338 0.7652919 0.6822019\n북강릉 0.7341812 0.7527663 0.8167416 0.7795962 0.7906997 0.7941227 0.8148382\n강릉   0.7149580 0.7318706 0.8101265 0.7709971 0.7745101 0.7762608 0.8010720\n서울   1.0000000 0.9034416 0.8584456 0.7104507 0.9177827 0.8563854 0.8173792\n인천   0.9034416 1.0000000 0.8437606 0.7519265 0.9186319 0.8938130 0.8185188\n원주   0.8584456 0.8437606 1.0000000 0.7923313 0.9010821 0.8754305 0.9010735\n울릉도 0.7104507 0.7519265 0.7923313 1.0000000 0.7714494 0.7889595 0.8108455\n수원   0.9177827 0.9186319 0.9010821 0.7714494 1.0000000 0.9122589 0.8823276\n서산   0.8563854 0.8938130 0.8754305 0.7889595 0.9122589 1.0000000 0.8851825\n청주   0.8173792 0.8185188 0.9010735 0.8108455 0.8823276 0.8851825 1.0000000\n대전   0.7954026 0.8153099 0.8866695 0.8259923 0.8755872 0.8770676 0.9460653\n추풍령 0.7457618 0.7853439 0.8518609 0.8388835 0.8163848 0.8387802 0.8844030\n안동   0.7609332 0.7874054 0.8734501 0.8522912 0.8272108 0.8508985 0.8804022\n포항   0.6901963 0.7380779 0.7922880 0.8278983 0.7547235 0.7837299 0.7927669\n대구   0.7459121 0.7782449 0.8356540 0.8370513 0.8069510 0.8263894 0.8558139\n전주   0.7642515 0.7936115 0.8562723 0.8163920 0.8369472 0.8513313 0.8930477\n창원   0.7119777 0.7725014 0.7870717 0.8173484 0.7681847 0.8075872 0.8107834\n광주   0.7629569 0.7974764 0.8364529 0.8099344 0.8232473 0.8191789 0.8362276\n부산   0.7138869 0.7669048 0.7855475 0.8278864 0.7721779 0.7986096 0.8053325\n목포   0.7357198 0.8008241 0.8086794 0.8039140 0.8053391 0.8202137 0.8271254\n여수   0.7224418 0.7838482 0.7872488 0.7859429 0.7769729 0.8076551 0.8087588\n흑산도 0.6402982 0.7277224 0.7130824 0.7063272 0.7092081 0.7222364 0.7221668\n고창   0.7777575 0.8201295 0.8482437 0.8056932 0.8431733 0.8395814 0.8624063\n홍성   0.8254348 0.8602341 0.8744583 0.7947631 0.9024237 0.9399633 0.9052226\n제주   0.6708805 0.7196343 0.7461081 0.7597712 0.7262343 0.7369349 0.7685377\n고산   0.7131687 0.7634657 0.7653086 0.7481479 0.7654535 0.7903832 0.7699712\n진주   0.7180531 0.7782956 0.7856156 0.8108397 0.7774315 0.8089461 0.8189387\n고창군 0.7606161 0.7985964 0.8342187 0.8025257 0.8305723 0.8266425 0.8603055\n영광군 0.7754790 0.8231978 0.8380360 0.8035935 0.8420618 0.8402787 0.8535021\n김해시 0.7107544 0.7617357 0.7818407 0.8168539 0.7640896 0.7930881 0.8067091\n순창군 0.7522028 0.7943400 0.8476217 0.8120839 0.8181173 0.8309264 0.8646071\n북창원 0.6942723 0.7456681 0.7737301 0.8155766 0.7573821 0.7810627 0.7932070\n양산시 0.7077062 0.7602863 0.7920598 0.8248106 0.7687923 0.7953383 0.8186250\n보성군 0.7323476 0.7953131 0.8069716 0.7931236 0.7892258 0.8111558 0.8236898\n강진군 0.7269920 0.7809981 0.7959230 0.7829792 0.7819954 0.7956073 0.8196199\n의령군 0.7214300 0.7737580 0.7990773 0.8118961 0.7835219 0.8134156 0.8193908\n함양군 0.7342408 0.7920410 0.8185744 0.8064611 0.8009412 0.8179605 0.8460731\n광양시 0.7255430 0.7768801 0.7947979 0.7909505 0.7755672 0.8122102 0.8139872\n청송군 0.7469890 0.7696582 0.8529069 0.8405379 0.8002023 0.8266329 0.8572851\n경주시 0.6839612 0.7335185 0.7844827 0.8416816 0.7522104 0.7786239 0.8099774\n            대전    추풍령      안동      포항      대구      전주      창원\n북춘천 0.8117429 0.7960143 0.8111964 0.7256428 0.7918798 0.7811925 0.7565177\n철원   0.7712529 0.7539013 0.7648565 0.6844198 0.7587116 0.7440809 0.7151796\n대관령 0.8246968 0.8435533 0.8662600 0.8058277 0.8434322 0.8050267 0.7979057\n춘천   0.8173543 0.8055568 0.8215898 0.7365150 0.8011658 0.7878076 0.7624217\n백령도 0.6938830 0.6979995 0.6962950 0.6518686 0.6988136 0.6829282 0.6870270\n북강릉 0.8270681 0.8511858 0.8705724 0.8046299 0.8314655 0.8045137 0.7819169\n강릉   0.8070489 0.8364496 0.8594888 0.7996858 0.8162024 0.7915923 0.7735388\n서울   0.7954026 0.7457618 0.7609332 0.6901963 0.7459121 0.7642515 0.7119777\n인천   0.8153099 0.7853439 0.7874054 0.7380779 0.7782449 0.7936115 0.7725014\n원주   0.8866695 0.8518609 0.8734501 0.7922880 0.8356540 0.8562723 0.7870717\n울릉도 0.8259923 0.8388835 0.8522912 0.8278983 0.8370513 0.8163920 0.8173484\n수원   0.8755872 0.8163848 0.8272108 0.7547235 0.8069510 0.8369472 0.7681847\n서산   0.8770676 0.8387802 0.8508985 0.7837299 0.8263894 0.8513313 0.8075872\n청주   0.9460653 0.8844030 0.8804022 0.7927669 0.8558139 0.8930477 0.8107834\n대전   1.0000000 0.9051969 0.8963897 0.8206232 0.8766620 0.9162440 0.8262034\n추풍령 0.9051969 1.0000000 0.9332177 0.8766116 0.9192329 0.8993273 0.8825123\n안동   0.8963897 0.9332177 1.0000000 0.8864675 0.9163065 0.8829340 0.8731629\n포항   0.8206232 0.8766116 0.8864675 1.0000000 0.8981294 0.8246486 0.8663423\n대구   0.8766620 0.9192329 0.9163065 0.8981294 1.0000000 0.8777951 0.8859490\n전주   0.9162440 0.8993273 0.8829340 0.8246486 0.8777951 1.0000000 0.8405484\n창원   0.8262034 0.8825123 0.8731629 0.8663423 0.8859490 0.8405484 1.0000000\n광주   0.8677244 0.8806658 0.8730501 0.8416918 0.8739759 0.8908651 0.8654766\n부산   0.8310058 0.8799602 0.8696335 0.8638794 0.8843102 0.8489446 0.9400507\n목포   0.8569471 0.8581555 0.8454306 0.8170333 0.8513113 0.8630528 0.8673670\n여수   0.8202697 0.8694117 0.8606069 0.8397541 0.8633614 0.8460959 0.9130218\n흑산도 0.7354413 0.7571018 0.7518644 0.7131656 0.7256126 0.7351549 0.7787853\n고창   0.8841327 0.8750561 0.8735055 0.8241180 0.8642089 0.9036888 0.8580873\n홍성   0.9042548 0.8601915 0.8690360 0.7902957 0.8475497 0.8820764 0.8193104\n제주   0.7878633 0.8164234 0.8086556 0.8126488 0.8170868 0.8174235 0.8473166\n고산   0.7825940 0.8053601 0.8043757 0.7822236 0.8134039 0.8045008 0.8471507\n진주   0.8437567 0.8921529 0.8778570 0.8791069 0.8982687 0.8609958 0.9397549\n고창군 0.8901846 0.8840486 0.8769324 0.8172666 0.8669280 0.9143162 0.8404442\n영광군 0.8803746 0.8747298 0.8746685 0.8249098 0.8628904 0.8956300 0.8538644\n김해시 0.8333760 0.8795387 0.8777225 0.8638930 0.8868820 0.8524791 0.9441381\n순창군 0.8889548 0.9052294 0.8909878 0.8524072 0.8841582 0.9104594 0.8719463\n북창원 0.8234483 0.8765764 0.8770335 0.8738155 0.8874937 0.8427517 0.9481923\n양산시 0.8396529 0.8840026 0.8815109 0.8748006 0.8961085 0.8588888 0.9245399\n보성군 0.8456575 0.8864898 0.8736437 0.8482321 0.8709818 0.8601169 0.9047818\n강진군 0.8413485 0.8648836 0.8436445 0.8153541 0.8539161 0.8628698 0.8823224\n의령군 0.8471875 0.9016696 0.8898874 0.8929157 0.9184673 0.8675363 0.9364399\n함양군 0.8731642 0.9254933 0.8950286 0.8654495 0.9174084 0.8907069 0.8919119\n광양시 0.8382006 0.8700948 0.8597472 0.8489323 0.8717704 0.8482418 0.9084509\n청송군 0.8707417 0.9206766 0.9374623 0.8976606 0.9237607 0.8639775 0.8615422\n경주시 0.8341432 0.8954423 0.8975146 0.9305404 0.9071324 0.8337050 0.8813468\n            광주      부산      목포      여수    흑산도      고창      홍성\n북춘천 0.7873227 0.7533812 0.7661873 0.7633536 0.6993936 0.7925044 0.8256934\n철원   0.7553035 0.7225822 0.7337243 0.7307870 0.6728543 0.7652972 0.7969195\n대관령 0.7951151 0.7948010 0.7737296 0.7903944 0.6807131 0.7831101 0.7952289\n춘천   0.7935236 0.7571069 0.7732826 0.7693580 0.7150437 0.8016362 0.8291781\n백령도 0.6725768 0.6806941 0.7140119 0.7068930 0.6839297 0.6958330 0.7379403\n북강릉 0.7790663 0.7825222 0.7596418 0.7751322 0.6629199 0.7713971 0.8018168\n강릉   0.7688906 0.7736873 0.7484550 0.7677728 0.6630222 0.7636234 0.7872580\n서울   0.7629569 0.7138869 0.7357198 0.7224418 0.6402982 0.7777575 0.8254348\n인천   0.7974764 0.7669048 0.8008241 0.7838482 0.7277224 0.8201295 0.8602341\n원주   0.8364529 0.7855475 0.8086794 0.7872488 0.7130824 0.8482437 0.8744583\n울릉도 0.8099344 0.8278864 0.8039140 0.7859429 0.7063272 0.8056932 0.7947631\n수원   0.8232473 0.7721779 0.8053391 0.7769729 0.7092081 0.8431733 0.9024237\n서산   0.8191789 0.7986096 0.8202137 0.8076551 0.7222364 0.8395814 0.9399633\n청주   0.8362276 0.8053325 0.8271254 0.8087588 0.7221668 0.8624063 0.9052226\n대전   0.8677244 0.8310058 0.8569471 0.8202697 0.7354413 0.8841327 0.9042548\n추풍령 0.8806658 0.8799602 0.8581555 0.8694117 0.7571018 0.8750561 0.8601915\n안동   0.8730501 0.8696335 0.8454306 0.8606069 0.7518644 0.8735055 0.8690360\n포항   0.8416918 0.8638794 0.8170333 0.8397541 0.7131656 0.8241180 0.7902957\n대구   0.8739759 0.8843102 0.8513113 0.8633614 0.7256126 0.8642089 0.8475497\n전주   0.8908651 0.8489446 0.8630528 0.8460959 0.7351549 0.9036888 0.8820764\n창원   0.8654766 0.9400507 0.8673670 0.9130218 0.7787853 0.8580873 0.8193104\n광주   1.0000000 0.8662811 0.9110081 0.8835384 0.7708545 0.9317725 0.8454437\n부산   0.8662811 1.0000000 0.8547592 0.9122591 0.7718563 0.8567057 0.8064307\n목포   0.9110081 0.8547592 1.0000000 0.8771530 0.8066237 0.9156667 0.8373956\n여수   0.8835384 0.9122591 0.8771530 1.0000000 0.7880432 0.8668393 0.8123592\n흑산도 0.7708545 0.7718563 0.8066237 0.7880432 1.0000000 0.7897982 0.7243897\n고창   0.9317725 0.8567057 0.9156667 0.8668393 0.7897982 1.0000000 0.8645012\n홍성   0.8454437 0.8064307 0.8373956 0.8123592 0.7243897 0.8645012 1.0000000\n제주   0.8389098 0.8500131 0.8583366 0.8651901 0.7764570 0.8476197 0.7577701\n고산   0.8394262 0.8437787 0.8590665 0.8730355 0.7821907 0.8369779 0.7893949\n진주   0.8802182 0.9241015 0.8799757 0.9290877 0.7820483 0.8674705 0.8215968\n고창군 0.9299782 0.8435251 0.9016680 0.8587757 0.7643243 0.9595650 0.8635911\n영광군 0.9225244 0.8451974 0.9229197 0.8684401 0.7873974 0.9668528 0.8616135\n김해시 0.8566343 0.9413610 0.8439175 0.8940024 0.7524935 0.8525176 0.8134961\n순창군 0.9367345 0.8627107 0.9000122 0.8786733 0.7606625 0.9162123 0.8602163\n북창원 0.8642426 0.9223357 0.8536178 0.8932863 0.7444008 0.8510559 0.7999140\n양산시 0.8688949 0.9399661 0.8448951 0.8910316 0.7500934 0.8548345 0.8160331\n보성군 0.9068480 0.8965864 0.9137876 0.9332811 0.8072589 0.8959504 0.8300761\n강진군 0.9057509 0.8789422 0.9185887 0.8955207 0.7868001 0.8910640 0.8274505\n의령군 0.8805880 0.9163458 0.8747732 0.9133704 0.7626229 0.8718523 0.8251108\n함양군 0.8913100 0.8830097 0.8799185 0.8925185 0.7677850 0.8902016 0.8434977\n광양시 0.8866290 0.8995939 0.8843385 0.9265798 0.7813267 0.8723510 0.8189972\n청송군 0.8567084 0.8637152 0.8320770 0.8541911 0.7166094 0.8562145 0.8399010\n경주시 0.8411881 0.8826649 0.8218488 0.8423813 0.7295972 0.8309374 0.8013453\n            제주      고산      진주    고창군    영광군    김해시    순창군\n북춘천 0.7091296 0.7449083 0.7489826 0.7805575 0.7856301 0.7465908 0.7943097\n철원   0.6879107 0.7306428 0.7138415 0.7413899 0.7575025 0.7116206 0.7505764\n대관령 0.7389474 0.7393850 0.8013164 0.7884387 0.7894362 0.7881967 0.8160578\n춘천   0.7170028 0.7508272 0.7617733 0.7870453 0.7931970 0.7493537 0.8019902\n백령도 0.6848686 0.7299169 0.7116293 0.6840555 0.7049749 0.6895253 0.6802432\n북강릉 0.7277671 0.7236955 0.7922470 0.7828055 0.7766498 0.7769105 0.8074319\n강릉   0.7267009 0.7193154 0.7843872 0.7670954 0.7679711 0.7689769 0.7920895\n서울   0.6708805 0.7131687 0.7180531 0.7606161 0.7754790 0.7107544 0.7522028\n인천   0.7196343 0.7634657 0.7782956 0.7985964 0.8231978 0.7617357 0.7943400\n원주   0.7461081 0.7653086 0.7856156 0.8342187 0.8380360 0.7818407 0.8476217\n울릉도 0.7597712 0.7481479 0.8108397 0.8025257 0.8035935 0.8168539 0.8120839\n수원   0.7262343 0.7654535 0.7774315 0.8305723 0.8420618 0.7640896 0.8181173\n서산   0.7369349 0.7903832 0.8089461 0.8266425 0.8402787 0.7930881 0.8309264\n청주   0.7685377 0.7699712 0.8189387 0.8603055 0.8535021 0.8067091 0.8646071\n대전   0.7878633 0.7825940 0.8437567 0.8901846 0.8803746 0.8333760 0.8889548\n추풍령 0.8164234 0.8053601 0.8921529 0.8840486 0.8747298 0.8795387 0.9052294\n안동   0.8086556 0.8043757 0.8778570 0.8769324 0.8746685 0.8777225 0.8909878\n포항   0.8126488 0.7822236 0.8791069 0.8172666 0.8249098 0.8638930 0.8524072\n대구   0.8170868 0.8134039 0.8982687 0.8669280 0.8628904 0.8868820 0.8841582\n전주   0.8174235 0.8045008 0.8609958 0.9143162 0.8956300 0.8524791 0.9104594\n창원   0.8473166 0.8471507 0.9397549 0.8404442 0.8538644 0.9441381 0.8719463\n광주   0.8389098 0.8394262 0.8802182 0.9299782 0.9225244 0.8566343 0.9367345\n부산   0.8500131 0.8437787 0.9241015 0.8435251 0.8451974 0.9413610 0.8627107\n목포   0.8583366 0.8590665 0.8799757 0.9016680 0.9229197 0.8439175 0.9000122\n여수   0.8651901 0.8730355 0.9290877 0.8587757 0.8684401 0.8940024 0.8786733\n흑산도 0.7764570 0.7821907 0.7820483 0.7643243 0.7873974 0.7524935 0.7606625\n고창   0.8476197 0.8369779 0.8674705 0.9595650 0.9668528 0.8525176 0.9162123\n홍성   0.7577701 0.7893949 0.8215968 0.8635911 0.8616135 0.8134961 0.8602163\n제주   1.0000000 0.9150980 0.8626319 0.8325309 0.8473773 0.8377909 0.8331779\n고산   0.9150980 1.0000000 0.8547233 0.8188369 0.8371967 0.8276814 0.8261756\n진주   0.8626319 0.8547233 1.0000000 0.8601463 0.8704198 0.9117871 0.8858196\n고창군 0.8325309 0.8188369 0.8601463 1.0000000 0.9449450 0.8390671 0.9210254\n영광군 0.8473773 0.8371967 0.8704198 0.9449450 1.0000000 0.8408795 0.9059102\n김해시 0.8377909 0.8276814 0.9117871 0.8390671 0.8408795 1.0000000 0.8548002\n순창군 0.8331779 0.8261756 0.8858196 0.9210254 0.9059102 0.8548002 1.0000000\n북창원 0.8365515 0.8271780 0.9237160 0.8416775 0.8476422 0.9467024 0.8598864\n양산시 0.8334769 0.8225911 0.9054248 0.8497796 0.8482214 0.9454422 0.8698994\n보성군 0.8695582 0.8604500 0.9229088 0.8858874 0.8957576 0.8920097 0.9058756\n강진군 0.8607902 0.8506182 0.9014361 0.8868625 0.8883946 0.8698947 0.9005197\n의령군 0.8535075 0.8465066 0.9511550 0.8599614 0.8731419 0.9158772 0.8877513\n함양군 0.8457343 0.8308656 0.9186005 0.8880126 0.8926160 0.8839439 0.9166942\n광양시 0.8455300 0.8555353 0.9387943 0.8625700 0.8690496 0.8931414 0.8978022\n청송군 0.8098152 0.7986642 0.8741628 0.8571222 0.8502198 0.8635978 0.8825241\n경주시 0.8189803 0.7838201 0.8836543 0.8337294 0.8299023 0.8931187 0.8527455\n          북창원    양산시    보성군    강진군    의령군    함양군    광양시\n북춘천 0.7269668 0.7510175 0.7704942 0.7566174 0.7612855 0.7796817 0.7592679\n철원   0.6884748 0.7133782 0.7420699 0.7314532 0.7190958 0.7394196 0.7261431\n대관령 0.7883019 0.8053604 0.7950918 0.7653234 0.8089384 0.8166946 0.7934692\n춘천   0.7349089 0.7556350 0.7839360 0.7659525 0.7690708 0.7869499 0.7683094\n백령도 0.6675491 0.6654975 0.7141459 0.6981070 0.7000047 0.7173924 0.7022263\n북강릉 0.7820283 0.7957811 0.7853251 0.7475696 0.8105361 0.8155327 0.7704416\n강릉   0.7788529 0.7849245 0.7764681 0.7393672 0.8038976 0.8052922 0.7641724\n서울   0.6942723 0.7077062 0.7323476 0.7269920 0.7214300 0.7342408 0.7255430\n인천   0.7456681 0.7602863 0.7953131 0.7809981 0.7737580 0.7920410 0.7768801\n원주   0.7737301 0.7920598 0.8069716 0.7959230 0.7990773 0.8185744 0.7947979\n울릉도 0.8155766 0.8248106 0.7931236 0.7829792 0.8118961 0.8064611 0.7909505\n수원   0.7573821 0.7687923 0.7892258 0.7819954 0.7835219 0.8009412 0.7755672\n서산   0.7810627 0.7953383 0.8111558 0.7956073 0.8134156 0.8179605 0.8122102\n청주   0.7932070 0.8186250 0.8236898 0.8196199 0.8193908 0.8460731 0.8139872\n대전   0.8234483 0.8396529 0.8456575 0.8413485 0.8471875 0.8731642 0.8382006\n추풍령 0.8765764 0.8840026 0.8864898 0.8648836 0.9016696 0.9254933 0.8700948\n안동   0.8770335 0.8815109 0.8736437 0.8436445 0.8898874 0.8950286 0.8597472\n포항   0.8738155 0.8748006 0.8482321 0.8153541 0.8929157 0.8654495 0.8489323\n대구   0.8874937 0.8961085 0.8709818 0.8539161 0.9184673 0.9174084 0.8717704\n전주   0.8427517 0.8588888 0.8601169 0.8628698 0.8675363 0.8907069 0.8482418\n창원   0.9481923 0.9245399 0.9047818 0.8823224 0.9364399 0.8919119 0.9084509\n광주   0.8642426 0.8688949 0.9068480 0.9057509 0.8805880 0.8913100 0.8866290\n부산   0.9223357 0.9399661 0.8965864 0.8789422 0.9163458 0.8830097 0.8995939\n목포   0.8536178 0.8448951 0.9137876 0.9185887 0.8747732 0.8799185 0.8843385\n여수   0.8932863 0.8910316 0.9332811 0.8955207 0.9133704 0.8925185 0.9265798\n흑산도 0.7444008 0.7500934 0.8072589 0.7868001 0.7626229 0.7677850 0.7813267\n고창   0.8510559 0.8548345 0.8959504 0.8910640 0.8718523 0.8902016 0.8723510\n홍성   0.7999140 0.8160331 0.8300761 0.8274505 0.8251108 0.8434977 0.8189972\n제주   0.8365515 0.8334769 0.8695582 0.8607902 0.8535075 0.8457343 0.8455300\n고산   0.8271780 0.8225911 0.8604500 0.8506182 0.8465066 0.8308656 0.8555353\n진주   0.9237160 0.9054248 0.9229088 0.9014361 0.9511550 0.9186005 0.9387943\n고창군 0.8416775 0.8497796 0.8858874 0.8868625 0.8599614 0.8880126 0.8625700\n영광군 0.8476422 0.8482214 0.8957576 0.8883946 0.8731419 0.8926160 0.8690496\n김해시 0.9467024 0.9454422 0.8920097 0.8698947 0.9158772 0.8839439 0.8931414\n순창군 0.8598864 0.8698994 0.9058756 0.9005197 0.8877513 0.9166942 0.8978022\n북창원 1.0000000 0.9308383 0.8916015 0.8620615 0.9229449 0.8904644 0.8949002\n양산시 0.9308383 1.0000000 0.8828348 0.8604153 0.9131405 0.8842711 0.8820246\n보성군 0.8916015 0.8828348 1.0000000 0.9349757 0.9044171 0.9078017 0.9330083\n강진군 0.8620615 0.8604153 0.9349757 1.0000000 0.8835146 0.8894260 0.9100773\n의령군 0.9229449 0.9131405 0.9044171 0.8835146 1.0000000 0.9237456 0.9156762\n함양군 0.8904644 0.8842711 0.9078017 0.8894260 0.9237456 1.0000000 0.8922293\n광양시 0.8949002 0.8820246 0.9330083 0.9100773 0.9156762 0.8922293 1.0000000\n청송군 0.8715869 0.8733397 0.8559264 0.8353581 0.8870534 0.8958706 0.8615321\n경주시 0.8952267 0.9012255 0.8513353 0.8256217 0.8981893 0.8811767 0.8530420\n          청송군    경주시\n북춘천 0.7907397 0.7300684\n철원   0.7476890 0.6859699\n대관령 0.8596892 0.8178307\n춘천   0.8010432 0.7338574\n백령도 0.6748956 0.6582473\n북강릉 0.8432934 0.8199419\n강릉   0.8330011 0.8096752\n서울   0.7469890 0.6839612\n인천   0.7696582 0.7335185\n원주   0.8529069 0.7844827\n울릉도 0.8405379 0.8416816\n수원   0.8002023 0.7522104\n서산   0.8266329 0.7786239\n청주   0.8572851 0.8099774\n대전   0.8707417 0.8341432\n추풍령 0.9206766 0.8954423\n안동   0.9374623 0.8975146\n포항   0.8976606 0.9305404\n대구   0.9237607 0.9071324\n전주   0.8639775 0.8337050\n창원   0.8615422 0.8813468\n광주   0.8567084 0.8411881\n부산   0.8637152 0.8826649\n목포   0.8320770 0.8218488\n여수   0.8541911 0.8423813\n흑산도 0.7166094 0.7295972\n고창   0.8562145 0.8309374\n홍성   0.8399010 0.8013453\n제주   0.8098152 0.8189803\n고산   0.7986642 0.7838201\n진주   0.8741628 0.8836543\n고창군 0.8571222 0.8337294\n영광군 0.8502198 0.8299023\n김해시 0.8635978 0.8931187\n순창군 0.8825241 0.8527455\n북창원 0.8715869 0.8952267\n양산시 0.8733397 0.9012255\n보성군 0.8559264 0.8513353\n강진군 0.8353581 0.8256217\n의령군 0.8870534 0.8981893\n함양군 0.8958706 0.8811767\n광양시 0.8615321 0.8530420\n청송군 1.0000000 0.9062223\n경주시 0.9062223 1.0000000\n\n\n\n%%R\nwrite.csv(weight, './data2/weight.csv', row.names=FALSE)"
  },
  {
    "objectID": "posts/SOLAR/2023-04-12-데이터수정.html#ept-weight",
    "href": "posts/SOLAR/2023-04-12-데이터수정.html#ept-weight",
    "title": "[SOLAR] Crate Dataset (22/06~22/09/15)",
    "section": "EPT Weight",
    "text": "EPT Weight\n\ntrain = pd.read_csv('./data2/train.csv')\n\n\ntrain.duplicated().sum()\n\n0\n\n\n\n%R -i train\n\n\n%%R\nlibrary(EPT)\ntrain%>%head()\n\n  region solar_radiation             date\n0 북춘천               0 2022-06-01-00:00\n1 북춘천               0 2022-06-01-01:00\n2 북춘천               0 2022-06-01-02:00\n3 북춘천               0 2022-06-01-03:00\n4 북춘천               0 2022-06-01-04:00\n5 북춘천               0 2022-06-01-05:00\n\n\n\nPlot\n\n%%R\nfor (i in 1:44){\n     assign(paste0('data',1:44)[i],train |> filter(region == unique(train$region)[i]))\n     assign(paste0('data',1:44)[i],eval(parse(text=paste0('data',i)))[order(eval(parse(text=paste0('data',i)))$date),])\n     assign(paste0('y',1:44)[i], eval(parse(text=paste0('data',i)))$solar_radiation)\n}\n\n\n%%R\nfor (i in 1:44){\n    plot(eval(parse(text=paste0('y',i)))[1:500], ann=FALSE)\n    lines(eval(parse(text=paste0('y',i))),lty=2)\n    title(main = as.character(unique(train$region)[i]), xlab='time', ylab='solar radiation')\n    }\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEPT 수행\n\n%%R\nept = function(y){\n    EpM = eptransf(signal=y,tau=24,process=c(\"envelope\",\"average\"))$EpM\n    EpM*2\n}\n\n\n%%R\nlibrary(tictoc)\n\nR[write to console]: \nAttaching package: ‘tictoc’\n\n\nR[write to console]: The following object is masked from ‘package:data.table’:\n\n    shift\n\n\n\n\n\n%%R\ntic('지역별 yU계산')\nfor (i in 1:44){\n    assign(paste0('yU',1:44)[i], ept(eval(parse(text=paste0('y',i)))))\n}\ntoc()\n\n지역별 yU계산: 33.726 sec elapsed\n\n\n\n\nyU저장\n\n%%R\ndf_yU = do.call(cbind.data.frame, mget(paste0('yU', 1:44)))\n\n\n%%R\nwrite.csv(df_yU, './data2/df_yU.csv', row.names=FALSE)\n\n\n\n시각화\n\n%%R\nfor (i in 1:44){\n    plot(eval(parse(text=paste0('y',i)))[1:500], ann=FALSE)\n    lines(eval(parse(text=paste0('yU',i))),col = 2, lty=2)\n    title(main = as.character(unique(train$region)[i]), xlab='time', ylab='solar radiation')\n    }\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nyU Correlation\n\n%%R\nyU_cor = cor(df_yU)\n\n\n%%R\nwrite.csv(yU_cor, './data2/yU_weight.csv', row.names=FALSE)"
  },
  {
    "objectID": "posts/SOLAR/2023-04-12-데이터수정.html#create-stgcn-datset",
    "href": "posts/SOLAR/2023-04-12-데이터수정.html#create-stgcn-datset",
    "title": "[SOLAR] Crate Dataset (22/06~22/09/15)",
    "section": "Create STGCN Datset",
    "text": "Create STGCN Datset\n\nimport\n\nimport pandas as pd\nimport numpy as np\n\n\ndf = pd.read_csv('./data2/solar_radiation.csv')\nweight = pd.read_csv('./data2/weight.csv')\nept_weight = pd.read_csv('./data2/yU_weight.csv')\n\n(103576, 4)\n\n\n\ndf.head()\n\n\n\n\n\n  \n    \n      \n      Unnamed: 0\n      region\n      solar_radiation\n      date\n    \n  \n  \n    \n      0\n      0\n      북춘천\n      0.0\n      2022-06-01-00:00\n    \n    \n      1\n      1\n      북춘천\n      0.0\n      2022-06-01-01:00\n    \n    \n      2\n      2\n      북춘천\n      0.0\n      2022-06-01-02:00\n    \n    \n      3\n      3\n      북춘천\n      0.0\n      2022-06-01-03:00\n    \n    \n      4\n      4\n      북춘천\n      0.0\n      2022-06-01-04:00\n    \n  \n\n\n\n\n\ndf.tail()\n\n\n\n\n\n  \n    \n      \n      Unnamed: 0\n      region\n      solar_radiation\n      date\n    \n  \n  \n    \n      103571\n      30003\n      경주시\n      0.41\n      2022-09-15-17:00\n    \n    \n      103572\n      30004\n      경주시\n      0.12\n      2022-09-15-18:00\n    \n    \n      103573\n      30005\n      경주시\n      0.01\n      2022-09-15-19:00\n    \n    \n      103574\n      30006\n      경주시\n      0.00\n      2022-09-15-20:00\n    \n    \n      103575\n      30007\n      경주시\n      0.00\n      2022-09-15-21:00\n    \n  \n\n\n\n\n\ndf.duplicated().sum()\n\n0\n\n\n\n# df = df.iloc[:,1:]\n\n\n%R -i df\n\n\n%%R\ndf = df |> mutate(date=ymd_hm(date))\ndf <- df %>%\n          group_by(region) %>%\n          mutate(row = row_number()) %>%\n          tidyr::pivot_wider(names_from = region, values_from = solar_radiation) %>%\n          select(-row)\n\n\n%%R\ndf %>% head()\n\n# A tibble: 6 × 45\n  date                북춘천  철원 대관령  춘천 백령도 북강릉  강릉  서울  인천\n  <dttm>               <dbl> <dbl>  <dbl> <dbl>  <dbl>  <dbl> <dbl> <dbl> <dbl>\n1 2022-06-01 00:00:00      0     0      0     0      0      0     0     0     0\n2 2022-06-01 01:00:00      0     0      0     0      0      0     0     0     0\n3 2022-06-01 02:00:00      0     0      0     0      0      0     0     0     0\n4 2022-06-01 03:00:00      0     0      0     0      0      0     0     0     0\n5 2022-06-01 04:00:00      0     0      0     0      0      0     0     0     0\n6 2022-06-01 05:00:00      0     0      0     0      0      0     0     0     0\n# … with 35 more variables: 원주 <dbl>, 울릉도 <dbl>, 수원 <dbl>, 서산 <dbl>,\n#   청주 <dbl>, 대전 <dbl>, 추풍령 <dbl>, 안동 <dbl>, 포항 <dbl>, 대구 <dbl>,\n#   전주 <dbl>, 창원 <dbl>, 광주 <dbl>, 부산 <dbl>, 목포 <dbl>, 여수 <dbl>,\n#   흑산도 <dbl>, 고창 <dbl>, 홍성 <dbl>, 제주 <dbl>, 고산 <dbl>, 진주 <dbl>,\n#   고창군 <dbl>, 영광군 <dbl>, 김해시 <dbl>, 순창군 <dbl>, 북창원 <dbl>,\n#   양산시 <dbl>, 보성군 <dbl>, 강진군 <dbl>, 의령군 <dbl>, 함양군 <dbl>,\n#   광양시 <dbl>, 청송군 <dbl>, 경주시 <dbl>\n# ℹ Use `colnames()` to see all variable names\n\n\n\n%%R\nwrite.csv(df,'./data2/restructuring_data.csv', row.names=FALSE)\n\n\nimport gc\ngc.collect()\n\n2599\n\n\n\n\nSTGCN Ver1\n\ndf = pd.read_csv('./data2/restructuring_data.csv')\ndf.head()\n\n\n\n\n\n  \n    \n      \n      date\n      북춘천\n      철원\n      대관령\n      춘천\n      백령도\n      북강릉\n      강릉\n      서울\n      인천\n      ...\n      순창군\n      북창원\n      양산시\n      보성군\n      강진군\n      의령군\n      함양군\n      광양시\n      청송군\n      경주시\n    \n  \n  \n    \n      0\n      2022-06-01 00:00:00\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      ...\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n    \n    \n      1\n      2022-06-01 01:00:00\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      ...\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n    \n    \n      2\n      2022-06-01 02:00:00\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      ...\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n    \n    \n      3\n      2022-06-01 03:00:00\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      ...\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n    \n    \n      4\n      2022-06-01 04:00:00\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      ...\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n    \n  \n\n5 rows × 45 columns\n\n\n\n\ndf.iloc[2116]\n\ndate    2022-09-05 04:00:00\n북춘천                     0.0\n철원                      0.0\n대관령                     0.0\n춘천                      0.0\n백령도                     0.0\n북강릉                     0.0\n강릉                      0.0\n서울                      0.0\n인천                      0.0\n원주                      0.0\n울릉도                     0.0\n수원                      0.0\n서산                      0.0\n청주                      0.0\n대전                      0.0\n추풍령                     0.0\n안동                      0.0\n포항                      0.0\n대구                      0.0\n전주                      0.0\n창원                      0.0\n광주                      0.0\n부산                      0.0\n목포                      0.0\n여수                      0.0\n흑산도                     0.0\n고창                      0.0\n홍성                      0.0\n제주                      0.0\n고산                      0.0\n진주                      0.0\n고창군                     0.0\n영광군                     0.0\n김해시                     0.0\n순창군                     0.0\n북창원                     0.0\n양산시                     0.0\n보성군                     0.0\n강진군                     0.0\n의령군                     0.0\n함양군                     0.0\n광양시                     0.0\n청송군                     0.0\n경주시                     0.0\nName: 2116, dtype: object\n\n\n\ndf2 = df.iloc[:,1:]\n\n\nnode_list =(df2.columns).tolist()\nnode_ids = {node : i for i, node in enumerate(node_list)}\nnode_ids\n\n{'북춘천': 0,\n '철원': 1,\n '대관령': 2,\n '춘천': 3,\n '백령도': 4,\n '북강릉': 5,\n '강릉': 6,\n '서울': 7,\n '인천': 8,\n '원주': 9,\n '울릉도': 10,\n '수원': 11,\n '서산': 12,\n '청주': 13,\n '대전': 14,\n '추풍령': 15,\n '안동': 16,\n '포항': 17,\n '대구': 18,\n '전주': 19,\n '창원': 20,\n '광주': 21,\n '부산': 22,\n '목포': 23,\n '여수': 24,\n '흑산도': 25,\n '고창': 26,\n '홍성': 27,\n '제주': 28,\n '고산': 29,\n '진주': 30,\n '고창군': 31,\n '영광군': 32,\n '김해시': 33,\n '순창군': 34,\n '북창원': 35,\n '양산시': 36,\n '보성군': 37,\n '강진군': 38,\n '의령군': 39,\n '함양군': 40,\n '광양시': 41,\n '청송군': 42,\n '경주시': 43}\n\n\n\nedges = []    \n \nfor i in range(44):\n    for j in range(44):\n        if i != j:\n            edges.append([i,j]) \n# print(edges)\n\n\nweights = []    \n \nfor i in range(44):\n    for j in range(44):\n        if i != j:\n            weights.append(weight.iloc[i,j]) \n\n\nnp.array(weights).shape\n\n(1892,)\n\n\n\nlen(df['date']) # time\n\n2354\n\n\n\nFX = []    \nfor i in range(2354):\n    FX.append(list(df2.iloc[i,:])) \n#FX\n\n\nnp.array(FX).shape\n\n(2354, 44)\n\n\n- weights, edges, node_ids, FX\n\ndata_dict = {'edges':edges, 'node_ids':node_ids, 'weights':weights, 'FX':FX}\n\n\ndata_dict.keys()\n\ndict_keys(['edges', 'node_ids', 'weights', 'FX'])\n\n\n\nfile_path = './data2/stgcn_data1.json'\n\n\nwith open(file_path, 'w') as f:\n    json.dump(data_dict, f)\n\n\nwith open(file_path, 'r') as f:\n    test = json.load(f, encoding='cp949')\n\n\nimport gc\ngc.collect()\n\n478\n\n\n\nnp.array(data_dict['weights']).mean()\n\n0.8219681077476771\n\n\n\n\nSTGCN Ver2\n\n# ept_weight\n\n\nept_weights = []    \n \nfor i in range(44):\n    for j in range(44):\n        if i != j:\n            ept_weights.append(ept_weight.iloc[i,j]) \n\n\nnp.mean(weights), np.mean(ept_weights)\n\n(0.8219681077476771, 0.5169148477886164)\n\n\n\ndata_dict2 = data_dict.copy()\n\n\ndata_dict2['weights'] = ept_weights\n\n\ndata_dict2['weights'][:10]\n\n[0.907927740795389,\n 0.753186806078073,\n 0.967586720050605,\n 0.501379102625285,\n 0.540227617256133,\n 0.529185554166601,\n 0.798735545675966,\n 0.772408710532103,\n 0.70807809817889,\n 0.405231743243313]\n\n\n\nnp.array(data_dict2['weights']).mean()\n\n0.5169148477886164\n\n\n\nfile_path = './data2/stgcn_data2.json'\n\n\n# with open(file_path, 'w') as f:\n#     json.dump(data_dict2, f)\n\n\n# with open(file_path, 'r') as f:\n#     test2 = json.load(f, encoding='cp949')"
  },
  {
    "objectID": "posts/SOLAR/2023-04-12-데이터수정.html#comparision",
    "href": "posts/SOLAR/2023-04-12-데이터수정.html#comparision",
    "title": "[SOLAR] Crate Dataset (22/06~22/09/15)",
    "section": "Comparision",
    "text": "Comparision\n\nplt.hist(np.array(weights), alpha = 0.5, label = 'weights')\nplt.hist(np.array(ept_weights), alpha = 0.5, label = 'EPT weights')\nplt.legend(loc='upper left')\n\n<matplotlib.legend.Legend at 0x7f8b479ab880>\n\n\n\n\n\n\n모듈 수정"
  },
  {
    "objectID": "posts/post-with-code/index.html",
    "href": "posts/post-with-code/index.html",
    "title": "Post With Code",
    "section": "",
    "text": "This is a post with executable code."
  },
  {
    "objectID": "posts/HousePrice/2023-04-20-ts-이산형확률분포.html",
    "href": "posts/HousePrice/2023-04-20-ts-이산형확률분포.html",
    "title": "Discrete Probability Distribution (추가중)",
    "section": "",
    "text": "다항분포는 이항분포와 비슷하지만 각 시행에서 나올 수 있는 결과의 범주가 2개이상이다. 이항분포의 확장버전이라고 생각하면 된다.\n\n\nref: https://www.youtube.com/watch?v=syVW7DgvUaY\n\n\n\n\n\n\nimage.png\n\n\n\n\n\n\n\n\nimage.png\n\n\n\n\n\n\n\n\nExample1\n\n\n\\[P(X_1=6, X_2=2, X_3=1, X_4=1) = \\frac{10!}{6!2!1!1!}(0.44)^6(0.42)^2(0.10)^1(0.04)^1 = 0.01290\\]\n\n\n\n\n\n\nExample2\n\n\n\\[P(X_1 = 2, X_2=1, X_3=3) = \\frac{6!}{2!1!3!}\\left(\\frac{8}{20}\\right)^2 \\left(\\frac{3}{20}\\right)^1 \\left(\\frac{9}{20}\\right)^3 = 0.13122\\]\n\n\n\n\n\n\nimage.png\n\n\n\n\n\n\n\n\nExample3\n\n\n복원추출이 아니라면, 더 이상 각 시행은 독립이 아니다.\n\\[P(X_1=2, X_2=1, X_3=3) = \\frac{\\binom{8}{2}\\binom{3}{1}\\binom{9}{3}}{\\binom{20}{6}}=0.18204\\]\n\n분모: total number of possible samples\n분자: total number of samples that get us what we want\n\n\n\n\n\\((X_1, X_2, X_3) \\sim MULT(n, p_1,p_2,p_3)\\)일 때 \\(X_1|X_2=x_2\\)의 조건부 확률밀도함수를 구하시오.\n(sol)\n(간단한 방법)\n\\[f_{X_1|X_2}(x_1|x_2) = \\frac{f_{X_1,X_2}(x_1,x_2)}{f_{X_2}(x_2)}\\]\nstep1\n우리가 관심있는 사건은 \\(X_1\\)이라 한다면 관심없는 두 사건 \\(X_2, X_3\\)를 하나로 생각한다면, 관심있는 사건, 관심없는 사건 두가지의 결과로 이루어진 이항분포라고 할 수 있다.\n\n\\(X_1 \\sim B(n,p_1)\\)\n\\(X_2 \\sim B(n,p_2)\\)\n\nstep2\n\n3가지 결과만 나오는 경우 \\(X_1,X_2\\)의 결합 pdf는 다음과 같이 정의할 수 있다. (\\(X_1, X_2\\)를 알면 자연스럽)게 \\(X_3\\)를 알 수 있다.\n\n\\[\\begin{align*} f_{X_1,X_2}(x_1,x_2) &= P(X_1=x_2, X_2=x_2)\\\\\n&= P(X_1=x_1, X_2=x_2, X_3 = n-x_1-x_2) \\\\\n&= \\frac{n!}{x_1!x_2!(n-x_1-x_2)!}p_1^{x_1}p_2^{x_2}p_3^{n-x_1-x_2}\\end{align*}\\]\n\nstep1에서 \\(X_1\\)과 \\(X_2\\)는 베르누이 시행을 독립적으로 \\(n\\)번 반복할 때 각 시행에서의 관심사건의 확률이 \\(p_1, p_2\\)인 이항분포를 따름을 알 수 있었다. 이를 이용하면 \\(X_2\\)의 marginal pdf를 구할 수 있다.\n\n\\[f_{X_2}(x_2) = \\frac{n!}{x_2!(n-x_2)!}p_2^{x_2}(1-p_2)^{n-x_2}\\]\nstep3\n이전 단계에서 구한 \\(X_1,X_2\\)와 결합pdf와 \\(X_2\\)의 marginal pdf를 이용하면 \\(X_1|X_2=x_2\\)의 조건부확률밀도함수를 구할 수 있다.\n\\[\\begin{align*}f_{X_1|X_2}(x_1|x_2) &= \\frac{f_{X_1,X_2}(x_1,x_2)}{f_{X_2}(x_2)}\\\\\n&= \\frac{\\frac{n!}{x_1!x_2!(n-x_1-x_2)!}p_1^{x_1}p_2^{x_2}p_3^{n-x_1-x_2}}{ \\frac{n!}{x_2!(n-x_2)!}p_2^{x_2}(1-p_2)^{n-x_2}} \\\\\n&= \\frac{(n-x_2)!}{x_1!(n-x_1-x_2)!}\\left(\\frac{p_1}{1-p_2}\\right)^{x_1}\\left(\\frac{p_3}{1-p_2}\\right)^{n-x_1-x_2}\\\\\n&=\\frac{(n-x_2)!}{x_1!(n-x_1-x_2)!}\\left(\\frac{p_1}{1-p_2}\\right)^{x_1}\\left(1-\\frac{p_1}{1-p_2}\\right)^{n-x_1-x_2}\\\\\n&= \\binom{n-x_2}{x_1}\\left(\\frac{p_1}{1-p_2}\\right)^{x_1} \\left(1-\\frac{p_1}{1-p_2}\\right)^{n-x_1-x_2}\\\\\n&\\sim B\\left(n-x_2, \\frac{p_1}{1-p_2}\\right) \\end{align*}\\]"
  },
  {
    "objectID": "posts/HousePrice/2023-04-26-lr-회귀진단.html",
    "href": "posts/HousePrice/2023-04-26-lr-회귀진단.html",
    "title": "04. 가변수(Indicator Variable) 실습",
    "section": "",
    "text": "모형: \\(y=\\beta_0 + \\beta_1x_1 + \\beta_2x_2 + \\epsilon, \\epsilon\\sim N(0,\\sigma^2) \\text{ indep }\\)\n유의성검정\n\n\n모형: \\(H_0: \\beta_1 = \\beta_2 = 0 \\quad (F)\\)\n회귀계수: \\(H_0:\\beta_1=0, H_0:\\beta_2=0 \\quad (t)\\)\n\n\n적합도: \\(R^2, R^2_{Adj}, \\sqrt{MSE} = RMSE\\) : 비교\n회귀진단\n\n\n\n잔차분석 (모형에 대한 가정 검토)  – \\(e_i = y_i -\\hat{y}_i\\) \n\n\n적절한 모형의 선택  – 변수변환,\\(\\log, x^2, \\dots,\\) 변수선택\n\n\n독립변수들간의 상관관계 검토 – 다중공선성 (multi-co-linearity)\n\n\n지렛대점(leverage point)의 검출\n\n\n이상치(outlier) 확인\n\n\n영향점(influential observation)의 검출\n\n\n오차항의 가정검토 (잔차분석)\n잔차라고 하는 것은 여러가지 의미를 갖는다. 잔차라고 하는 것은 우리가 설정한 모형에서 오차항에 대한 가정을 보는 것인데 오차는 실제 관측할 수 없는 값을 의미하기 때문에 오차 대신에 잔차를 이용해서 잔차가 마치 오차인 것 처럼 가정 검토를 하는 것이다.\n잔차는 \\(\\text{실제값}-\\text{예측값}\\)인데 이 잔차를 (\\(e_i = y_i-\\hat{y}_i\\)) 오차항에 대략적으로 대한 추정값(\\(\\hat{\\epsilon}_i\\))이라고 생각할 수 있다.\n따라서 \\(\\epsilon\\sim N(0,\\sigma^2) \\text{ indep }\\) 라고 했으니 이를 검토하기 위해 잔차(\\(e_1, e_2,\\dots e_n)\\)을 사용하는 것\n\n\n\n\n\n\nlibrary(ggplot2)\n\n\ndt <- data.frame(\n  y = c(17,26,21,30,22,1,12,19,4,16,\n        28,15,11,38,31,21,20,13,30,14),\n  x1 = c(151,92,175,31,104,277,210,120,290,238,\n         164,272,295,68,85,224,166,305,124,246),\n  x2 = rep(c('M','F'), each=10)\n)\n\nhead(dt)\n\n\n\nA data.frame: 6 × 3\n\n    yx1x2\n    <dbl><dbl><chr>\n\n\n    117151M\n    226 92M\n    321175M\n    430 31M\n    522104M\n    6 1277M\n\n\n\n\n\ncontrasts(factor(dt$x2))\n\n\n\nA matrix: 2 × 1 of type dbl\n\n    M\n\n\n    F0\n    M1\n\n\n\n\n\n\n\n\nggplot(dt, aes(x1, y, col=x2)) + \n  geom_point(size=4) + \n  # geom_text(label=rownames(dt)) +\n  theme_bw() +\n  guides(col=guide_legend(title='성별')) +\n  scale_color_manual(labels=c('여자','남자'),\n                     values = c('darkorange', 'steelblue'))\n\n\n\n\n\n교호작용 없이 가변수를 모델에 넣어줘야겠다고 생각해볼 수 있다.\n\n\n\n\n범주형 변수(\\(x_2)\\) 즉, 성별구분 없이 모형적합.\n\nmodel_1 <- lm(y~x1, dt)\nsummary(model_1)\n\n\nCall:\nlm(formula = y ~ x1, data = dt)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-9.579 -4.737  0.721  4.224  7.936 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept) 36.40361    2.78580  13.068 1.26e-10 ***\nx1          -0.09323    0.01396  -6.677 2.91e-06 ***\n---\nSignif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n\nResidual standard error: 5.124 on 18 degrees of freedom\nMultiple R-squared:  0.7124,    Adjusted R-squared:  0.6964 \nF-statistic: 44.58 on 1 and 18 DF,  p-value: 2.906e-06\n\n\n\n모형자체는 상당히 유의하고, \\(MSE, R^2\\) 확인\n\n\nggplot(dt, aes(x1, y)) + \n  geom_point(size=4) + \n  geom_abline(slope = coef(model_1)[2], \n              intercept = coef(model_1)[1], col= 'red')+\n  theme_bw()\n\n\n\n\n\\(\\hat{y} = 36.40-0.0932x_1\\)\n\n평균적으로 \\(x=0\\)이라면 \\(36.40\\) 시간이 걸린다.\n시험성적이 1점 올라갈때마다 \\(0.09\\) 시간정도 감소한다.\n\n\n\n\n\\(\\begin{cases} x_2=0 & \\text{if F} \\text{ (BASE)}\\\\ x_2 = 1 & \\text{if M} \\end{cases}\\)\n\\(E(y|F): \\beta_0 + \\beta_1x_1\\)\n\\(E(y|M): \\beta_0 + \\beta_1x_2 + \\beta_2 = (\\beta_0 + \\beta_2) + \\beta_1x_1\\)\n\\(\\begin{align*}\\Rightarrow\\beta_2 &= E(y|M) - E(y|F) \\\\ &= \\beta_0 + \\beta_2 + \\beta_1x_1 - \\{ \\beta_0 + \\beta_1x_1\\} \\\\ &= \\text{시험(적성검사)성적이 동일할 때 여자와 남자의 소요시간 평균의 차이}\\end{align*}\\)\n\n# 뭐가 0이고 1??\ncontrasts(factor(dt$x2))\n\n\n\nA matrix: 2 × 1 of type dbl\n\n    M\n\n\n    F0\n    M1\n\n\n\n\n\ncontrast: factor로 인식이 됐을 때 뭐가 0이고 뭐가 1인지 알려줌\n교재와는 달리 \\(F\\)가 \\(0\\), \\(M\\)이 \\(1\\)임을 주의하자.\n해당 경우 \\(0\\)이 베이스이므로 여자가 베이스!!\n실제모형적합시 \\(x_2\\) 그대로 넣어주면 된다. 자연스럽게 팩터형 변수로 바뀜.\n\n\nmodel_2 <- lm(y~x1 + x2, dt)\nsummary(model_2)\n\n\nCall:\nlm(formula = y ~ x1 + x2, data = dt)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-5.0165 -1.7450 -0.6055  1.8803  6.1835 \n\nCoefficients:\n             Estimate Std. Error t value Pr(>|t|)    \n(Intercept) 41.768865   1.948930  21.432 9.64e-14 ***\nx1          -0.100918   0.008621 -11.707 1.47e-09 ***\nx2M         -7.933953   1.414702  -5.608 3.13e-05 ***\n---\nSignif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n\nResidual standard error: 3.123 on 17 degrees of freedom\nMultiple R-squared:  0.8991,    Adjusted R-squared:  0.8872 \nF-statistic: 75.72 on 2 and 17 DF,  p-value: 3.42e-09\n\n\n\n가설 : \\(\\beta_1=\\beta_2 = 0\\) \\(\\to \\text{p-value}=3.42e-09\\)로 유의\n\\(R^2, R^2_{Adj}\\) 이전 모델1에 비해 매우 증가 (\\(0.2\\) 정도 증가)\n\\(RMSE\\) 도 매우 감소\nx2M : 남자그룹의 회귀계수가 \\(-7.933953\\)을 의미한다. (즉, \\(F=0, M=1\\))\n\n\\(\\hat{\\beta}_2=-0.7933953\\) (base가 바뀌었으므로 교재와 부호가 다른것은 당연)\n적성검사 성적이 동일하다면 여자(base)보다 남자가 습득하는데 걸리는 시간이 \\(7.93\\) 시간만큼 적게 걸린다.\n\n\n\\(\\to\\) \\(x_2\\)라는 변수가 들어가면서 적합력이 매우 좋아짐을 알 수 있고 개별회귀계수에 대해서도 매우 유의함을 알 수 있다.\n\nggplot(dt, aes(x1, y, col=x2)) + \n  geom_point(size=4) + \n  theme_bw() + \n  ## Female\n  geom_abline(slope = coef(model_2)[2],  # beta1\n              intercept = coef(model_2)[1], col= 'darkorange')+ ## beta0\n  ## Male\n  geom_abline(slope = coef(model_2)[2],  # beta1\n              intercept = coef(model_2)[1]+coef(model_2)[3], col= 'steelblue')+ ## beta0 + beta3\n  guides(col=guide_legend(title=\"성별\")) +\n  scale_color_manual(labels = c(\"여자\", \"남자\"), values = c(\"darkorange\", \"steelblue\"))\n\n\n\n\n\ncoef(model_2)\n\n(Intercept)41.7688645584521x1-0.100917724773997x2M-7.93395261660133\n\n\n\n\n\n\\(H_0: \\beta_2=0 \\text{ vs. } H_1: \\beta_2 \\neq 0\\)\n\nsummary(model_2)$coef\n\n\n\nA matrix: 3 × 4 of type dbl\n\n    EstimateStd. Errort valuePr(>|t|)\n\n\n    (Intercept)41.76886461.948929636 21.4316949.640000e-14\n    x1-0.10091770.008620641-11.7065221.468240e-09\n    x2M-7.93395261.414702366 -5.6082133.134533e-05\n\n\n\n\n\nx2M의 p-value(양측검정에 대한 유의확률 값)가 아주 작기때문에 \\(\\beta_2\\)가 유의하다고 할 수 있다.\n\\(\\text{Std.Error} = \\widehat{\\text{s.e}}(\\hat{\\beta}_2)\\)\n\\(t=\\frac{\\hat{\\beta}_2}{\\widehat{\\text{s.e}}(\\hat{\\beta}_2)}\\)\n\n\n\n\n\\(H_0: \\beta_2=0 \\text{ vs. } H_1: \\beta_2 < 0\\)\n단측검정에 대한 유의확률값은 양측검정읠 p-value의 값을 2로 나눠준 값이다.\n\ncat('p-value=', 3.134533e-05/2)\n\np-value= 1.567267e-05\n\n\n따라서 남성이 여성보다 평균시간이 더 적게 걸린다.\n\n\n\nRM: model_1\nFM: model_2\n\nanova(model_1, model_2)\n\n\n\nA anova: 2 × 6\n\n    Res.DfRSSDfSum of SqFPr(>F)\n    <dbl><dbl><dbl><dbl><dbl><dbl>\n\n\n    118472.5913NA      NA      NA          NA\n    217165.8145 1306.776831.452063.134533e-05\n\n\n\n\n\n\\(RSS\\) : \\(SSE\\)라고 생각\n\n\n\n\nPartial F-test\n\n\n\n자유도가 \\(1\\)일 때 t분포의 유의확률과 \\(F\\)분포의 유의확률은 동일, t통계량을 제곱하면 F통계량이 된다.\n\n\n\n\n\n\\(y=\\beta_0 + \\beta_1x_1 + \\beta_2x_2 + \\beta_3x_1x_2 + \\epsilon\\)\n\\(\\begin{cases} x_2=0 & \\text{if F} \\text{ (BASE)}\\\\ x_2 = 1 & \\text{if M} \\end{cases}\\)\n\\(E(y|F): \\beta_0 + \\beta_1x_1 \\\\ E(y|M): \\beta_0 + \\beta_1x_2 + \\beta_2 = (\\beta_0 + \\beta_2) + (\\beta_1+\\beta_3)x_1\\)\n\nmodel_3 <- lm(y~x1*x2, dt) # lm(y~x1+x2+x1:x2, dt)\nsummary(model_3)\n\n\nCall:\nlm(formula = y ~ x1 * x2, data = dt)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-5.0463 -1.7591 -0.6232  1.9311  6.1102 \n\nCoefficients:\n             Estimate Std. Error t value Pr(>|t|)    \n(Intercept) 41.969620   2.635580  15.924 3.11e-11 ***\nx1          -0.101948   0.012474  -8.173 4.20e-07 ***\nx2M         -8.313516   3.541379  -2.348   0.0321 *  \nx1:x2M       0.002089   0.017766   0.118   0.9078    \n---\nSignif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n\nResidual standard error: 3.218 on 16 degrees of freedom\nMultiple R-squared:  0.8992,    Adjusted R-squared:  0.8803 \nF-statistic: 47.56 on 3 and 16 DF,  p-value: 3.405e-08\n\n\n\n모형 자체 유의\n\\(\\beta_3\\) 즉, 교호작용 텀을 추가하였지만 \\(R^2_{Adj}\\)는 오히려 감소 (\\(R^2_{Adj}: 0.8872(\\beta_1, \\beta_2)\\to 0.8803(\\beta_1,\\beta_2, \\beta_3)\\))\n\\(RMSE\\) 역시 약간 증가. (\\(3.123 \\to 3.218\\))\n\\(\\beta_3\\)를 넣었어도 모형이 좋아지지 않네? \\(\\to\\) 실제로 \\(\\beta_3\\)의 회귀계수가 유의하지 않다고 나왔다. (통계적으로 유의하지 X)\n\n\n\n\n교호작용\n\n\n\n## y = b0 + b1x1 + b2x2 + b3x1x2\n## M : x2=0 => E(y|M) = b0+b1x1\n## F : x2=1 => E(y|F) = b0 + b1x1 + b2 + b3x1 \n##                    = (b0+b2) + (b1+b3)x1\n\nggplot(dt, aes(x1, y, col=x2)) + \n  geom_point(size=4) + \n  theme_bw() + \n  geom_abline(slope = coef(model_3)[2], \n              intercept = coef(model_3)[1], col= 'darkorange')+\n  geom_abline(slope = coef(model_3)[2]+coef(model_3)[4], \n              intercept = coef(model_3)[1]+coef(model_3)[3], col= 'steelblue')+\n  guides(col=guide_legend(title=\"성별\")) +\n  scale_color_manual(labels = c(\"여자\", \"남자\"), values = c(\"darkorange\", \"steelblue\"))\n\n\n\n\n\n\n\\(H_0: \\beta_3=0 \\text{ vs. } H_1: \\beta_3 \\neq 0\\)\n\nsummary(model_3)$coef\n\n\n\nA matrix: 4 × 4 of type dbl\n\n    EstimateStd. Errort valuePr(>|t|)\n\n\n    (Intercept)41.969619602.6355804515.92424153.106803e-11\n    x1-0.101947770.01247420-8.17268934.198832e-07\n    x2M-8.313515643.54137909-2.34753623.209176e-02\n    x1:x2M 0.002089330.01776597 0.11760299.078460e-01\n\n\n\n\n- Partial F-test\n\\(H_0: \\beta_3=0 \\text{ vs. } H_1: \\beta_3 \\neq 0\\)\n\nanova(model_2, model_3)\n\n\n\nA anova: 2 × 6\n\n    Res.DfRSSDfSum of SqFPr(>F)\n    <dbl><dbl><dbl><dbl><dbl><dbl>\n\n\n    117165.8145NA       NA        NA      NA\n    216165.6713 10.14320670.013830450.907846\n\n\n\n\n\nPartial F-test 결과도 위와 같다.\n\n\n\n\n\\(H_0: \\beta_2=\\beta_3=0 \\text{ vs. } H_1: \\text{not } H_1 \\neq 0\\)\n\n\\(RM:\\) model_1 \\((x_1)\\)\n\\(FM:\\) model_3 \\((x_1*x_2)\\)\n\n- Partial F-test\n\nanova(model_1, model_3)\n\n\n\nA anova: 2 × 6\n\n    Res.DfRSSDfSum of SqFPr(>F)\n    <dbl><dbl><dbl><dbl><dbl><dbl>\n\n\n    118472.5913NA    NA      NA          NA\n    216165.6713 2306.9214.820680.0002280824\n\n\n\n\n\n\n\nmodel_1(RM) vs. model_3(FM)\n\n\n\n\n\n\n\ndt2 <- data.frame(y = dt$y,\n                  x1 = dt$x1,\n                  x2 = as.numeric(dt$x2=='M'),\n                  x3 = as.numeric(dt$x2=='F'))\n\ndt2\n\n\n\nA data.frame: 20 × 4\n\n    yx1x2x3\n    <dbl><dbl><dbl><dbl>\n\n\n    1715110\n    26 9210\n    2117510\n    30 3110\n    2210410\n     127710\n    1221010\n    1912010\n     429010\n    1623810\n    2816401\n    1527201\n    1129501\n    38 6801\n    31 8501\n    2122401\n    2016601\n    1330501\n    3012401\n    1424601\n\n\n\n\n\n\n\\(\\beta_0\\)와 \\(\\beta_2x_2 + \\beta_2x_2\\) 가 linearly independent하지 않아서 rank가 줄어들기 때문에 LSE를 구할 수 없게 된다. \\((1 = x_2 + x_3)\\)\n아래의 표에서 확인할 수 있듯이 \\(x3\\)에 대한 LSE 값이 구해지지 않았다. (Full rank가 아니기 때문에 구해지지 않는다.)\n\nmodel_4 <- lm(y~ ., dt2)\nsummary(model_4)\n\n\nCall:\nlm(formula = y ~ ., data = dt2)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-5.0165 -1.7450 -0.6055  1.8803  6.1835 \n\nCoefficients: (1 not defined because of singularities)\n             Estimate Std. Error t value Pr(>|t|)    \n(Intercept) 41.768865   1.948930  21.432 9.64e-14 ***\nx1          -0.100918   0.008621 -11.707 1.47e-09 ***\nx2          -7.933953   1.414702  -5.608 3.13e-05 ***\nx3                 NA         NA      NA       NA    \n---\nSignif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n\nResidual standard error: 3.123 on 17 degrees of freedom\nMultiple R-squared:  0.8991,    Adjusted R-squared:  0.8872 \nF-statistic: 75.72 on 2 and 17 DF,  p-value: 3.42e-09\n\n\n\n\n\n\n절편, \\(x_2, x_3\\) 중 하나를 날리면 된다.\n\n\n\n\\(\\begin{cases} x_2=\\begin{cases}1 & M\\\\ 0 & F \\end{cases} \\\\ x_3=\\begin{cases} 0 & M\\\\ 1 & F\\end{cases}\\end{cases}\\)\n\\(E(y|M) = \\beta_1x_1 + \\beta_2\\)\n\\(E(y|F) = \\beta_1x_1 + \\beta_3\\)\n기울기는 동일한데 절편이 \\(\\beta_2, \\beta_3\\) 이렇게 차이가 나는 것이다.\n앞에서 썼던 절편이 있는 모형으로 친다면 \\(E(y|M) = (\\beta_0 + \\beta_2) + \\beta_1x_1\\) 이고, \\(\\beta_2 = \\beta_0+\\beta_2\\) 라고 생각하면 된다.\n\nmodel_5 <- lm(y~0+x1+x2+x3, dt2) ## 절편이 없는 모델.\nsummary(model_5)\n\n\nCall:\nlm(formula = y ~ 0 + x1 + x2 + x3, data = dt2)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-5.0165 -1.7450 -0.6055  1.8803  6.1835 \n\nCoefficients:\n    Estimate Std. Error t value Pr(>|t|)    \nx1 -0.100918   0.008621  -11.71 1.47e-09 ***\nx2 33.834912   1.758659   19.24 5.64e-13 ***\nx3 41.768865   1.948930   21.43 9.64e-14 ***\n---\nSignif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n\nResidual standard error: 3.123 on 17 degrees of freedom\nMultiple R-squared:  0.982, Adjusted R-squared:  0.9788 \nF-statistic:   309 on 3 and 17 DF,  p-value: 5.047e-15\n\n\n\n\n\nmodel_5: 절편이 없는 모델\n\n\n\n\n\n성별에 따른 절편의 차이가 있을까?\n\n\n\n가변수를 사용하거나 절편을 없는 모델을 사용하는 방법이 있는데 절편이 없는 모형보다 가변수 사용을 추천(해석 측면에서 좋음)\n\n\n\n\n\n\n\nlibrary(ISLR)\n\nhead(Carseats)\ndim(Carseats)\n\n\n\nA data.frame: 6 × 11\n\n    SalesCompPriceIncomeAdvertisingPopulationPriceShelveLocAgeEducationUrbanUS\n    <dbl><dbl><dbl><dbl><dbl><dbl><fct><dbl><dbl><fct><fct>\n\n\n    1 9.50138 7311276120Bad   4217YesYes\n    211.22111 4816260 83Good  6510YesYes\n    310.06113 3510269 80Medium5912YesYes\n    4 7.40117100 4466 97Medium5514YesYes\n    5 4.15141 64 3340128Bad   3813YesNo \n    610.8112411313501 72Bad   7816No Yes\n\n\n\n\n\n40011\n\n\n• Sales : 판매량 (단위: 1,000)\n• Price : 각 지점에서의 카시트 가격\n• ShelveLoc : 진열대의 등급 (Bad, Medium, Good)\n• Urban :도시 여부 (Yes, No)\n• US : 미국 여부 (Yes, No)\n\n\n\nBad(base) vs. Medium vs. Good\n\n\n\n\n가격이 동일하다면 평균적인 판매량이 나쁜위치에 있는 카시트보다 좋은 위치에 있는 카시트가 \\(\\beta_2\\) 만큼 더 차이가 날 것이다.\n가격이 동일하다면 평균적인 판매량이 나쁜위치에 있는 카시트보다 중간 위치에 있는 카시트가 \\(\\beta_3\\)만큼 더 차이가 날 것이다.\n\n\nfit <- lm(fit<-lm(Sales~Price+ShelveLoc, \n                  data=Carseats))\nsummary(fit)        \n\n\nCall:\nlm(formula = fit <- lm(Sales ~ Price + ShelveLoc, data = Carseats))\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-5.8229 -1.3930 -0.0179  1.3868  5.0780 \n\nCoefficients:\n                 Estimate Std. Error t value Pr(>|t|)    \n(Intercept)     12.001802   0.503447  23.839  < 2e-16 ***\nPrice           -0.056698   0.004059 -13.967  < 2e-16 ***\nShelveLocGood    4.895848   0.285921  17.123  < 2e-16 ***\nShelveLocMedium  1.862022   0.234748   7.932 2.23e-14 ***\n---\nSignif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n\nResidual standard error: 1.917 on 396 degrees of freedom\nMultiple R-squared:  0.5426,    Adjusted R-squared:  0.5391 \nF-statistic: 156.6 on 3 and 396 DF,  p-value: < 2.2e-16\n\n\n\n\n\nlm(formula = fit <- lm(Sales ~ Price + ShelveLoc, data = Carseats))\n\n\n\n가격이 1만큼 높아지면 평균 판매량이 \\(0.056698\\) 만큼 감소한다. (음의관계)\n\n\ncontrasts(Carseats$ShelveLoc) # Good(x2), Medium(x3)\n\n\n\nA matrix: 3 × 2 of type dbl\n\n    GoodMedium\n\n\n    Bad00\n    Good10\n    Medium01\n\n\n\n\n\nggplot(Carseats, aes(Price, Sales, col=ShelveLoc)) + \n  geom_point() + \n  theme_bw() + \n  geom_abline(slope = coef(fit)[2], \n              intercept = coef(fit)[1], col= 'darkorange')+\n  geom_abline(slope = coef(fit)[2], \n              intercept = coef(fit)[1]+coef(fit)[3], col= 'steelblue')+\n  geom_abline(slope = coef(fit)[2], \n              intercept = coef(fit)[1]+coef(fit)[4], col= 'darkgreen')+\n  guides(col=guide_legend(title=\"ShelveLoc\")) +\n  scale_color_manual(labels = c(\"Bad\", \"Good\", \"Medium\"), \n                     values = c(\"darkorange\", \"steelblue\",\"darkgreen\"))\n\n\n\n\n\n\n\nBad vs. Good vs. Medium\n\n\n\nfit1 <- lm(Sales~Price+ShelveLoc+US, \n                  data=Carseats)\nsummary(fit1)        \n\n\nCall:\nlm(formula = Sales ~ Price + ShelveLoc + US, data = Carseats)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-5.1720 -1.2587 -0.0056  1.2815  4.7462 \n\nCoefficients:\n                 Estimate Std. Error t value Pr(>|t|)    \n(Intercept)     11.476347   0.498083  23.041  < 2e-16 ***\nPrice           -0.057825   0.003938 -14.683  < 2e-16 ***\nShelveLocGood    4.827167   0.277294  17.408  < 2e-16 ***\nShelveLocMedium  1.893360   0.227486   8.323 1.42e-15 ***\nUSYes            1.013071   0.195034   5.194 3.30e-07 ***\n---\nSignif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n\nResidual standard error: 1.857 on 395 degrees of freedom\nMultiple R-squared:  0.5718,    Adjusted R-squared:  0.5675 \nF-statistic: 131.9 on 4 and 395 DF,  p-value: < 2.2e-16\n\n\n\n\n\ndt <- data.frame(\n  y = c(377,249,355,475,139,452,440,257),\n  x1 = c(480,720,570,300,800,400,340,650)\n)\n\n\nggplot(data = dt, aes(x = x1, y = y)) + \n  geom_point(color='steelblue') + \n  theme_bw()\n\n\n\n\n\n### threshould = 500\n## x2(x1-xw)=x2(x1-500) = (x1 - 500)+ := x2\n\ndt$x2 = sapply(dt$x1, function(x) max(0, x-500))\n\nm <- lm(y ~ x1+x2, dt)\nsummary(m)\n\n\nCall:\nlm(formula = y ~ x1 + x2, data = dt)\n\nResiduals:\n      1       2       3       4       5       6       7       8 \n-22.765  29.765  18.068   4.068 -17.463  20.605 -15.117 -17.160 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept) 589.5447    60.4213   9.757 0.000192 ***\nx1           -0.3954     0.1492  -2.650 0.045432 *  \nx2           -0.3893     0.2310  -1.685 0.152774    \n---\nSignif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n\nResidual standard error: 24.49 on 5 degrees of freedom\nMultiple R-squared:  0.9693,    Adjusted R-squared:  0.9571 \nF-statistic: 79.06 on 2 and 5 DF,  p-value: 0.0001645\n\n\n\ndt2 <- rbind(dt[,2:3], c(500,0))\ndt2$y <- predict(m, newdata = dt2)\n\n\n# this is the predicted line of multiple linear regression\nggplot(data = dt, aes(x = x1, y = y)) + \n  geom_point(color='steelblue') +\n  geom_line(color='darkorange',\n            data = dt2, aes(x=x1, y=y))+\n  geom_vline(xintercept = 500, lty=2, col='red')+\n  theme_bw()"
  },
  {
    "objectID": "posts/HousePrice/2023-04-11-6wk.html",
    "href": "posts/HousePrice/2023-04-11-6wk.html",
    "title": "6wk: 측도론 (2)",
    "section": "",
    "text": "youtube: https://youtube.com/playlist?list=PLQqh36zP38-y2r-mEbWKnTAC_8CN5HcGo"
  },
  {
    "objectID": "posts/HousePrice/2023-04-11-6wk.html#약한조건-약한정리-강한조건-강한정리",
    "href": "posts/HousePrice/2023-04-11-6wk.html#약한조건-약한정리-강한조건-강한정리",
    "title": "6wk: 측도론 (2)",
    "section": "약한조건, 약한정리, 강한조건, 강한정리",
    "text": "약한조건, 약한정리, 강한조건, 강한정리\n- 정리: 어떠한 조건을 만족하면, 어떠한 결론이 나온다.\n\n결론: 우리가 원하는 것.\n조건: 우리가 원하는 것을 얻기 위한 고난과정.\n\n- 결론이 동일하다면 조건이 약할 수록 유리하다.\n\n정리1: 수업에 온라인으로 참석하거나 오프라인으로 참석한다면 모두 출석으로 인정한다.\n정리2: 수업에 오프라인으로 참석할때만 출석으로 인정한다.\n\n\n정리2의 조건이 만족되면 정리1의 조건은 자동으로 만족된다. 따라서 정리2의 조건이 더 강한 조건이다. 조건이 강할수록 불리하므로 정리2가 더 불리하다.\n\n- 조건이 동일하다면 결론이 강한 쪽이 유리하다.\n\n정리1: 중간고사와 기말고사를 모두 응시한다면, B학점 이상이다.\n정리2: 중간고사와 기말고사를 모두 응시한다면, A학점 이상이다.\n\n\n정리2의 결론이 만족되면 정리1의 결론은 자동으로 만족되므로 정리2의 결론이 더 강하다. 결론은 강할수록 유리하므로 정리2가 더 유리하다."
  },
  {
    "objectID": "posts/HousePrice/2023-04-11-6wk.html#쓸모없는-측도",
    "href": "posts/HousePrice/2023-04-11-6wk.html#쓸모없는-측도",
    "title": "6wk: 측도론 (2)",
    "section": "쓸모없는 측도",
    "text": "쓸모없는 측도\n- 세상엔 측도의 정의를 만족하지만 쓸모 없는 측도가 있다.\n\n예시1: \\({\\cal F}\\)의 모든 원소의 메져값은 0이다.\n예시2: \\({\\cal F}\\)의 모든 원소의 메져값은 무한대이다.\n\n- 예시2와 같은 측도를 고려하고 싶지 않음 \\(\\Rightarrow\\) 유한측도, 시그마유한측도의 개발"
  },
  {
    "objectID": "posts/HousePrice/2023-04-11-6wk.html#쓸모없는-가측공간",
    "href": "posts/HousePrice/2023-04-11-6wk.html#쓸모없는-가측공간",
    "title": "6wk: 측도론 (2)",
    "section": "쓸모없는 가측공간",
    "text": "쓸모없는 가측공간\n- 세상엔 쓸모없는 잴 수 없는 공간이 있다. (유의미한 측도를 주는게 불가능한 잴 수 있는 공간)\n\n예시1: \\({\\cal F}= \\{\\emptyset, \\Omega\\}\\)\n예시2: \\(\\Omega =\\mathbb{R}\\) 일때 \\({\\cal F}=2^{\\mathbb{R}}\\) (르벡메져로 측정불가능함, 모든 원소의 메져를 0으로 잡으면 무모순으로 길이를 정의할 수는 있겠으나 무슨의미?)\n\n- 예시2와 같은 \\({\\cal F}\\)는 고려하고 싶지 않음 \\(\\Rightarrow\\) \\(\\sigma({\\cal A})\\), 카라테오도리 확장정리의 고안."
  },
  {
    "objectID": "posts/HousePrice/2023-04-11-6wk.html#유한측도-시그마유한측도",
    "href": "posts/HousePrice/2023-04-11-6wk.html#유한측도-시그마유한측도",
    "title": "6wk: 측도론 (2)",
    "section": "유한측도, 시그마유한측도",
    "text": "유한측도, 시그마유한측도\n- \\(m\\)이 잴 수 있는 공간 \\((\\Omega, {\\cal F})\\)에서의 측도라고 하자.\n\n\\(\\forall A \\in {\\cal F}\\), \\(m(A) < \\infty\\) 이면 \\(m\\)을 유한측도라고 한다.1\n\\(\\exists A_1,A_2,\\dots \\in {\\cal F}\\) such that (1) \\(\\cup_{i=1}^{\\infty}A_i = \\Omega\\) (2) \\(\\forall i \\in \\mathbb{N}:~ m(A_i)<\\infty\\) 이면 \\(m\\)을 시그마유한측도라고 한다.\n\n- NOTE: 모든 확률측도는 유한측도이다. 모든 유한측도는 시그마유한측도이다.2\n\n확률측도라는 것은 매우 강한 조건임\n시그마유한측도라는 것은 확률측도보다 훨씬 약한 조건임\n\n- 직관: 제 생각일 뿐이어요..\n\n세상엔 측도의 정의는 만족하지만 쓸모없는 측도가 있다. (모든 원소를 쟀더니 0이더라, 모든 원소를 쟀더니 무한대더라)\n그래서 모든 원소값에 무한대를 주는 측도는 인정하고 싶은 마음이 별로 없음. (하지만 측도의 정의는 만족)\n그래서 그냥 유한측도만 생각하기로 했는데…\n\n- 유한측도는 아니지만 시그마유한측도의 정의를 만족하는 경우 (엄청 중요해 보이는 예제들이 시그마유한측도잖아?)\n\n르벡메져\n카운팅메져: \\(m\\) is counting msr on \\((\\Omega, {\\cal F})\\) iff \\(m(A) = \\begin{cases} |A| & {\\tt if}~ A~{\\tt is~finite} \\\\ \\infty & {\\tt if}~A~{\\tt is~infinite}\\end{cases}\\)\n\n- 시그마유한측도의 느낌: 전체집합을 카운터블 유니온으로 커버하는 메져유한인 집합열이 1개만 있으면 된다.\n(기억해둘만한 예시)\n\\((\\mathbb{Z}, 2^{\\mathbb{Z}})\\) 를 잴 수 있는 공간이라고 하자. \\(m\\)을 공간 \\((\\mathbb{Z}, 2^{\\mathbb{Z}})\\)에서의 카운팅메져라고 하자.\n집합열1\n\n\\(A_1=\\mathbb{N}\\)\n\\(A_2=\\mathbb{N} \\cup \\{0\\}\\)\n\\(A_3=\\mathbb{N} \\cup \\{-1,0\\}\\)\n\\(\\dots\\)\n\n집합열2\n\n\\(B_1=\\{0\\}\\)\n\\(B_2=\\{0,1\\}\\)\n\\(B_3=\\{-1,0,1\\}\\)\n\\(\\dots\\)\n\n집합열1와 집합열2는\n\n(1) \\(\\cup_{i=1}^{\\infty}A_i=\\mathbb{Z}\\), (2) \\(\\forall i \\in \\mathbb{N}:~ m(A_i)=\\infty\\)\n(1) \\(\\cup_{i=1}^{\\infty}B_i=\\mathbb{Z}\\), (2) \\(\\forall i \\in \\mathbb{N}:~ m(B_i)<\\infty\\)\n\n를 만족한다. 즉 집합열1은 전체집합을 카운터블 유니온으로 커버하지만 메져유한은 아니고, 집합열2는 전제집합을 카운터블 유니온으로 커버하고 메져유한이다. 집합열2의 존재로 인하여 \\(m\\)은 \\((\\mathbb{Z}, 2^{\\mathbb{Z}})\\)에서의 시그마유한측도가 된다."
  },
  {
    "objectID": "posts/HousePrice/2023-04-11-6wk.html#확률공간",
    "href": "posts/HousePrice/2023-04-11-6wk.html#확률공간",
    "title": "6wk: 측도론 (2)",
    "section": "확률공간",
    "text": "확률공간\n- \\(P:{\\cal F} \\to [0,1]\\) 가 잴 수 있는 공간 \\((\\Omega, {\\cal F})\\) 에서의 확률측도라면, \\((\\Omega, {\\cal F}, P)\\) 를 확률공간이라 선언할 수 있다.\n- \\((\\Omega, {\\cal F})\\)가 잴수 있는 공간이라는 선언은 \\({\\cal F}\\)가 \\(\\Omega\\)에 대한 시그마필드라는 것이 내포되어 있다.\n- \\((\\Omega, {\\cal F}, P)\\)가 확률공간이라는 선언에는\n\n\\({\\cal F}\\)는 \\(\\Omega\\)에 대한 시그마필드이며,\n\\(P\\)는 \\((\\Omega, {\\cal F})\\)에서의 확률측도임이 내포되어 있다.\n\n- 교재의 언급 (p1) – 초록색부분\n\n\n\n그림1: 교재에 언급된 확률공간, 잴 수 있는 공간의 정의"
  },
  {
    "objectID": "posts/HousePrice/2023-04-11-6wk.html#시그마유한측도공간",
    "href": "posts/HousePrice/2023-04-11-6wk.html#시그마유한측도공간",
    "title": "6wk: 측도론 (2)",
    "section": "시그마유한측도공간",
    "text": "시그마유한측도공간\n- \\(m:{\\cal F} \\to [0,\\infty]\\)이 잴 수 있는 공간 \\((\\Omega, {\\cal F})\\)에서의 시그마유한측도라면, \\((\\Omega, {\\cal F}, m)\\)을 시그마유한측도공간이라 부른다.\n- \\((\\Omega, {\\cal F}, m)\\)이 시그마유한측도공간이라는 선언에는\n\n\\({\\cal F}\\)는 \\(\\Omega\\)에 대한 시그마필드이며,\n\\(m\\)는 \\((\\Omega, {\\cal F})\\)에서의 시그마유한측도임이 내포되어 있다."
  },
  {
    "objectID": "posts/HousePrice/2023-04-11-6wk.html#state",
    "href": "posts/HousePrice/2023-04-11-6wk.html#state",
    "title": "6wk: 측도론 (2)",
    "section": "state",
    "text": "state\n- Thm (귀찮아서 만든 이론1): 모든 \\({\\cal A} \\subset 2^{\\Omega}\\) 에 대하여 smallest \\(\\sigma\\)-field containing \\({\\cal A}\\), 즉 \\(\\sigma({\\cal A})\\)는 존재한다.\n\n그리고 당연히 smallest 조건에 의에서 유일성이 보장됨"
  },
  {
    "objectID": "posts/HousePrice/2023-04-11-6wk.html#증명을-위한-준비학습",
    "href": "posts/HousePrice/2023-04-11-6wk.html#증명을-위한-준비학습",
    "title": "6wk: 측도론 (2)",
    "section": "증명을 위한 준비학습",
    "text": "증명을 위한 준비학습\n- 이론: (\\(\\star\\)) 임의의 인덱스 집합 \\(I\\neq\\emptyset\\)를 고려하자. 여기에서 \\(I\\)는 uncountable set일 수도 있다. 아래의 사실이 성립함\n\n\\({\\cal F}_i\\)가 모두 시그마필드라면, \\(\\cap_{i \\in I}{\\cal F_i}\\) 역시 시그마필드이다.\n\n(증명)\n편의상 \\({\\cal F}= \\cap_{i \\in I} {\\cal F}_i\\) 라고 하자. \\({\\cal F}\\)가 시그마필드임을 보이기 위해서는\n\n\\(A \\in {\\cal F} \\Rightarrow A^c \\in {\\cal F}\\)\n\\(A_1,A_2 \\dots \\in {\\cal F} \\Rightarrow \\cup_{i}A_i \\in {\\cal F}\\)\n\n만 보이면 된다. (이럴때는 전체집합 조건하나를 빼는게 유리하다)\n1번체크\n\\(A \\in {\\cal F} \\Rightarrow \\forall i: A \\in {\\cal F}_i \\Rightarrow \\forall i: A^c \\in {\\cal F}_i \\Rightarrow A^c \\in {\\cal F}\\)\n2번체크\n\\(A_1,A_2,\\dots \\in {\\cal F} \\Rightarrow \\forall i: A_1,A_2,\\dots \\in {\\cal F}_i \\Rightarrow \\forall i: \\cup_jA_j \\in {\\cal F}_i \\Rightarrow \\cup_jA_j \\in {\\cal F}\\)"
  },
  {
    "objectID": "posts/HousePrice/2023-04-11-6wk.html#증명",
    "href": "posts/HousePrice/2023-04-11-6wk.html#증명",
    "title": "6wk: 측도론 (2)",
    "section": "증명",
    "text": "증명\n- Thm (귀찮아서 만든 이론1): 모든 \\({\\cal A} \\subset 2^{\\Omega}\\) 에 대하여 smallest \\(\\sigma\\)-field containing \\({\\cal A}\\), 즉 \\(\\sigma({\\cal A})\\)는 존재한다.\n\n그리고 당연히 smallest 조건에 의해 유일성이 보장됨\n\n(증명)\n\\({\\cal A}\\)를 포함하는 모든 시그마필드를 구하고 그걸 교집합하여 결과를 \\({\\cal F}\\)라고 하자. 아래의 사실은 자명하게 성립한다.\n\n시그마필드의 교집합은 시그마필드이므로 \\({\\cal F}\\)는 시그마필드이다.\n교집합을 하면 할수록 집합은 작아지므로 \\({\\cal F}\\)는 위에서 구한 시그마필드중에서 가장 작다.\n\\({\\cal F}\\)는 \\({\\cal A}\\)를 포함한다.\n\n따라서 \\({\\cal F}\\)는 (\\({\\cal A}\\)를 포함하는 모든 시그마필드를 교집합하여 얻은 집합) \\({\\cal A}\\)를 포함하는 가장 작은 시그마필드가 된다.\n- 아래는 교재의 언급 (p3)\n\n\n\n그림2: Durret교재에서 언급된 “귀찮아서 만든 이론1”"
  },
  {
    "objectID": "posts/HousePrice/2023-04-11-6wk.html#state-1",
    "href": "posts/HousePrice/2023-04-11-6wk.html#state-1",
    "title": "6wk: 측도론 (2)",
    "section": "state",
    "text": "state\n- Thm: 딘킨의 \\(\\pi-\\lambda\\) 정리 ver1. (\\(\\star\\))\n\\({\\cal P}\\)가 파이시스템이면 \\(l({\\cal P})=\\sigma({\\cal P})\\)이다."
  },
  {
    "objectID": "posts/HousePrice/2023-04-11-6wk.html#증명을-위한-준비학습-1",
    "href": "posts/HousePrice/2023-04-11-6wk.html#증명을-위한-준비학습-1",
    "title": "6wk: 측도론 (2)",
    "section": "증명을 위한 준비학습",
    "text": "증명을 위한 준비학습\n- 이론: 임의의 인덱스 집합 \\(I\\neq\\emptyset\\)를 고려하자. 여기에서 \\(I\\)는 uncountable set일 수도 있다. 아래의 사실이 성립한다.\n\n\\({\\cal F}_i\\)가 모두 시그마필드라면, \\(\\cap_{i \\in I}{\\cal F_i}\\) 역시 시그마필드이다.\n\\({\\cal A}_i\\)가 모두 시그마링, \\(\\cap_{i \\in I}{\\cal A_i}\\) 역시 시그마링이다.\n\\({\\cal A}_i\\)가 모두 알지브라라면, \\(\\cap_{i \\in I}{\\cal A_i}\\) 역시 알지브라이다.\n\\({\\cal A}_i\\)가 모두 링이라면, \\(\\cap_{i \\in I}{\\cal A_i}\\) 역시 링이다.\n\\({\\cal A}_i\\)가 모두 람다시스템이라면, \\(\\cap_{i \\in I}{\\cal A_i}\\) 역시 람다시스템이다.\n\n\n세미알지브라, 세미링, 파이시스템은 성립안함.\n\n- 예제1: 아래를 고려하자.\n\n\\(\\Omega = \\{1,2,3,4\\}\\)\n\\({\\cal A}_1 = \\{\\emptyset, \\{1\\}, \\{2,3\\}, \\{4\\}, \\Omega\\}\\)\n\\({\\cal A}_2 = \\{\\emptyset, \\{1\\}, \\{2\\}, \\{3,4\\}, \\Omega\\}\\)\n\n\\({\\cal A}_1, {\\cal A}_2\\)는 모두 세미알지브라이다. 하지만 \\({\\cal A}_1 \\cap {\\cal A}_2 = \\{\\emptyset, \\Omega, \\{1\\}\\}\\)은 세미알지브라가 아니다.\n\n이 예제에서 세미알지브라를 세미링으로 바꾸고 읽어도 성립함.\n\n- 예제2: 아래를 고려하자.\n\n\\(\\Omega=\\{H,T\\}\\)\n\\({\\cal A}_1 = \\{\\{H\\}\\}\\)\n\\({\\cal A}_2 = \\{\\{T\\}\\}\\)\n\n\\({\\cal A}_1, {\\cal A}_2\\)는 모두 파이시스템이다. 하지만 \\({\\cal A}_1 \\cap {\\cal A}_2 = \\emptyset\\)은 파이시스템이 아니다.\n- 이론: 임의의 \\({\\cal A}\\)에 대하여 아래는 존재한다.\n\n\\({\\cal A}\\)를 포함하는 가장 작은 시그마필드, \\(\\sigma({\\cal A})\\)\n\\({\\cal A}\\)를 포함하는 가장 작은 시그마링\n\\({\\cal A}\\)를 포함하는 가장 작은 알지브라\n\\({\\cal A}\\)를 포함하는 가장 작은 링\n\\({\\cal A}\\)를 포함하는 가장 작은 람다시스템, \\(l({\\cal A})\\)\n\n- 참고: “\\({\\cal A}\\)를 포함하는 가장 작은 세미링”, 혹은 “\\({\\cal A}\\)를 포함하는 가장 작은 세미알지브라”와 같은 것은 존재하지 않음.\n- 예제3: 아래를 고려하자.\n\n\\(\\Omega = \\{1,2,3,4\\}\\)\n\\({\\cal A} = \\{\\emptyset, \\Omega, \\{1\\}\\}\\)\n\n이때 \\({\\cal A}\\)를 포함하는 가장 작은 세미알지브라가\n\\[{\\cal A}_1 = \\{\\emptyset, \\Omega, \\{1\\}, \\{2,3,4\\}\\}\\]\n라고 주장할 수는 없음. 왜냐하면\n\\[{\\cal A}_2 = \\{\\emptyset, \\Omega, \\{1\\}, \\{2\\},\\{3\\},\\{4\\}\\}\\]\n역시 \\({\\cal A}\\)를 포함하는 세미알지브라이지만 \\({\\cal A}_1 \\not \\subset {\\cal A}_2\\)이므로.\n- 이론: \\({\\cal P}\\)가 파이시스템이라고 하자. 아래가 성립한다.\n\n\\({\\cal P}\\)를 포함하는 가장 작은 시그마필드는 그 자체로 파이시스템이다. (즉 \\(\\sigma({\\cal P})\\)는 파이시스템이다)\n\\({\\cal P}\\)를 포함하는 가장 작은 시그마링은 그 자체로 파이시스템이다.\n\\({\\cal P}\\)를 포함하는 가장 작은 알지브라는 그 자체로 파이시스템이다.\n\\({\\cal P}\\)를 포함하는 가장 작은 링은 그 자체로 파이시스템이다.\n\\({\\cal P}\\)를 포함하는 가장 작은 람다시스템은 그 자체로 파이시스템이다?? (즉 \\(l({\\cal P})\\)는 파이시스템이다?)\n\n- 1-4는 자명한데, 5는 자명하지 않다. 하지만 성립한다. (5의 증명은 복잡함. 그냥 암기하자.)\n- 이론: \\({\\cal A}\\)가 람다시스템이다. \\(\\Rightarrow\\) (\\({\\cal A}\\)는 시그마필드이다. \\(\\Leftrightarrow\\) \\({\\cal A}\\)는 파이시스템이다.)\n(증명) 아래의 표를 살펴보면 간단하게 증명가능하다.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\\(A \\cap B\\)\n\\(\\emptyset\\)\n\\(A-B\\)\n\\(\\cup_iA_i=\\uplus_i B_i\\)\n\\(\\Omega\\)\n\\(A^c\\)\n\\(A\\cup B\\)\n\\(\\cup_{i=1}^{\\infty}A_i\\)\n\\(\\uplus_{i=1}^{\\infty}B_i\\)\n\\(\\cap_{i=1}^{\\infty}A_i\\)\n\n\n\n\n\\(\\pi\\)-system\n\\(O\\)\n\\(X\\)\n\\(X\\)\n\\(X\\)\n\\(X\\)\n\\(X\\)\n\\(X\\)\n\\(X\\)\n\\(X\\)\n\\(X\\)\n\n\n\\(\\lambda\\)-system\n\\(X\\)\n\\(O\\)\n\\(\\Delta'\\)\n\\(X\\)\n\\(O\\)\n\\(O\\)\n\\(X\\)\n\\(X\\)\n\\(O\\)\n\\(X\\)\n\n\n\\(\\sigma\\)-field\n\\(O\\)\n\\(O\\)\n\\(O\\)\n\\(O\\)\n\\(O\\)\n\\(O\\)\n\\(O\\)\n\\(O\\)\n\\(O\\)\n\\(O\\)"
  },
  {
    "objectID": "posts/HousePrice/2023-04-11-6wk.html#증명-1",
    "href": "posts/HousePrice/2023-04-11-6wk.html#증명-1",
    "title": "6wk: 측도론 (2)",
    "section": "증명",
    "text": "증명\n(증명)\n\\(l(\\cal P) \\subset \\sigma({\\cal P})\\) 임을 보이고, \\(l(\\cal P) \\supset \\sigma({\\cal P})\\) 임을 보이면된다.\n“\\(\\subset\\)”: 당연하다.3\n“\\(\\supset\\)”: \\(l({\\cal P})\\)가 시그마필드임을 보이면 자동으로 \\(l({\\cal P}) \\supset \\sigma({\\cal P})\\)임이 보여진다.\n\\(l({\\cal P})\\)이 시그마필드임은 아래를 조합하면 간단히 증명된다.\n\n파이시스템 \\({\\cal P}\\)를 포함하는 가장 작은 람다시스템 \\(l({\\cal P})\\)은 그 자체로 파이시스템이다.\n\\({\\cal A}\\)가 람다시스템이다. \\(\\Rightarrow\\) (\\({\\cal A}\\)는 시그마필드이다. \\(\\Leftrightarrow\\) \\({\\cal A}\\)는 파이시스템이다.)\n\n- 생각의 시간\n\n시그마필드(=잴 수 있는 집합의 모임)을 만들기 위해서는, 그 모임(=collection)이 파이시스템이면서 동시에 람다시스템임을 보이면 된다.\n딘킨의 정리는 적당한 파이시스템을 만들고 그것을 통하여 잴 수 있는 집합의 모임을 확률의 공리에 맞게만 설정한다면, 그것이 시그마필드가 된다는 것을 보이는 것이다.\n\n- 제 생각\n\n메져가 “선분의 길이”를 일반화 하는 개념이라 생각한다면 파이시스템에서 시작하여 시그마필드로 확장하는 것이 자연스럽다.\n메져가 “확률”을 일반화하는 개념이라 생각한다면 람다시스템에서 시작하는게 자연스럽다.4\n딘킨의 \\(\\pi-\\lambda\\) 정리는 두 흐름을 합치는 정리이다."
  },
  {
    "objectID": "posts/HousePrice/2023-04-11-6wk.html#딘킨의-pi-lambda-정리-ver2.",
    "href": "posts/HousePrice/2023-04-11-6wk.html#딘킨의-pi-lambda-정리-ver2.",
    "title": "6wk: 측도론 (2)",
    "section": "딘킨의 \\(\\pi-\\lambda\\) 정리 ver2.",
    "text": "딘킨의 \\(\\pi-\\lambda\\) 정리 ver2.\n- 이론: 딘킨의 \\(\\pi-\\lambda\\) 정리 ver2.\n\\({\\cal P}\\)가 파이시스템이고 \\({\\cal L}\\)이 \\({\\cal P}\\)를 포함하는 람다시스템이라면 \\(\\sigma({\\cal P}) \\subset {\\cal L}\\)이다.\n(설명)\nDurret에 나온 딘킨의 \\(\\pi-\\lambda\\) thm 이다. 굉장히 불친절한 편인데, ver2가 증명되면 ver1은 자명하게5 임플라이 되므로 ver2를 대신 state한 것이다.\n\nver2가 ver1를 임플라이 하는 이유: ver1의 \\(l({\\cal P}) \\subset \\sigma({\\cal P})\\)은 당연하고 \\(l({\\cal P}) \\supset \\sigma({\\cal P})\\)만 보이면 되는데, 이미 \\(\\sigma({\\cal P}) \\subset {\\cal L}\\)임을 보였으므로 \\(l({\\cal P})\\)의 정의에 의하여 \\({\\cal L} \\supset l({\\cal P}) \\supset \\sigma({\\cal P})\\)이 성립한다.\n\n- 교재의 언급 (p 456)\n\n\n\n그림2: 교재에 언급된 딘킨의 정리, 부록에 있음"
  },
  {
    "objectID": "posts/HousePrice/2023-04-11-6wk.html#state-2",
    "href": "posts/HousePrice/2023-04-11-6wk.html#state-2",
    "title": "6wk: 측도론 (2)",
    "section": "state",
    "text": "state\n- 귀찮아서 만든 이론2: 운이 좋다면, \\({\\cal A}\\) 에서 확률의 공리를 만족하는 적당한 함수 \\(\\tilde{P}:{\\cal A} \\to [0,1]\\)를 \\((\\Omega, \\sigma({\\cal A}))\\) 에서의 확률측도 \\(P\\)로 업그레이드 할 수 있으며 업그레이드 결과는 유일하다.\n- 귀찮아서 만든 이론2는 (1) 업그레이드가 가능하냐 (2) 그 업그레이드가 유일하냐 를 따져야하는데 이중 유일성만을 따져보자.\n- Thm: \\((\\Omega, \\sigma({\\cal A}), P)\\)를 확률공간이라고 하자. 여기에서 \\({\\cal A}\\)는 파이시스템이라고 가정하자. 그렇다면 확률측도 \\(P:\\sigma({\\cal A}) \\to [0,1]\\)의 값은 \\(P: {\\cal A} \\to [0,1]\\)의 값에 의하여 유일하게 결정된다.\n\n\\({\\cal A}\\)가 파이시스템이라면, \\({\\cal A}\\)에서는 agree하지만 \\(\\sigma({\\cal A})\\)에서는 agree하지 않는 확률측도 \\(P:\\sigma({\\cal A}) \\to [0,1]\\)는 존재할 수 없다는 의미이다."
  },
  {
    "objectID": "posts/HousePrice/2023-04-11-6wk.html#활용예제-star",
    "href": "posts/HousePrice/2023-04-11-6wk.html#활용예제-star",
    "title": "6wk: 측도론 (2)",
    "section": "활용예제 (\\(\\star\\))",
    "text": "활용예제 (\\(\\star\\))\n- 아래의 이론을 이해하기 위한 예제들을 살펴보자.\n\n이론: \\((\\Omega, \\sigma({\\cal A}), P)\\)를 확률공간이라고 하자. 여기에서 \\({\\cal A}\\)는 파이시스템이라고 가정하자. 그렇다면 확률측도 \\(P:\\sigma({\\cal A}) \\to [0,1]\\)의 값은 \\(P: {\\cal A} \\to [0,1]\\)의 값에 의하여 유일하게 결정된다.\n\n(예제1) – 4주차에서 했던 예제에요\n- \\(\\Omega=\\{1,2,3,4\\}\\)이라고 하고 \\({\\cal A} = \\{\\emptyset, \\{1\\},\\{2\\},\\{3,4\\},\\Omega\\}\\) 라고 하자.\n- \\({\\cal A}\\)는 파이시스템이다.\n- 아래표의 왼쪽의 \\(P\\)와 같은 확률 측도를 고려하자.\n\n\n\n\n\\(P\\)\n\\(P'\\)\n\n\n\n\n\\(\\emptyset\\)\n\\(0\\)\n\\(0\\)\n\n\n\\(\\{1\\}\\)\n\\(\\frac{1}{4}\\)\n\\(\\frac{1}{4}\\)\n\n\n\\(\\{2\\}\\)\n\\(\\frac{1}{2}\\)\n\\(\\frac{1}{2}\\)\n\n\n\\(\\{3,4\\}\\)\n\\(\\frac{1}{4}\\)\n\\(\\frac{1}{4}\\)\n\n\n\\(\\Omega\\)\n\\(1\\)\n\\(1\\)\n\n\n\\(-\\)\n\\(-\\)\n\\(-\\)\n\n\n\\(\\{1,2\\}\\)\n\\(\\frac{3}{4}\\)\n\\(\\frac{3}{4}\\) 이 아닐 수 있어?\n\n\n\\(\\{1,3,4\\}\\)\n\\(\\frac{1}{2}\\)\n\\(\\frac{1}{2}\\) 이 아닐 수 있어?\n\n\n\\(\\{2,3,4\\}\\)\n\\(\\frac{3}{4}\\)\n\\(\\frac{3}{4}\\) 이 아닐 수 있어?\n\n\n\n\\({\\cal A}\\)에서는 \\(P\\)와 그 값이 같지만 \\(\\sigma({\\cal A})-{\\cal A}\\)에서는 다른값을 가질 수도 있는 \\((\\Omega, \\sigma({\\cal A}))\\) 에서의 확률측도 \\(P'\\)는 존재하지 않는다.\n즉 \\({\\cal A}\\)가 파이시스템이라면, \\((\\Omega,\\sigma({\\cal A}))\\)에의 모든 확률측도 \\(P\\)는 \\({\\cal A}\\)에서의 값만 define하면 나머지 \\(\\sigma({\\cal A})-{\\cal A}\\)에서의 값은 유니크하게 결정된다.\n- 이 이론에 대한 짧은 생각\n\n생각1: 일단 \\((\\Omega,\\sigma({\\cal A})\\)에서의 확률측도 \\(P\\)의 존재성은 가정하고 들어간다. 즉 “존재한다면 유일하다”는 의미이지, “유일하게 존재한다”의 의미는 아니다.\n생각2: 따라서 이 정리는 “\\({\\cal A}\\)가 파이시스템일 경우, 함수 \\(\\tilde{P}:{\\cal A} \\to [0,1]\\)가 \\((\\Omega,\\sigma({\\cal A}))\\)에서의 확률측도 \\(P\\)로 업그레이드가 가능하다면 그 결과는 유일하다” 정도로 해석할 수 있다.\n\n(예제2) – 이것도 4주차에서 했던 예제입니다.\n- \\(\\Omega=\\{1,2,3,4\\}\\) 이라고 하고 \\({\\cal A} = \\{\\emptyset, \\{1,2\\},\\{2,3\\}, \\Omega\\}\\) 라고 하자.\n- 여기에서 \\({\\cal A}\\)는 파이시스템이 아니다. 따라서 \\({\\cal A}\\)에서의 값은 agree하지만 \\((\\Omega, \\sigma({\\cal A}))\\)에서 agree하지 않는 서로 다른 확률측도가 존재할 수 있다.\n\n\n\n\n\\(P_1\\)\n\\(P_2\\)\n\n\n\n\n\\(\\emptyset\\)\n\\(0\\)\n\\(0\\)\n\n\n\\(\\{1,2\\}\\)\n\\(\\frac{1}{2}\\)\n\\(\\frac{1}{2}\\)\n\n\n\\(\\{2,3\\}\\)\n\\(\\frac{1}{2}\\)\n\\(\\frac{1}{2}\\)\n\n\n\\(\\Omega\\)\n\\(1\\)\n\\(1\\)\n\n\n\\(-\\)\n\\(-\\)\n\\(-\\)\n\n\n\\(\\{1\\}\\)\n\\(0\\)\n\\(\\frac{1}{2}\\)\n\n\n\\(\\{2\\}\\)\n\\(\\frac{1}{2}\\)\n\\(0\\)\n\n\n\\(\\{3\\}\\)\n\\(0\\)\n\\(\\frac{1}{2}\\)\n\n\n\\(\\{4\\}\\)\n\\(\\frac{1}{2}\\)\n\\(0\\)\n\n\n\\(\\{1,3\\}\\)\n\\(0\\)\n\\(1\\)\n\n\n\\(\\{1,4\\}\\)\n\\(\\frac{1}{2}\\)\n\\(\\frac{1}{2}\\)\n\n\n\\(\\{2,4\\}\\)\n\\(1\\)\n\\(0\\)\n\n\n\\(\\{3,4\\}\\)\n\\(\\frac{1}{2}\\)\n\\(\\frac{1}{2}\\)\n\n\n\\(\\{2,3,4\\}\\)\n\\(1\\)\n\\(\\frac{1}{2}\\)\n\n\n\\(\\{1,3,4\\}\\)\n\\(\\frac{1}{2}\\)\n\\(1\\)\n\n\n\\(\\{1,2,4\\}\\)\n\\(1\\)\n\\(\\frac{1}{2}\\)\n\n\n\\(\\{1,2,3\\}\\)\n\\(\\frac{1}{2}\\)\n\\(1\\)\n\n\n\n- 만약에 이 예제에서 \\({\\cal A}\\)를 아래와 같이 수정한다면\n\\[{\\cal A}=\\{\\emptyset, \\{1,2\\}, \\{2,3\\}, \\{2\\}\\}\\]\n이번에는 \\({\\cal A}\\)는 파이시스템이 된다. 따라서 이 경우 \\((\\Omega, \\sigma({\\cal A}))\\)에서의 모든 확률측도 \\(P\\)는 \\({\\cal A}\\)의 값에 의하여 유일하게 결정된다.\n(예제3)\n- \\(\\Omega=\\{H,T\\}\\) 이라고 하고 \\({\\cal A} = \\{\\{H\\}\\}\\) 라고 하자.\n- 여기에서 \\({\\cal A}\\)은 파이시스템이므로 가측공간 \\((\\Omega,\\sigma({\\cal A}))\\)에서 정의가능한 모든 확률측도 \\(P\\)는 \\({\\cal A}\\)에서의 값으로만 정의해도 무방하다.6\n(예제4) – 통계학과라서 행복해\n- \\(\\Omega=\\{a,b\\}\\) 이라고 하고 \\({\\cal A} = \\{\\{a\\}\\}\\) 라고 하자.\n- 여기에서 \\({\\cal A}\\)은 파이시스템이다.\n- 가측공간 \\((\\Omega,\\sigma({\\cal A}))\\)에서 정의가능한 모든 확률측도 \\(P\\)는 \\({\\cal A}\\)에서의 값으로 유일하게 결정된다.\n- 그렇지만 가측공간 \\((\\Omega,\\sigma({\\cal A})\\)에서 정의가능한 “측도” \\(m\\)은 \\({\\cal A}\\)에서의 값으로 유일하게 결정되지 않는다.7\n\n\n\n\n\\(m_1\\)\n\\(m_2\\)\n\n\n\n\n\\(\\{a\\}\\)\n\\(\\frac{1}{2}\\)\n\\(\\frac{1}{2}\\)\n\n\n\\(-\\)\n\\(-\\)\n\\(-\\)\n\n\n\\(\\emptyset\\)\n\\(0\\)\n\\(0\\)\n\n\n\\(\\{b\\}\\)\n\\(\\frac{1}{2}\\)\n\\(1\\)\n\n\n\\(\\Omega\\)\n\\(1\\)\n\\(\\frac{3}{2}\\)"
  },
  {
    "objectID": "posts/HousePrice/2023-04-11-6wk.html#증명-2",
    "href": "posts/HousePrice/2023-04-11-6wk.html#증명-2",
    "title": "6wk: 측도론 (2)",
    "section": "증명",
    "text": "증명\n- 아래의 이론에 대한 증명\n\nThm: \\((\\Omega, \\sigma({\\cal A}), P)\\)를 확률공간이라고 하자. 여기에서 \\({\\cal A}\\)는 파이시스템이라고 가정하자. 그렇다면 확률측도 \\(P:\\sigma({\\cal A}) \\to [0,1]\\)의 값은 \\(P: {\\cal A} \\to [0,1]\\)의 값에 의하여 유일하게 결정된다.\n\n증명 (확률측도라는 가정을 추가하여 교재의 버전을 살짝 쉽게 만듬)\nLET\n\n\\((\\Omega, \\sigma({\\cal A}))\\) 는 잴 수 있는 공간임.\n\\(P_1,P_2\\)는 \\((\\Omega, \\sigma({\\cal A}))\\)에서의 확률측도임.\n\\(P_1,P_2\\)는 “\\(\\forall A \\in {\\cal A}: P_1(A)=P_2(A)\\)”를 만족함.\n\n전략: 잴 수 있는 공간 \\((\\Omega, \\sigma({\\cal A}))\\) 에서의 두 측도 \\(P_1\\), \\(P_2\\)가 \\({\\cal A}\\)에서는 일치하지만 \\(\\sigma({\\cal A})-{\\cal A}\\)에서는 일치하지 않는 경우를 찾으려 해보고, 그것이 불가능함을 보이자.\nLET: \\(\\tilde{\\cal D}=\\{B \\in \\sigma({\\cal A}): P_1(B) \\neq P_2(B)\\}\\)\nISTST: \\(\\tilde{\\cal D} =\\emptyset\\)\nISTST: \\({\\cal D} = \\{B \\in \\sigma({\\cal A}): P_1(B) = P_2(B) \\} = \\sigma({\\cal A})\\)\nISTST: (1) \\({\\cal D} \\subset \\sigma({\\cal A})\\) (2) \\({\\cal D} \\supset \\sigma({\\cal A})\\)\nISTST: \\({\\cal D} \\supset \\sigma({\\cal A})\\)\nNOTE: IF (1) \\({\\cal D}\\) is containing \\({\\cal A}\\) (2) \\({\\cal D}\\) is \\(\\lambda\\)-system, THEN we can say \\({\\cal D} \\supset \\sigma({\\cal A})=l({\\cal A})\\)\nISTST: (1) \\({\\cal A} \\subset {\\cal D}\\) (2) \\({\\cal D}\\) is \\(\\lambda\\)-system.\nISTST: 1. \\(\\Omega \\in {\\cal D}\\) 2. \\(A,B \\in {\\cal D}, A\\subset B\\) \\(\\Rightarrow\\) \\(B-A \\in {\\cal D}\\) 3. \\(\\forall B_1,B_2,\\dots, \\in {\\cal D}\\), \\(\\uplus_{i=1}^{\\infty} B_i \\in {\\cal D}\\)\nCHECK 1: \\(P_1(\\Omega) = P_2(\\Omega)\\)\nCHECK 2: \\(P_1(B-A) = P_1(B)-P_1(A) = P_2(B) - P_2(A) = P_2(B-A)\\)\nCHECK 3: \\(P_1(\\uplus_{i=1}^{\\infty} B_i)=P_1(B_1)+P_1(B_2)\\dots = P_2(B_1)+P_2(B_2) +\\dots = P_2(\\uplus_{i=1}^\\infty B_i)\\)\n- 보충노트\n\nsupp_6wk.pdf"
  },
  {
    "objectID": "posts/HousePrice/2023-04-18-7wk.html",
    "href": "posts/HousePrice/2023-04-18-7wk.html",
    "title": "7wk: 측도론 (3)",
    "section": "",
    "text": "youtube: https://youtube.com/playlist?list=PLQqh36zP38-yQ5IXoRW0pW0Gyd8MnRwaW"
  },
  {
    "objectID": "posts/HousePrice/2023-04-18-7wk.html#헷갈리는-표현-infty의-포함",
    "href": "posts/HousePrice/2023-04-18-7wk.html#헷갈리는-표현-infty의-포함",
    "title": "7wk: 측도론 (3)",
    "section": "헷갈리는 표현: \\(\\infty\\)의 포함",
    "text": "헷갈리는 표현: \\(\\infty\\)의 포함\n- 자연수집합 \\(\\mathbb{N}\\)은 \\(\\{\\infty\\}\\)를 포함하지 않는다. 마찬가지로 실수집합 \\(\\mathbb{R}\\) 역시 \\(\\{-\\infty\\}, \\{\\infty\\}\\)를 포함하지 않는다. 만약에 이를 포함하고 싶을 경우는 아래와 같이 표현한다.\n\n\\(\\mathbb{R} \\cup \\{-\\infty\\} \\cup \\{\\infty\\} = \\bar{\\mathbb{R}}\\)\n\\(\\mathbb{N} \\cup \\{-\\infty\\}\\)\n\n여기에서 \\(\\bar{\\mathbb{R}}\\)은 확장된 실수라고 부르는데 교재에따라 사용하기도 하고 사용하지 않기도 한다.\n- 만약에 \\(\\mathbb{N}\\)이 \\(\\{\\infty\\}\\)를 포함한다면\n\n\\(\\forall n \\in \\mathbb{N}:~ 0<\\frac{1}{n} \\leq 1\\)\n\n와 같은 표현은 불가능할 것이다.\n- 구간에 대한 표현들: 구간에 대한 몇가지 표현을 정리하면 아래와 같다.\n\n\\((-\\infty, b] = \\{x: x\\leq b, ~x,b \\in \\mathbb{R}\\}\\)\n\\((-\\infty, b) = \\{x: x < b,~ x,b \\in \\mathbb{R}\\}\\)\n\n- 구긴에 대한 표현 응용: 아래와 같은 표현을 고려하자. (교재의 예제 1.1.8과 비슷한 표현)\n\n\\({\\cal A} = \\{(a,b]: -\\infty \\leq a < b \\leq \\infty\\}\\)\n\n\\({\\cal A}\\)의 원소의 형태는\n\n\\(\\{x: a<x\\leq b,~ a,x,b \\in \\mathbb{R}\\}\\)\n\\(\\{x: a<x,~ a,x \\in \\mathbb{R}\\}\\)\n\\(\\{x: x\\leq b,~ x,b \\in \\mathbb{R}\\}\\)\n\\(\\{x: x \\in \\mathbb{R}\\}\\)\n\n이다.\n\n약간 무식하게 생각하면 \\([-\\infty, b) = (-\\infty,b)\\) 로 해석하면 된다. 즉 \\(\\{-\\infty\\} \\notin [-\\infty,b)\\) 이라는 의미! 보는것 처럼 \\([-\\infty, b)\\)와 같은 표현은 엄청난 혼란을 불러오는 표현이므로 사용을 자제한다."
  },
  {
    "objectID": "posts/HousePrice/2023-04-18-7wk.html#메져의-종류와-성질",
    "href": "posts/HousePrice/2023-04-18-7wk.html#메져의-종류와-성질",
    "title": "7wk: 측도론 (3)",
    "section": "메져의 종류와 성질",
    "text": "메져의 종류와 성질\n- 메져의 종류와 성질 요약\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n분류\n\\(m(\\emptyset)=0\\)\n\\(\\sigma\\)-add\n\\(A_i\\uparrow \\Omega\\), \\(m(A_i)<\\infty\\)\n\\(m(\\Omega)<\\infty\\)\n\\(m(\\Omega)=1\\)\n\\(.\\)\nmonotone\n\\(\\sigma\\)-subadd\nconti-below\nconti-above\n\n\n\n\nmsr\n\\(O\\)\n\\(O\\)\n\\(X\\)\n\\(X\\)\n\\(X\\)\n\\(.\\)\n\\(O\\)\n\\(O\\)\n\\(O\\)\n\\(\\Delta\\)\n\n\n\\(\\sigma\\)-finite-msr\n\\(O\\)\n\\(O\\)\n\\(O\\)\n\\(X\\)\n\\(X\\)\n\\(.\\)\n\\(O\\)\n\\(O\\)\n\\(O\\)\n\\(\\Delta\\)\n\n\nfinite-msr\n\\(O\\)\n\\(O\\)\n\\(O\\)\n\\(O\\)\n\\(X\\)\n\\(.\\)\n\\(O\\)\n\\(O\\)\n\\(O\\)\n\\(O\\)\n\n\nprob-msr\n\\(O\\)\n\\(O\\)\n\\(O\\)\n\\(O\\)\n\\(O\\)\n\\(.\\)\n\\(O\\)\n\\(O\\)\n\\(O\\)\n\\(O\\)\n\n\n\n- 용어들\n\n\\(\\sigma\\)-additive: \\(m(\\uplus_{i=1}^{\\infty} B_i) = \\sum_{i=1}^{\\infty} m(B_i)\\)\nmonotone: \\(A\\subset B \\Rightarrow m(A) \\subset m(B)\\)\n\\(\\sigma\\)-subadditive: \\(m(\\cup_{i=1}^{\\infty} A_i) \\leq \\sum_{i=1}^{\\infty} m(A_i)\\)\ncontinuous from below: \\(A_i \\uparrow A\\) \\(\\Rightarrow\\) \\(m(\\lim_{n\\to\\infty}A_i)=\\lim_{n\\to\\infty}m(A_i)\\)\ncontinuous from above: (1) \\(A_i \\downarrow A\\) and (2) \\(m(A_1)<\\infty\\) \\(\\Rightarrow\\) \\(m(\\lim_{n\\to\\infty}A_i)=\\lim_{n\\to\\infty}m(A_i)\\)\n\n- 교재의 언급 (p2. Thm 1.1.1)\n\n\n\n그림1: 메져의 성질 durret p2\n\n\n- \\(\\sigma\\)-finite msr 에 대한 동치조건: \\(m\\)이 \\((\\Omega, {\\cal F})\\)에서의 msr이라면, 아래는 동치이다. (ref: https://en.wikipedia.org/wiki/%CE%A3-finite_measure)\n언어버전\n\nThe set \\(\\Omega\\) can be covered with at most countably many measurable sets with finite measure.\nThe set \\(\\Omega\\) can be covered with at most countably many measurable disjoint sets with finite measure.\nThe set \\(\\Omega\\) can be covered with monotone sequence of measurable sets with finite measure.\n\n수식버전\n\nThere are sets \\(A_1,A_2,\\dots \\in {\\cal A}\\) with \\(m(A_i)<\\infty\\) such that \\(\\cup_{i=1}^{\\infty}A_i=\\Omega\\)\nThere are sets \\(B_1,B_2,\\dots \\in {\\cal A}\\) with \\(m(B_i)<\\infty\\) and \\(B_1,B_2\\dots\\) are disjoints such that \\(\\uplus_{i=1}^{\\infty}B_i=\\Omega\\)\nThere are sets \\(C_1,C_2,\\dots \\in {\\cal A}\\) with \\(m(C_i)<\\infty\\) and $C_1 C_2 $ such that \\(\\cup_{i=1}^{\\infty}C_i=\\Omega\\)"
  },
  {
    "objectID": "posts/HousePrice/2023-04-18-7wk.html#복습-motivating-ex",
    "href": "posts/HousePrice/2023-04-18-7wk.html#복습-motivating-ex",
    "title": "7wk: 측도론 (3)",
    "section": "복습 & Motivating EX",
    "text": "복습 & Motivating EX\n- 귀찮아서 만든 이론2: 운이 좋다면, \\({\\cal A}\\) 에서 확률의 공리를 만족하는 적당한 함수 \\(\\tilde{P}:{\\cal A} \\to [0,1]\\)를 \\((\\Omega, \\sigma({\\cal A}))\\) 에서의 확률측도 \\(P\\)로 업그레이드 할 수 있으며 업그레이드 결과는 유일하다.\n- 이론: \\((\\Omega, \\sigma({\\cal A}), P)\\)를 확률공간이라고 하자. 여기에서 \\({\\cal A}\\)는 파이시스템이라고 가정하자. 그렇다면 확률측도 \\(P:\\sigma({\\cal A}) \\to [0,1]\\)의 값은 \\(P: {\\cal A} \\to [0,1]\\)의 값에 의하여 유일하게 결정된다.\n- 이 이론은 확률측도일 경우만 성립하고 측도일 경우는 실패했었다.\n(예제1) – 통계학과라서 행복했던 예제\n\\(\\Omega=\\{a,b\\}\\) 이라고 하고 \\({\\cal A} = \\{\\{a\\}\\}\\) 라고 하자. 가측공간 \\((\\Omega,\\sigma({\\cal A}))\\)에서 정의가능한 모든 확률측도 \\(P\\)는 \\({\\cal A}\\)에서의 값으로 유일하게 결정됨을 확인하였다. 하지만 가측공간 \\((\\Omega,\\sigma({\\cal A}))\\)에서 정의가능한 측도 \\(m\\)은 \\({\\cal A}\\)에서의 값으로 유일하게 결정되지 않는다.\n\n\n\n\n\\(m_1\\)\n\\(m_2\\)\n\n\n\n\n\\(\\{a\\}\\)\n\\(\\frac{1}{2}\\)\n\\(\\frac{1}{2}\\)\n\n\n\\(-\\)\n\\(-\\)\n\\(-\\)\n\n\n\\(\\emptyset\\)\n\\(0\\)\n\\(0\\)\n\n\n\\(\\{b\\}\\)\n\\(\\frac{1}{2}\\)\n\\(1\\)\n\n\n\\(\\Omega\\)\n\\(1\\)\n\\(\\frac{3}{2}\\)\n\n\n\n- 직관: 그냥 \\({\\cal A}\\)에 \\(\\Omega\\)가 있었다면 되는거 아닌가? 예를들어 아래와 같이 설정한다면?\n\n\n\n\n\\(m_1\\)\n\\(m_2\\)\n\n\n\n\n\\(\\{a\\}\\)\n\\(\\frac{1}{2}\\)\n\\(\\frac{1}{2}\\)\n\n\n\\(\\Omega\\)\n\\(\\frac{3}{2}\\)\n\\(\\frac{3}{2}\\)\n\n\n\\(-\\)\n\\(-\\)\n\\(-\\)\n\n\n\\(\\emptyset\\)\n\\(0\\)\n\\(0\\)\n\n\n\\(\\{b\\}\\)\n\\(1\\)\n\\(1\\)\n\n\n\n\\(m_1(\\{b\\})=m_2(\\{b\\})=1\\) 일 수밖에 없지 않을까?\n- 혹시 아래와 같이 이론을 수정하면 되지 않을까?\n\n\\((\\Omega, \\sigma({\\cal A}))\\)을 잴 수 있는 공간이라고 하고, \\(m\\)을 이 공간에서의 메져라고 하자. 만약에 \\({\\cal A}\\)가 “전체집합을 포함하는 파이시스템” 이라면 메져 \\(m:\\sigma({\\cal A}) \\to [0,1]\\)의 값은 \\(m: {\\cal A} \\to [0,1]\\)의 값에 의하여 유일하게 결정된다. (거의 맞는데 한 조건이 빠져서 틀렸음)\n\n(예제2)\n\\(\\Omega=\\{a,b,c\\}\\) 이라고 하고 \\({\\cal A} = \\{\\{a\\},\\Omega\\}\\) 라고 하자. 여기에서 \\({\\cal A}\\)는 “\\(\\Omega\\)가 포함된 파이시스템”이다. 가측공간 \\((\\Omega,\\sigma({\\cal A}))\\)에서 정의가능한측도 \\(m\\)은 \\({\\cal A}\\)에서의 값으로 유일하게 결정될까?\n(풀이) 아래의 반례가 존재함.\n\n\n\n\n\\(m_1\\)\n\\(m_2\\)\n\n\n\n\n\\(\\{a\\}\\)\n\\(\\frac{1}{2}\\)\n\\(\\frac{1}{2}\\)\n\n\n\\(\\Omega\\)\n\\(\\infty\\)\n\\(\\infty\\)\n\n\n\\(-\\)\n\\(-\\)\n\\(-\\)\n\n\n\\(\\emptyset\\)\n\\(0\\)\n\\(0\\)\n\n\n\\(\\{b\\}\\)\n\\(1\\)\n\\(\\infty\\)\n\n\n\\(\\{c\\}\\)\n\\(\\infty\\)\n\\(5\\)\n\n\n\\(\\{a,b\\}\\)\n\\(\\frac{3}{2}\\)\n\\(\\infty\\)\n\n\n\\(\\{a,c\\}\\)\n\\(\\infty\\)\n\\(\\frac{11}{2}\\)\n\n\n\\(\\{b,c\\}\\)\n\\(\\infty\\)\n\\(\\infty\\)\n\n\n\n- 이론: \\((\\Omega, \\sigma({\\cal A}))\\)을 잴 수 있는 공간이라고 하고, \\(m\\)을 이 공간에서의 유한측도라고 하자. 그리고 \\({\\cal A}\\)는 전제집합을 포함하는 파이시스템이라고 하자. 그렇다면 메져 \\(m:\\sigma({\\cal A}) \\to [0,M]\\)의 값은 \\(m: {\\cal A} \\to [0,M]\\)의 값에 의하여 유일하게 결정된다. (단, \\(M=m(\\Omega)<\\infty\\))\n(예제3) – \\({\\cal A}\\)가 \\(\\Omega\\)를 포함하지 않는데, 메져가 유일하게 결정될 것 같은 예제\n\\(\\Omega = \\mathbb{Z}\\) 이라고 하자. \\(\\Omega\\)의 부분집합들로 이루어진 집합열 \\(A_1,A_2,\\dots\\) 를 아래와 같이 정의하자.\n\n\\(A_{1} = [-\\frac{1}{2}, \\frac{2}{2}] \\cap \\mathbb{Z} = \\{0, 1\\}\\)\n\\(A_{2} = [-\\frac{2}{2}, \\frac{3}{2}] \\cap \\mathbb{Z} = \\{-1, 0, 1\\}\\)\n\\(A_{3} = [-\\frac{3}{2}, \\frac{4}{2}] \\cap \\mathbb{Z} = \\{-1, 0, 1, 2\\}\\)\n\\(A_{4} = [-\\frac{4}{2}, \\frac{5}{2}] \\cap \\mathbb{Z} = \\{-2, -1, 0, 1, 2\\}\\)\n\\(A_{5} = [-\\frac{5}{2}, \\frac{6}{2}] \\cap \\mathbb{Z} = \\{-2, -1, 0, 1, 2, 3\\}\\)\n\\(\\dots\\)\n\n관심있는 집합들의 모임은 \\({\\cal A}=\\{A_n:n \\in \\mathbb{N}\\}\\)로 정의하자. 가측공간 \\((\\Omega,\\sigma({\\cal A}))\\)에서 정의가능한 측도 \\(m\\)은 \\({\\cal A}\\)의 값으로 유일하게 결정될까?\n(관찰)\n풀이에 앞서서 아래의 사실을 관찰해보자.\n\n\\({\\cal A}\\)는 파이시스템이다.\n집합열 \\(A_n\\)의 극한은 \\(\\Omega\\)이다. 집합열 \\(A_n\\)은 증가하는 수열이므로 이 경우 \\(A_n \\uparrow \\Omega\\)라고 표현할 수 있다.\n모든 \\(A_n\\)이 \\({\\cal A}\\)의 멤버라고 했으나 \\(A_n\\)의 극한 \\(\\Omega\\)가 \\({\\cal A}\\)의 멤버라고 한 적은 없다. 따라서 \\({\\cal A}\\)는 전체집합을 포함하지는 않는 파이시스템이다.\n\n(풀이)\n가측공간 \\((\\Omega,\\sigma({\\cal A}))\\)에서 정의가능한 측도 \\(m\\)은 \\({\\cal A}\\)의 값으로 유일하게 결정하는 것이 가능할 것 같다. (실제로 가능해) 왜냐하면\n\n\\(m(A_1),m(A_2), m(A_3) \\dots\\) 의 값이 결정 \\(\\Rightarrow\\) \\(m(\\{0,1\\})\\), \\(m(\\{-1\\})\\), \\(m(\\{2\\})\\), \\(\\dots\\) 의 값이 결정\n\n이므로, 0과 1을 제외한 \\(\\mathbb{Z}\\)의 모든 원소의 길이가 유일하게 결정되니까.\n생각의 시간\n아래의 이론을 다시 관찰하자.\n\n이론: \\((\\Omega, \\sigma({\\cal A}))\\)을 잴 수 있는 공간이라고 하고, \\(m\\)을 이 공간에서의 유한측도라고 하자. 그리고 \\({\\cal A}\\)는 전제집합을 포함하는 파이시스템이라고 하자. 그렇다면 메져 \\(m:\\sigma({\\cal A}) \\to [0,M]\\)의 값은 \\(m: {\\cal A} \\to [0,M]\\)의 값에 의하여 유일하게 결정된다. (단, \\(M=m(\\Omega)<\\infty\\))\n\n(의문1)\n\\({\\cal A}\\)가 꼭 전체집합을 포함할 필요는 없어보인다. 즉 조건 \\(\\Omega \\in {\\cal A}\\)는 굳이 필요 없어보인다. 이 조건은 더 약한 아래의 조건으로 대치가능하다.\n\n\\(\\exists A_1,A_2,\\dots \\in {\\cal A}\\) such that \\(A_i \\uparrow \\Omega\\)\n\n만약에 \\(\\Omega \\in {\\cal A}\\)인 경우는 \\(A_1=\\Omega\\)로 잡으면 위 조건이 그냥 성립한다. 따라서 위의 조건은 \\(\\Omega \\in {\\cal A}\\) 보다 약한 조건이다. 그리고 심지어 위의 조건은 다시 아래의 더 약한 조건으로 바꿀 수 있다.\n\n\\(\\exists A_1,A_2,\\dots \\in {\\cal A}\\) such that \\(\\cup_{i=1}^{\\infty} A_i = \\Omega\\)\n\n(의문2)\n심지어 \\(m(\\Omega) = \\infty\\) 이어도 상관없다.1 이 예제에서\n\n\\(m(\\{0,1\\})=2\\)\n\\(m(\\{-1\\})=1\\)\n\\(m(\\{2\\})=1\\)\n\\(\\dots\\)\n\n이라고 하면 \\(m\\)은 잴 수 있는 공간 \\((\\Omega,\\sigma({\\cal A}))\\)에서의 카운팅메져가 되고, 그 \\(m\\)은 \\(A \\in {\\cal A}\\)에서의 값으로 유일하게 결정된다. 문제가 생길만한 것은\n\n\\(m(\\{0,1\\})=2\\)\n\\(m(\\{-1\\})=1\\)\n\\(m(\\{2\\})=\\infty\\) <– 이러면 곤란\n\\(\\dots\\)\n\n와 같은 경우이므로, 이 경우만 제약하면 된다. 즉 \\(m\\)이 시그마유한측도라고 제한하면 될 것 같다."
  },
  {
    "objectID": "posts/HousePrice/2023-04-18-7wk.html#state",
    "href": "posts/HousePrice/2023-04-18-7wk.html#state",
    "title": "7wk: 측도론 (3)",
    "section": "state",
    "text": "state\n- Thm: \\((\\Omega, \\sigma({\\cal A}),m)\\)을 시그마유한측도공간(\\(\\sigma\\)-finite measure space)이라고 하자. \\({\\cal A}\\)은 아래를 만족하는 파이시스템이라고 하자.\n\n\\(\\exists A_1,A_2,\\dots \\in {\\cal A}\\) such that \\(\\cup_{i=1}^{\\infty} A_i = \\Omega\\)\n\\(\\forall i \\in \\mathbb{N}:~ m(A_i) <\\infty\\)\n\n그렇다면 메져 \\(m:\\sigma({\\cal A}) \\to [0,\\infty]\\)의 값은 \\(m: {\\cal A} \\to [0,\\infty]\\)의 값에 의하여 유일하게 결정된다.\n\n조건 1,2는 결국 \\(m\\)을 시그마유한측도로 만들어주는 그 집합열이 \\(\\sigma({\\cal A})-{\\cal A}\\)가 아니라 \\({\\cal A}\\)에 있어야 한다는 의미임."
  },
  {
    "objectID": "posts/HousePrice/2023-04-18-7wk.html#증명",
    "href": "posts/HousePrice/2023-04-18-7wk.html#증명",
    "title": "7wk: 측도론 (3)",
    "section": "증명",
    "text": "증명\n- 노트: supp_7wk.pdf\n- 교재의 증명: 교재의 증명은 좀 더 강한 조건에서 했음. (“\\(A_1,A_2,\\dots, {\\cal A}\\) with \\(m(A_i)<\\infty\\) such that \\(A_i \\uparrow \\Omega\\)” 를 가정함.)\n\n\n\n그림2: 카라데오도리 확장정리의 유일성 part 증명, durret p457-8"
  },
  {
    "objectID": "posts/HousePrice/2023-04-18-7wk.html#state-1",
    "href": "posts/HousePrice/2023-04-18-7wk.html#state-1",
    "title": "7wk: 측도론 (3)",
    "section": "state",
    "text": "state\n- Thm: \\({\\cal A}\\)가 \\(\\Omega\\)에 대한 semiring이라고 하자. 함수 \\(\\tilde{m}: {\\cal A} \\to [0,\\infty]\\)가\n\n\\(\\tilde{m}(\\emptyset)=0\\)\n\\(\\tilde{m}(\\uplus_{i=1}^{n} B_i)=\\sum_{i=1}^{n}\\tilde{m}(B_i)\\)\n\\(\\tilde{m}(\\cup_{i=1}^{\\infty} A_i) \\leq \\sum_{i=1}^{\\infty}\\tilde{m}(A_i)\\)\n\\(\\exists A_1,A_2 \\dots \\in {\\cal A}\\) with \\(m(A_i)<\\infty\\) such that \\(\\cup_{i=1}^{\\infty}A_i = \\Omega\\)\n\n를 만족한다면 \\(\\tilde{m}\\)은 \\((\\Omega,\\sigma({\\cal A})\\)에서의 측도 \\(m\\)으로 업그레이드 가능하며, 이 업그레이드 결과는 유일하다.\n\n이 결과를 ver1로 생각하자.\n\n- 교재의 state (ver2, ver3)\n\n\n\n그림3: 카라데오도리 확장저정리 ver2, durret p456\n\n\n\nver1과의 비교: \\({\\cal A}\\)가 알지브라라는 것은 세미링보다 훨씬 강한 조건이다. 또한 measure on an algebra \\({\\cal A}\\)란 것은 1,2,3 조건을 다 합친것 보다 강한 조건이다. \\(\\sigma\\)-finite이라는 조건은 \\({\\cal A}\\)의 차이를 제외하면 동일하다.\n\n\n\n\n그림4: 카라데오도리 확장정리 ver3, durret p5\n\n\n\nver1과의 비교: \\({\\cal A}\\)가 세미알지브라라는 조건은 세미링보다 강한 조건이다. (i), (ii)의 \\({\\cal A}\\)의 차이만 있을 뿐 거의 동일하다. 4의 조건도 \\({\\cal A}\\)의 차이를 제외하고는 동일하다."
  },
  {
    "objectID": "posts/HousePrice/2023-04-18-7wk.html#예제-3월28일-4wk-예제들",
    "href": "posts/HousePrice/2023-04-18-7wk.html#예제-3월28일-4wk-예제들",
    "title": "7wk: 측도론 (3)",
    "section": "예제: 3월28일 (4wk) 예제들",
    "text": "예제: 3월28일 (4wk) 예제들\n(예제1) – motivating EX\n- \\(\\Omega=\\{1,2,3,4\\}\\)이라고 하자. 내가 관심있는 집합의 모음은 아래와 같다.\n\\[{\\cal A} = \\{\\emptyset, \\{1\\},\\{2\\},\\{3,4\\},\\Omega\\}\\]\n- 소망: 그래도 그냥 \\({\\cal A}\\)에서만 확률 비슷한 함수 \\(\\tilde{P}\\)를 잘 정의하면 \\((\\Omega,\\sigma({\\cal A}))\\)에서의 확률측도로 업그레이드 가능하고 업그레이드 결과가 유일할까?\n\n\\(\\tilde{P}(\\emptyset) = 0\\)\n\\(\\tilde{P}(\\{1\\}) = 1/4\\)\n\\(\\tilde{P}(\\{2\\}) = 1/2\\)\n\\(\\tilde{P}(\\{3,4\\}) = 1/4\\)\n\\(\\tilde{P}(\\Omega) = 1\\)\n\n- 조건체크\n\n\\({\\cal A}\\)는 세미알지브라(그러므로 세미링)이다.\n\\({\\cal A}\\)는 전체집합을 포함하고 있으며 \\({\\tilde P}(\\Omega)=1\\)이다. \\(\\Rightarrow\\) 조건 (4)가 만족.\n\\({\\tilde P}\\)는 (1) \\(\\tilde{P}(\\emptyset)=0\\) 이고 (2) add 를 만족하며 (3) \\(\\sigma\\)-subadd 를 만족한다.\n\n\n참고: 이 예제의 경우 \\(|\\Omega|<\\infty\\) 이므로 \\(\\sigma\\)-subadd 는 subadd 와 같은 성질이다. 그리고 add 는 subadd를 imply 하므로 사실상 (2) 만 체크하면 끝난다.2\n\n(예제2) – motivating EX (2)\n- \\(\\Omega=\\{1,2,3,4\\}\\)이라고 하고 \\({\\cal A} = \\{\\emptyset, \\{1\\},\\{2\\}, \\{3,4\\}, \\Omega\\}\\) 라고 하자. 그리고 아래와 같은 \\(\\sigma({\\cal A})\\)를 다시 상상하자.\n\\[\\sigma({\\cal A}) = \\big\\{\\emptyset, \\{1\\}, \\{2\\}, \\{1,2\\}, \\{3,4\\}, \\{1,3,4\\}, \\{2,3,4\\}, \\Omega \\big\\}\\]\n- 위의 시그마필드에서 확률을 예제1과 다른 방식으로 정의할 수 도 있다. 예를들면 아래와 같은 방식으로 정의가능하다.\n\n\n\n\n\\(P_1\\)\n\\(\\tilde{P}_1\\)\n\n\n\n\n\\(\\emptyset\\)\n\\(0\\)\n\\(0\\)\n\n\n\\(\\{1\\}\\)\n\\(\\frac{1}{3}\\)\n\\(\\frac{1}{3}\\)\n\n\n\\(\\{2\\}\\)\n\\(\\frac{1}{3}\\)\n\\(\\frac{1}{3}\\)\n\n\n\\(\\{3,4\\}\\)\n\\(\\frac{1}{3}\\)\n\\(\\frac{1}{3}\\)\n\n\n\\(\\Omega\\)\n\\(1\\)\n\\(1\\)\n\n\n\\(-\\)\n\\(-\\)\n\\(-\\)\n\n\n\\(\\{1,2\\}\\)\n\\(\\frac{2}{3}\\)\nNone\n\n\n\\(\\{1,3,4\\}\\)\n\\(\\frac{2}{3}\\)\nNone\n\n\n\\(\\{2,3,4\\}\\)\n\\(\\frac{2}{3}\\)\nNone\n\n\n\n또한 아래와 같은 방식도 가능하다.\n\n\n\n\n\\(P_2\\)\n\\(\\tilde{P}_2\\)\n\n\n\n\n\\(\\emptyset\\)\n\\(0\\)\n\\(0\\)\n\n\n\\(\\{1\\}\\)\n\\(0\\)\n\\(0\\)\n\n\n\\(\\{2\\}\\)\n\\(0\\)\n\\(0\\)\n\n\n\\(\\{3,4\\}\\)\n\\(1\\)\n\\(1\\)\n\n\n\\(\\Omega\\)\n\\(1\\)\n\\(1\\)\n\n\n\\(-\\)\n\\(-\\)\n\\(-\\)\n\n\n\\(\\{1,2\\}\\)\n\\(0\\)\nNone\n\n\n\\(\\{1,3,4\\}\\)\n\\(1\\)\nNone\n\n\n\\(\\{2,3,4\\}\\)\n\\(1\\)\nNone\n\n\n\n어떠한 방식으로 정의하든 \\({\\cal A}\\)에서 확률 비슷한 것 \\(\\tilde{P}_1,\\tilde{P}_2\\)를 잘 정의하기만 \\(\\sigma({\\cal A})\\)에서의 확률 \\(P\\)로 적절하게 확장할 수 있다. 심지어 이런 확장은 유일한 듯 하다.\n- 당연함. 예제1과 동일하게 \\(\\tilde{P_1}\\)과 \\(\\tilde{P_2}\\)가 add 성질만 만족한다는 사실을 체크하면 끝난다.\n(예제3) – 운이 안 좋은 경우\n- \\(\\Omega=\\{1,2,3\\}\\) 이라고 하고 \\({\\cal A} = \\{\\emptyset, \\{1,2\\},\\{2,3\\}, \\Omega\\}\\) 라고 하자.\n- 아래와 같은 확률 비슷한 함수 \\(\\tilde{P}:{\\cal A} \\to [0,1]\\)를 정의하자.\n\n\\(\\tilde{P}(\\emptyset) = 0\\)\n\\(\\tilde{P}(\\{1,2\\}) = 0\\)\n\\(\\tilde{P}(\\{2,3\\}) = 0\\)\n\\(\\tilde{P}(\\Omega) = 1\\)\n\n- 체크: 일단 \\({\\cal A}\\)는 세미링이 아니다. 따라서 확장 불가능. 세미링이 맞다고 하여도 subadd가 성립하지 않는다.\n(예제4) – 운이 안 좋은 경우\n- \\(\\Omega=\\{1,2,3,4\\}\\) 이라고 하고 \\({\\cal A} = \\{\\emptyset, \\{1,2\\},\\{2,3\\}, \\Omega\\}\\) 라고 하자.\n- 아래와 같은 확률 비슷한 함수 \\(\\tilde{P}:{\\cal A} \\to [0,1]\\)를 정의하자.\n\n\\(\\tilde{P}(\\emptyset) = 0\\)\n\\(\\tilde{P}(\\{1,2\\}) = 1/2\\)\n\\(\\tilde{P}(\\{2,3\\}) = 1/2\\)\n\\(\\tilde{P}(\\Omega) = 1\\)\n\n- 체크: \\(\\tilde{P}\\)는 괜찮게 정의되었다. (1)-(4)가 모두 성립한다. (위의 예제와는 다르게 subadd 역시 성립함!!) 하지만 \\({\\cal A}\\)가 세미링이 아니어서 탈락."
  },
  {
    "objectID": "posts/HousePrice/2023-05-02-TS-hw6.html",
    "href": "posts/HousePrice/2023-05-02-TS-hw6.html",
    "title": "TS HW6",
    "section": "",
    "text": "* 동일 표본공간 \\(S\\) 상에 정의된 두 사건 \\(A\\), \\(B\\)가 공통된 부분이 없을 때, 즉 \\(A\\cap B = \\varnothing\\) 이면 두 사건 \\(A, B\\) 는 상호배반(mutually exclusive) 이라고 한다.\n* 공리에 근거한 확률의 성질에 따라 \\(P(\\varnothing) = 0\\) 이다.\n\\(P(A\\cup B) = P(A) + P(B) - P(A\\cap B) \\\\ \\qquad \\quad \\space \\space = P(A) + P(B)\\)\n\\(P(A\\cap (A\\cup B)) = P((A\\cap A) \\cup (A\\cap B)) = P(A\\cup \\varnothing) = P(A)\\)\n따라서 \\(P(A|A\\cup B) = \\frac{P\\left(A\\cap (A\\cup B)\\right)}{P(A\\cup B)} = \\frac{P(A)}{P(A) + P(B)}\\) 이다.\n\n\n\n\\(P(S) = P(A\\cup B) = P(A)+P(B)-P(A\\cap B)=1 \\\\ \\quad \\quad = 0.8+0.5-P(A\\cap B)=1 \\\\ \\therefore P(A\\cap B)=0.3\\)\n\n\n\n두 사건 \\(A\\), \\(B\\) 에 대하여 \\(P(A \\cap B) = P(A)P(B)\\) 가 성립할 때 서로 독립 이라고 한다.\n* \\(P(A|B) = \\frac{P(A\\cap B)}{P(B)}\\)\n* \\(P(A|B^c) = \\frac{P(A\\cap B^c)}{P(B^c)} = \\frac{P(A) - P(A\\cap B)}{1-P(B)}\\)\n** $ = $\n\\(P(A\\cap B)\\left[1-P(B)\\right] = P(B)\\left[P(A) - P(A\\cap B)\\right]\\)\n\\(P(A\\cap B) - P(B)P(A\\cap B) = P(A)P(B) - P(B)P(A\\cap B)\\)\n\\(P(A\\cap B) = P(A)P(B)\\) 이므로, 두 사건 \\(A,B\\) 는 서로 독립이다.\n\n\n\n\n\n\\(X\\) = 뒷면이 나오는 횟수\n\\(P(H) = 0.2\\), \\(\\quad H\\): 앞면, \\(T\\): 뒷면\n\n\n\n\\(\\{X=1\\} = \\{THH, HTH, HHT\\}\\)\n\n\n\n\n주의: \\(x\\)의 범위도 구체적으로 기술.\n\n\\(Y=2+X\\) 라 하면, 앞면이 2번 나올 때까지 동전을 던진 횟수가 된다. 그러므로 \\(Y\\sim \\text{NB}\\left(2,0.2\\right)\\)이다.\n\\(X\\)의 pmf는 다음과 같다.\n\\(\\begin{equation}\\begin{split}f_X(x) &= P(X=x) = P(Y=2+x) = f_Y(2+x)\\\\ &=\\binom{2+x-1}{2-1}(0.2)^2(0.8)^x, x=0,1,\\dots \\\\ &=\\binom{1+x}{1}(0.2)^2(0.8)^x, x=0,1\\dots\\end{split}\\end{equation}\\)\n\n\n\n\n\\[E(Y_k) = -2 + k, \\quad Var(Y_k) = 4, k=1,2,3\\]\n\n\\(E(Y_1) = -1, E(Y_2) = 0, E(Y_3)=1\\)\n\\(Var(Y_1) = Var(Y_2) = Var(Y_3) = 4\\)\n\\(Cov(Y_1, Y_2) = 0, Cov(Y_1,Y_3) = 0, Cov(Y_2,Y_3)=0\\) (\\(Y_i\\) 가 서로 독립이므로)\n\n\n\n\\(Var(Y_2) = E[(Y_2)^2] - E[Y_2]^2\\)\n\\(4 = E[(Y_2)^2]-0\\)\n\\(\\therefore E[(Y_2)^2] = 4\\)\n\n\n\n\\(E(Y_1 + 2Y_2 -Y_3) = E(Y_1) + 2E(Y_2) -E(Y_3) = -2\\)\n\\(Var(Y_1 + 2Y_2 - Y_3) = Var(Y_1) + 4Var(Y_2) + Var(Y_3)=24\\)\n\n\n\n\\(\\text{Corr}(Y_1+Y_2, Y_1-Y_2) = \\frac{\\text{cov}(Y_1+Y_2, Y_1-Y_2)}{\\sqrt{\\text{Var}{(Y_1+Y_2)}\\text{Var}{(Y_1-Y_2)}}}=0\\)\n\\(Y_1+Y_2\\) 와 \\(Y_1-Y_2\\) 두 변수의 상관계수가 \\(0\\)으로 선형관계가 없다.\n\n\n\n\n\\(P(Y<X, Y<1/4) = \\int_{0}^{1/4}\\int_{0}^y 24xy dxdy + \\int_0^{1/4}\\int_{1-y}^1 24xy dxdy=\\frac{3}{256} + \\frac{29}{256} = \\frac{1}{8}\\)\n\n\n\n\n\n\n주의: \\(x\\)의 범위도 명확히 기술\n\n\\(f_X(x) = \\int_{-\\infty}^{\\infty}f_{X,Y}(x,y)dy\\)\n\\(=\\int_{-\\infty}^{\\infty} 2e^{-(x+y)}I(0<x<y, y>0)dy\\)\n\\(=\\int_{x}^{\\infty} 2e^{-(x+y)}I(x>0)dy\\)\n\\(=2e^{-x}I(x>0)\\int_{x}^{\\infty} e^{-y}dy\\)\n\\(=2e^{-x}I(x>0) \\left[-e^{-y}\\bigr\\rvert_x^{\\infty}\\right]\\)\n\\(=2e^{-2x} I(x>0)\\)\n\n\n\n\\(E(X) = \\int_{-\\infty}^{\\infty} xf_X(x)dx\\)\n\\(=\\int_{-\\infty}^{\\infty} x2e^{-2x} I(x>0)dx\\)\n\\(=2\\int_{0}^{\\infty}e^{-2x} I(x>0)dx\\)\n\\(=2\\cdot -\\frac{1}{2}e^{-2x}\\bigr\\rvert_{0}^{\\infty}\\)\n\\(=-e^{-2x}\\bigr\\rvert_{0}^\\infty = 1\\)\n\n\n\n조건부 분산은 정의에 의해 다음과 같이 표현할 수 있다.\n\\(Var(Y|x) = E(Y^2|x) - [E(Y|x)]^2 \\tag{2.15}\\)\n위에서 구한 \\(X\\)의 주변확률밀도함수와(\\(f_X(x)\\)) \\(X,Y\\)의 결합밀도함수(\\(f_{X,Y}(x,y)\\))를 이용하여 \\(Y|x\\)의 조건부 확률밀도 함수를 구할 수 있다.\n\\(f(Y|x) = \\frac{f_{X,Y}(x,y)}{f_X(x)} = \\frac{2e^{-(x+y)}I(0<x<y)}{2e^{-2x}I(x>0)}= e^{x-y}I(0<x<y)\\)\n조건부 확률밀도함수를 이용하여 조건부 분산을 구해보자.\n* \\(E(Y|x) = \\int_{-\\infty}^{\\infty}y e^{x-y} I(0<x<y)\\)\n\\(=\\int_{x}^{\\infty}y e^{x-y} I(x>0)dy\\)\n\\(=e^x I(x>0)\\int_{x}^{\\infty}y e^{-y} dy\\)\n\\(= e^x \\cdot e^{-x}(x+1) I(x>0) = x+1 I(x>0)\\)\n* \\(E(Y^2|x) = \\int_{-\\infty}^{\\infty}y^2 e^{x-y} I(0<x<y)\\)\n\\(=\\int_{x}^{\\infty}y^2 e^{x-y} I(x>0)dy\\)\n\\(=e^x I(x>0)\\int_{x}^{\\infty}y^2 e^{-y} dy\\)\n\\(= e^x \\cdot e^{-x}(x^2+2x+2) I(x>0) = x^2+2x+2 I(x>0)\\)\n** \\(x=2\\)로 주어져있으므로, 아래와 같이 다시 쓸 수 있다.\n\\(\\therefore Var(Y|x=2) = E(Y^2|x=2) - [E(Y|x=2)]^2 = 10 - 3^2 = 1\\)\n\n\n\n\n\\[M_x(t) = \\frac{1}{1-2t}, \\quad M_y(t) = \\frac{1}{1-4t+4t^2}\\]\n두 확률변수 \\(X,Y\\)는 독립이면, 결합적률생성함수는 각각의 적률생성함수의 곱과 같다. 따라서 \\(M_{X,Y}(t_1,t_2) = M_x(t_1)M_y(t_2)\\)이 성립한다.\n\\(M_{X,Y}(t_1,t_2) = M_X(t_1)M_Y(t_2) = \\frac{1}{1-2t_1}\\frac{1}{1-4t_2+ 4t_2^2}\\)\n\\(E(X^2Y) = \\frac{\\partial^3 M_{X,Y}(t_1,t_2)}{\\partial^2 t_1 \\partial t_2}\\bigr\\rvert_{t_1=t_2=0}=8(1-2t_1)^{-3}4(1-2t_2)^{-3}\\bigr\\rvert_{t_1=t_2=0} = 32\\)\n\n\n\n\n\n\\(X_1 \\sim Ber(p)\\)\n\\(f_X(x) = p^x(1-p)^{1-x}, \\quad x=0,1\\)\n\\(M_{X_1}(e^{tX_1}) = E(e^{tX_1}) = \\sum_{x_1=0}^1 e^{tX_1}p^{x_1}(1-p)^{1-x_1}=1-p+e^tp\\)\n\n\n\n\\(Y= X_1 + X_2+\\dots +X_5, \\quad Y\\sim \\text{Bin}(5,p)\\)\n\\(\\begin{equation}\\begin{split}P(Y\\geq 2) = 1- P(Y \\leq 1) &= 1-P(Y=0)-P(Y=1) \\\\ &= 1- \\left[_{5}\\textrm{C}_0(1-p)^5+ _{5}\\textrm{C}_1 p(1-p)^4 \\right] \\\\ &=1-\\left[(1-p)^5 + 5p(1-p)^4\\right] \\end{split}\\end{equation}\\)\n\n\n\n\\(\\begin{equation}\\begin{split} E(X_1|X_1+X_2+\\cdots+X_5=3) &= \\sum_{x_1=0}^1 x_1 \\cdot P(X_1=x_1|X_1+X_2+\\cdots+X_5=3) \\\\ &= \\frac{\\sum_{x_1=0}^1 x_1 P(X_1=x_1,X_1+X_2+\\cdots+X_5=3)}{P(X_1+X_2+\\cdots+X_5=3)} \\\\ &= \\frac{\\sum_{x_1=0}^1 x_1 P(X_1=x_1) P(X_2+\\cdots+X_5=3-x_1)}{P(X_1+X_2+\\cdots+X_5=3)} \\\\ &= \\frac{0 \\cdot P(X_2+\\cdots+X_5=3) + 1 \\cdot P(X_1=1) P(X_2+\\cdots+X_5=2)}{P(X_1+X_2+\\cdots+X_5=3)} \\\\ &= \\frac{p \\cdot \\binom{4}{2}p^2(1-p)^2}{\\binom{5}{3}p^3(1-p)^2} \\\\ &= \\frac{4}{5} \\end{split}\\end{equation}\\)\n\\(\\therefore E(X_1|X_1+X_2+\\cdots+X_5=3) = \\frac{4}{5}\\)"
  },
  {
    "objectID": "posts/HousePrice/2023-05-02-TS-hw6.html#x_1-x_2-dots-x_n이-u0theta로부터의-랜덤표본이라고-할-때-다음을-구하시오.",
    "href": "posts/HousePrice/2023-05-02-TS-hw6.html#x_1-x_2-dots-x_n이-u0theta로부터의-랜덤표본이라고-할-때-다음을-구하시오.",
    "title": "TS HW6",
    "section": "1. \\(X_1, X_2, \\dots, X_n\\)이 \\(U(0,\\theta)\\)로부터의 랜덤표본이라고 할 때, 다음을 구하시오.",
    "text": "1. \\(X_1, X_2, \\dots, X_n\\)이 \\(U(0,\\theta)\\)로부터의 랜덤표본이라고 할 때, 다음을 구하시오.\n\n(1) \\(X_{(1)}\\)과 \\(X_{(n)}\\)의 결합확률밀도함수\n\\(f(x_{(1)},x_{(n)}) = n(n-1)\\left[\\frac{x_{(n)}-x_{(1)}}{\\theta}\\right]^{n-2}\\frac{1}{\\theta^2} = n(n-1)\\theta^{-n}\\left[ x_{(n)} - x_{(1)}\\right]^{n-2}\\)\n\n\n(2) 표본범위 \\(X_{(n)}-X_{(1)}\\)의 확률밀도함수\n\\(\\begin{cases}Z_1 = X_{(n)}-X_{(1)} \\\\ Z_2 = X_{(1)}\\end{cases} \\Rightarrow \\begin{cases} X_{(n)} = Z_1 + Z_2\\\\ X_{(1)} = Z_2\\end{cases}, \\quad 0<X_{(1)}<X_{(n)}<\\theta\\)\n\\(g(z_1,z_2) = f(Z_2,z_1+z_2)|J| = n(n-1)\\theta^n z_1^{n-2}, \\quad 0<z_2<z_1+z_2<\\theta\\)\n\\(g(z_1) = n(n-1)\\theta^nz_1^{n-2}\\int_{0}^{\\theta-z_1}dz_2 = n(n-1)\\theta^{-n}z_1^{n-2}(\\theta-z_1), \\quad 0<z_2,\\theta\\)"
  },
  {
    "objectID": "posts/HousePrice/2023-05-02-TS-hw6.html#x_1x_2dotsx_n이-explambda-즉-fxlambda-e-lambda-xix0으로부터의-랜덤표본이라고-할-때-다음을-구하시오.",
    "href": "posts/HousePrice/2023-05-02-TS-hw6.html#x_1x_2dotsx_n이-explambda-즉-fxlambda-e-lambda-xix0으로부터의-랜덤표본이라고-할-때-다음을-구하시오.",
    "title": "TS HW6",
    "section": "2. \\(X_1,X_2,\\dots,X_n\\)이 \\(\\exp(\\lambda)\\) 즉, \\(f(x)=\\lambda e^{-\\lambda x}I(x>0)\\)으로부터의 랜덤표본이라고 할 때, 다음을 구하시오.",
    "text": "2. \\(X_1,X_2,\\dots,X_n\\)이 \\(\\exp(\\lambda)\\) 즉, \\(f(x)=\\lambda e^{-\\lambda x}I(x>0)\\)으로부터의 랜덤표본이라고 할 때, 다음을 구하시오.\n\n\\(f(x) = \\lambda e^{-\\lambda x} I(x>0)\\)\n\\(F(x) = \\int_{0}^{\\infty} \\lambda e^{-\\lambda x} = 1-e^{-\\lambda x}\\)\n\n\n(1) \\(X_{(1)}\\)의 확률밀도함수\n\\(f_{X_{(1)}}(x_{(1)}) = n[1-F(x_{(1)})]^{n-1} f(x_{(1)})\\)\n\\(=n[1-(1-e^{-\\lambda x_{(1)}})]^{n-1}\\lambda e^{-\\lambda x_{(1)}}\\)\n\\(=n\\lambda [e^{-\\lambda x_{(1)}}]^n, \\quad x_{(1)}>0\\)\n\n\n(2) 표본범위 \\(X_{(n)}\\)의 확률밀도함수\n\\(f_{X_{(n)}}(x_{(n)}) = n[F(x_{(n)})]^{n-1} f(x_{(n)})\\)\n\\(= n[1-e^{-\\lambda x_{(n)}}]^{n-1} \\lambda e^{-\\lambda x_{(n)}}\\)\n\\(=n\\lambda [1-e^{-\\lambda x_{(n)}}]^{n-1} e^{-\\lambda x_{(n)}},\\quad x_{(n)} >0\\)\n\n\n(3) \\(n=2r+1\\) 이라고 가정하고, 표본중위수 \\(X_{(r)}\\) 의 확률밀도함수\n\\(f_{X_{(r)}} = \\frac{(2r+1)!}{(r-1)!1!(r+1)!}F(x_{(r)})^{r-1}[1-F(x_{(r)})]^{r+1}f(x_{(r)})\\)\n\\(=\\frac{(2r+1)!}{(r-1)!1!(r+1)!}[1-e^{-\\lambda x_{(r)}}]^{r-1}[1-(1-e^{-\\lambda x_{(r)}})]^{r+1}\\lambda e^{-\\lambda x_{(r)}}\\)\n$={r-1}[e^{-x_{(r)}}]{r+2}, x_{(r)} > 0 $"
  },
  {
    "objectID": "posts/HousePrice/2023-04-19-lr-hw2.html",
    "href": "posts/HousePrice/2023-04-19-lr-hw2.html",
    "title": "MLR_hw2",
    "section": "",
    "text": "dt.csv 데이터를 이용하여 회귀모형을 적합하려고 한다. 이는 매장별 유아 카시트 판매액(Sales)를 예측하기 위한 데이터 이다. 다음 물음에 답하여라. (R을 이용하여 풀이)(검정에서는 유의수준 α = 0.05 사용)\n\nlibrary(tidyverse)\n\n── Attaching packages ─────────────────────────────────────── tidyverse 1.3.1 ──\n\n✔ ggplot2 3.4.1     ✔ purrr   1.0.1\n✔ tibble  3.2.0     ✔ dplyr   1.1.0\n✔ tidyr   1.3.0     ✔ stringr 1.5.0\n✔ readr   2.1.4     ✔ forcats 1.0.0\n\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\n\n\n\n\ndf = read_csv('./dt.csv')\nstr(df)\n\nRows: 400 Columns: 8\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\ndbl (8): Sales, CompPrice, Income, Advertising, Population, Price, Age, Educ...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nspc_tbl_ [400 × 8] (S3: spec_tbl_df/tbl_df/tbl/data.frame)\n $ Sales      : num [1:400] 9.5 11.22 10.06 7.4 4.15 ...\n $ CompPrice  : num [1:400] 138 111 113 117 141 124 115 136 132 132 ...\n $ Income     : num [1:400] 73 48 35 100 64 113 105 81 110 113 ...\n $ Advertising: num [1:400] 11 16 10 4 3 13 0 15 0 0 ...\n $ Population : num [1:400] 276 260 269 466 340 501 45 425 108 131 ...\n $ Price      : num [1:400] 120 83 80 97 128 72 108 120 124 124 ...\n $ Age        : num [1:400] 42 65 59 55 38 78 71 67 76 76 ...\n $ Education  : num [1:400] 17 10 12 14 13 16 15 10 10 17 ...\n - attr(*, \"spec\")=\n  .. cols(\n  ..   Sales = col_double(),\n  ..   CompPrice = col_double(),\n  ..   Income = col_double(),\n  ..   Advertising = col_double(),\n  ..   Population = col_double(),\n  ..   Price = col_double(),\n  ..   Age = col_double(),\n  ..   Education = col_double()\n  .. )\n - attr(*, \"problems\")=<externalptr> \n\n\n\n이 데이터의 산점도 행렬을 그리시오.\n\n\npairs(df, pch=16, col='darkorange')\n\n\n\n\n\nSales를 예측하기 위한 중회귀분석을 하려고 한다. 이를 위한 모형을 설정하시오.\n최소제곱법의 의한 회귀직선을 적합시키시키고, 모형 적합 결과를 설명하시오.\n\n\\(S = \\sum_{i=1}^n \\epsilon_i^2=\\sum_{i=1}^n(y_i - (\\beta_0 + \\beta_1x_{i1} + \\dots \\beta_7x_{i7}))^2\\)\n최소제곱추정량: \\((\\hat{\\beta}_0, \\hat{\\beta}_1,\\dots, \\hat{\\beta}_7)=\\underset{(\\beta_0, \\beta_1,\\dots,\\beta_7)\\in \\mathbb{R}^3}{\\text{argmin}} \\sum_{i=1}^n \\{y_i - (\\beta_0 + \\beta_1x_{i1} + \\dots \\beta_7x_{i7})\\}^2\\)\n\nfit_Sales <- lm(Sales ~ ., data=df)\nsummary(fit_Sales)\n\n\nCall:\nlm(formula = Sales ~ ., data = df)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-5.0598 -1.3515 -0.1739  1.1331  4.8304 \n\nCoefficients:\n              Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  7.7076934  1.1176260   6.896 2.15e-11 ***\nCompPrice    0.0939149  0.0078395  11.980  < 2e-16 ***\nIncome       0.0128717  0.0034757   3.703 0.000243 ***\nAdvertising  0.1308637  0.0151219   8.654  < 2e-16 ***\nPopulation  -0.0001239  0.0006877  -0.180 0.857092    \nPrice       -0.0925226  0.0050521 -18.314  < 2e-16 ***\nAge         -0.0449743  0.0060083  -7.485 4.75e-13 ***\nEducation   -0.0399844  0.0371257  -1.077 0.282142    \n---\nSignif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n\nResidual standard error: 1.929 on 392 degrees of freedom\nMultiple R-squared:  0.5417,    Adjusted R-squared:  0.5335 \nF-statistic: 66.18 on 7 and 392 DF,  p-value: < 2.2e-16\n\n\n\n회귀직선의 유의성 검정을 위한 가설을 설정하고, 분산분석표를 이용하여 가설 검정을 수행하시오.\n\n\\(H_0: \\beta_1=\\beta_2 = \\dots = \\beta_7 = 0\\)\n\\(H_1: \\text{not } H_0\\)\n\nnull_model <- lm(Sales ~ 1, data=df) # H0\nfit_Sales <- lm(Sales ~ ., data=df) # H1\n\nanova(null_model, fit_Sales)\n\n\n\nA anova: 2 × 6\n\n    Res.DfRSSDfSum of SqFPr(>F)\n    <dbl><dbl><dbl><dbl><dbl><dbl>\n\n\n    13993182.275NA      NA      NA          NA\n    23921458.562 71723.71366.180211.413772e-62\n\n\n\n\n\n오차의 분산에 대한 추정량을 구하시오.\n결정계수와 수정된 결정계수를 구하시오.\n\n\nsummary(fit_Sales)\n\n\nCall:\nlm(formula = Sales ~ ., data = df)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-5.0598 -1.3515 -0.1739  1.1331  4.8304 \n\nCoefficients:\n              Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  7.7076934  1.1176260   6.896 2.15e-11 ***\nCompPrice    0.0939149  0.0078395  11.980  < 2e-16 ***\nIncome       0.0128717  0.0034757   3.703 0.000243 ***\nAdvertising  0.1308637  0.0151219   8.654  < 2e-16 ***\nPopulation  -0.0001239  0.0006877  -0.180 0.857092    \nPrice       -0.0925226  0.0050521 -18.314  < 2e-16 ***\nAge         -0.0449743  0.0060083  -7.485 4.75e-13 ***\nEducation   -0.0399844  0.0371257  -1.077 0.282142    \n---\nSignif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n\nResidual standard error: 1.929 on 392 degrees of freedom\nMultiple R-squared:  0.5417,    Adjusted R-squared:  0.5335 \nF-statistic: 66.18 on 7 and 392 DF,  p-value: < 2.2e-16\n\n\n\n$R^2 = 0.5417,R^2=0.5335 $\n\n\n개별 회귀계수의 유의성검정을 수행하시오.\n회귀계수에 대한 90% 신뢰구간을 구하시오.\nCompPrice = 100, Income = 70, Advertising = 20, Population = 300, Price = 80, Education = 12 인 지역에 위치한 매장의 평균 판매액을 예측하고, 95% 신뢰구간을 구하시오.\n\n\nmodel_ = lm(Sales ~ .-Age , data=df)\n\n\nnew_df = data.frame(Age =30 , CompPrice=100, Income=70, Advertising = 20, Population = 300, Price = 80, Education = 12)\nnew_df\n\n\n\nA data.frame: 1 × 7\n\n    AgeCompPriceIncomeAdvertisingPopulationPriceEducation\n    <dbl><dbl><dbl><dbl><dbl><dbl><dbl>\n\n\n    3010070203008012\n\n\n\n\n\npredict(model_,\n        newdata = new_df,\n        interval = c('confidence'),\n        level = 0.95) ## 평균반응\n\n\n\nA matrix: 1 × 3 of type dbl\n\n    fitlwrupr\n\n\n    110.142619.53712810.7481\n\n\n\n\n\n위 매장에 대하여 개별 판매액 예측하고, 95% 신뢰구간을 구하시오.\n잔차에 대한 산점도를 그리고, 결과를 설명하여라.\n잔차에 대한 등분산성 검정을 수행하여라.\n잔차에 대한 히스토그램, QQ plot을 그리고, 정규성 검정을 수행하여라.\n잔차에 대한 독립성 검정을 수행하시오."
  },
  {
    "objectID": "posts/HousePrice/2023-04-19-lr-hw2.html#q2.-다음-물음에-답하여라.",
    "href": "posts/HousePrice/2023-04-19-lr-hw2.html#q2.-다음-물음에-답하여라.",
    "title": "MLR_hw2",
    "section": "Q2. 다음 물음에 답하여라.",
    "text": "Q2. 다음 물음에 답하여라.\n위 데이터에 대하여 다음 물음에 답하여라. (R을 이용하여 풀이)(검정에서는 유의수준 α = 0.05 사용)\n\n위에서 적합한 모형에서 개별 회귀계수의 유의성 검정 결과 유의하지 않은 변수는 무엇인가?\n위에서 유의하지 않았던 변수를 제외한 모형을 축소모형(Reduced Model)으로 하는 부분 F검정을 수행 하여라. 검정에 필요한 가설을 설정하고, 검정 결과를 설명하시오.\n1번에서 설정한 모형과, 축소모형 중 어느 모형이 이 데이터에 대한 설명을 잘 하고 있는지를 비교하시오."
  },
  {
    "objectID": "posts/HousePrice/2023-04-19-lr-hw2.html#q3.-일반-선형-가설검정-general-linear-hypothesis-test을-수행하여라.",
    "href": "posts/HousePrice/2023-04-19-lr-hw2.html#q3.-일반-선형-가설검정-general-linear-hypothesis-test을-수행하여라.",
    "title": "MLR_hw2",
    "section": "Q3. 일반 선형 가설검정 (General Linear Hypothesis Test)을 수행하여라.",
    "text": "Q3. 일반 선형 가설검정 (General Linear Hypothesis Test)을 수행하여라.\n1번에서 설정한 모형에 대하여 아래의 일반 선형 가설검정(General Linear Hypothesis Test)을 수행하시오. (R을 이용하여 풀이)(검정에서는 유의수준 α = 0.05 사용)(회귀계수는 βi 로 표현해야 하지만, 각자 설정이 다를 수가 있기 때문에 회귀계수 대신 변수 이름을 사용하겠음. 예 β1 =CompPrice)\n\n\\(H_0 : \\text{CompPrice}=\\text{Income} \\text{ vs. } H_1 : \\text{not } H_0\\)\n\\(H_0 : \\text{CompPrice}= -\\text{Price} \\text{ vs. } H_1 : \\text{not } H_0\\)\n\\(H_0\\)를 기각할 수 있는 제약조건을 만들어 보시오.(단 2개 이상의 변수 사용)"
  },
  {
    "objectID": "posts/HousePrice/2023-04-18-mlr-보스턴집값.html",
    "href": "posts/HousePrice/2023-04-18-mlr-보스턴집값.html",
    "title": "MLR prac1",
    "section": "",
    "text": "library(MASS)\nlibrary(lmtest)\n\nLoading required package: zoo\n\n\n\nAttaching package: 'zoo'\n\n\nThe following objects are masked from 'package:base':\n\n    as.Date, as.Date.numeric"
  },
  {
    "objectID": "posts/HousePrice/2023-04-18-mlr-보스턴집값.html#matrix",
    "href": "posts/HousePrice/2023-04-18-mlr-보스턴집값.html#matrix",
    "title": "MLR prac1",
    "section": "matrix",
    "text": "matrix\n\\[\\bf{y} = \\bf{X}\\bf{\\beta} + \\bf{\\epsilon} \\Rightarrow \\hat{\\bf{\\beta}}=(\\bf{X}^\\top X)^{-1}\\bf{X}^\\top \\bf{y}\\]\n\nn = nrow(Boston)\nX = cbind(rep(1,n), Boston$rm, Boston$lstat)\ny = Boston$medv\n\n\nbeta_hat = solve(t(X)%*%X) %*% t(X) %*% y # 행렬곱 (%*%)\nbeta_hat\n\n           [,1]\n[1,] -1.3582728\n[2,]  5.0947880\n[3,] -0.6423583\n\n\n\ncoef(fit_Boston)\n\n(Intercept)          rm       lstat \n -1.3582728   5.0947880  -0.6423583 \n\n\n\nlm을 이용해서 하나 행렬을 이용해서 하나 동일한 결과를 얻음을 확인할 수 있다.\n\n\\[\\hat{y} = \\bf{X}\\hat{\\bf{\\beta}}\\]\n\ny_hat = X %*% beta_hat\ny_hat[1:5] # 상위 5개의 값 확인.\n\n[1] 28.94101 25.48421 32.65907 32.40652 31.63041\n\n\n\nfitted(fit_Boston)[1:5]\n\n       1        2        3        4        5 \n28.94101 25.48421 32.65907 32.40652 31.63041 \n\n\n\n\\(\\hat{y}\\)도 마찬가지로 동일한 결과를 얻음을 확인할 수 있다.\n\n\\[SSE = \\sum(y_i - \\hat{y}_i)^2,\\quad RMSE = \\sqrt\\frac{SSE}{n-p-1} = \\hat{\\sigma}\\]\n\nsse <- sum((y - y_hat)^2) ##SSE\nsqrt(sse/(n-2-1)) ##RMSE\n\n[1] 5.540257\n\nsummary(fit_Boston)$sigma\n\n[1] 5.540257\n\n\n\n\n\ndt <- Boston[,which(names(Boston) %in% c('medv', 'rm', 'lstat'))]\nhead(dt)\n\n     rm lstat medv\n1 6.575  4.98 24.0\n2 6.421  9.14 21.6\n3 7.185  4.03 34.7\n4 6.998  2.94 33.4\n5 7.147  5.33 36.2\n6 6.430  5.21 28.7\n\n\n\nfit_Boston<-lm(medv~., data=dt)\nfit_Boston<-lm(medv~rm+lstat, data=dt)\n\nsummary(fit_Boston)\n\n\nCall:\nlm(formula = medv ~ rm + lstat, data = dt)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-18.076  -3.516  -1.010   1.909  28.131 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept) -1.35827    3.17283  -0.428    0.669    \nrm           5.09479    0.44447  11.463   <2e-16 ***\nlstat       -0.64236    0.04373 -14.689   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 5.54 on 503 degrees of freedom\nMultiple R-squared:  0.6386,    Adjusted R-squared:  0.6371 \nF-statistic: 444.3 on 2 and 503 DF,  p-value: < 2.2e-16\n\n## hat y = -1.3583 + 5.0948*rm - 0.6424*lstat"
  },
  {
    "objectID": "posts/HousePrice/2023-04-18-mlr-보스턴집값.html#분산분석-회귀직선의-유의성-검정",
    "href": "posts/HousePrice/2023-04-18-mlr-보스턴집값.html#분산분석-회귀직선의-유의성-검정",
    "title": "MLR prac1",
    "section": "분산분석 : 회귀직선의 유의성 검정",
    "text": "분산분석 : 회귀직선의 유의성 검정\n\nanova(fit_Boston) ## Full model\n\nAnalysis of Variance Table\n\nResponse: medv\n           Df  Sum Sq Mean Sq F value    Pr(>F)    \nrm          1 20654.4 20654.4  672.90 < 2.2e-16 ***\nlstat       1  6622.6  6622.6  215.76 < 2.2e-16 ***\nResiduals 503 15439.3    30.7                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\n\n\n\n\nTip\n\n\n\n\\[H_0 : \\beta_1=\\beta_2=0 \\text{ vs. } H_1:not \\space H_0\\]\n\n\\(H_0\\) : 귀무가설, null hypothesis, 영가설 모두 동일한 표현이다.\n\n\n\n\\(H_0: y = \\beta_0 \\cdot 1\\) \\(H_1: y = \\beta_0 \\cdot 1 + \\beta_1 x_1 + \\beta_2 x_2\\)\n\nnull_model <- lm(medv~1, data=dt)  # H0\nfit_Boston <- lm(medv~., data=dt)  # H1\n\nanova(null_model, fit_Boston) ## null 가설 선택? 설명변수 다쓴 모델 선택?\n\nAnalysis of Variance Table\n\nModel 1: medv ~ 1\nModel 2: medv ~ rm + lstat\n  Res.Df   RSS Df Sum of Sq      F    Pr(>F)    \n1    505 42716                                  \n2    503 15439  2     27277 444.33 < 2.2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\nModel1은 절편만 쓴 것이고, Model2는 설명변수 2개모두 다 쓴 것이다.\nRSS와 SSR은 다름을 주의하자.\n\\(H_0\\) 에 가정된 모형을 선택할지 \\(H_1\\) 에 가정된 모형을 선택할지 F통계량 확인."
  },
  {
    "objectID": "posts/HousePrice/2023-04-18-mlr-보스턴집값.html#beta-의-신뢰구간",
    "href": "posts/HousePrice/2023-04-18-mlr-보스턴집값.html#beta-의-신뢰구간",
    "title": "MLR prac1",
    "section": "\\(\\beta\\) 의 신뢰구간",
    "text": "\\(\\beta\\) 의 신뢰구간\n\n\n\n\n\n\nImportant\n\n\n\n\\(\\beta_i\\) 의 \\(100(1-\\alpha)\\%\\) \\(\\text{CI}\\)\n\n\\(\\hat{\\beta}_i \\pm t_{\\alpha/2}(n-p-1) \\cdot \\hat{\\text{s.e}}(\\hat{\\beta}_i)\\)\n\n\n\n\n\n\n\n\n\nImportant\n\n\n\n\\(\\beta_i\\) 의 covariance-variance matrix\n\\(Var(\\beta) = (\\bf{X}^\\top \\bf{X})^{-1} \\cdot \\sigma^2 = \\begin{bmatrix} Var(\\beta_0) & Cov(\\beta_0, \\beta_1) & Cov(\\beta_0, \\beta_2) \\\\ Cov(\\beta_0, \\beta_1) & Var(\\beta_1) & Cov(\\beta_1, \\beta_2) \\\\ Cov(\\beta_0, \\beta_2) & Cov(\\beta_1, \\beta_2) & Var(\\beta_2) \\end{bmatrix}\\)\n\n\n\n# variance-covariance matrix\nvcov(fit_Boston)  ##var(hat beta) = (X^TX)^-1 \\sigma^2\n\n            (Intercept)          rm        lstat\n(Intercept) 10.06683612 -1.39248641 -0.099178133\nrm          -1.39248641  0.19754958  0.011930670\nlstat       -0.09917813  0.01193067  0.001912441\n\n\n\nconfint(fit_Boston, level = 0.95)\n\n                 2.5 %     97.5 %\n(Intercept) -7.5919003  4.8753547\nrm           4.2215504  5.9680255\nlstat       -0.7282772 -0.5564395\n\n\n\ncoef(fit_Boston) + qt(0.975, 503) * summary(fit_Boston)$coef[,2]\n\n(Intercept)          rm       lstat \n  4.8753547   5.9680255  -0.5564395 \n\ncoef(fit_Boston) - qt(0.975, 503) * summary(fit_Boston)$coef[,2]\n\n(Intercept)          rm       lstat \n -7.5919003   4.2215504  -0.7282772 \n\n\n\n\\(n=506, p =2 \\to df = 503\\)\nsummary(fit_Boston)$coef[,2] : covariance를 이용한 표준오차. (summary의 2번째 열의 리턴값.)"
  },
  {
    "objectID": "posts/HousePrice/2023-04-18-mlr-보스턴집값.html#평균반응-개별-y-추정",
    "href": "posts/HousePrice/2023-04-18-mlr-보스턴집값.html#평균반응-개별-y-추정",
    "title": "MLR prac1",
    "section": "평균반응, 개별 y 추정",
    "text": "평균반응, 개별 y 추정\n\\(E(Y|x_0)\\) , \\(y=E(Y|x_0) + \\epsilon\\)\n\nnew_dt <- data.frame(rm=7, lstat=10)\nnew_dt\n\n  rm lstat\n1  7    10\n\n\n\n# hat y0 = -1.3583 + 5.0948*7 - 0.6424*10\npredict(fit_Boston, newdata = new_dt)\n\n       1 \n27.88166 \n\n\n\nc(1,7,10)%*%beta_hat # 절편주의!\n\n         [,1]\n[1,] 27.88166\n\n\n\n\\(\\hat{y}_0 = x_0^\\top \\beta = \\begin{bmatrix} 1 & 7 & 10\\end{bmatrix} \\begin{bmatrix} \\hat{\\beta}_0 \\\\ \\hat{\\beta}_1 \\\\ \\hat{\\beta}_2\\end{bmatrix}\\)\n\\(x_0 = \\begin{bmatrix} 1 \\\\ 7 \\\\ 10\\end{bmatrix}\\)\n\n\npredict(fit_Boston, \n        newdata = new_dt,\n        interval = c(\"confidence\"), \n        level = 0.95)  ##평균반응\n\n       fit      lwr      upr\n1 27.88166 27.17347 28.58985\n\n\n\npredict(fit_Boston, newdata = new_dt, \n        interval = c(\"prediction\"), \n        level = 0.95)  ## 개별 y\n\n       fit      lwr      upr\n1 27.88166 16.97375 38.78957\n\n\n\nfit값은 동일하나 구간이 넓어진 것을 확인할 수 있다."
  },
  {
    "objectID": "posts/HousePrice/2023-04-18-mlr-보스턴집값.html#잔차분석",
    "href": "posts/HousePrice/2023-04-18-mlr-보스턴집값.html#잔차분석",
    "title": "MLR prac1",
    "section": "잔차분석",
    "text": "잔차분석\n\n\\(\\epsilon\\) : 선형성, 등분산성, 정규성, 독립성\n\nyhat <- fitted(fit_Boston)\nres <- resid(fit_Boston)\n\n\nplot(res ~ yhat,pch=16, ylab = 'Residual')\nabline(h=0, lty=2, col='grey')\n\n\n\n\n\n잔차그림만 봤을 때는 판단하기 좀 에매하다.\n선형성 좀 에매하다.\nU자패턴이 나오는 이유는 제곱항을 추가하는 것보다는 오차의 독립성 문제..(제곱항을 추가했을 때 성능이 별로 좋아지지 않음.)\n\n\n\n등분산성\n\n## H0 : 등분산  vs.  H1 : 이분산 (Heteroscedasticity)\nbptest(fit_Boston)\n\n\n    studentized Breusch-Pagan test\n\ndata:  fit_Boston\nBP = 1.5297, df = 2, p-value = 0.4654\n\n\n\n등분산이라고 할 수 있다."
  },
  {
    "objectID": "posts/HousePrice/2023-04-18-mlr-보스턴집값.html#잔차의-qq-plot",
    "href": "posts/HousePrice/2023-04-18-mlr-보스턴집값.html#잔차의-qq-plot",
    "title": "MLR prac1",
    "section": "잔차의 QQ plot",
    "text": "잔차의 QQ plot\n\npar(mfrow=c(1,2))\nqqnorm(res, pch=16)\nqqline(res, col = 2)\n\nhist(res)\n\n\n\npar(mfrow=c(1,1))"
  },
  {
    "objectID": "posts/HousePrice/2023-04-18-mlr-보스턴집값.html#shapiro-wilk-test",
    "href": "posts/HousePrice/2023-04-18-mlr-보스턴집값.html#shapiro-wilk-test",
    "title": "MLR prac1",
    "section": "Shapiro-Wilk Test",
    "text": "Shapiro-Wilk Test\n\n## H0 : normal distribution  vs. H1 : not H0\nshapiro.test(res)\n\n\n    Shapiro-Wilk normality test\n\ndata:  res\nW = 0.9098, p-value < 2.2e-16\n\n\n\n이상치제거해보면 괜찮을 것 같다."
  },
  {
    "objectID": "posts/HousePrice/2023-04-18-mlr-보스턴집값.html#독립성검정-dw-test",
    "href": "posts/HousePrice/2023-04-18-mlr-보스턴집값.html#독립성검정-dw-test",
    "title": "MLR prac1",
    "section": "독립성검정 : DW test",
    "text": "독립성검정 : DW test\n\ndwtest(fit_Boston, alternative = \"two.sided\")  #H0 : uncorrelated vs H1 : rho != 0\n\n\n    Durbin-Watson test\n\ndata:  fit_Boston\nDW = 0.83421, p-value < 2.2e-16\nalternative hypothesis: true autocorrelation is not 0"
  },
  {
    "objectID": "posts/HousePrice/2023-04-18-mlr-보스턴집값.html#h0-tbeta-c",
    "href": "posts/HousePrice/2023-04-18-mlr-보스턴집값.html#h0-tbeta-c",
    "title": "MLR prac1",
    "section": "\\(H0 : T\\beta = c\\)",
    "text": "\\(H0 : T\\beta = c\\)\n\n\\(H_0 : \\beta_1 = 1\\)\n즉, \\(H_0: \\beta_1 = 1\\) 이라는 것은 다음과 같다.\n\\(y = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + \\epsilon\\)\n\\(H_0: y = \\beta_0 + x_1 + \\beta_2x_2 + \\epsilon \\\\ \\Rightarrow y-x_1 = \\beta_0 + \\beta_2x_2 + \\epsilon \\\\ \\Rightarrow z = \\beta_0 + \\beta_2x_2 + \\epsilon\\)\n위와 같이 변수변환을 하게 되면 결국 단순선형회귀가 된다.\n\n개별회귀계수 유의성 검정인 t검정 해도 됩니다. \\(\\big(t_0 = \\frac{\\hat{\\beta}_1-1}{\\hat{\\text{s.e}(\\hat{\\beta}_1)}}\\big)\\)\n\n\nlibrary(car)\n\n\n#H_0 : beta_1 = 1\nlinearHypothesis(fit, c(0,1,0), 1)\n\nLinear hypothesis test\n\nHypothesis:\nx1 = 1\n\nModel 1: restricted model\nModel 2: y ~ x1 + x2\n\n  Res.Df    RSS Df Sum of Sq      F Pr(>F)\n1      8 40.105                           \n2      7 36.326  1    3.7788 0.7282 0.4217\n\n\n\n귀무가설을 기각할 수 없다.\n\n\n#b1-b2=0 => (0,1,-1) *beta \n#H_0 : beta_1 = beta2\nlinearHypothesis(fit, c(0,1,-1), 0)\n\nLinear hypothesis test\n\nHypothesis:\nx1 - x2 = 0\n\nModel 1: restricted model\nModel 2: y ~ x1 + x2\n\n  Res.Df    RSS Df Sum of Sq      F Pr(>F)\n1      8 39.535                           \n2      7 36.326  1     3.209 0.6184 0.4574\n\n\n\n#H_0 : beta_1 = beta2 + 1\nlinearHypothesis(fit, c(0,1,-1), 1)\n\nLinear hypothesis test\n\nHypothesis:\nx1 - x2 = 1\n\nModel 1: restricted model\nModel 2: y ~ x1 + x2\n\n  Res.Df    RSS Df Sum of Sq      F Pr(>F)\n1      8 36.549                           \n2      7 36.326  1   0.22253 0.0429 0.8418\n\n\n\n데이터 수가 적기 때문에 통계량 값 자체가 작아질 수 밖에 없다. (웬만하면 기각못함.)\n표준오차가 작으려면 데이터 수가 많아야한다.\n\n\n#H_0 : beta_1 = beta2 + 5\nlinearHypothesis(fit, c(0,1,-1), 5)\n\nLinear hypothesis test\n\nHypothesis:\nx1 - x2 = 5\n\nModel 1: restricted model\nModel 2: y ~ x1 + x2\n\n  Res.Df     RSS Df Sum of Sq     F   Pr(>F)   \n1      8 127.035                               \n2      7  36.326  1    90.709 17.48 0.004133 **\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n또는 다음의 방법으로 검정을 수행할 수 있다.\n\n##H_0 : beta_1 = beta2 + 1\n#y=b0 + b1x1 + b2x2 + e = b0+x1 + b2(x1+x2)+e\n#y-x1 = b0+b2(x1+x2)+e :   RM\n\n\ny1 <- y-x1\nz1 <- x1 + x2\n\n\nfit2 <- lm(y1~z1)\nsummary(fit2)\n\n\nCall:\nlm(formula = y1 ~ z1)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-2.5054 -1.9294  0.4236  0.6821  3.4473 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  -1.0014     2.2175  -0.452 0.663574    \nz1            0.6824     0.1242   5.493 0.000578 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 2.137 on 8 degrees of freedom\nMultiple R-squared:  0.7904,    Adjusted R-squared:  0.7642 \nF-statistic: 30.17 on 1 and 8 DF,  p-value: 0.0005785\n\nanova(fit2)\n\nAnalysis of Variance Table\n\nResponse: y1\n          Df  Sum Sq Mean Sq F value    Pr(>F)    \nz1         1 137.851 137.851  30.174 0.0005785 ***\nResiduals  8  36.549   4.569                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\nanova(fit)  ##FM\n\nAnalysis of Variance Table\n\nResponse: y\n          Df  Sum Sq Mean Sq F value  Pr(>F)    \nx1         1 313.043 313.043 60.3231 0.00011 ***\nx2         1  19.030  19.030  3.6671 0.09704 .  \nResiduals  7  36.326   5.189                    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nanova(fit2)  #RM\n\nAnalysis of Variance Table\n\nResponse: y1\n          Df  Sum Sq Mean Sq F value    Pr(>F)    \nz1         1 137.851 137.851  30.174 0.0005785 ***\nResiduals  8  36.549   4.569                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n# F = {(SSE_RM - SSE_FM)/r} / {SSE_FM/(n-p-1)}\np <- fit$rank-1\nq <- fit2$rank-1\nSSE_FM <- anova(fit)$Sum[p+1] #SSE_FM\nSSE_RM <- anova(fit2)$Sum[q+1]  #SSE_RM\n\nF0 <- ((SSE_RM-SSE_FM)/(p-q))/(SSE_FM/(length(y)-p-1))\nF0\n\n[1] 0.04288074\n\n\n\n#기각역 F_{0.05}(p-q,n-p-1)\nqf(0.95,p-q,length(y)-p-1)\n\n[1] 5.591448\n\n\n\n# p-value\npf(F0, p-q,length(y)-p-1,lower.tail = F)\n\n[1] 0.841845"
  },
  {
    "objectID": "posts/HousePrice/2023-04-25-8wk.html",
    "href": "posts/HousePrice/2023-04-25-8wk.html",
    "title": "8wk: 측도론 (4)",
    "section": "",
    "text": "youtube: https://youtube.com/playlist?list=PLQqh36zP38-xlxvNIex1h6j7lUQALgCU1"
  },
  {
    "objectID": "posts/HousePrice/2023-04-25-8wk.html#cap_n1infty-frac1nfrac1n0",
    "href": "posts/HousePrice/2023-04-25-8wk.html#cap_n1infty-frac1nfrac1n0",
    "title": "8wk: 측도론 (4)",
    "section": "\\(\\cap_{n=1}^{\\infty}(-\\frac{1}{n},\\frac{1}{n})=\\{0\\}\\)",
    "text": "\\(\\cap_{n=1}^{\\infty}(-\\frac{1}{n},\\frac{1}{n})=\\{0\\}\\)\n- \\(\\cap_{n=1}^{\\infty}(-\\frac{1}{n},\\frac{1}{n}) =\\{0\\}\\)을 증명하라.\n(증명)\nstep1: \\(\\cap_{n=1}^{\\infty}(-\\frac{1}{n},\\frac{1}{n})\\)은 원소로 \\(0\\)을 포함한다.\n\\(\\forall n \\in \\mathbb{N}\\): \\(-\\frac{1}{n} < 0 < \\frac{1}{n}\\)\n\\(\\Leftrightarrow \\forall n \\in \\mathbb{N}\\): \\(0 \\in (-\\frac{1}{n},\\frac{1}{n})\\)\n\\(\\Leftrightarrow\\) \\(0 \\in (-\\frac{1}{1},\\frac{1}{1})\\) and \\(0 \\in (-\\frac{1}{2},\\frac{1}{2})\\) \\(\\dots\\)\n\\(\\Leftrightarrow\\) \\(0 \\in (-\\frac{1}{1},\\frac{1}{1}) \\cap (-\\frac{1}{2},\\frac{1}{2}) \\cap \\dots\\)\n\\(\\Leftrightarrow\\) \\(0 \\in \\cap_{n=1}^{\\infty}(-\\frac{1}{1},\\frac{1}{1})\\)\nstep2: \\(\\cap_{n=1}^{\\infty}(-\\frac{1}{n},\\frac{1}{n})\\)은 원소로 \\(0\\)보다 큰 임의의 양수를 포함하지 않는다.\n포함한다고 가정하자. 즉\n\\(\\exists \\delta >0\\) such that \\(0+\\delta \\in \\cap_{n=1}^{\\infty}(-\\frac{1}{n},\\frac{1}{n})\\)\nNOTE: From \\(\\delta>0\\), \\(\\exists N \\in \\mathbb{N}\\) such that \\(0<\\frac{1}{N}<\\delta\\)\nTHUS \\(\\delta \\notin (-\\frac{1}{N},\\frac{1}{N})\\) \\(\\Rightarrow\\) CONTRADICTION! (\\(\\because \\cap_{n=1}^{\\infty}(-\\frac{1}{n},\\frac{1}{n}) \\subset (-\\frac{1}{N},\\frac{1}{N}))\\)\nstep3: \\(\\cap_{n=1}^{\\infty}(-\\frac{1}{n},\\frac{1}{n})\\)은 원소로 \\(0\\)보다 큰 임의의 음수를 포함하지 않는다."
  },
  {
    "objectID": "posts/HousePrice/2023-04-25-8wk.html#vacuous-truth",
    "href": "posts/HousePrice/2023-04-25-8wk.html#vacuous-truth",
    "title": "8wk: 측도론 (4)",
    "section": "Vacuous truth",
    "text": "Vacuous truth\n- \\(P \\Rightarrow Q\\) 에서, \\(P\\)가 틀렸거나 \\(P\\)를 만족하는 집합이 공집합일 경우 \\(P\\Rightarrow Q\\)라는 명제는 항상 참이되고 이러한 참을 배큐어스 트루 라고 말한다.\n- 이해를 돕기 위한 예시\n\n명제1: 최규빈교수보다 나이 많은 학생은 A+를 받지 못했다.\n명제2: 최규빈교수보다 나이 많은 학생은 A+를 받았다.\n\n여기에서 명제1,명제2는 모두 참이어야 한다. 그래야 명제1,명제2의 대우는 모두 참이 되며\n\n대우1: A+를 받은 학생은 최규빈교수보다 나이가 적다.\n대우2: A+를 받지 못한 학생은 최규빈교수보다 나이가 적다.\n\n두 대우의 합성명제인 아래도 참이 된다.\n\nA+을 받거나 받지 못한 학생은 최규빈교수보다 나이가 적다."
  },
  {
    "objectID": "posts/HousePrice/2023-04-25-8wk.html#정의",
    "href": "posts/HousePrice/2023-04-25-8wk.html#정의",
    "title": "8wk: 측도론 (4)",
    "section": "정의",
    "text": "정의\n- 정의: \\(\\Omega\\)에 대한 부분집합의 모임 \\({\\cal T}\\)가 아래의 조건을 만족하면 \\({\\cal T}\\)를 \\(\\Omega\\)의 토폴로지라고 부른다.\n\n\\(\\emptyset, \\Omega \\in {\\cal T}\\)\n\\(\\forall A,B \\in {\\cal T}:~ A\\cap B \\in {\\cal T}\\) (finite intersection에 닫혀있음)\n\\(\\forall {\\cal A} \\subset {\\cal T}: ~ (\\cup_{A \\in {\\cal A}}A ) \\in {\\cal T}\\) (uncoutable union, arbitrary union에 닫혀있음)\n\n- \\((\\Omega,{\\cal T})\\)를 위상공간 (topological space) 이라고 부른다. 그리고 \\({\\cal T}\\)의 원소를 \\({\\cal T}\\)-open set이라고 부른다.\n- 모티브: 실수위에서의 열린구간 \\((a,b)\\)의 개념을 추상화하고 싶음. 즉 open interval \\(\\overset{일반화}{\\to}\\) open set 을 하고 싶음. 그리고 이러한 open set 만을 모은 collection \\({\\cal T}\\)라는 기호로 표현하고 싶음.\n\n관찰1: \\((1,3) \\cap (2,4) = (2,3)\\) // 2개의 open-interval을 교집합하니 open-interval이 나옴\n관찰2: \\(\\cap_{n=1}^{\\infty}(1-\\frac{1}{n},3+\\frac{1}{n}) =[1,3]\\) // countable many한 open-interval을 교집합하면 closed-interval이 나옴\n관찰3: \\(\\cup_{n=1}^{\\infty}(1+\\frac{1}{n},3-\\frac{1}{n})= (1,3)\\) // countable many한 open-interval을 합집합하면 open-interval이 나옴\n관찰4: \\(\\cup_{\\epsilon>0}^{\\infty}(1+\\epsilon,3-\\epsilon) =(1,3)\\) // uncountalbe many한 open-interval을 합집합해도 open-interval이 나옴\n\n- 왜 open interval을 추상화하고 싶을까?\n\nopen interval은 엄청 특이한 성질이 있음. 구간 \\((a,b)\\)의 모든 점 \\(x\\)는 점 \\(x\\)를 포함하는 (아주 작은) 열린구간 \\((x-\\epsilon,x+\\epsilon)\\) 이 \\((a,b)\\)사이에 존재함.\n이 성질은 극한의 개념을 정의하기에 매우 유리하다. (따라서 연속, 끊어짐 등을 이해하기에도 좋다)\n\n- \\(\\Omega=\\mathbb{R}\\)일 경우 open-set\n\n\\((1,2)\\)\n\\((1,2)\\cup (5,6)\\)\n\\((a-\\epsilon, a+\\epsilon)\\), where \\(\\epsilon>0\\) and \\(a\\in\\mathbb{R}\\)\n\\(\\dots\\)\n\n- 체크\n\n\\(\\Omega=\\mathbb{R}\\), \\({\\cal T}=\\{\\emptyset, \\Omega\\}\\)라고 하자. \\({\\cal T}\\)는 \\(\\Omega\\)에 대한 토폴로지이며 따라서 \\((\\Omega, {\\cal T})\\)는 위상공간이 된다.\n\\(\\Omega=\\mathbb{R}\\), \\({\\cal T}=2^{\\mathbb{R}}\\)라고 하자. 그렇다면 \\({\\cal T}\\)는 \\(\\Omega\\)에 대한 토폴로지이며 따라서 \\((\\Omega,{\\cal T})\\)는 위상공간이 된다.\n\n그렇지만 우린 이런걸 쓰고 싶은게 아니야 (\\(\\star\\))"
  },
  {
    "objectID": "posts/HousePrice/2023-04-25-8wk.html#짧은지식",
    "href": "posts/HousePrice/2023-04-25-8wk.html#짧은지식",
    "title": "8wk: 측도론 (4)",
    "section": "짧은지식",
    "text": "짧은지식\n- 이론: \\(\\Omega=\\mathbb{R}\\) 일때 \\({\\cal U}=\\{O:O = \\cup_{i=1}^{\\infty}(a_i, b_i),~ a_i\\leq b_i \\in \\mathbb{R}\\}\\)라고 하자. 즉 \\({\\cal U}\\)는 open interval의 countable union으로 표현가능한 집합들의 모임이다. 그렇다면 \\((\\mathbb{R}, {\\cal U})\\)는 위상공간이 된다.\n\n그리고 특별히 이러한 위상 \\({\\cal U}\\)를 \\(\\mathbb{R}\\)에서의 standard topology, Euclidean topology, 혹은 usual topology 라고 부른다. 사실 \\({\\cal U}\\)가 바로 우리가 토폴로지를 정의하는 이유이다 (매우 중요하다는 뜻이에요)\n\n\n\\({\\cal U}\\)의 원소를 원래 엄밀하게는 \\({\\cal U}\\)-open set이라고 불러야 하지만 이 경우는 \\({\\cal U}\\)를 생략하여 open set 이라고 부르기도 한다. 즉 우리가 일반적으로 말하는 “실수 \\(\\mathbb{R}\\)에서의 열린집합, 혹은 그냥 열린집합” 은 \\({\\cal U}\\)-open set을 의미한다.\n\n\n이 이론이 의미하는 바는 (1) 실수에서의 열린구간의 일반화 버전은 열린집합이며 (2) 열린집합은 열린구간의 가산합집합으로 표현가능하다 라는 뜻이다.\n\n\n\\({\\cal U}\\)를 한글로는 보통위상이라고 표현하기도 하지만 그렇게 널리 사용되지는 않는다. 하지만 따로 지칭할 용어가 마땅치 않아서 나는 그냥 보통위상이라고 부르겠다.\n\n- 이론: \\((\\mathbb{R},{\\cal U})\\)를 보통위상공간 (usual topological space) 이라고 하자. 모든 \\(O \\in {\\cal U}\\) 는 아래를 만족한다.\n\n\\(\\forall o \\in O, \\exists a,b \\in \\mathbb{R}\\) such that \\(o \\in (a,b) \\subset O \\quad \\cdots (\\star)\\)\n\n\n참고로 어떠한 집합 \\(O\\)에 대하여 \\((\\star)\\)를 만족하는 원소 \\(o\\)를 interior point of \\(O\\) 라고 부른다. 따라서 어떤 집합의 모든 원소가 그 집합의 interior point라면 그 집합은 openset이라고 해석할 수 있다.\n\n\n저는 나이테정리라고 외웠어요..\n\n- 실수에서의 \\({\\cal U}\\)-openset 을 정의하는 방법\n\n열린구간의 가산합집합\n모든원소가 interior point인 집합\n\n- 위상공간 \\((\\mathbb{R},{\\cal U})\\)를 고려하자. 여기에서 \\({\\cal U}=\\{O:O = \\cup_{i=1}^{\\infty}(a_i, b_i),~ a_i\\leq b_i \\in \\mathbb{R}\\}\\)를 의미한다. 아래의 사실들을 관찰하라.\n\n모든 열린구간은 열린집합이다.\n\\((-\\infty, a)\\)와 \\((a,\\infty)\\)는 모두 열린집합이다.\n한점의 원소 \\(\\{a\\}\\)는 닫힌집합이다. (\\(\\{a\\}\\)의 여집합이 열린집합이므로)\n\\((-\\infty, a]\\)와 \\([a,\\infty)\\)는 모두 닫힌집합이다.\n공집합과 \\(\\mathbb{R}\\)은 열린집합이다.1 따라서 공집합과 \\(\\mathbb{R}\\)은 닫힌집합이다."
  },
  {
    "objectID": "posts/HousePrice/2023-04-25-8wk.html#시그마필드-vs-토폴로지",
    "href": "posts/HousePrice/2023-04-25-8wk.html#시그마필드-vs-토폴로지",
    "title": "8wk: 측도론 (4)",
    "section": "시그마필드 vs 토폴로지",
    "text": "시그마필드 vs 토폴로지\n\n\n\n\n\n\n\n\n\n시그마필드\n토폴로지\n\n\n\n\n시작\n“길이를 잴 수 있는 집합”이란 개념을 일반화 하고 싶다\n“열린구간”의 개념을 일반화 하고 싶다\n\n\n기호\n\\({\\cal F}\\)\n\\({\\cal T}\\)\n\n\n공간\n\\((\\Omega,{\\cal F})\\)\n\\((\\Omega,{\\cal T})\\)\n\n\n원소\n\\({\\cal F}\\)-measurable set, measurable set\n\\({\\cal T}\\)-open set\n\n\n쓸모없는공간\n\\((\\mathbb{R},2^{\\mathbb R})\\)\n\\((\\mathbb{R},2^{\\mathbb R})\\)\n\n\n쓸모있는공간\n\\((\\mathbb{R},{\\cal R})\\)\n\\((\\mathbb{R},{\\cal U})\\)\n\n\n\n\n\\({\\cal R}\\)이 뭔데..?"
  },
  {
    "objectID": "posts/HousePrice/2023-04-25-8wk.html#borel-sigma-field",
    "href": "posts/HousePrice/2023-04-25-8wk.html#borel-sigma-field",
    "title": "8wk: 측도론 (4)",
    "section": "Borel \\(\\sigma\\)-field",
    "text": "Borel \\(\\sigma\\)-field\n- 정의: \\((\\mathbb{R}, {\\cal U})\\)를 보통위상공간이라고 하자. 아래와 같은 시그마필드를 Borel \\(\\sigma\\)-algebera on \\(\\mathbb{R}\\)이라고 한다.\n\\[{\\cal B}(\\mathbb{R}):=\\sigma({\\cal U})\\]\n그리고 \\({\\cal B}(\\mathbb{R})\\)의 원소를 Borel measurable sets이라고 부른다.\n- 참고: 교재에서는 \\({\\cal B}(\\mathbb{R})\\)를 \\({\\cal R}\\)로 표현하기도 한다.\n- 이론: 아래와 같은 집합을 고려하자.\n\n\\({\\cal A}_1:= \\{A\\subset \\mathbb{R}: A \\text{ is open}\\}\\)2\n\\({\\cal A}_2:= \\{(a,b): a,b \\in \\mathbb{R}, a<b\\}\\)\n\\({\\cal A}_3:= \\{[a,b): a,b \\in \\mathbb{R}, a<b\\}\\)\n\\({\\cal A}_4:= \\{(a,b]: a,b \\in \\mathbb{R}, a<b\\}\\)\n\\({\\cal A}_5:= \\{[a,b]: a,b \\in \\mathbb{R}, a<b\\}\\)\n\\({\\cal A}_6:= \\{(-\\infty,b): a,b \\in \\mathbb{R}, a<b\\}\\)\n\\({\\cal A}_7:= \\{(-\\infty,b]: a,b \\in \\mathbb{R}, a<b\\}\\)\n\\({\\cal A}_8:= \\{(a,\\infty): a,b \\in \\mathbb{R}, a<b\\}\\)\n\\({\\cal A}_9:= \\{[a,\\infty): a,b \\in \\mathbb{R}, a<b\\}\\)\n\n아래가 성립한다.\n\\[{\\cal R}:={\\cal B}(\\mathbb{R}) = \\sigma({\\cal A}_1)=\\sigma({\\cal A}_2)=\\dots=\\sigma({\\cal A}_9)\\]\n(증명??) – 증명까지는 아니고 그냥 설명..\n\n예비학습1: countable union의 countable union은 countable union이다.\n\\[\\mathbb{Q}^+ = \\cup_{m \\in \\mathbb{N}}\\big(\\cup_{n \\in \\mathbb{N}}\\{m/n\\}\\big)\\]\n예비학습2: “\\(\\sigma({\\cal A}_1)\\)의 모든원소는 \\({\\cal A}_1\\)의 원소를 재료로하여 만들수 있다” 라고 표현할 수 있으며, 여기에서 “만들 수 있다” 라는 의미는 \\({\\cal A}_1\\)의 원소에 가산합집합, 가산교집합, 여집합, 차집합등의 연산을 적용하여 \\(\\sigma({\\cal A})\\)의 원소를 만들 수 있다라는 의미이다.\n예비학습3: 아래의 연산들은 모두 시그마필드에서 닫혀있다.\n\n가산합집합의 가산합집합\n가산합집합의 가산합집합의 가산합집합\n여집합의 가산교집합의 가산합집합의 차집합\n\\(\\dots\\)\n\n즉 시그마필드는 가산합집합과, 여집합에 닫혀있고 그들의 합성연산에 닫혀있다고 해석할 수 있다.\n\n이제 아래가 성립한다고 가정해보자.\n\n\\(\\sigma({\\cal A}_1)\\)의 모든 원소는 \\({\\cal A}_1\\)의 원소를 이용하여 만들 수 있다. 즉 \\({\\cal A}_1\\)의 모든원소에 가산합집합, 여집합, 혹은 그들의 합성연산을 적용하여 \\(\\sigma({\\cal A}_1)\\)의 모든 원소를 나타낼 수 있다.\n\\({\\cal A}_1\\)의 모든 원소는 \\({\\cal A}_2\\)의 원소를 이용하여 만들 수 있다. 즉 \\({\\cal A}_1\\)의 모든원소에 가산합집합, 여집합 혹은 그들의 합성연산을 적용하여 \\({\\cal A}_2\\)의 모든 원소를 나타낼 수 있다.\n\n그렇다면 궁극적으로는 \\({\\cal A}_2\\)의 원소를 가산합집합, 여집합, 혹은 그들의 합성연산을 적용하여 \\(\\sigma({\\cal A}_1)\\)를 표현할 수 있다는 의미이고 이는 \\({\\cal R}=\\sigma({\\cal A}_1)=\\sigma({\\cal A}_2)\\)를 의미한다. \\({\\cal R}=\\sigma({\\cal A}_3)=\\sigma({\\cal A}_4)=\\dots=\\sigma({\\cal A}_9)\\) 역시 유사하게 따질 수 있다.\n- 이론: 위의 이론의 \\({\\cal A}_2,\\dots,{\\cal A}_9\\)에서 \\(\\mathbb{R}\\) 대신에 \\(\\mathbb{Q}\\)를 사용해도 성립한다.\n- NOTE: \\({\\cal A}_1,\\dots,{\\cal A}_9\\)는 모두 파이시스템이다."
  },
  {
    "objectID": "posts/HousePrice/2023-04-25-8wk.html#르벡메져",
    "href": "posts/HousePrice/2023-04-25-8wk.html#르벡메져",
    "title": "8wk: 측도론 (4)",
    "section": "르벡메져",
    "text": "르벡메져\n- Thm: \\(\\Omega=\\mathbb{R}\\) 에 대하여 아래와 같은 collection \\({\\cal A}\\)를 고려하자.\n\\[{\\cal A}=\\{(a,b]: a,b\\in \\mathbb{R}, a<b\\}\\]\n그리고 아래와 같은 함수 \\(\\tilde{m}:{\\cal A} \\to [0,\\infty]\\)을 고려하자.\n\\[\\tilde{m}((a,b]) = b-a\\]\n이러한 함수 \\(\\tilde{m}\\)은 \\((\\mathbb{R},{\\cal R})\\)에서의 메져 \\(m:{\\cal R} \\to [0,\\infty]\\)로 쉽게 업그레이드 가능하며 이 업그레이드 결과는 유일하다.\n(증명)\n카라테오도리의 확장정리에 의하여\n\n\\({\\cal A}\\)가 세미링임을 체크하고\n\\(\\tilde{m}:{\\cal A}\\to[0,\\infty]\\)이 \\({\\cal A}\\)에서 (1) additive (2) \\(\\sigma\\)-subadditive (3) \\(\\sigma\\)-finite 을 만족한다는 사실을 체크하면 된다.\n\n된다. \\(\\tilde{m}\\)이 \\(\\sigma\\)-subaddtive 성질을 가진다는 것을 보이는 것이 어려운데 이는 받아들이자.\n- 정의: 위의 이론에 의하여 업그레이드 된 메져 \\(m\\)을 르벡메져라고 한다.\n- 이론: \\((\\mathbb{R},{\\cal R})\\)를 잴 수 있는 공간이라고 하고, \\(m\\)을 이 공간에서의 르벡메져라고 하자. 아래와 같은 집합들의 모임을 생각하자.\n\n\\({\\cal A}_1:= \\{A\\subset \\mathbb{R}: A \\text{ is open}\\}\\)\n\\({\\cal A}_2:= \\{(a,b): a,b \\in \\mathbb{R}, a<b\\}\\)\n\\({\\cal A}_3:= \\{[a,b): a,b \\in \\mathbb{R}, a<b\\}\\)\n\\({\\cal A}_4:= \\{(a,b]: a,b \\in \\mathbb{R}, a<b\\}\\)\n\\({\\cal A}_5:= \\{[a,b]: a,b \\in \\mathbb{R}, a<b\\}\\)\n\\({\\cal A}_6:= \\{(-\\infty,b): a,b \\in \\mathbb{R}, a<b\\}\\)\n\\({\\cal A}_7:= \\{(-\\infty,b]: a,b \\in \\mathbb{R}, a<b\\}\\)\n\\({\\cal A}_8:= \\{(a,\\infty): a,b \\in \\mathbb{R}, a<b\\}\\)\n\\({\\cal A}_9:= \\{[a,\\infty): a,b \\in \\mathbb{R}, a<b\\}\\)\n\n\\({\\cal A}_1,{\\cal A}_2,\\dots, {\\cal A}_9\\)에서의 르벡메져와 그 값이 일치하지만 \\({\\cal R} - {\\cal A}_1, \\dots, {\\cal R}-{\\cal A}_9\\) 등에서는 일치하지 않는 새로운 메져 \\(m'\\)은 존재할 수 없다. 즉 르벡메져는 \\({\\cal A}_1,\\dots,{\\cal A}_9\\)에서의 값으로 유일하게 결정된다.\n(설명)\n르벡메져는 \\(\\sigma\\)-finite한 메져이고, \\({\\cal A}_{1}\\dots{\\cal A}_{9}\\)는 모두 “7wk-파이시스템에서의 확장이론(메져버전)”에 소개된 이론의 조건 1,2를 만족하는 파이시스템이다. 따라서 르벡메져의 값은 \\({\\cal A}_1\\dots,{\\cal A}_9\\)에서의 값으로 유일하게 결정된다."
  },
  {
    "objectID": "posts/HousePrice/2023-04-25-8wk.html#생략때문에-헷갈려",
    "href": "posts/HousePrice/2023-04-25-8wk.html#생략때문에-헷갈려",
    "title": "8wk: 측도론 (4)",
    "section": "생략때문에 헷갈려",
    "text": "생략때문에 헷갈려\n- 어떠한 수학교재에서, 아무말 없이 open set 이라고만 하면 보통위상공간 (usual topological space) 으로부터 정의되는 open set을 의미한다. 즉 usual topological space \\((\\mathbb{R},{\\cal U})\\)에서 \\({\\cal U}\\)의 원소를 의미한다.\n- 어떠한 수학교재에서, 아무말 없이 measurable set 이라고 하면 르벡측도로 잴 수 있는 집합을 말한다. 즉 \\((\\mathbb{R}, {\\cal R})\\) 에서의 \\({\\cal R}\\)의 원소를 의미한다. 즉 일반적으로 정의하는 “잴 수 있는 집합”에서 “잴 수 있다”는 의미는 “르벡측도로 잴 수 있다”는 의미이다.3 일반적인 \\((\\Omega, {\\cal F})\\)에서 \\({\\cal F}\\)의 원소는 ${F}-measurable set 이라고 표현해야 옳다.\n- 하지만 때에 따라서는 \\({\\cal F}\\)의 원소를 그냥 measurable set이라고 부른다.\n예시1\n여기에서 measuralbe set은 앞에서 정의한 \\({\\cal F}\\)의 원소라는 의미이다.\n\n\n\n그림1: measurable set에 대한 교재의 언급, 눈치껏 그전의 문맥에서 정의한 \\({\\cal F}\\)-measurable set을 의미함을 알아들어야 함\n\n\n- measure, measurable 등의 의미는 눈치껏 알아먹어야 한다.\n예시2\n일반적으로 measure라는 단어가 사용되면 “르벡측도로 재다”라는 의미를 지칭하는 경우가 많음\n\n\n\n그림2: 여기에서 사용되는 “measure”의 의미는 문맥상 “르벡측도로 재다”라는 의미로 해석해야함\n\n\n예시3\n\\((\\Omega, {\\cal F})\\)를 잴 수 있는 공간이라고 할 때는 meaure의 의미가 꼭 “르벡측도로 재다” 라는 것을 의미하는 건 아님\n예시4\n비탈리집합이 nonmeasurable set이라는 의미는 르벡측도로 측정불가능한 집합이라는 것을 의미함.\n\n\n\n그림3: 여기에서 \\(N\\)은 비탈리집합을 의미하며 여기에서 “nonmeasurable” 이라는 뜻은 르벡메져로 측정불가능한 집합이라는 의미"
  },
  {
    "objectID": "posts/HousePrice/2023-04-25-8wk.html#토폴로지와-측도론의-논리전개",
    "href": "posts/HousePrice/2023-04-25-8wk.html#토폴로지와-측도론의-논리전개",
    "title": "8wk: 측도론 (4)",
    "section": "토폴로지와 측도론의 논리전개",
    "text": "토폴로지와 측도론의 논리전개\n- 토폴로지와 측도론을 공부하면서 비슷한점이 있다고 느낌\n- 비슷한점1: 모두 어떠한 속성을 가지는 집합을 “일반화” 하기 위해서 생겨났다. 예를들면, 잴 수 있는 집합이라는 것은 “수직선에서 길이를 잴 수 있는 집합”의 개념을 일반화하고 싶었어서 만들었으며, 열린집합이라는 것은 “수직선에서의 열린구간”이라는 개념을 일반화하고 싶어서 만들었다.\n- 비슷한점2: 따라서 “잴 수 있는 집합들의 모임”, “열린집합들의 모임” 이라는 집합들의 집합이라는 장치를 고안하였다. 그리고 이러한 과정에서 일반적인 “길이(length)를 잴 수 있는 집합”의 속성, “열린구간”의 속성을 모아 “잴 수 있는 집합의 모임”, “열린집합의 모임” 을 정의하는 재료로 사용하였다.\n- 비슷한점3: “잴 수 있는 집합들의 모임”, “열린집합들의 모임”의 원소를 각각 \\({\\cal F}\\)-mesurable set, \\({\\cal T}\\)-open set이라고 부르는 것도 유사하다.\n- 비슷한점4: \\(\\Omega=\\mathbb{R}\\)에 대한 시그마필드와 토폴로지가 각각 \\({\\cal R}\\)이거나 \\({\\cal U}\\)이라면 그냥 잴 수 있는 집합, 열린 집합 이라고 부르는 것도 유사하다.\n- 비슷한점5: 비슷한점4의 경우를 제외하고는 \\({\\cal F}\\)-mesurable set, \\({\\cal T}\\)-open set이라고 부르는게 원칙인데 이것도 문맥에 따라서 그냥 생략하고 쓰는 것도 유사하다. (사실 매번 언급하는게 귀찮기는 해)\n- 비슷한점6: 일반화의 과정에서 발생하는 이상한 개념의 충돌이 존재한다.\n\n잴 수 있는 집합의 모임을 \\((\\mathbb{R},2^\\mathbb{R})\\)로 설정하면 비탈리집합도 잴 수 있다. (그렇지만 \\((\\mathbb{R}, {\\cal R})\\)에서는 비탈리집합이 잴 수 없는 집합이므로 보통 책에서는 “잴 수 없는 집합”이라고 배운다)\n열린집합의 모임을 \\((\\mathbb{R},2^\\mathbb{R})\\)로 설정하면 한점만 포함하는 집합 \\(\\{x\\}\\)는 열린집합이 된다. (그렇지만 \\((\\mathbb{R},{\\cal U})\\)에서는 한점만 포함하는 집합은 닫힌집합이므로 보통 책에서는 “한점만 포함하는 집합은 닫힌집합이다” 라고 배운다.\n\n\n제 생각: 사실 이는 일반화 과정이 겪는 불가피한 문제인듯 해요. “문자, 그림, 기호 따위를 쓸 수 있는 도구” 정도로 펜슬의 의미를 확장하면 손가락도 펜슬이 되고, 발가락도 펜슬이 됩니다.\n\n- 비슷한점7: 열린집합과 토폴로지, 잴수있는 집합과 시그마필드를 정의하는 두가지 루트가 존재한다.\n\n루트1: 토폴로지를 먼저 정의하고 토폴로지의 원소가 열린집합이라고 정의한다. 혹은 시그마필드를 먼저 정의하고 시그마필드의 원소가 잴 수 있는 집합이라고 정의한다.\n루트2: 열린집합을 정의하고 (집합의 모든 원소가 interior point이면 열린집합), 열린집합의 모임으로 토폴로지를 정의한다. 혹은 잴 수 있는 집합을 정의하고, 잴 수 있는 집합의 모임으로 시그마필드를 정의한다."
  },
  {
    "objectID": "posts/HousePrice/2023-04-25-8wk.html#확률공간과-용어들",
    "href": "posts/HousePrice/2023-04-25-8wk.html#확률공간과-용어들",
    "title": "8wk: 측도론 (4)",
    "section": "확률공간과 용어들",
    "text": "확률공간과 용어들\n- 동전예제에서의 확률공간 \\((\\Omega,{\\cal F},P)\\)를 가정하고 용어를 정리해보자.\n\noutcomes: \\(H\\),\\(T\\)\nset of “outcomes”: \\(\\Omega=\\{H,T\\}\\)\nevent: \\(\\emptyset\\), \\(\\{H\\}\\), \\(\\{T\\}\\), \\(\\{H,T\\}\\)\nset of “events”: \\({\\cal F}\\)\nprobabilites: \\(P:{\\cal F} \\to [0,1]\\)\n\n- 교재의 언급\n\n\n\n그림4: 확률을 위한 기본용어"
  },
  {
    "objectID": "posts/HousePrice/2023-04-19-ts-hw5.html",
    "href": "posts/HousePrice/2023-04-19-ts-hw5.html",
    "title": "TS HW5",
    "section": "",
    "text": "ref: 4차시 과제 참고\n\n\\((X_1, X_2, X_3) \\sim MULT(n, p_1,p_2,p_3)\\)일 때 \\(X_1|X_2=x_2\\)의 조건부 확률밀도함수를 구하시오.\n(sol)\n(간단한 방법)\n\\[f_{X_1|X_2}(x_1|x_2) = \\frac{f_{X_1,X_2}(x_1,x_2)}{f_{X_2}(x_2)}\\]\nstep1\n우리가 관심있는 사건은 \\(X_1\\)이라 한다면 관심없는 두 사건 \\(X_2, X_3\\)를 하나로 생각한다면, 관심있는 사건, 관심없는 사건 두가지의 결과로 이루어진 이항분포라고 할 수 있다.\n\n\\(X_1 \\sim B(n,p_1)\\)\n\\(X_2 \\sim B(n,p_2)\\)\n\nstep2\n\n3가지 결과만 나오는 경우 \\(X_1,X_2\\)의 결합 pdf는 다음과 같이 정의할 수 있다. (\\(X_1, X_2\\)를 알면 자연스럽)게 \\(X_3\\)를 알 수 있다.\n\n\\[\\begin{align*} f_{X_1,X_2}(x_1,x_2) &= P(X_1=x_2, X_2=x_2)\\\\\n&= P(X_1=x_1, X_2=x_2, X_3 = n-x_1-x_2) \\\\\n&= \\frac{n!}{x_1!x_2!(n-x_1-x_2)!}p_1^{x_1}p_2^{x_2}p_3^{n-x_1-x_2}\\end{align*}\\]\n\nstep1에서 \\(X_1\\)과 \\(X_2\\)는 베르누이 시행을 독립적으로 \\(n\\)번 반복할 때 각 시행에서의 관심사건의 확률이 \\(p_1, p_2\\)인 이항분포를 따름을 알 수 있었다. 이를 이용하면 \\(X_2\\)의 marginal pdf를 구할 수 있다.\n\n\\[f_{X_2}(x_2) = \\frac{n!}{x_2!(n-x_2)!}p_2^{x_2}(1-p_2)^{n-x_2}\\]\nstep3\n이전 단계에서 구한 \\(X_1,X_2\\)와 결합pdf와 \\(X_2\\)의 marginal pdf를 이용하면 \\(X_1|X_2=x_2\\)의 조건부확률밀도함수를 구할 수 있다.\n\\[\\begin{align*}f_{X_1|X_2}(x_1|x_2) &= \\frac{f_{X_1,X_2}(x_1,x_2)}{f_{X_2}(x_2)}\\\\\n&= \\frac{\\frac{n!}{x_1!x_2!(n-x_1-x_2)!}p_1^{x_1}p_2^{x_2}p_3^{n-x_1-x_2}}{ \\frac{n!}{x_2!(n-x_2)!}p_2^{x_2}(1-p_2)^{n-x_2}} \\\\\n&= \\frac{(n-x_2)!}{x_1!(n-x_1-x_2)!}\\left(\\frac{p_1}{1-p_2}\\right)^{x_1}\\left(\\frac{p_3}{1-p_2}\\right)^{n-x_1-x_2}\\\\\n&=\\frac{(n-x_2)!}{x_1!(n-x_1-x_2)!}\\left(\\frac{p_1}{1-p_2}\\right)^{x_1}\\left(1-\\frac{p_1}{1-p_2}\\right)^{n-x_1-x_2}\\\\\n&= \\binom{n-x_2}{x_1}\\left(\\frac{p_1}{1-p_2}\\right)^{x_1} \\left(1-\\frac{p_1}{1-p_2}\\right)^{n-x_1-x_2}\\\\\n&\\sim B\\left(n-x_2, \\frac{p_1}{1-p_2}\\right) \\end{align*}\\]\n\n\n\n\\(X\\sim N(\\mu, \\sigma^2)\\)일 때 다음을 구하시오.\n\n\n(sol) Folded normal distribution과 비슷한듯.\n\\(X\\)의 pdf는 \\(f_X(x) = \\frac{1}{\\sqrt{2\\pi}\\sigma}\\exp\\left[-\\frac{(x-\\mu)^2}{2\\sigma^2}\\right]\\) 이고,\n\\(Y\\)의 cdf는 아래와 같다.\n\\(\\begin{align*}F_Y(y) = P(Y\\leq y) &= P(|X-\\mu|\\leq y) \\\\ &= P(\\mu-y \\leq X \\leq \\mu+y)\\\\ &= F_X(\\mu+y) - F_X(\\mu-y)\\end{align*}\\)\n\\(\\begin{align*}f_Y(y) = \\frac{d}{dy}F_Y(y) &= f_X(\\mu+y) + f_X(\\mu-y) \\\\ &= \\frac{1}{\\sqrt{2\\pi}\\sigma}e^{-\\frac{(\\mu+y-\\mu)^2}{2\\sigma^2}} + \\frac{1}{\\sqrt{2\\pi}\\sigma}e^{-\\frac{(\\mu-y-\\mu)^2}{2\\sigma^2}} \\\\ &= \\frac{1}{\\sqrt{2\\pi}\\sigma}e^{-\\frac{y^2}{2\\sigma^2}} + \\frac{1}{\\sqrt{2\\pi}\\sigma}e^{-\\frac{y^2}{2\\sigma^2}} \\\\ &=2 \\frac{1}{\\sqrt{2\\pi}\\sigma}e^{-\\frac{y^2}{2\\sigma^2}}, \\quad y\\geq 0\\end{align*}\\)\n\n\n\n(sol) 로그정규확률밀도함수\n\\(X\\)의 pdf는 \\(f_X(x) = \\frac{1}{\\sqrt{2\\pi}\\sigma}\\exp\\left[-\\frac{(x-\\mu)^2}{2\\sigma^2}\\right]\\) 이고,\n\\(Y\\)의 cdf는 \\(F_Y(y) = P(Y\\leq y) = P(e^X\\leq y) = P(X\\leq \\ln y) = F_X(\\ln y)\\) 이므로, \\(Y\\)의 pdf는 아래와 같다.\n\\(\\begin{align*}f_Y(y) &= \\frac{d}{dy}F_Y(y) = \\frac{1}{y}f_X(\\ln y)\\\\ &= \\frac{1}{\\sigma y \\sqrt{2\\pi}}\\exp\\left[-\\frac{(\\ln y-\\mu)^2}{2\\sigma^2}\\right], \\quad 0<y<\\infty \\end{align*}\\)\n\n\n\n\n한 개의 전자 시스템에 두 가지 다른 유형의 구성 요소가 각각 하날씩 공동으로 작동하고 있다. \\(Y_1\\)과 \\(Y_2\\)는 각각 유형 I 및 유형 II의 구성요소의 수명길이를 나타낸다고 한다. \\(Y_1\\)과 \\(Y_2\\)의 결합확률밀도함수가\n\\[f_{Y_1,Y_2}(y_1,y_2) = \\frac{1}{8}y_1 e^{-(y_1+y_2)/2} I(y_1>0, y_2>0)\\]\n로 주어졌을 때, 다음을 구하시오. (측정값은 백 시간 단위.)\n\n\n\\(\\left\\{\\begin{matrix}  \\begin{align*}&Z_1 = Y_1 + Y_2 \\\\  &Z_2 = Y_2 \\\\ \\end{align*}\\end{matrix}\\right. \\Rightarrow \\left\\{\\begin{matrix} y_1 = z_1-z_2 \\\\ y_2 = z_2 \\quad \\quad \\end{matrix}\\right.\\to J = \\begin{vmatrix}\\frac{\\partial y_1}{\\partial z_1} & \\frac{\\partial y_1}{\\partial z_2} \\\\ \\frac{\\partial y_2}{\\partial z_1} & \\frac{\\partial y_2}{\\partial z_2} \\end{vmatrix}= \\begin{vmatrix} 1 & -1 \\\\ 0 & 1\\end{vmatrix} = 1\\)\n\\(\\begin{align*}g_{z_1,z_2}(z_1,z_2) &= f_{Y_1,Y_2}(z_1-z_2, z_2)|J|\\\\ &= \\frac{1}{8}(z_1-z_2)e^{-(z_1-z_2+z_2)/2}, \\quad I(0<z_2<z_1) \\\\ &= \\frac{1}{8}(z_1-z_2)e^{-z_1/2}, \\quad I(0<z_2<z_1)\\end{align*}\\)\n (이부분 빼먹음! : \\(z_1\\)의 marginal pdf를 구해야한다…) \n\\(\\begin{align*}f_{Z_1}(z_1) &=\\int_{0}^{z_1}g_{Z_1,Z_2}(z_1,z_2) dz_2 \\\\ &= \\int_{0}^{z_1}\\frac{1}{8}(z_1-z_2)e^{-z_1/2}dz_2 \\\\ &= \\frac{1}{8}e^{-z_1/2}\\int_{0}^{z_1}(z_1-z_2)dz_2 \\\\ &= \\frac{1}{8}e^{-z_1/2}\\left[z_1z_2-\\frac{1}{2}z_2^2\\right]_0^{z_1}\\\\ &= \\frac{1}{8}e^{-z_1/2}\\left[\\frac{1}{2}z_1^2\\right] = \\frac{z_1^2e^{-z_1/2}}{16}\\space I(z_1>0)\\end{align*}\\)\n\n\n\n\\(y_1 >0 , y_2 > 0\\) \\(\\Rightarrow\\) \\(u>0 , v>0\\)\n\\(\\left\\{\\begin{matrix}  \\begin{align*}&U = Y_2/Y_1 \\\\  &V = Y_1 \\\\ \\end{align*}\\end{matrix}\\right. \\Rightarrow \\left\\{\\begin{matrix} y_1 = v \\\\ y_2 = uv \\end{matrix}\\right.\\to J = \\begin{vmatrix}\\frac{\\partial y_1}{\\partial u} & \\frac{\\partial y_1}{\\partial v} \\\\ \\frac{\\partial y_2}{\\partial u} & \\frac{\\partial y_2}{\\partial v} \\end{vmatrix}= \\begin{vmatrix} 0 & 1 \\\\ v & u\\end{vmatrix} = |-v| = v\\)\n\\(\\begin{align*}g_{u,v}(u,v) &= f_{Y_1,Y_2}(v,uv)|J|\\\\ &= \\frac{1}{8}ve^{-(v+uv)/2} v, \\quad I(u>0)I(v>0) \\\\ &= \\frac{1}{8}v^2e^{-(v+uv)/2} , \\quad I(u>0)I(v>0)\\end{align*}\\)\n\n(2)의 결과를 이용하여 \\(U\\)의 주변확률밀도함수\n\n\\(\\begin{align*}g_u(u) &= \\int_{-\\infty}^\\infty \\frac{1}{8}v^2e^{-(v+uv)/2} I(u>0)I(v>0)dv \\\\ &= \\frac{1}{8}I(u>0)\\int_{0}^\\infty v^2e^{-(v+uv)/2} dv \\\\ &= \\frac{(1+u)^3}{4} \\quad I(u>0)\\end{align*}\\)\n\n\n\n\n두 명의 경계병이 1마일 길이의 도로를 순찰하도록 지시받았다고 한다. 경계병은 도로 상에서 서로 독립적으로 선택된 지점으로 파견되는데, 경계병이 할당된 위치에 도달할 때 서로 1/2마일 이내에 있을 확률을 구하시오.\n\nref: Find the distribution of |X−Y| if X and Y are i.i.d. uniform on [0,1]\n\n\\[f_{X,Y}(x,y) = 1 \\quad I(0 \\leq x, y \\leq 1)\\]\n$X = $ 경계병1이 할당된 위치, $Y = $ 경계병2가 할당된 위치라고 하자.\n$X U(0,1),YU(0,1) $이며 서로 independent 하다.\n\\(Z = |X - Y|, \\space 0\\leq z \\leq 1\\)라고 할때, \\(P(Z\\leq 1/2)\\) 를 구하면 된다.\n\\(\\begin{align*}P(Z>z) &= P(|X-Y|>z) \\\\ &= P(X-Y>z) + P(X-Y<-z) \\\\ &= P(Y<X-z) + P(Y>z+X) \\\\ &= \\frac{(1-z)^2}{2} + \\frac{(1-z)^2}{2}\\\\ &= (1-z)^2,\\quad 0 \\leq z \\leq 1\\end{align*}\\)\n\n\n\nP(Z>z) 풀이\n\n\n따라서 \\(Z\\)의 cdf는 다음과 같다.\n\\(\\begin{align*}F_Z(z) &= 1-P(Z>z) \\\\ &= 1-(1-z)^2 \\\\ &= 1-(1-2z+z^2) = 2z-z^2, \\quad 0\\leq z <1\\end{align*}\\)\n\\(\\therefore F_Z(1/2) = P(Z\\leq 1/2) = 1-1/4 = 3/4\\)\n\n\n\n\\(X\\)와 \\(Y\\)는 서로 독립이고 동일한 기하분포를 따른다고 할 때 다음을 구하시오.\n\n\\(X\\sim Geo(p_1), Y\\sim Geo(p_2)\\) 이며 서로 independent하다. 서로 동일한 기하분포를 따른다고 했으므로 여기서는 \\(p_1= p_2 = p\\)이다.\n\\(\\text{pmf} : f(k) = (1-p)^{k-1}p, \\quad k=1,2,\\dots\\)\n\n풀수 있는 방식은 1)누적분포접근법 2) 변수변환접근법 이 있지만, 지금 푼 방식은 쉽긴하지만 확장하기 어렵다. –\n\\(\\begin{align*}P(X=Y) =\\underset{x=y}{\\sum\\sum} f_{X,Y}(x,y) &= \\underset{\\begin{pmatrix} x=y \\\\ x=1,2,\\dots \\\\ y=1,2,\\dots\\end{pmatrix}}{\\sum\\sum} p^2(1-p)^{x+y-2} \\\\ &\\overset{\\text{X=Y}}{=}\\sum_{k=1}^\\infty p^2(1-p)^{2k-2}=\\sum_{k=1}^\\infty p^2(1-p)^{2(k-1)} \\\\ &= \\frac{}{}\\end{align*}\\)\n\n\n\nref: If Two Independent Geometric Random Variables are equal\n\n\\(\\begin{align*}P(X=Y) &= P\\left(\\bigcup_{x=1}^\\infty \\{X=Y, X=k\\}\\right) \\\\ &=\\sum_{k=1}^\\infty P(X=Y, X=k) \\\\ &= \\sum_{k=1}^\\infty P(X=k)P(Y=k) \\\\ &= \\sum_{k=1}^\\infty (1-p_1)^{k-1}p_1(1-p_2)^{k-1}p_2 \\\\ &= p_1p_2\\sum_{k=0}^\\infty\\{(1-p_1)(1-p_2)\\}^k \\\\ &= \\frac{p_1p_2}{1-(1-p_1)(1-p_2)}, \\quad 0\\leq p_1,p_2 \\leq 1\\end{align*}\\)\n동일한 기하분포를 따른다고 했으므로 다시 정리하면,\n\\[P(X=Y) = \\frac{p^2}{1-(1-p)^2}=\\frac{p}{2-p}, \\quad 0\\leq p \\leq 1\\]\n\n\n\n\nref: Distribution of X-Y when X and Y are independent geometric\n\n\\(\\begin{align*}P(X-Y=1) &= \\sum_{k=1}^\\infty P(Y=k,X=1+k) \\\\ &=\\sum_{k=1}^\\infty P(Y=k)P(X=1+k) \\\\ &= \\sum_{k=1}^\\infty (1-p)^{k-1}p(1-p)^{1+k-1}p \\\\ &= p^2\\sum_{k=1}^\\infty (1-p)^{2k-1} \\\\ &= \\frac{p^2(1-p)}{1-(1-p)^{2}}=\\frac{p^2(1-p)}{p(2-p)}=\\frac{p(1-p)}{2-p}\\end{align*}\\)\n\n\n\n\nref:Independence of min(X,Y) and X-Y for two Geometric rvs\n\ncase1 : \\(X-Y\\geq 0, u\\geq 0\\)\n\\(\\begin{align*}P(U=u, u\\geq 0) &= P(X-Y=u, u\\geq 0) \\\\ &= \\sum_{k=1}^\\infty P(Y=k, X=u+k) \\\\ &=\\sum_{k=1}^\\infty P(Y=k)P(X=u+k) \\\\ &= \\sum_{k=1}^\\infty (1-p)^{k-1}p(1-p)^{u+k-1}p \\\\ &= p^2(1-p)^u\\sum_{k=1}^\\infty (1-p)^{k-1}(1-p)^{k-1}\\\\ &= p^2(1-p)^u\\sum_{k=1}^\\infty ((1-p)^{2})^{k-1} \\\\ &= \\frac{p^2(1-p)^u}{p(2-p)}=\\frac{p(1-p)^u}{2-p}\\end{align*}\\) \\(\\to\\) OK\ncase2 : \\(X-Y<0, u\\leq 0\\)\n\\(\\begin{align*}P(U=u, u\\leq 0) &= P(X-Y=u, u\\leq 0) \\\\ &= \\sum_{k=1}^\\infty P(X=k, Y=k-u) \\\\ &=\\sum_{k=1}^\\infty P(X=k)P(Y=k-u) \\\\ &= \\frac{p^2(1-p)^{-u}}{p(2-p)}=\\frac{p}{(1-p)^u(2-p)}\\end{align*}\\) \\(\\to\\)  Try again! \n\\(P(U=u) = \\begin{cases}  P(X=k+u, Y=k)= \\frac{p(1-p)^u}{2-p} & \\text{ if } u \\geq 0 \\\\  P(X=k, Y=k-u) = \\frac{p}{(1-p)^u(2-p)} & \\text{ if } u < 0 \\end{cases}\\)\n 수업시간 풀이 – \\(u\\)가 음수일 때 주의하자. \ncase2번 부분에서 먼저 내가 푼 방식으로 다시 풀어보자.\n\\(u\\)가 음수일때는 제약조건이 하나 더 붙는다. \\(x-y=u \\to x=y+u\\) 만약 \\(u\\)가 엄청나게 작은 음수가 된다면 \\(x\\)가 음수가 되버리는데 \\(x\\)는 음수일 수가 없다. 따라서 \\(y+u\\geq 1\\) 이라는 제약조건이 필요하다.\n\n\n\n\n어떤 합성물의 알코올 비율 \\(Y\\)는 다음 확률밀도함수를 따르는 확률변수라고 하자.\n\\[f(y) = 20y^3(1-y)I(0<y<1)\\]\n그 합성물의 판매가는 알코올 함량에 따라 결정된다고 한다. \\(1/3 < y < 2/3\\)이면 1갤런 당 \\(C_1\\)달러, 그렇지 않으면 \\(C_2\\) 달러에 판매된다. 생산비가 갤런 당 \\(C_3\\) 달러라면, 갤런당 판매수익의 확률분포를 구하시오.\nsol  수업시간 풀이 \n\\(Y \\sim \\text{Beta}(4,2)\\)\n\\(X=\\)판매수익 이라 놓자.\n\\(X = (C_1-C_3)I(1/3<y<2/3) + (C_2-C_3)I(Y\\leq 1/3 \\text{ or } Y\\geq 2/3)\\)\n\\(\\Rightarrow \\begin{cases} C_1-C_3 & ,1/3<Y<2/3 \\\\ C_2-C_3 &, o.w\\end{cases}\\)\n갤런당 판매수익의 확률분포는 다음과 같다.\n\\(\\Rightarrow \\begin{cases} P(X=C_1-C_3) = P(1/3<Y<2/3) = \\frac{101}{243} \\\\ P(X=C_2-C_3) = 1-P(1/3<Y<2/3)=1-\\frac{101}{243}=\\frac{142}{243}\\end{cases}\\)\n\\(\\begin{align*}P(1/3 < Y < 2/3) &= \\int_{1/3}^{2/3} 20y^3(1-y)I(0<y<1) \\\\ &= 20\\int_{1/3}^{2/3} (y^3-y^4)\\\\ &=20\\left(\\frac{1}{4}y^4 -\\frac{1}{5}y^5\\right)\\biggr\\rvert_{1/3}^{2/3} \\\\ &=\\frac{101}{243}\\end{align*}\\)\n(검산)\n\n(1/4*((2/3)**4)-(1/5)*((2/3)**5) - ( ((1/4)*((1/3)**4)-(1/5)*((1/3)**5)))) * 20\n\n0.4156378600823045\n\n\n\n101/243\n\n0.4156378600823045"
  },
  {
    "objectID": "posts/HousePrice/2023-04-05-lr-hw1-feedback.html",
    "href": "posts/HousePrice/2023-04-05-lr-hw1-feedback.html",
    "title": "House Price feedback",
    "section": "",
    "text": "이상값들을 제거하고 모형적합을 새로 해보자.\n\n\nData Link\n이전 분석내용\n\n앞서 분석내용에서 절편을 제거하기 전과 후의 회귀모형의 \\(R^2\\) 값 차이가 이상하리만큼 차이가 컸음. (\\(R^2:0.5021 \\to 0.91836\\)) 혹시 이상값 때문일까?\n\noptions(warn=-1)\n\nlibrary(lmtest) ## bptest, dwtest\nlibrary(tidyverse)\nlibrary(janitor)\nlibrary(\"gridExtra\")\n\nlibrary(corrplot)\nlibrary(ggplot2)\nlibrary(scales)\nlibrary(ggrepel)\n\n\ndf <- read.csv('./house_price/train.csv')\nhead(df)\n\n\n\nA data.frame: 6 × 81\n\n    IdMSSubClassMSZoningLotFrontageLotAreaStreetAlleyLotShapeLandContourUtilities⋯PoolAreaPoolQCFenceMiscFeatureMiscValMoSoldYrSoldSaleTypeSaleConditionSalePrice\n    <int><int><chr><int><int><chr><chr><chr><chr><chr>⋯<int><chr><chr><chr><int><int><int><chr><chr><int>\n\n\n    1160RL65 8450PaveNARegLvlAllPub⋯0NANA   NA    0 22008WDNormal 208500\n    2220RL80 9600PaveNARegLvlAllPub⋯0NANA   NA    0 52007WDNormal 181500\n    3360RL6811250PaveNAIR1LvlAllPub⋯0NANA   NA    0 92008WDNormal 223500\n    4470RL60 9550PaveNAIR1LvlAllPub⋯0NANA   NA    0 22006WDAbnorml140000\n    5560RL8414260PaveNAIR1LvlAllPub⋯0NANA   NA    0122008WDNormal 250000\n    6650RL8514115PaveNAIR1LvlAllPub⋯0NAMnPrvShed700102009WDNormal 143000\n\n\n\n\n\np1 <- ggplot(data=df, aes(x=SalePrice)) +\n        geom_histogram(fill='darkgreen')\n        # scale_x_continuous(breaks= seq(0, 800000, by=100000), labels = comma)\np2 <- ggplot(data=df, aes(x=GrLivArea)) +\n        geom_histogram(fill='darkgreen')\n\ngrid.arrange(p1, p2, ncol=2)\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n생각해보니까 위의 히스토그램만 봐도 집값이 이상적으로 매우 높은 관측치들이 몇몇 보임. (매우 비싼 고급 주택?)\n\n\nggplot(data = df[!is.na(df$SalePrice), ], \n       aes(x = GrLivArea, y = SalePrice)) +\n  geom_point(col='orange', alpha=0.5) +\n  geom_smooth(method = \"lm\", se = F, color = \"steelblue\") +\n  scale_y_continuous(breaks = seq(0, 800000, by=100000), labels = comma) +\n  geom_text_repel(aes(label = ifelse(df$GrLivArea[!is.na(df$SalePrice)] > 4500,\n                                     rownames(df), '')))\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n실거주면적이 \\(4000\\tt{sqft}\\) (약 112평) 이상인데 \\(200,000\\) (2억 6천만원)달러??\n\ndf1 <- df[c('SalePrice','GrLivArea')]\nhead(df1)\n\n\n\nA data.frame: 6 × 2\n\n    SalePriceGrLivArea\n    <int><int>\n\n\n    12085001710\n    21815001262\n    32235001786\n    41400001717\n    52500002198\n    61430001362"
  },
  {
    "objectID": "posts/HousePrice/2023-04-05-lr-hw1-feedback.html#선형회귀모형-적합-model1",
    "href": "posts/HousePrice/2023-04-05-lr-hw1-feedback.html#선형회귀모형-적합-model1",
    "title": "House Price feedback",
    "section": "선형회귀모형 적합 (model1)",
    "text": "선형회귀모형 적합 (model1)\n\nmodel1 <- lm(SalePrice ~ GrLivArea, df_out)\nmodel1\n\n\nCall:\nlm(formula = SalePrice ~ GrLivArea, data = df_out)\n\nCoefficients:\n(Intercept)    GrLivArea  \n       7169          115  \n\n\n\nsummary(model1)\n\n\nCall:\nlm(formula = SalePrice ~ GrLivArea, data = df_out)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-197730  -29815    -337   23239  332534 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept) 7168.970   4432.501   1.617    0.106    \nGrLivArea    115.040      2.782  41.358   <2e-16 ***\n---\nSignif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n\nResidual standard error: 53920 on 1456 degrees of freedom\nMultiple R-squared:  0.5402,    Adjusted R-squared:  0.5399 \nF-statistic:  1710 on 1 and 1456 DF,  p-value: < 2.2e-16\n\n\n\nanova(model1)\n\n\n\nA anova: 2 × 5\n\n    DfSum SqMean SqF valuePr(>F)\n    <int><dbl><dbl><dbl><dbl>\n\n\n    GrLivArea   14.973669e+124.973669e+121710.4446.591113e-248\n    Residuals14564.233790e+122.907823e+09      NA           NA"
  },
  {
    "objectID": "posts/HousePrice/2023-04-05-lr-hw1-feedback.html#선형회귀모형-적합-절편x-model2",
    "href": "posts/HousePrice/2023-04-05-lr-hw1-feedback.html#선형회귀모형-적합-절편x-model2",
    "title": "House Price feedback",
    "section": "선형회귀모형 적합 (절편X, model2)",
    "text": "선형회귀모형 적합 (절편X, model2)\n\nmodel2 <- lm(SalePrice ~ 0 + GrLivArea, df_out)\nmodel2\n\n\nCall:\nlm(formula = SalePrice ~ 0 + GrLivArea, data = df_out)\n\nCoefficients:\nGrLivArea  \n    119.3  \n\n\n\nsummary(model2)\n\n\nCall:\nlm(formula = SalePrice ~ 0 + GrLivArea, data = df_out)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-205038  -30039    1205   24581  329621 \n\nCoefficients:\n          Estimate Std. Error t value Pr(>|t|)    \nGrLivArea 119.3044     0.8867   134.5   <2e-16 ***\n---\nSignif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n\nResidual standard error: 53950 on 1457 degrees of freedom\nMultiple R-squared:  0.9255,    Adjusted R-squared:  0.9255 \nF-statistic: 1.81e+04 on 1 and 1457 DF,  p-value: < 2.2e-16\n\n\n\naov(model2)\n\nCall:\n   aov(formula = model2)\n\nTerms:\n                   GrLivArea    Residuals\nSum of Squares  5.269620e+13 4.241397e+12\nDeg. of Freedom            1         1457\n\nResidual standard error: 53954.13\nEstimated effects are balanced"
  },
  {
    "objectID": "posts/HousePrice/2023-04-05-lr-hw1-feedback.html#summary",
    "href": "posts/HousePrice/2023-04-05-lr-hw1-feedback.html#summary",
    "title": "House Price feedback",
    "section": "Summary",
    "text": "Summary\n절편을 제거한 것이 회귀모형 설명력에 큰 영향이 있는걸까?\n여전히 절편을 제거한 후에 모형의 설명력 차이가 크다.\n이전 분석내용과 차이점은 이상치를 제거하기 전보다 설명력이 좀 더 좋아졌다는 것이다.\n\ncol <- c('변수','스케일링','변수변환','변동사항', 'R2')\nscore <- as.matrix(col) \ndim(score) <- c(1,5)\nscore\n\n\n\nA matrix: 1 × 5 of type chr\n\n    변수스케일링변수변환변동사항R2\n\n\n\n\n\nscore <- matrix(0, ncol=6, nrow=4, byrow=T)\ncolnames(score) <- c('변수','스케일링','변수변환','이상치제거','변동사항', 'R2')\n\n\nscore[1,] <- c('집값, 실거주면적','X','X','X','단순선형회귀(절편O)',0.5021)\nscore[2,] <- c('집값, 실거주면적','X','X','X','단순선형회귀(절편X)',0.9186)\nscore[3,] <- c('집값, 실거주면적','X','X','O','단순선형회귀(절편O) + 이상치제거',0.5402)\nscore[4,] <- c('집값, 실거주면적','X','X','O','단순선형회귀(절편X) + 이상치제거',0.9255)\nscore\n\n\n\nA matrix: 4 × 6 of type chr\n\n    변수스케일링변수변환이상치제거변동사항R2\n\n\n    집값, 실거주면적XXX단순선형회귀(절편O)             0.5021\n    집값, 실거주면적XXX단순선형회귀(절편X)             0.9186\n    집값, 실거주면적XXO단순선형회귀(절편O) + 이상치제거0.5402\n    집값, 실거주면적XXO단순선형회귀(절편X) + 이상치제거0.9255"
  },
  {
    "objectID": "posts/HousePrice/2023-04-05-lr-hw1-feedback.html#절편-있는-회귀모형-model3",
    "href": "posts/HousePrice/2023-04-05-lr-hw1-feedback.html#절편-있는-회귀모형-model3",
    "title": "House Price feedback",
    "section": "절편 있는 회귀모형 (model3)",
    "text": "절편 있는 회귀모형 (model3)\n\nmodel3 <- lm(SalePrice ~ GrLivArea, df_log)\nmodel3\n\n\nCall:\nlm(formula = SalePrice ~ GrLivArea, data = df_log)\n\nCoefficients:\n(Intercept)    GrLivArea  \n  1.116e+01    5.708e-04  \n\n\n\nsummary(model3)\n\n\nCall:\nlm(formula = SalePrice ~ GrLivArea, data = df_log)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-1.31695 -0.14499  0.03338  0.16232  0.90721 \n\nCoefficients:\n             Estimate Std. Error t value Pr(>|t|)    \n(Intercept) 1.116e+01  2.263e-02  493.23   <2e-16 ***\nGrLivArea   5.708e-04  1.420e-05   40.19   <2e-16 ***\n---\nSignif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n\nResidual standard error: 0.2753 on 1456 degrees of freedom\nMultiple R-squared:  0.5259,    Adjusted R-squared:  0.5256 \nF-statistic:  1615 on 1 and 1456 DF,  p-value: < 2.2e-16"
  },
  {
    "objectID": "posts/HousePrice/2023-04-05-lr-hw1-feedback.html#절편없는-회귀모형-model4",
    "href": "posts/HousePrice/2023-04-05-lr-hw1-feedback.html#절편없는-회귀모형-model4",
    "title": "House Price feedback",
    "section": "절편없는 회귀모형 (model4)",
    "text": "절편없는 회귀모형 (model4)\n\nmodel4 <- lm(SalePrice ~ 0 + GrLivArea, df_log)\nmodel4\n\n\nCall:\nlm(formula = SalePrice ~ 0 + GrLivArea, data = df_log)\n\nCoefficients:\nGrLivArea  \n  0.00721  \n\n\n\nsummary(model4)\n\n\nCall:\nlm(formula = SalePrice ~ 0 + GrLivArea, data = df_log)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-18.7523  -0.5975   1.5293   3.6004   8.1707 \n\nCoefficients:\n           Estimate Std. Error t value Pr(>|t|)    \nGrLivArea 7.210e-03  5.864e-05     123   <2e-16 ***\n---\nSignif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n\nResidual standard error: 3.568 on 1457 degrees of freedom\nMultiple R-squared:  0.9121,    Adjusted R-squared:  0.912 \nF-statistic: 1.512e+04 on 1 and 1457 DF,  p-value: < 2.2e-16"
  },
  {
    "objectID": "posts/HousePrice/2023-04-05-lr-hw1-feedback.html#summary-1",
    "href": "posts/HousePrice/2023-04-05-lr-hw1-feedback.html#summary-1",
    "title": "House Price feedback",
    "section": "Summary",
    "text": "Summary\n이상값 제거 + 로그변환 까지 한 결과를 이전 분석내용과 비교한 결과는 다음과 같다.\n\nscore <- matrix(0, ncol=6, nrow=6, byrow=T)\ncolnames(score) <- c('변수','스케일링','변수변환','이상치제거','변동사항', 'R2')\n\n\nscore[1,] <- c('집값, 실거주면적','X','X','X','단순선형회귀(절편O)',0.5021)\nscore[2,] <- c('집값, 실거주면적','X','X','X','단순선형회귀(절편X)',0.9186)\nscore[3,] <- c('집값, 실거주면적','X','X','O','단순선형회귀(절편O) + 이상치제거',0.5402)\nscore[4,] <- c('집값, 실거주면적','X','X','O','단순선형회귀(절편X) + 이상치제거',0.9255)\nscore[5,] <- c('집값, 실거주면적','X','O','O','단순선형회귀(절편X) + 이상치제거',0.5259)\nscore[6,] <- c('집값, 실거주면적','X','O','O','단순선형회귀(절편X) + 이상치제거',0.9120)\n\n\nscore\n\n\n\nA matrix: 6 × 6 of type chr\n\n    변수스케일링변수변환이상치제거변동사항R2\n\n\n    집값, 실거주면적XXX단순선형회귀(절편O)             0.5021\n    집값, 실거주면적XXX단순선형회귀(절편X)             0.9186\n    집값, 실거주면적XXO단순선형회귀(절편O) + 이상치제거0.5402\n    집값, 실거주면적XXO단순선형회귀(절편X) + 이상치제거0.9255\n    집값, 실거주면적XOO단순선형회귀(절편X) + 이상치제거0.5259\n    집값, 실거주면적XOO단순선형회귀(절편X) + 이상치제거0.912"
  },
  {
    "objectID": "posts/HousePrice/2023-04-04-lr-hw1-project.html",
    "href": "posts/HousePrice/2023-04-04-lr-hw1-project.html",
    "title": "House Price",
    "section": "",
    "text": "Data Link\n\n\nLotarea : 대지면적\nGrLivArea: 지상 생활권 면적 (sqft)\nSlaePrice: 집 값 (dollar)\n\n\noptions(warn=-1)\n\nlibrary(lmtest) ## bptest, dwtest\nlibrary(tidyverse)\nlibrary(janitor)\nlibrary(\"gridExtra\")\n\nlibrary(corrplot)\nlibrary(ggplot2)\nlibrary(scales)\nlibrary(ggrepel)"
  },
  {
    "objectID": "posts/HousePrice/2023-04-04-lr-hw1-project.html#데이터-불러오기",
    "href": "posts/HousePrice/2023-04-04-lr-hw1-project.html#데이터-불러오기",
    "title": "House Price",
    "section": "데이터 불러오기",
    "text": "데이터 불러오기\n\ndf <- read.csv('./house_price/train.csv')\nhead(df)\n\n\n\nA data.frame: 6 × 81\n\n    IdMSSubClassMSZoningLotFrontageLotAreaStreetAlleyLotShapeLandContourUtilities⋯PoolAreaPoolQCFenceMiscFeatureMiscValMoSoldYrSoldSaleTypeSaleConditionSalePrice\n    <int><int><chr><int><int><chr><chr><chr><chr><chr>⋯<int><chr><chr><chr><int><int><int><chr><chr><int>\n\n\n    1160RL65 8450PaveNARegLvlAllPub⋯0NANA   NA    0 22008WDNormal 208500\n    2220RL80 9600PaveNARegLvlAllPub⋯0NANA   NA    0 52007WDNormal 181500\n    3360RL6811250PaveNAIR1LvlAllPub⋯0NANA   NA    0 92008WDNormal 223500\n    4470RL60 9550PaveNAIR1LvlAllPub⋯0NANA   NA    0 22006WDAbnorml140000\n    5560RL8414260PaveNAIR1LvlAllPub⋯0NANA   NA    0122008WDNormal 250000\n    6650RL8514115PaveNAIR1LvlAllPub⋯0NAMnPrvShed700102009WDNormal 143000\n\n\n\n\n\nstr(df)\n\n'data.frame':   1460 obs. of  81 variables:\n $ Id           : int  1 2 3 4 5 6 7 8 9 10 ...\n $ MSSubClass   : int  60 20 60 70 60 50 20 60 50 190 ...\n $ MSZoning     : chr  \"RL\" \"RL\" \"RL\" \"RL\" ...\n $ LotFrontage  : int  65 80 68 60 84 85 75 NA 51 50 ...\n $ LotArea      : int  8450 9600 11250 9550 14260 14115 10084 10382 6120 7420 ...\n $ Street       : chr  \"Pave\" \"Pave\" \"Pave\" \"Pave\" ...\n $ Alley        : chr  NA NA NA NA ...\n $ LotShape     : chr  \"Reg\" \"Reg\" \"IR1\" \"IR1\" ...\n $ LandContour  : chr  \"Lvl\" \"Lvl\" \"Lvl\" \"Lvl\" ...\n $ Utilities    : chr  \"AllPub\" \"AllPub\" \"AllPub\" \"AllPub\" ...\n $ LotConfig    : chr  \"Inside\" \"FR2\" \"Inside\" \"Corner\" ...\n $ LandSlope    : chr  \"Gtl\" \"Gtl\" \"Gtl\" \"Gtl\" ...\n $ Neighborhood : chr  \"CollgCr\" \"Veenker\" \"CollgCr\" \"Crawfor\" ...\n $ Condition1   : chr  \"Norm\" \"Feedr\" \"Norm\" \"Norm\" ...\n $ Condition2   : chr  \"Norm\" \"Norm\" \"Norm\" \"Norm\" ...\n $ BldgType     : chr  \"1Fam\" \"1Fam\" \"1Fam\" \"1Fam\" ...\n $ HouseStyle   : chr  \"2Story\" \"1Story\" \"2Story\" \"2Story\" ...\n $ OverallQual  : int  7 6 7 7 8 5 8 7 7 5 ...\n $ OverallCond  : int  5 8 5 5 5 5 5 6 5 6 ...\n $ YearBuilt    : int  2003 1976 2001 1915 2000 1993 2004 1973 1931 1939 ...\n $ YearRemodAdd : int  2003 1976 2002 1970 2000 1995 2005 1973 1950 1950 ...\n $ RoofStyle    : chr  \"Gable\" \"Gable\" \"Gable\" \"Gable\" ...\n $ RoofMatl     : chr  \"CompShg\" \"CompShg\" \"CompShg\" \"CompShg\" ...\n $ Exterior1st  : chr  \"VinylSd\" \"MetalSd\" \"VinylSd\" \"Wd Sdng\" ...\n $ Exterior2nd  : chr  \"VinylSd\" \"MetalSd\" \"VinylSd\" \"Wd Shng\" ...\n $ MasVnrType   : chr  \"BrkFace\" \"None\" \"BrkFace\" \"None\" ...\n $ MasVnrArea   : int  196 0 162 0 350 0 186 240 0 0 ...\n $ ExterQual    : chr  \"Gd\" \"TA\" \"Gd\" \"TA\" ...\n $ ExterCond    : chr  \"TA\" \"TA\" \"TA\" \"TA\" ...\n $ Foundation   : chr  \"PConc\" \"CBlock\" \"PConc\" \"BrkTil\" ...\n $ BsmtQual     : chr  \"Gd\" \"Gd\" \"Gd\" \"TA\" ...\n $ BsmtCond     : chr  \"TA\" \"TA\" \"TA\" \"Gd\" ...\n $ BsmtExposure : chr  \"No\" \"Gd\" \"Mn\" \"No\" ...\n $ BsmtFinType1 : chr  \"GLQ\" \"ALQ\" \"GLQ\" \"ALQ\" ...\n $ BsmtFinSF1   : int  706 978 486 216 655 732 1369 859 0 851 ...\n $ BsmtFinType2 : chr  \"Unf\" \"Unf\" \"Unf\" \"Unf\" ...\n $ BsmtFinSF2   : int  0 0 0 0 0 0 0 32 0 0 ...\n $ BsmtUnfSF    : int  150 284 434 540 490 64 317 216 952 140 ...\n $ TotalBsmtSF  : int  856 1262 920 756 1145 796 1686 1107 952 991 ...\n $ Heating      : chr  \"GasA\" \"GasA\" \"GasA\" \"GasA\" ...\n $ HeatingQC    : chr  \"Ex\" \"Ex\" \"Ex\" \"Gd\" ...\n $ CentralAir   : chr  \"Y\" \"Y\" \"Y\" \"Y\" ...\n $ Electrical   : chr  \"SBrkr\" \"SBrkr\" \"SBrkr\" \"SBrkr\" ...\n $ X1stFlrSF    : int  856 1262 920 961 1145 796 1694 1107 1022 1077 ...\n $ X2ndFlrSF    : int  854 0 866 756 1053 566 0 983 752 0 ...\n $ LowQualFinSF : int  0 0 0 0 0 0 0 0 0 0 ...\n $ GrLivArea    : int  1710 1262 1786 1717 2198 1362 1694 2090 1774 1077 ...\n $ BsmtFullBath : int  1 0 1 1 1 1 1 1 0 1 ...\n $ BsmtHalfBath : int  0 1 0 0 0 0 0 0 0 0 ...\n $ FullBath     : int  2 2 2 1 2 1 2 2 2 1 ...\n $ HalfBath     : int  1 0 1 0 1 1 0 1 0 0 ...\n $ BedroomAbvGr : int  3 3 3 3 4 1 3 3 2 2 ...\n $ KitchenAbvGr : int  1 1 1 1 1 1 1 1 2 2 ...\n $ KitchenQual  : chr  \"Gd\" \"TA\" \"Gd\" \"Gd\" ...\n $ TotRmsAbvGrd : int  8 6 6 7 9 5 7 7 8 5 ...\n $ Functional   : chr  \"Typ\" \"Typ\" \"Typ\" \"Typ\" ...\n $ Fireplaces   : int  0 1 1 1 1 0 1 2 2 2 ...\n $ FireplaceQu  : chr  NA \"TA\" \"TA\" \"Gd\" ...\n $ GarageType   : chr  \"Attchd\" \"Attchd\" \"Attchd\" \"Detchd\" ...\n $ GarageYrBlt  : int  2003 1976 2001 1998 2000 1993 2004 1973 1931 1939 ...\n $ GarageFinish : chr  \"RFn\" \"RFn\" \"RFn\" \"Unf\" ...\n $ GarageCars   : int  2 2 2 3 3 2 2 2 2 1 ...\n $ GarageArea   : int  548 460 608 642 836 480 636 484 468 205 ...\n $ GarageQual   : chr  \"TA\" \"TA\" \"TA\" \"TA\" ...\n $ GarageCond   : chr  \"TA\" \"TA\" \"TA\" \"TA\" ...\n $ PavedDrive   : chr  \"Y\" \"Y\" \"Y\" \"Y\" ...\n $ WoodDeckSF   : int  0 298 0 0 192 40 255 235 90 0 ...\n $ OpenPorchSF  : int  61 0 42 35 84 30 57 204 0 4 ...\n $ EnclosedPorch: int  0 0 0 272 0 0 0 228 205 0 ...\n $ X3SsnPorch   : int  0 0 0 0 0 320 0 0 0 0 ...\n $ ScreenPorch  : int  0 0 0 0 0 0 0 0 0 0 ...\n $ PoolArea     : int  0 0 0 0 0 0 0 0 0 0 ...\n $ PoolQC       : chr  NA NA NA NA ...\n $ Fence        : chr  NA NA NA NA ...\n $ MiscFeature  : chr  NA NA NA NA ...\n $ MiscVal      : int  0 0 0 0 0 700 0 350 0 0 ...\n $ MoSold       : int  2 5 9 2 12 10 8 11 4 1 ...\n $ YrSold       : int  2008 2007 2008 2006 2008 2009 2007 2009 2008 2008 ...\n $ SaleType     : chr  \"WD\" \"WD\" \"WD\" \"WD\" ...\n $ SaleCondition: chr  \"Normal\" \"Normal\" \"Normal\" \"Abnorml\" ...\n $ SalePrice    : int  208500 181500 223500 140000 250000 143000 307000 200000 129900 118000 ...\n\n\n\nstr(df[,c(1:10, 81)])\n\n'data.frame':   1460 obs. of  11 variables:\n $ Id         : int  1 2 3 4 5 6 7 8 9 10 ...\n $ MSSubClass : int  60 20 60 70 60 50 20 60 50 190 ...\n $ MSZoning   : chr  \"RL\" \"RL\" \"RL\" \"RL\" ...\n $ LotFrontage: int  65 80 68 60 84 85 75 NA 51 50 ...\n $ LotArea    : int  8450 9600 11250 9550 14260 14115 10084 10382 6120 7420 ...\n $ Street     : chr  \"Pave\" \"Pave\" \"Pave\" \"Pave\" ...\n $ Alley      : chr  NA NA NA NA ...\n $ LotShape   : chr  \"Reg\" \"Reg\" \"IR1\" \"IR1\" ...\n $ LandContour: chr  \"Lvl\" \"Lvl\" \"Lvl\" \"Lvl\" ...\n $ Utilities  : chr  \"AllPub\" \"AllPub\" \"AllPub\" \"AllPub\" ...\n $ SalePrice  : int  208500 181500 223500 140000 250000 143000 307000 200000 129900 118000 ..."
  },
  {
    "objectID": "posts/HousePrice/2023-04-04-lr-hw1-project.html#data-fields",
    "href": "posts/HousePrice/2023-04-04-lr-hw1-project.html#data-fields",
    "title": "House Price",
    "section": "Data fields",
    "text": "Data fields\nHere’s a brief version of what you’ll find in the data description file.\n\n\n\n\n\n\n\nVariable name\nDescription\n\n\n\n\nSalePrice\nthe property’s sale price in dollars. This is the target variable that you’re trying to predict.\n\n\nMSSubClass\nThe building class\n\n\nMSZoning\nThe general zoning classification\n\n\nLotFrontage:\nLinear feet of street connected to property\n\n\nLotArea\nLot size in square feet\n\n\nStreet:\nType of road access\n\n\nAlley:\nType of alley access\n\n\nLotShape:\nGeneral shape of property\n\n\nLandContour:\nFlatness of the property\n\n\nUtilities:\nType of utilities available\n\n\nLotConfig:\nLot configuration\n\n\nLandSlope:\nSlope of property\n\n\nNeighborhood:\nPhysical locations within Ames city limits\n\n\nCondition1:\nProximity to main road or railroad\n\n\nCondition2:\nProximity to main road or railroad (if a second is present)\n\n\nBldgType:\nType of dwelling\n\n\nHouseStyle:\nStyle of dwelling\n\n\nOverallQual:\nOverall material and finish quality\n\n\nOverallCond:\nOverall condition rating\n\n\nYearBuilt:\nOriginal construction date\n\n\nYearRemodAdd:\nRemodel date\n\n\nRoofStyle:\nType of roof\n\n\nRoofMatl:\nRoof material\n\n\nExterior1st:\nExterior covering on house\n\n\nExterior2nd:\nExterior covering on house (if more than one material)\n\n\nMasVnrType:\nMasonry veneer type\n\n\nMasVnrArea:\nMasonry veneer area in square feet\n\n\nExterQual:\nExterior material quality\n\n\nExterCond:\nPresent condition of the material on the exterior\n\n\nFoundation:\nType of foundation\n\n\nBsmtQual:\nHeight of the basement\n\n\nBsmtCond:\nGeneral condition of the basement\n\n\nBsmtExposure:\nWalkout or garden level basement walls\n\n\nBsmtFinType1:\nQuality of basement finished area\n\n\nBsmtFinSF1:\nType 1 finished square feet\n\n\nBsmtFinType2:\nQuality of second finished area (if present)\n\n\nBsmtFinSF2:\nType 2 finished square feet\n\n\nBsmtUnfSF:\nUnfinished square feet of basement area\n\n\nTotalBsmtSF:\nTotal square feet of basement area\n\n\nHeating:\nType of heating\n\n\nHeatingQC:\nHeating quality and condition\n\n\nCentralAir:\nCentral air conditioning\n\n\nElectrical:\nElectrical system\n\n\n1stFlrSF:\nFirst Floor square feet\n\n\n2ndFlrSF:\nSecond floor square feet\n\n\nLowQualFinSF:\nLow quality finished square feet (all floors)\n\n\nGrLivArea\nAbove grade (ground) living area square feet\n\n\nBsmtFullBath:\nBasement full bathrooms\n\n\nBsmtHalfBath:\nBasement half bathrooms\n\n\nFullBath:\nFull bathrooms above grade\n\n\nHalfBath:\nHalf baths above grade\n\n\nBedroom:\nNumber of bedrooms above basement level\n\n\nKitchen:\nNumber of kitchens\n\n\nKitchenQual:\nKitchen quality\n\n\nTotRmsAbvGrd:\nTotal rooms above grade (does not include bathrooms)\n\n\nFunctional:\nHome functionality rating\n\n\nFireplaces:\nNumber of fireplaces\n\n\nFireplaceQu:\nFireplace quality\n\n\nGarageType:\nGarage location\n\n\nGarageYrBlt:\nYear garage was built\n\n\nGarageFinish:\nInterior finish of the garage\n\n\nGarageCars:\nSize of garage in car capacity\n\n\nGarageArea:\nSize of garage in square feet\n\n\nGarageQual:\nGarage quality\n\n\nGarageCond:\nGarage condition\n\n\nPavedDrive:\nPaved driveway\n\n\nWoodDeckSF:\nWood deck area in square feet\n\n\nOpenPorchSF:\nOpen porch area in square feet\n\n\nEnclosedPorch:\nEnclosed porch area in square feet\n\n\n3SsnPorch:\nThree season porch area in square feet\n\n\nScreenPorch:\nScreen porch area in square feet\n\n\nPoolArea:\nPool area in square feet\n\n\nPoolQC:\nPool quality\n\n\nFence:\nFence quality\n\n\nMiscFeature:\nMiscellaneous feature not covered in other categories\n\n\nMiscVal:\nValue of miscellaneous feature\n\n\nMoSold:\nMonth Sold\n\n\nYrSold:\nYear Sold\n\n\nSaleType:\nType of sale\n\n\nSaleCondition:\nCondition of sale"
  },
  {
    "objectID": "posts/HousePrice/2023-04-04-lr-hw1-project.html#탐색",
    "href": "posts/HousePrice/2023-04-04-lr-hw1-project.html#탐색",
    "title": "House Price",
    "section": "탐색",
    "text": "탐색\n\ndim(df)\n\n\n146081\n\n\n\nis.na(df) %>% colSums()\n\nId0MSSubClass0MSZoning0LotFrontage259LotArea0Street0Alley1369LotShape0LandContour0Utilities0LotConfig0LandSlope0Neighborhood0Condition10Condition20BldgType0HouseStyle0OverallQual0OverallCond0YearBuilt0YearRemodAdd0RoofStyle0RoofMatl0Exterior1st0Exterior2nd0MasVnrType8MasVnrArea8ExterQual0ExterCond0Foundation0BsmtQual37BsmtCond37BsmtExposure38BsmtFinType137BsmtFinSF10BsmtFinType238BsmtFinSF20BsmtUnfSF0TotalBsmtSF0Heating0HeatingQC0CentralAir0Electrical1X1stFlrSF0X2ndFlrSF0LowQualFinSF0GrLivArea0BsmtFullBath0BsmtHalfBath0FullBath0HalfBath0BedroomAbvGr0KitchenAbvGr0KitchenQual0TotRmsAbvGrd0Functional0Fireplaces0FireplaceQu690GarageType81GarageYrBlt81GarageFinish81GarageCars0GarageArea0GarageQual81GarageCond81PavedDrive0WoodDeckSF0OpenPorchSF0EnclosedPorch0X3SsnPorch0ScreenPorch0PoolArea0PoolQC1453Fence1179MiscFeature1406MiscVal0MoSold0YrSold0SaleType0SaleCondition0SalePrice0\n\n\n\nnumeric_vars <- which(sapply(df, is.numeric)) # index vector numeric variables\nnumeric_var_names <- names(numeric_vars) \ncat('There are', length(numeric_vars), 'numeric variables')\n\nThere are 38 numeric variables\n\n\n\nnumeric_data <- df[, numeric_vars]\ncor_numeric <- cor(numeric_data, use=\"pairwise.complete.obs\") #correlations of all numeric variables\n\n#sort on decreasing correlations with SalePrice\ncor_sorted <- as.matrix(sort(cor_numeric[,'SalePrice'], decreasing = TRUE))\n\n#select only high corelations\nCorHigh <- names(which(apply(cor_sorted, 1, function(x) abs(x)>0.5))) \ncor_numVar <- cor_numVar[CorHigh, CorHigh]\n\ncorrplot.mixed(cor_numVar, tl.col=\"black\", tl.pos = \"lt\")\n\n\n\n\nOverallQual과 GrLivArea가 SalesPrice와 강한 양의 상관을 보인다.\n다음은 SalePrice와 상관관계가 높은 변수들이다. - OverallQual : 집의 전체적인 원자재 및 마감재에 대한 평가 - GrLivArea : 지상 생활권 면적(제곱 피트) - GarageCars : 주차 공간 - GarageArea : 차고 면적(제곱 피트) - TotalBsmtSf : 지하 공간 면적(제곱 피트) - X1stFlrSF : 1층 면적(제곱 피트) - FullBath : 풀옵션 화장실 개수 - TotRmsAbvGrd : 방의 개수 (화장실이 포함되지 않은 방.) - YearBuilt : 건설 연도 - YearRemodAdd : 리모델링 연도(YearBuilt와 동일하면, 리모델링을 하지 않은 집.)\n\nhead(cor_sorted)\n\n\n\nA matrix: 6 × 1 of type dbl\n\n    SalePrice1.0000000\n    OverallQual0.7909816\n    GrLivArea0.7086245\n    GarageCars0.6404092\n    GarageArea0.6234314\n    TotalBsmtSF0.6135806\n\n\n\n\n\nOverallQual\n\nggplot(data=df[!is.na(df$SalePrice),], aes(x=factor(OverallQual), y=SalePrice))+\n        geom_boxplot(col='blue') + labs(x='Overall Quality') +\n        scale_y_continuous(breaks= seq(0, 800000, by=100000), labels = comma)\n\n\n\n\n원자재/마감재에 대한 Qaulity가 높을수록 집 값은 증가하는 경향이 나타남.\n\n\nGrLivArea\n\nggplot(data = df[!is.na(df$SalePrice), ], \n       aes(x = GrLivArea, y = SalePrice)) +\n  geom_point(col='orange', alpha=0.5) +\n  #geom_smooth(method = \"lm\", se = F, color = \"steelblue\") +\n  scale_y_continuous(breaks = seq(0, 800000, by=100000), labels = comma)\n  #geom_text_repel(aes(label = ifelse(df$GrLivArea[!is.na(df$SalePrice)] > 4500,\n                                     # rownames(df), '')))\n\n\n\n\n\nggplot(data = df[!is.na(df$SalePrice), ], \n       aes(x = GrLivArea, y = SalePrice)) +\n  geom_point(col='orange', alpha=0.5) +\n  geom_smooth(method = \"lm\", se = F, color = \"steelblue\") +\n  scale_y_continuous(breaks = seq(0, 800000, by=100000), labels = comma) +\n  geom_text_repel(aes(label = ifelse(df$GrLivArea[!is.na(df$SalePrice)] > 4500,\n                                     rownames(df), '')))\n\n`geom_smooth()` using formula = 'y ~ x'"
  },
  {
    "objectID": "posts/HousePrice/2023-04-04-lr-hw1-project.html#단순-선형회귀모형",
    "href": "posts/HousePrice/2023-04-04-lr-hw1-project.html#단순-선형회귀모형",
    "title": "House Price",
    "section": "단순 선형회귀모형",
    "text": "단순 선형회귀모형\n\ndf1 <- df[c('SalePrice','GrLivArea')]\nhead(df1)\n\n\n\nA data.frame: 6 × 2\n\n    SalePriceGrLivArea\n    <int><int>\n\n\n    12085001710\n    21815001262\n    32235001786\n    41400001717\n    52500002198\n    61430001362\n\n\n\n\n\ncolSums(is.na(df1)) # 결측값 없음\n\nSalePrice0GrLivArea0\n\n\n\nsummary(df[c('SalePrice', 'GrLivArea')])\n\n   SalePrice        GrLivArea   \n Min.   : 34900   Min.   : 334  \n 1st Qu.:129975   1st Qu.:1130  \n Median :163000   Median :1464  \n Mean   :180921   Mean   :1515  \n 3rd Qu.:214000   3rd Qu.:1777  \n Max.   :755000   Max.   :5642  \n\n\n\np1 <- ggplot(data=df, aes(x=SalePrice)) +\n        geom_histogram(fill='darkgreen')\n        # scale_x_continuous(breaks= seq(0, 800000, by=100000), labels = comma)\np2 <- ggplot(data=df, aes(x=GrLivArea)) +\n        geom_histogram(fill='darkgreen')\n\ngrid.arrange(p1, p2, ncol=2)\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n오른쪽으로 skewed 되어 있음. (후에 변수변환 고려.)\n\n\n적합1\n\\[\\widehat{\\text{SalePrice}} = \\text{GrLivArea}\\times 107.\n1 + 18569 \\]\n\nmodel1 <- lm(SalePrice ~ GrLivArea, df1)\nmodel1\n\n\nCall:\nlm(formula = SalePrice ~ GrLivArea, data = df1)\n\nCoefficients:\n(Intercept)    GrLivArea  \n    18569.0        107.1  \n\n\n\nsummary(model1)\n\n\nCall:\nlm(formula = SalePrice ~ GrLivArea, data = df1)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-462999  -29800   -1124   21957  339832 \n\nCoefficients:\n             Estimate Std. Error t value Pr(>|t|)    \n(Intercept) 18569.026   4480.755   4.144 3.61e-05 ***\nGrLivArea     107.130      2.794  38.348  < 2e-16 ***\n---\nSignif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n\nResidual standard error: 56070 on 1458 degrees of freedom\nMultiple R-squared:  0.5021,    Adjusted R-squared:  0.5018 \nF-statistic:  1471 on 1 and 1458 DF,  p-value: < 2.2e-16\n\n\n\n회귀모형의 유의성 검정\n\n\\(H_0 : \\beta_1 = 0 \\text{ vs. } \\beta_1 \\neq 0\\)\n\n\nanova(model1)\n\n\n\nA anova: 2 × 5\n\n    DfSum SqMean SqF valuePr(>F)\n    <int><dbl><dbl><dbl><dbl>\n\n\n    GrLivArea   14.623740e+124.62374e+121470.5854.518034e-223\n    Residuals14584.584171e+123.14415e+09      NA           NA\n\n\n\n\n\ncat('기각치 F(1,1458;0.05): ', qf(0.95, 1, 48), '\\n') ## F(0.05)\ncat('F0: ' , summary(model1)$fstatistic[1])\n\n기각치 F(1,1458;0.05):  4.042652 \nF0:  1470.585\n\n\n\\(F_0 > F(1, 1458 ;0.05)\\) 이므로 회귀모형은 유의하지 않다는 귀무가설을 기각할 수 있다. 따라서 적합된 회귀모형은 유의하다고 판단한다.\n\n\n회귀계수의 유의성 검정\n\nsummary(model1)\n\n\nCall:\nlm(formula = SalePrice ~ GrLivArea, data = df1)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-462999  -29800   -1124   21957  339832 \n\nCoefficients:\n             Estimate Std. Error t value Pr(>|t|)    \n(Intercept) 18569.026   4480.755   4.144 3.61e-05 ***\nGrLivArea     107.130      2.794  38.348  < 2e-16 ***\n---\nSignif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n\nResidual standard error: 56070 on 1458 degrees of freedom\nMultiple R-squared:  0.5021,    Adjusted R-squared:  0.5018 \nF-statistic:  1471 on 1 and 1458 DF,  p-value: < 2.2e-16\n\n\n\nsummary(model1)$coef\n\n\n\nA matrix: 2 × 4 of type dbl\n\n    EstimateStd. Errort valuePr(>|t|)\n\n\n    (Intercept)18569.02594480.754549 4.144174 3.606554e-05\n    GrLivArea  107.1304   2.79362138.3482074.518034e-223\n\n\n\n\n\nqt(0.975, 1458)\nqt(0.025, 1458)\n\n1.96159238529673\n\n\n-1.96159238529673\n\n\n\n유의수준 \\(5\\%\\) 기각역 : \\(|t| \\geq 1.96\\)\n따라서 유의수준 \\(5\\%\\)하에서 회귀계수가 유의하지 않다는 귀무가설을 기각할 수 있다.\n\n\n\n회귀계수의 신뢰구간\n\nconfint(model1, level = 0.95)\n\n\n\nA matrix: 2 × 2 of type dbl\n\n    2.5 %97.5 %\n\n\n    (Intercept)9779.611927358.4399\n    GrLivArea 101.6504  112.6103\n\n\n\n\n\n\n평균반응 추정\n\n\\(1\\tt{sqft} \\to 0.028\\)평\n\n\nnew_dt <- data.frame(GrLivArea = 1500) ## 42.15평 \n\n\npredict(model1,\n        newdata = new_dt,\n        interval = c(\"confidence\"), ## 구간추정, confidence option (평균반응)\n        level = 0.95) ## 평균반응\n\n\n\nA matrix: 1 × 3 of type dbl\n\n    fitlwrupr\n\n\n    1179264.6176384.7182144.4\n\n\n\n\n\n실거주면적이 \\(1500\\)sqft 일 때 집값이 평균적으로 \\(179264.6\\) 달러로 추정된다.\n42평에 한화로 약 2억 3521만원\n\n\n\n개별 \\(y\\) 추정\n\npredict(model1,\n        newdata = new_dt,\n        interval = c(\"prediction\"),  ## prediction option (개별 y)\n        level = 0.95) ## 개별 y\n\n\n\nA matrix: 1 × 3 of type dbl\n\n    fitlwrupr\n\n\n    1179264.669235.04289294.1\n\n\n\n\n평균반응과 개별 \\(y\\) 추정 결과 점 추정값은 \\(179264.6\\) 으로 동일한데 개별 \\(y\\) 추정했을 경우 신뢰구간의 폭이 더 넓어진다. (불확실성 증가)\n\n\n신뢰대\n\ndt_pred <- data.frame(\n  GrLivArea = c(1:dim(df1)[1]),\n  predict(model1,\n          newdata = data.frame(GrLivArea=c(1:dim(df1)[1])),\n          interval='confidence', level = 0.95), ## 평균반응\n  predict(model1,\n          newdata=data.frame(GrLivArea=c(1:dim(df1)[1])),\n          interval='prediction',level = 0.95)[,-1]) ## 개별 y\n\nnames(dt_pred)[5:6] <- c('plwr', 'pupr')\nhead(dt_pred)\n\n\n\nA data.frame: 6 × 6\n\n    GrLivAreafitlwruprplwrpupr\n    <int><dbl><dbl><dbl><dbl><dbl>\n\n\n    1118676.16 9891.9227460.39-91665.88129018.2\n    2218783.2910004.2327562.35-91558.34129124.9\n    3318890.4210116.5327664.30-91450.79129231.6\n    4418997.5510228.8427766.25-91343.25129338.3\n    5519104.6810341.1527868.21-91235.71129445.1\n    6619211.8110453.4527970.16-91128.17129551.8\n\n\n\n\n\nbarx <- mean(df1$GrLivArea)\nbary <- mean(df1$SalePrice)\ncat('barx: ', barx, '\\n')\ncat('bary: ', bary, '\\n')\n\nbarx:  1515.464 \nbary:  180921.2 \n\n\n\n## 신뢰대 \nplot(SalePrice~GrLivArea, data = df1,\n     xlab = \"실거주면적\",\n     ylab = \"집값\",\n     ylim = c(min(dt_pred$plwr), max(dt_pred$pupr)),\n     xlim = c(min(dt_pred$GrLivArea)+500, max(dt_pred$GrLivArea)),\n     pch  = 20, # plot character (기호 모양)\n     cex  = 2, # size\n     col  = \"grey\"\n     )\nabline(model1, lwd = 5, col = \"darkorange\")\n\nlines(dt_pred$GrLivArea, dt_pred$lwr, col = \"dodgerblue\", lwd = 3, lty = 2)\nlines(dt_pred$GrLivArea, dt_pred$upr, col = \"dodgerblue\", lwd = 3, lty = 2)\nlines(dt_pred$GrLivArea, dt_pred$plwr, col = \"darkgreen\", lwd = 3, lty = 3)\nlines(dt_pred$GrLivArea, dt_pred$pupr, col = \"darkgreen\", lwd = 3, lty = 3)\n\nabline(v=barx, lty=2, lwd=0.2, col='dark grey')\n\n\n\n\n\n\n\n잔차분석1\n\n잔차에 대한 산점도\n\n## Model1 residual plot\nplot(fitted(model1),resid(model1), col = 'grey', pch=16, \n     xlab = expression(hat(y)),\n     ylab = \"Residual\",\n     main = \"Residual plot in Model1\")\nabline(h=0, col='darkorange', lty=2, lwd=2)\n\n\n\n\n\n\n등분산 검정\n\nbptest(model1)\n\n\n    studentized Breusch-Pagan test\n\ndata:  model1\nBP = 318.13, df = 1, p-value < 2.2e-16\n\n\n\n\n정규성 검정\n\ndf1$yhat <- model1$fitted\ndf1$resid <- model1$residuals\n\n\n## 잔차의 QQ plot\nqqnorm(df1$resid, pch=16)\nqqline(df1$resid, col = 2)\n\n\n\n\n\n## Shapiro-Wilk Test\n## H0 : normal distribution  vs. H1 : not H0\nshapiro.test(resid(model1))\n\n\n    Shapiro-Wilk normality test\n\ndata:  resid(model1)\nW = 0.90957, p-value < 2.2e-16\n\n\n\nhist(df1$resid,\n     xlab = \"Residuals\",\n     main = \"Histogram of Residuals, model1\",\n     col = \"darkgreen\",\n     border = \"steelblue\")\n\n\n\n\n\n\n독립성\n\n# 독립성검정 : DW test\n#H0 : uncorrelated vs H1 : rho != 0\ndwtest(model1, alternative = \"two.sided\")  \n\n\n    Durbin-Watson test\n\ndata:  model1\nDW = 2.0247, p-value = 0.6374\nalternative hypothesis: true autocorrelation is not 0\n\n\n\n유의수준 \\(5\\%\\) 하에서 등분산성, 정규성 가정을 만족하지 않는다. 따라서 위에서 적합한 모델은 사용할 수 없다..\n\n\n\n\n적합2: 절편이 없는 회귀모형\n\\[y = \\beta_1x + \\epsilon\\]\n\nmodel2 <- lm(SalePrice ~ 0 + GrLivArea, df1)\nmodel2\n\n\nCall:\nlm(formula = SalePrice ~ 0 + GrLivArea, data = df1)\n\nCoefficients:\nGrLivArea  \n    118.1  \n\n\n\n회귀모형의 유의성 검정\n\n\\(H_0 : \\beta_1 = 0 \\text{ vs. } \\beta_1 \\neq 0\\)\n\n\nanova(model2)\n\n\n\nA anova: 2 × 5\n\n    DfSum SqMean SqF valuePr(>F)\n    <int><dbl><dbl><dbl><dbl>\n\n\n    GrLivArea   15.235916e+135.235916e+1316470.3 0\n    Residuals14594.638169e+123.179006e+09     NANA\n\n\n\n\n\n\n회귀계수의 유의성 검정\n\nsummary(model2)$coef\n\n\n\nA matrix: 1 × 4 of type dbl\n\n    EstimateStd. Errort valuePr(>|t|)\n\n\n    GrLivArea118.06910.9199952128.33660\n\n\n\n\n\nsummary(model2)\n\n\nCall:\nlm(formula = SalePrice ~ 0 + GrLivArea, data = df1)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-506146  -28044    2922   26479  332542 \n\nCoefficients:\n          Estimate Std. Error t value Pr(>|t|)    \nGrLivArea   118.07       0.92   128.3   <2e-16 ***\n---\nSignif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n\nResidual standard error: 56380 on 1459 degrees of freedom\nMultiple R-squared:  0.9186,    Adjusted R-squared:  0.9186 \nF-statistic: 1.647e+04 on 1 and 1459 DF,  p-value: < 2.2e-16\n\n\n\n\n회귀계수의 신뢰구간\n\nconfint(model2, level = 0.95)\n\n\n\nA matrix: 1 × 2 of type dbl\n\n    2.5 %97.5 %\n\n\n    GrLivArea116.2644119.8738\n\n\n\n\n\n\n평균반응 추정\n\npredict(model2,\n        newdata = new_dt,\n        interval = c(\"confidence\"), ## 구간추정, confidence option (평균반응)\n        level = 0.95) ## 평균반응\n\n\n\nA matrix: 1 × 3 of type dbl\n\n    fitlwrupr\n\n\n    1177103.6174396.7179810.6\n\n\n\n\n\n실거주면적이 1500sqft 일 때 집값이 평균적으로 177103.6 달러로 추정된다.\n42평에 한화로 약 2억 3237만원\n\n\n\n개별 \\(y\\) 추정\n\npredict(model2,\n        newdata = new_dt,\n        interval = c(\"prediction\"),  ## prediction option (개별 y)\n        level = 0.95) ## 개별 y\n\n\n\nA matrix: 1 × 3 of type dbl\n\n    fitlwrupr\n\n\n    1177103.666470.77287736.5\n\n\n\n\n\n## Model2 residual plot\nplot(fitted(model2),resid(model1), col = 'grey', pch=16, \n     xlab = expression(hat(y)),\n     ylab = \"Residual\",\n     main = \"Residual plot in Model2\")\nabline(h=0, col='darkorange', lty=2, lwd=2)\n\n\n\n\n\nmodel2의 residual plot을 보면 model1과 유사한 양상을 띈다.\n\\(\\hat{y}\\)가 커질수록 점점 산포가 증가하는 형태로 등분산성에 위배되는 형태이다."
  },
  {
    "objectID": "posts/HousePrice/2023-04-04-lr-hw1-project.html#두-회귀모형-비교",
    "href": "posts/HousePrice/2023-04-04-lr-hw1-project.html#두-회귀모형-비교",
    "title": "House Price",
    "section": "두 회귀모형 비교",
    "text": "두 회귀모형 비교\n\ndf1 %>% colnames()\n\n\n'SalePrice''GrLivArea'\n\n\n\n## basic\nplot(SalePrice~GrLivArea, data = df1,\n     xlab = \"생활면적 (sqft)\",\n     ylab = \"집값\",\n     pch  = 20,\n     cex  = 2,\n     col  = \"darkorange\")\n     #ylim = c(0,35),\n     #xlim = c(0, 12))\nabline(model1, col='steelblue', lwd=2) ## model1\nabline(model2, col='violet', lwd=2)  ## model2\n\n\n\n\n\n## using ggplot2\ng1 <- ggplot(data = df[!is.na(df$SalePrice), ], \n           aes(x = GrLivArea, y = SalePrice)) +\n              geom_point(col='orange', alpha=0.5) +\n              geom_smooth(method = \"lm\", se = F, color = \"steelblue\") + ## model1 (절편O)\n              scale_y_continuous(breaks = seq(0, 800000, by=100000), labels = comma) +\n              geom_text_repel(aes(label = ifelse(df$GrLivArea[!is.na(df$SalePrice)] > 4500,\n                                                 rownames(df), '')))\n\ng1 + geom_abline(intercept = 0, slope = model2$coef, col = 'violet' , lwd = 1) ## model2 (절편X)\n\n`geom_smooth()` using formula = 'y ~ x'"
  },
  {
    "objectID": "posts/HousePrice/2023-03-30-lr-hw1.html",
    "href": "posts/HousePrice/2023-03-30-lr-hw1.html",
    "title": "HW1",
    "section": "",
    "text": "원점을 지나는 회귀모형은 다음과 같이 정의할 수 있다.\n\\[y_i = \\beta_1x_i + \\epsilon_i, \\quad \\epsilon_i \\overset{iid}{\\sim} N(0,\\sigma^2), \\quad i=1,\\dots, n\\]\n\n\n오차제곱합은 다음과 같이 정의할 수 있다.\n\\[SSE = \\sum_{i=1}^n\\epsilon_i^2 = \\sum_{i=1}^n(y_i-\\beta_1x_i)^2\\]\n오차제곱합을 최소로 하는 \\(\\beta_1\\)의 값을 추정값 \\(\\hat{\\beta}_1\\)으로 하는 방법을 최소제곱법(method of least squares)이라고 한다. 오차제곱합 \\(S\\)를 최소화 시키는 \\(\\beta_1\\)를 구하기 위하여 \\(S\\)를 \\(\\beta_1\\)에 대하여 편미분하여 그 값을 \\(0\\)으로 만드는 \\(\\hat{\\beta}_0, \\hat{\\beta}_1\\)으로 대치하여 정리하면 다음과 같다.\n\\[\\begin{align*}\\frac{\\partial{S}}{\\partial{\\beta}_0} &= -2\\sum_{i=1}^nx_i(y_i-\\beta_1x_i) = 0 \\\\\n&\\Rightarrow \\sum_{i=1}^nx_iy_i - \\hat{\\beta}_1\\sum_{i=1}^nx_i^2 = 0 \\\\\n&\\Rightarrow \\hat{\\beta}_1 = \\frac{\\sum_{i=1}^nx_iy_i}{\\sum_{i=1}^nx_i^2}\\end{align*}\\]\n\n\n\n\\(\\hat{\\beta}_1\\)은 관측값 \\(y_i\\)에 대한 선형추정량이다. (\\(\\to\\)기댓값과 분산을 쉽게 유도)\n\\(\\hat{\\beta}_1\\)을 \\(y_i\\)의 선형결합 꼴로 만들어주기 위하여 \\(\\hat{\\beta}_1 = \\frac{\\sum_{i=1}^nx_iy_i}{\\sum_{i=1}^nx_i^2}\\)에서 \\(\\frac{x_i}{\\sum_{i=1}^n x_i^2}\\)를 \\(a_i\\)로 두자.\n\\[\\begin{align*}E(\\hat{\\beta}_1) &= E\\left(\\frac{\\sum_{i=1}^nx_iy_i}{\\sum_{i=1}^nx_i^2}\\right) \\\\\n&= E\\left(\\sum_{i=1}^na_iy_i\\right),\\quad a_i = \\frac{x_i}{\\sum_{i=1}^n x_i^2} \\\\\n&= \\sum_{i=1}^na_iE(y_i) , \\quad  y_i \\sim N(\\beta_1x_i, \\sigma^2)\\\\\n&= \\beta_1\\sum_{i=1}^na_ix_i = \\beta_1\\sum_{i=1}^n\\frac{x_i}{\\sum_{i=1}^n x_i^2}x_i\\\\\n&= \\beta_1\\frac{\\sum_{i=1}^nx_i^2}{\\sum_{i=1}^n x_i^2} = \\beta_1\\end{align*}\\]\n\n\n\n\\[\\begin{align*}Var(\\hat{\\beta}_1) &= Var\\left(\\sum_{i=1}^na_iy_i\\right) \\\\\n&= \\sum_{i=1}^na_i^2Var(y_i) \\\\\n&= \\frac{\\sum_{i=1}^nx_i^2}{\\left[\\sum_{i=1}^nx_i^2\\right]^2}\\sigma^2, \\quad y_i\\sim N(\\beta_1x_i, \\sigma^2) \\\\\n&= \\frac{\\sigma^2}{\\sum_{i=1}^n x_i^2}\\end{align*}\\]\n\n\n\n\n\n\n분산분석표\n\n\n\n\n\n- 회귀직선의 유의성 검정 (F-test)\n가설\n\n\\(H_0: \\beta_1 = 0\\) (적합된 회귀모형은 유의하지 않다.)\n\\(H_1: \\beta_1 \\neq 0\\) (적합된 회귀모형은 유의하다.)\n\n검정통계량 - \\(F = \\frac{SSR/1}{SSE/(n-1)} = \\frac{MSR}{MSE} \\sim_{H_0} F(1, n-1)\\)\n\n\n\n1. 기각역(critical region)\n\\(F_0 \\geq F_{\\alpha}(1, n-1)\\) 이면 귀무가설을 기각할 수 있다. 즉, 적합된 회귀선이 유의하다고 할 수 있다.\n2. 유의확률(p-value)\n\\(P(F\\geq F_0) < \\alpha\\) 이면 귀무가설을 기각할 수 있다. 즉, 적합된 회귀선이 유의하다고 할 수 있다.\n\n\n\n\\[H_0: \\beta_1 = 0 \\text{ vs. } H_1: \\beta_1 > 0\\]\n- 회귀계수에 대한 유의성 검정\n1. 기각역(critical region)\n검정통계량: \\(T = \\frac{\\hat{\\beta}_1-0}{\\sqrt{Var(\\hat{\\beta}_1)}}\\sim_{H_0} t(n-1), \\quad \\text{관측값: } t\\)\n\\(\\begin{align*}T = \\frac{\\hat{\\beta}_1-0}{\\sqrt{Var(\\hat{\\beta}_1)}} = \\frac{\\hat{\\beta}_1}{\\sqrt{\\frac{\\sigma^2}{\\sum_{i=1}^n x_i^2}}} = \\frac{\\hat{\\beta}_1}{\\frac{\\sigma}{\\sqrt{\\sum_{i=1}^n x_i^2}}} = \\frac{\\hat{\\beta}_1}{\\frac{\\hat{\\sigma}}{\\sqrt{\\sum_{i=1}^n x_i^2}}} = \\frac{\\hat{\\beta}_1}{\\sqrt{\\frac{MSE}{\\sum_{i=1}^n x_i^2}}}\\end{align*}\\)\n1. 기각역(critical region)\n\\(t \\geq t_{\\alpha}(n-1)\\) 이면(기각역에 포함되면) 귀무가설을 기각할 수 있다. 즉, 회귀계수는 유의하다고 할 수 있다.\n2. 유의확률(p-value)\n유의확률 \\(P(T\\geq t)\\)가 주어진 유의수준 \\(\\alpha\\) 보다 작으면 귀무가설을 기각할 수 있다."
  },
  {
    "objectID": "posts/HousePrice/2023-03-30-lr-hw1.html#q2.",
    "href": "posts/HousePrice/2023-03-30-lr-hw1.html#q2.",
    "title": "HW1",
    "section": "Q2.",
    "text": "Q2.\ncars.csv 데이터를 이용하여 회귀모형을 적합하려고 한다. 이는 자동차의 속도(mph)에 따른 제동거리(ft)를 조사한 데이터이다. 다음 물음에 답하여라. (R을 이용하여 풀이) (검정에서는 유의수준 \\(\\alpha=0.05\\) 사용)\n\nlibrary(ggplot2)\nlibrary(lmtest) ## bptest, dwtest\nlibrary(tidyverse)\n\n\ncars <- read.csv('./data/cars.csv')\nhead(cars)\ndim(cars)\n\n\n\nA data.frame: 6 × 2\n\n    speeddist\n    <int><int>\n\n\n    14 2\n    2410\n    37 4\n    4722\n    5816\n    6910\n\n\n\n\n\n502\n\n\n\n(1) 이 데이터의 산점도를 그리고 두 변수 사이의 관계를 설명하시오.\n\nggplot(cars, aes(speed, dist)) + \n    geom_point(col = 'darkorange') +\n    xlab('속도') + ylab('제동거리') +\n    theme_bw() +\n    theme(axis.title = element_text(size=14))\n\n\n\n\n\n자동차의 속도와 제동거리와 양의 상관이 있는 것으로 보인다. (자동차 속도가 증가하면 제동거리가 증가하는 패턴을 보인다.)\n\n\n\n(2) 최소제곱법의 의한 회귀직선을 적합시키고, 모형 적합 결과를 설명하시오.\n\\[\\widehat{\\text{dist}} = 3.932\\times \\text{speed} - 17.579\\]\n\nmodel1 <- lm(dist~speed, cars)\nmodel1\n\n\nCall:\nlm(formula = dist ~ speed, data = cars)\n\nCoefficients:\n(Intercept)        speed  \n    -17.579        3.932  \n\n\n\nsummary(model1)\n\n\nCall:\nlm(formula = dist ~ speed, data = cars)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-29.069  -9.525  -2.272   9.215  43.201 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept) -17.5791     6.7584  -2.601   0.0123 *  \nspeed         3.9324     0.4155   9.464 1.49e-12 ***\n---\nSignif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n\nResidual standard error: 15.38 on 48 degrees of freedom\nMultiple R-squared:  0.6511,    Adjusted R-squared:  0.6438 \nF-statistic: 89.57 on 1 and 48 DF,  p-value: 1.49e-12\n\n\n\n# ls(summary(model1))\n\n\ncat('기각치 F(1,48;0.05): ', qf(0.95, 1, 48), '\\n') ## F(0.05)\ncat('F0: ' , summary(model1)$fstatistic[1])\n\n기각치 F(1,48;0.05):  4.042652 \nF0:  89.56711\n\n\n\\(F_0 > F(1, 48 ;0.05)\\) 이므로 회귀모형은 유의하지 않다는 귀무가설을 기각할 수 있다. 따라서 적합된 회귀모형은 유의하다고 판단한다.\n\npf(89.57, 1, 48, lower.tail = FALSE) ## p-value\n\n1.48907673149885e-12\n\n\nsummary - speed가 \\(1\\tt{mph}\\) 증가할수록 dist가 \\(3.9324\\tt{ft}\\)만큼 증가하는 경향이 있다. - 적합된 회귀선은 전체 변동 중 \\(65.11\\%\\) 를 설명한다. - \\(F\\)의 기각치는 \\(4.04\\)인데 \\(F_0=89.567\\)이므로 적합된 회귀직선은 매우 유의함을 알 수 있다. - speed의 회귀계수 역시 \\(t-value\\) 에 대응하는 \\(p-value<0.05\\) 이므로 유의함을 알 수 있다.\n\n\n(3) 데이터의 산점도를 그리고 추정한 회귀직선을 (1)에서 그린 산점도 위에 그리시오.\n\nggplot(cars, aes(x=speed, y=dist)) + \n    geom_point(col = 'darkorange') +\n    stat_smooth(method = 'lm', se=F) +\n    xlab('속도') + ylab('제동거리') +\n    theme_bw() +\n    theme(axis.title = element_text(size=14))\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n(4) 분산분석표를 작성하고 회귀직선의 유의 여부를 검정하시오.\n\\(H_0: \\beta_1 = 0 \\text{ (회귀모형이 유의하지 않다.) } \\text{ vs. } H_1: \\beta_1 \\neq 0 \\text{ (회귀모형이 유의하다.) }\\)\n\nanova(model1)\n\n\n\nA anova: 2 × 5\n\n    DfSum SqMean SqF valuePr(>F)\n    <int><dbl><dbl><dbl><dbl>\n\n\n    speed 121185.4621185.458989.567111.489836e-12\n    Residuals4811353.52  236.5317      NA          NA\n\n\n\n\n유의수준 \\(5\\%\\) 하에서 F-통계량에 대응되는 p-value가 \\(1.489836e-12\\)로 유의수준 \\(0.05\\) 보다 작으므로 귀무가설을 기각할 수 있다. 따라서 적합된 회귀모형은 유의하다고 판단한다.\n\n\n(5) 결정계수와 상관계수를 구하고 이 둘의 관계를 설명하시오.\n단순선형회귀일 때는 표본상관계수의 제곱이 결정계수와 같다. 즉, \\(r^2 = R^2\\)\n$R^2 = = = 0.6511 = r_{xy}^2 $\n\na <- summary(model1)\nls(a)\n\n\n'adj.r.squared''aliased''call''coefficients''cov.unscaled''df''fstatistic''r.squared''residuals''sigma''terms'\n\n\n\ncat('상관계수의 제곱 (r2): ', cor(cars$speed, cars$dist)**2, '\\n')\ncat('결정계수 (R2): ', a$r.squared)\n\n상관계수의 제곱 (r2):  0.6510794 \n결정계수 (R2):  0.6510794\n\n\n\n\n(6) \\(\\beta_0, \\beta_1\\)에 대한 개별 회귀계수의 유의성 검정을 수행하시오.\n\n\\(H_0: \\beta_1 = 0 \\text{ vs. } H_1: \\beta_1 \\neq 0\\)\n\\(H_0: \\beta_0 = 0 \\text{ vs. } H_1: \\beta_0 \\neq 0\\)\n\n\n# a = summary(model1)\na$coef\n\n\n\nA matrix: 2 × 4 of type dbl\n\n    EstimateStd. Errort valuePr(>|t|)\n\n\n    (Intercept)-17.5790956.7584402-2.6010581.231882e-02\n    speed  3.9324090.4155128 9.4639901.489836e-12\n\n\n\n\n유의수준 \\(5\\%\\) 하에서 각각의 회귀계수 \\(\\beta_0, \\beta_1\\)의 \\(t-\\)통계량에 대응하는 p-value가 모두 유의수준 \\(0.05\\)보다 작으므로 귀무가설을 기각할 수 있다. 따라서 회귀계수 \\(\\beta_0, \\beta_1\\)은 유의하다고 할 수 없다.\n\n\n(7) \\(\\beta_0, \\beta_1\\)에 대한 \\(90\\%\\) 신뢰구간을 구하시오.\n\\[\\hat{\\beta}_1 \\pm t_{\\alpha/2}(n-2) * se(\\hat{\\beta}_1)\\]\n- 함수 이용\n\nconfint(model1, level = 0.90)\n\n\n\nA matrix: 2 × 2 of type dbl\n\n    5 %95 %\n\n\n    (Intercept)-28.914514-6.243676\n    speed  3.235501 4.629317\n\n\n\n\n- 직접 계산\n\ncoef(model1) - qt(0.05, 48, lower.tail=FALSE)*summary(model1)$coef[,2]\n\n(Intercept)-28.9145142706524speed3.23550067631595\n\n\n\ncoef(model1) + qt(0.05, 48, lower.tail=FALSE)*summary(model1)$coef[,2]\n\n(Intercept)-6.24367551036937speed4.62931684193222\n\n\n\n\n(8) 속도가 \\(18.5\\text{mpg}\\)인 차량의 평균 제동거리를 예측하고, \\(95\\%\\) 신뢰구간을 구하시오.\n\\(\\hat{y} = \\hat{\\beta}_0 + \\hat{\\beta}_1 * 18.5\\)\n\nmodel1$coefficients[1] + model1$coefficients[2]*18.5 ## point estimate\n\n(Intercept): 55.1704671532847\n\n\n\nnew_spd <- data.frame(speed=18.5)\npredict(model1,\n        newdata = new_spd,\n        interval = c(\"confidence\"), ## 구간추정, confidence option (평균반응)\n        level = 0.95) ## 평균반응\n\n\n\nA matrix: 1 × 3 of type dbl\n\n    fitlwrupr\n\n\n    155.1704750.0879760.25296\n\n\n\n\n\n\n(9) 속도가 \\(18.5\\text{mpg}\\)인 차량의 개별 제동거리를 예측하고, \\(95\\%\\) 신뢰구간을 구하시오.\n\npredict(model1,\n        newdata = new_spd,\n        interval = c('prediction'), ## prediction option (개별 y)\n        level = 0.95) ## 개별 y\n\n\n\nA matrix: 1 × 3 of type dbl\n\n    fitlwrupr\n\n\n    155.1704723.8328486.5081\n\n\n\n\n\n신뢰구간이 동일한 \\(95\\%\\) 임에도 불구하고 평균 제동거리의 신뢰구간에 비해 개별 제동거리의 신뢰구간 폭이 증가한 것을 볼 수 있다. 불확실성이 증가했기 때문에 이러한 결과가 나왔다고 할 수 있다.\n\n\ndt_pred <- data.frame(\n  speed = c(1:50),\n  predict(model1,\n          newdata = data.frame(speed=c(1:50)),\n          interval='confidence', level = 0.95),\n  predict(model1,\n          newdata=data.frame(speed=c(1:50)),\n          interval='prediction',level = 0.95)[,-1])\n\nnames(dt_pred)[5:6] <- c('plwr', 'pupr') ## 개별 y에 대한 신뢰구간\ndt_pred\n\n\n\nA data.frame: 50 × 6\n\n    speedfitlwruprplwrpupr\n    <int><dbl><dbl><dbl><dbl><dbl>\n\n\n    1 1-13.646686-26.447265 -0.846107-47.114135 19.82076\n    2 2 -9.714277-21.733068  2.304513-42.890574 23.46202\n    3 3 -5.781869-17.026591  5.462853-38.685654 27.12192\n    4 4 -1.849460-12.329543  8.630624-34.499842 30.80092\n    5 5  2.082949 -7.644150 11.810048-30.333587 34.49948\n    6 6  6.015358 -2.973341 15.004056-26.187314 38.21803\n    7 7  9.947766  1.678977 18.216556-22.061423 41.95696\n    8 8 13.880175  6.307527 21.452823-17.956287 45.71664\n    9 9 17.812584 10.905120 24.720047-13.872245 49.49741\n    1010 21.744993 15.461917 28.028068 -9.809601 53.29959\n    1111 25.677401 19.964525 31.390278 -5.768620 57.12342\n    1212 29.609810 24.395138 34.824483 -1.749529 60.96915\n    1313 33.542219 28.731336 38.353102  2.247492 64.83695\n    1414 37.474628 32.947783 42.001472  6.222305 68.72695\n    1515 41.407036 37.021152 45.792921 10.174821 72.63925\n    1616 45.339445 40.937676 49.741215 14.104995 76.57390\n    1717 49.271854 44.698988 53.844720 18.012832 80.53088\n    1818 53.204263 48.321378 58.087148 21.898386 84.51014\n    1919 57.136672 51.829133 62.444210 25.761756 88.51159\n    2020 61.069080 55.247285 66.890875 29.603089 92.53507\n    2121 65.001489 58.597384 71.405594 33.422574 96.58040\n    2222 68.933898 61.896301 75.971494 37.220445100.64735\n    2323 72.866307 65.156644 80.575970 40.996976104.73564\n    2424 76.798715 68.387653 85.209778 44.752478108.84495\n    2525 80.731124 71.596083 89.866166 48.487298112.97495\n    2626 84.663533 74.786898 94.540168 52.201813117.12525\n    2727 88.595942 77.963783 99.228100 55.896429121.29545\n    2828 92.528350 81.129508103.927193 59.571576125.48512\n    2929 96.460759 84.286181108.635337 63.227708129.69381\n    3030100.393168 87.435427113.350908 66.865293133.92104\n    3131104.325577 90.578517118.072636 70.484817138.16634\n    3232108.257985 93.716452122.799519 74.086776142.42919\n    3333112.190394 96.850033127.530756 77.671674146.70911\n    3434116.122803 99.979906132.265699 81.240021151.00558\n    3535120.055212103.106599137.003824 84.792330155.31809\n    3636123.987620106.230544141.744697 88.329114159.64613\n    3737127.920029109.352101146.487958 91.850883163.98918\n    3838131.852438112.471568151.233308 95.358144168.34673\n    3939135.784847115.589198155.980495 98.851399172.71829\n    4040139.717255118.705205160.729306102.331141177.10337\n    4141143.649664121.819771165.479557105.797854181.50147\n    4242147.582073124.933053170.231093109.252014185.91213\n    4343151.514482128.045184174.983780112.694084190.33488\n    4444155.446891131.156281179.737500116.124517194.76926\n    4545159.379299134.266446184.492153119.543753199.21485\n    4646163.311708137.375767189.247649122.952219203.67120\n    4747167.244117140.484322194.003912126.350328208.13791\n    4848171.176526143.592180198.760871129.738482212.61457\n    4949175.108934146.699401203.518468133.117067217.10080\n    5050179.041343149.806040208.276646136.486457221.59623\n\n\n\n\n\n\n(10) 원점을 지나는 회귀직선을 구하시오.\n\\[\\widehat{\\text{dist}} = 2.9091\\times \\text{speed}\\]\n\nmodel2 <- lm(dist~ 0 + speed, cars)\nsummary(model2)\n\n\nCall:\nlm(formula = dist ~ 0 + speed, data = cars)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-26.183 -12.637  -5.455   4.590  50.181 \n\nCoefficients:\n      Estimate Std. Error t value Pr(>|t|)    \nspeed   2.9091     0.1414   20.58   <2e-16 ***\n---\nSignif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n\nResidual standard error: 16.26 on 49 degrees of freedom\nMultiple R-squared:  0.8963,    Adjusted R-squared:  0.8942 \nF-statistic: 423.5 on 1 and 49 DF,  p-value: < 2.2e-16\n\n\n\n\n(11) 위 회귀직선에서 회귀계수(기울기)의 \\(90\\%\\) 신뢰구간을 구하시오.\n- 함수이용\n\nconfint(model2, level = 0.90)\n\n\n\nA matrix: 1 × 2 of type dbl\n\n    5 %95 %\n\n\n    speed2.672123.146144\n\n\n\n\n- 직접계산\n\nb = summary(model2)\nb\n\n\nCall:\nlm(formula = dist ~ 0 + speed, data = cars)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-26.183 -12.637  -5.455   4.590  50.181 \n\nCoefficients:\n      Estimate Std. Error t value Pr(>|t|)    \nspeed   2.9091     0.1414   20.58   <2e-16 ***\n---\nSignif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n\nResidual standard error: 16.26 on 49 degrees of freedom\nMultiple R-squared:  0.8963,    Adjusted R-squared:  0.8942 \nF-statistic: 423.5 on 1 and 49 DF,  p-value: < 2.2e-16\n\n\n\ncoef(model2) - qt(0.05, 49, lower.tail=FALSE)*b$coef[,2]\n\nspeed: 2.67212042854855\n\n\n\ncoef(model2) + qt(0.05, 49, lower.tail=FALSE)*b$coef[,2]\n\nspeed: 3.14614385932565\n\n\n\n\n(12) 원점을 지나는 회귀직선에 대한 분산분석표를 작성하고, 회귀직선의 유의 여부를 검정하시오.\n\\(H_0: \\beta_1 = 0 \\text{ vs. }H_1: \\beta_0 \\neq 0\\)\n\nanova(model2)\n\n\n\nA anova: 2 × 5\n\n    DfSum SqMean SqF valuePr(>F)\n    <int><dbl><dbl><dbl><dbl>\n\n\n    speed 1111949.22111949.2232423.46829.227817e-26\n    Residuals49 12953.78   264.3628      NA          NA\n\n\n\n\n\ncat('기각치 F(0.05): ', qf(0.95, 1, 49),'\\n') \ncat('F0: ', summary(model2)$fstatistic[1])\n\n기각치 F(0.05):  4.038393 \nF0:  423.4682\n\n\n\\(F_0 > F(1,49;0.05)\\)\n\n\\(F\\)의 기각치는 \\(4.038\\)인데 \\(F_0=423.4682\\)이므로 적합된 회귀직선은 매우 유의함을 알 수 있다.\n유의수준 \\(5\\%\\)하에서 F-통계량에 대응하는 \\(p-value=9.227817e-26\\)로 유의수준 \\(5\\%\\) 보다 작으므로 귀무가설을 기각할 수 있다. 따라서 회귀모형은 유의하다고 할 수 있다.\n\n\n\n(13) 원점을 지나는 회귀직선의 결정계수를 구하시오.\n\nb$r.squared\n\n0.896289305805206\n\n\n\n\n(14) 원점을 포함한 회귀직선과 포함하지 않은 회귀직선의 결과를 비교하여라.\n\nsummary(model1)\n\n\nCall:\nlm(formula = dist ~ speed, data = cars)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-29.069  -9.525  -2.272   9.215  43.201 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept) -17.5791     6.7584  -2.601   0.0123 *  \nspeed         3.9324     0.4155   9.464 1.49e-12 ***\n---\nSignif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n\nResidual standard error: 15.38 on 48 degrees of freedom\nMultiple R-squared:  0.6511,    Adjusted R-squared:  0.6438 \nF-statistic: 89.57 on 1 and 48 DF,  p-value: 1.49e-12\n\n\n\nsummary(model2)\n\n\nCall:\nlm(formula = dist ~ 0 + speed, data = cars)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-26.183 -12.637  -5.455   4.590  50.181 \n\nCoefficients:\n      Estimate Std. Error t value Pr(>|t|)    \nspeed   2.9091     0.1414   20.58   <2e-16 ***\n---\nSignif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n\nResidual standard error: 16.26 on 49 degrees of freedom\nMultiple R-squared:  0.8963,    Adjusted R-squared:  0.8942 \nF-statistic: 423.5 on 1 and 49 DF,  p-value: < 2.2e-16\n\n\n\nanova(model1)\n\n\n\nA anova: 2 × 5\n\n    DfSum SqMean SqF valuePr(>F)\n    <int><dbl><dbl><dbl><dbl>\n\n\n    speed 121185.4621185.458989.567111.489836e-12\n    Residuals4811353.52  236.5317      NA          NA\n\n\n\n\n\nanova(model2)\n\n\n\nA anova: 2 × 5\n\n    DfSum SqMean SqF valuePr(>F)\n    <int><dbl><dbl><dbl><dbl>\n\n\n    speed 1111949.22111949.2232423.46829.227817e-26\n    Residuals49 12953.78   264.3628      NA          NA\n\n\n\n\n\nR-squared, Adjusted R-squared 모두 model2가 더 크므로 model2가 더 좋은 것 같다. 즉, 절편이 없는(원점을 지나는) 회귀모형이 더 좋은 것 같다.\n\n\n\n(15) 잔차에 대한 산점도를 그리고, 결과를 설명하여라.\n\nmodel1 <- lm(dist ~ speed, cars)\n\n\n## Model1 residual plot\nplot(fitted(model1),resid(model1), col = 'grey', pch=16, \n     xlab = expression(hat(y)),\n     ylab = \"Residual\",\n     main = \"Residual plot in Model1\")\nabline(h=0, col='darkorange', lty=2, lwd=2)\n\n\n\n\n\n\\(\\text{resiaul}=0\\)을 기준으로 위\\(\\cdot\\)아래가 대칭적으로 잘 퍼져있는 것 처럼 보인다. (\\(\\hat{y}\\)가 커질수록 조금 증가하는 것 같기도 하지만 추후 검정을 통해 확인) \\(\\to\\) 등분산, 선형성\n잔차의 산점도에 별다른 패턴이 보이지 않는 것 같다. \\(\\to\\) 독립성\n\n\n\n(16) 잔차에 대한 등분산성 검정을 수행하시오.\n- Breusch-Pegan Teset\n\\(H_0\\): 등분산 vs. \\(H_1\\): 이분산 (Heteroscedasticity)\n\nbptest(model1)\n\n\n    studentized Breusch-Pagan test\n\ndata:  model1\nBP = 3.2149, df = 1, p-value = 0.07297\n\n\n\\(p-value = 0.07297\\)로 유의수준 \\(0.05\\) 보다 크므로 귀무가설을 기각할 수 없다. 따라서 유의수준 \\(5\\%\\)하에서 잔차들이 등분산성을 만족한다.\n\n잔차에 대한 히스토그램, QQ plot을 그리고, 정규성 검정을 수행하여라.\n\n\n## 잔차의 QQ plot\nqqnorm(cars$resid, pch=16)\nqqline(cars$resid, col = 2)\n\n\n\n\n잔차의 QQPlot을 보면 45도선 기준으로 오른쪽 꼬리부분의 점들이 선에서 많이 벗어나 있는 것을 확인할 수 있다.\n\nhist(cars$resid,\n     xlab = \"Residuals\",\n     main = \"Histogram of Residuals, model1\",\n     col = \"darkgreen\",\n     border = \"steelblue\")\n\n\n\n\n\n잔차들의 히스토그램을 봤을 때 약간 오른쪽으로 꼬리가 긴 skewed된 그래프이다.\n\n\n## Shapiro-Wilk Test\n## H0 : normal distribution  vs. H1 : not H0\nshapiro.test(resid(model1))\n\n\n    Shapiro-Wilk normality test\n\ndata:  resid(model1)\nW = 0.94509, p-value = 0.02152\n\n\nShapiro-Wilk 정규성 검정 결과 \\(p-value=0.02152\\)로 유의수준 \\(0.05\\) 보다 작으므로 유의수준 \\(5\\%\\)하에서 귀무가설을 기각할 수 있다. 따라서 잔차는 정규성을 만족한다고 판단한다.\n\n\n(18) 잔차에 대한 독립성 검정을 수행하시오.\n\n# 독립성검정 : DW test\ndwtest(model1, alternative = \"two.sided\")  #H0 : uncorrelated vs H1 : rho != 0\n\n\n    Durbin-Watson test\n\ndata:  model1\nDW = 1.6762, p-value = 0.1904\nalternative hypothesis: true autocorrelation is not 0\n\n\n잔차의 독립성을 검정하는 Durbin-Watson 검정 결과 \\(p-value = 0.1904\\)로 유의수준 \\(5\\%\\) 보다 크므로 귀무가설을 기각할 수 없다."
  },
  {
    "objectID": "posts/HousePrice/2023-04-05-5wk.html",
    "href": "posts/HousePrice/2023-04-05-5wk.html",
    "title": "5wk: 측도론 (1)",
    "section": "",
    "text": "youtube: https://youtube.com/playlist?list=PLQqh36zP38-xOLs7lnyb8ZjM3KB-N2u7I"
  },
  {
    "objectID": "posts/HousePrice/2023-04-05-5wk.html#수학과의-기호",
    "href": "posts/HousePrice/2023-04-05-5wk.html#수학과의-기호",
    "title": "5wk: 측도론 (1)",
    "section": "수학과의 기호",
    "text": "수학과의 기호\n- 아래는 기호는 몇 가지 영어단어의 축약형이다.\n\nfor all: \\(\\forall\\)\nexists: \\(\\exists\\)\nsuch that, satisfying: \\({\\sf s.t.}\\), \\({\\sf st}\\)\nif-then, implies, therefore: \\(\\Rightarrow\\)\nif and only if: \\(\\Leftrightarrow\\)\nbecause: \\(\\because\\)\ntherefore: \\(\\therefore\\)\nquod erat: \\(\\square\\), \\(\\blacksquare\\)\n\n- 예시1: 모든 실수 \\(x\\)에 대하여, \\(x^2\\)은 양수이다.\n언어\n\nfor any \\(x\\) in \\(\\mathbb{R}\\), \\(x^2 \\geq 0\\). \\(\\quad\\) (이런느낌: \\(x^2 \\geq 0\\), 단 \\(x\\)는 실수)\nfor arbitrary \\(x \\in \\mathbb{R}\\), \\(x^2 \\geq 0\\).\nfor any choice of \\(x \\in \\mathbb{R}\\), \\(x^2 \\geq 0\\).\nfor all \\(x \\in \\mathbb{R}\\), \\(x^2 \\geq 0\\).\nif \\(x \\in \\mathbb{R}\\), then \\(x^2 \\geq 0\\). \\(\\quad\\) (\\(x\\)가 실수라면 \\(x^2 \\geq 0\\), 1번과 뉘앙스 차이)\n\n기호\n\n\\(\\forall x \\in \\mathbb{R}\\): \\(x^2\\geq 0\\).\n\\(\\forall x \\in \\mathbb{R}\\), \\(x^2\\geq 0\\).\n\\(x^2 \\geq 0\\), for all \\(x \\in \\mathbb{R}\\).\n\\(x^2 \\geq 0\\), \\(\\forall x \\in \\mathbb{R}\\).\n\\(x \\in \\mathbb{R} \\Rightarrow x^2 \\geq 0\\).\n\n\n거의 쓰는 사람 마음임, 그런데 뉘앙스가 조금씩 다름.\n\n- 예시2: \\(\\Omega\\)의 임의의 부분집합 \\(A\\),\\(B\\)에 대하여, \\(A=B\\) 일 필요충분조건은 \\(A\\subset B\\) 이고 \\(B \\subset A\\) 이어야 한다.\n언어\n\nfor all \\(A,B \\subset \\Omega\\), \\(A=B\\) if and only if (1) \\(A \\subset B\\) and (2) \\(B \\subset A\\).\n\n기호\n\n\\(A = B \\Leftrightarrow A \\subset B \\text{ and } B \\subset A, \\forall A,B \\in \\Omega\\).\n\\(A = B \\Leftrightarrow \\big(A \\subset B \\text{ and } B \\subset A\\big), \\forall A,B \\in \\Omega\\).\n\\(\\forall A,B \\subset \\Omega\\): \\(A = B \\Leftrightarrow \\big(A \\subset B \\text{ and } B \\subset A\\big)\\)\n\n\n의미가 때로는 모호할때가 있지만 눈치껏 알아먹어야 한다.\n\n- 예시3: 임의의 양수 \\(\\epsilon>0\\)에 대하여 \\(|x| \\leq \\epsilon\\)이라면 \\(x=0\\)일 수 밖에 없다.\n언어\n\nIf \\(|x|< \\epsilon\\) for all \\(\\epsilon>0\\), then \\(x=0\\).\nIf \\(|x|< \\epsilon\\), \\(\\forall \\epsilon>0\\), then \\(x=0\\).\nFor all \\(\\epsilon>0\\), \\(|x|< \\epsilon\\) implies \\(x=0\\). – 틀린표현\n\n기호\n\n\\(|x| < \\epsilon,~ \\forall \\epsilon>0 \\Rightarrow x=0\\)\n\\(\\forall \\epsilon>0: |x| < \\epsilon \\Rightarrow x=0\\) – 애매하다?\n\\(\\big(\\forall \\epsilon>0:|x| < \\epsilon\\big) \\Rightarrow x=0\\)\n\\(\\big(\\forall \\epsilon>0\\big)\\big(|x| < \\epsilon \\Rightarrow x=0\\big)\\) – 틀린표현\n\n틀린이유?\n\\(\\epsilon = 0.5\\)라고 하자. \\(|x|<0.5 \\Rightarrow x=0\\) ? (X)"
  },
  {
    "objectID": "posts/HousePrice/2023-04-05-5wk.html#기타-약어-및-상투적인-표현",
    "href": "posts/HousePrice/2023-04-05-5wk.html#기타-약어-및-상투적인-표현",
    "title": "5wk: 측도론 (1)",
    "section": "기타 약어 및 상투적인 표현",
    "text": "기타 약어 및 상투적인 표현\n- 약어\n\n\\({\\sf WLOG}\\): Without Loss Of Generality\n\\({\\sf WTS}\\): What/Want To Show\n\\({\\sf iff}\\): if and only if\n\\({\\sf Q.E.D.}\\): 증명완료 (쓰지마..)\n\\({\\sf LHS}\\): Left Hand Side\n\\({\\sf RHS}\\): Right Hand Side\n\n- 상투적인 표현\n\nIt suffices to show that, It is sufficient to show that"
  },
  {
    "objectID": "posts/HousePrice/2023-04-05-5wk.html#before",
    "href": "posts/HousePrice/2023-04-05-5wk.html#before",
    "title": "5wk: 측도론 (1)",
    "section": "Before",
    "text": "Before\n- 아래의 기호를 약속\n\n전체집합: \\(\\Omega\\)\n관심있는 집합의 모임: \\({\\cal A} \\subset 2^{\\Omega}\\)\n\n- \\(\\Omega \\neq \\emptyset\\), \\({\\cal A} \\neq \\emptyset\\) 를 가정.\n- 약속: 집합 \\({\\cal A} \\subset 2^{\\Omega}\\)에 대하여 아래와 같은 용어를 약속하자.\n\n\\(\\cap\\)-closed (closed under intersection) or a \\(\\pi\\)-system: \\(\\forall A,B \\in {\\cal A}:~ A \\cap B \\in {\\cal A}\\) (교집합에 닫혀있다. 특별히 “파이시스템”이라고 부른다.)\n\\(\\sigma\\)-\\(\\cap\\)-closed (closed under countable interserction): \\(\\forall \\{A_i\\}_{i=1}^{\\infty} \\subset {\\cal A}:~ \\cap_{i=1}^{\\infty} A_i \\in {\\cal A}\\)\n\\(\\cup\\)-closed (closed under unions): \\(\\forall A,B \\in {\\cal A}:~ A\\cup B \\in {\\cal A}\\)\n\\(\\sigma\\)-\\(\\cup\\)-closed (closed under countable unois): \\(\\forall \\{A_i\\}_{i=1}^{\\infty} \\subset {\\cal A}:~ \\cup_{i=1}^{\\infty}A_i \\in {\\cal A}\\)\n＼-closed (closed under differences): \\(\\forall A,B \\in {\\cal A}:~ A-B \\in {\\cal A}\\) (차집합에 닫혀있다.)\n\\(^c\\)-closed (closed under complements): \\(\\forall A \\in {\\cal A}:~ A^c \\in {\\cal A}\\) (여집합에 닫혀있다.)\n\n\\(\\cal{A}\\) is \\(\\cap\\)-closed 예시 - \\(\\forall A, B \\in \\cal{A} : A\\cap B \\in \\cal{A}\\) - \\(A,B \\in \\cal{A} \\Rightarrow A\\cap B \\in \\cal{A}\\) - \\(A\\cap B \\in \\cal{A}, \\text{ for all } A,B \\in \\cal{A}\\) - 위에 세개 다 같은 표현.\n\\(\\sigma\\)-\\(\\cap\\)-closed\n\n\\(A_1, A_2, \\dots, \\in \\cal{A}\\) : \\(A_1\\cap A_2 \\cap \\dots \\in \\cal{A}\\)\n\\(\\{A_1, A_2, \\dots \\}\\subset \\cal{A} = \\{A_i\\}_{i=1}^\\infty\\)\n\n\\(A_1, A_2,\\dots\\) 집합열이 \\(\\cal{A}\\)의 부분집합이라는 것은 결국,\n\\(A_1 \\in \\cal{A}, A_2 \\in \\cal{A} \\dots\\) 이렇게 된다는 것을 의미.\n\n\n\\(\\forall \\{A_i\\}_{i=1}^n\\)는 \\(\\forall A_1A_2\\dots \\in \\cal{A}\\)라는 의미.\n- 우리만의 약속:\n\n앞으로 서로소인 집합들에 대한 합집합은 기호로 \\(\\uplus\\)라고 표현하겠다.\n따라서 앞으로 \\(B_1 \\uplus B_2\\)의 의미는 (1) \\(B_1 \\cup B_2\\) (2) \\(B_1 \\cap B_2 = \\emptyset\\) 을 의미한다고 정의하겠다. (꼭 서로소임을 명시하지 않아도)\n\\(\\sigma\\)-\\(\\uplus\\)-closed 의 의미는 \\(\\uplus_{i=1}^{\\infty}B_i \\in {\\cal A}, \\forall \\{B_i\\}_{i=1}^{\\infty} \\subset {\\cal A}:\\) 의 의미이다.\n\n서로소인 집합의 countable union에 대하여 닫혀있다는 것은 (우리만의 약속 마지막부분 \\(\\sigma\\)-\\(\\uplus\\)-closed)\n* \\(B_1, B_2, \\dots \\in \\cal{A}\\)\n** \\(B_1, B_2, \\dots\\) 서로소\n*, **를 만족하면, \\(B_1\\cup B_2 \\cup \\dots \\in \\cal{A}\\) 가 성립한다.\n- 이론: \\({\\cal A}\\subset 2^{\\Omega}\\) 가 여집합에 닫혀있다면 , 아래가 성립한다.\n\n\\({\\cal A}\\)가 교집합2에 닫혀있음. \\(\\Leftrightarrow\\) \\({\\cal A}\\)가 합집합3에 닫혀있음.\n\\({\\cal A}\\)가 가산교집합4에 닫혀있음. \\(\\Leftrightarrow\\) \\({\\cal A}\\)가 가산합집합5에 닫혀있음.\n\n(증명) 생략 – 추가\n\n\\(A,B \\in \\cal{A}\\Rightarrow\\) \\(A\\cap B \\in \\cal{A} \\qquad A\\cup B \\in \\cal{A}\\)\n\\(A^c, B^c \\in \\cal{A}\\) (여집합에 닫혀있으므로)\n\\(A^c \\cap B^c \\in \\cal{A}\\) (교집합에 닫혀있으므로)\n\\((A^c \\cap B^c)^c \\in \\cal{A}\\) (여집합에 닫혀있으므로)\n\\((A^c \\cap B^c)^c = (A\\cup B)\\) 이므로 \\((A\\cup B) \\in \\cal{A}\\)\n\n반대방향도 쉽게증명가능\n- 이론: \\({\\cal A}\\subset 2^{\\Omega}\\)가 차집합에 닫혀있다면, 아래가 성립한다.\n\n\\({\\cal A}\\)는 교집합에 닫혀있다.\n\\({\\cal A}\\)가 가산합집합에 닫혀있다. \\(\\Rightarrow\\) \\({\\cal A}\\)가 가산교집합에 닫혀있다.\n\\(\\forall \\{A_i\\} \\subset {\\cal A},~ \\exists \\{B_i\\} \\subset {\\cal A}\\) such that \\(\\cup_{i=1}^{\\infty} A_i = \\uplus_{i=1}^{\\infty} B_i\\).6 (중요!)\n\n(증명)\n\nNote: \\(A\\cap B = A-(A-B)\\).\nNote: \\(\\cap_{i=1}^{\\infty}A_i = \\cap_{i=2}^{n}(A_1\\cap A_i)= \\cap_{i=2}^{n}(A_1 - (A_1-A_i))=A_1 - \\cup_{i=2}^{n}(A_1-A_i)\\).\nNote: \\(\\cup_{i=1}^{\\infty}A_i = A_1 \\uplus(A_2-A_1) \\uplus \\big((A_3-A_1) - A_2 \\big) \\uplus \\big(\\big((A_4-A_1)-A_2\\big)-A_3\\big)\\uplus \\cdots\\)\n\n\n차집합에 닫혀있다는 것은 매우 좋은 성질임."
  },
  {
    "objectID": "posts/HousePrice/2023-04-05-5wk.html#시그마필드-starstarstar",
    "href": "posts/HousePrice/2023-04-05-5wk.html#시그마필드-starstarstar",
    "title": "5wk: 측도론 (1)",
    "section": "시그마필드 (\\(\\star\\star\\star\\))",
    "text": "시그마필드 (\\(\\star\\star\\star\\))\n- 정의: 시그마필드 (\\(\\sigma\\)-field, \\(\\sigma\\)-algebra)\n집합 \\({\\cal F} \\subset 2^{\\Omega}\\)가 아래의 조건을 만족하면 \\({\\cal F}\\)를 \\(\\Omega\\)에 대한 시그마필드라고 부른다.\n\n\\(\\Omega \\in {\\cal F}\\).\n\\({\\cal F}\\)는 여집합에 닫혀있다. (예시. \\(A\\)를 잴 수 있으면 \\(A^c\\)도 잴 수 있어.)\n\\({\\cal F}\\)는 가산합집합에 닫혀있다.\n\n- 시그마필드의 정의에서 1을 생략하기도 한다. 이럴 경우는 특별히 \\({\\cal F}\\neq\\emptyset\\)임을 강조한다. 1을 생략할 수 있는 논리는 아래와 같다.\n\n\\({\\cal F}\\)는 공집합이 아니므로 최소한 하나의 집합 \\(A\\)는 포함해야 한다. 즉 \\(A \\in {\\cal F}\\).\n2번 원리에 의하여 \\(A^c \\in {\\cal F}\\).\n시그마필드는 합집합에 닫혀있으므로 \\(A\\cup A^c \\in {\\cal F}\\)."
  },
  {
    "objectID": "posts/HousePrice/2023-04-05-5wk.html#알지브라-필드-star",
    "href": "posts/HousePrice/2023-04-05-5wk.html#알지브라-필드-star",
    "title": "5wk: 측도론 (1)",
    "section": "알지브라, 필드 (\\(\\star\\))",
    "text": "알지브라, 필드 (\\(\\star\\))\n- 정의1: 알지브라, 필드 (algebra, field)\n집합 \\({\\cal A}\\subset 2^{\\Omega}\\)가 아래의 조건을 만족하면 \\({\\cal A}\\)를 \\(\\Omega\\)에 대한 대수라고 부른다.\n\n\\(\\Omega \\in {\\cal A}\\).\n\\({\\cal A}\\)는 차집합에 닫혀있다.\n\\({\\cal A}\\)는 합집합에 닫혀있다.\n\n- 알지브라 역시 1의 조건을 생략하기도 한다.\n- 전체집합을 포함 \\(\\Rightarrow\\) (차집합에 닫혀있음 \\(\\Rightarrow\\) 여집합에 닫혀있음) \\(\\Rightarrow\\) 따라서 대수는 여집합에 닫혀있다.\n- 차집합에 닫혀있음 \\(\\Rightarrow\\) 교집합에 닫혀있게 된다.\n\n혹은 (여집합에 닫혀있음 & 합집합에 닫혀있음) \\(\\Rightarrow\\) 교집합에 닫혀있음.\n\n- 정의2: 알지브라의 또 다른 정의\n집합 \\({\\cal A}\\subset 2^{\\Omega}\\)가 아래의 조건을 만족하면 \\({\\cal A}\\)를 \\(\\Omega\\)에 대한 대수라고 부른다.\n\n\\(\\Omega \\in {\\cal A}\\).\n\\({\\cal A}\\)는 교집합에 닫혀있다.\n\\({\\cal A}\\)는 여집합에 닫혀있다.\n\n- 여집합에 닫혀있음 \\(\\Rightarrow\\) (합집합에 닫혀있음 \\(\\Leftrightarrow\\) 교집합에 닫혀있음) \\(\\Rightarrow\\) 2번 조건을 합집합으로 바꿔도 무방\n- 정의3: 알지브라의 또 또 다른 정의 (교재의 정의)\n집합 \\({\\cal A}\\subset 2^{\\Omega}\\)가 아래의 조건을 만족하면 \\({\\cal A}\\)를 \\(\\Omega\\)에 대한 대수라고 부른다.\n\n\\(\\Omega \\in {\\cal A}\\).\n\\({\\cal A}\\)는 여집합에 닫혀있다.\n\\({\\cal A}\\)는 합집합에 닫혀있다.\n\n- 알지브라의 예시\n\n\\(\\Omega = \\{H,T\\}\\), \\({\\cal A} = 2^\\Omega\\) 일때, \\({\\cal A}\\)는 알지브라이다. (\\(|\\Omega| <\\infty\\) 이라면 “시그마필드 = 알지브라(필드)” 이다.)\n\n\n이렇게 기억하자! 오메가의 원소가 finite한 경우, “시그마필드 = 알지브라” 가 된다. 왜냐? countable union한 것을 따지는 것은 finite한 union을 따지는 것과 동일하다."
  },
  {
    "objectID": "posts/HousePrice/2023-04-05-5wk.html#링",
    "href": "posts/HousePrice/2023-04-05-5wk.html#링",
    "title": "5wk: 측도론 (1)",
    "section": "링",
    "text": "링\n- 정의: 링 (ring)\n집합 \\({\\cal A}\\subset 2^{\\Omega}\\)가 아래의 조건을 만족하면 \\({\\cal A}\\)를 \\(\\Omega\\)에 대한 링이라고 부른다.\n\n\\(\\emptyset \\in {\\cal A}\\). $$<– 이부분이 다름 (전체집합 대신 공집합이 들어갔다고 생각.)\n\\({\\cal A}\\)는 차집합에 닫혀있다.\n\\({\\cal A}\\)는 합집합에 닫혀있다.\n\n- 여기에서 1의 조건을 생략할 수 있다. (이럴경우 특별히 \\({\\cal A}\\neq \\emptyset\\) 임을 강조한다.)\n\n\\({\\cal A}\\)는 공집합이 아니므로 최소한 하나의 원소 \\(A\\)는 가져야 한다.\n\n조건2에 의하여 \\(A-A\\) 역시 \\({\\cal A}\\)의 원소이다.\n\n- 링은 차집합에 닫혀있음 \\(\\Rightarrow\\) 링은 교집합에도 닫혀있음 \\(\\Rightarrow\\) 링은 교집합과 합집합 모두에 닫혀 있다.\n- 링과 알지브라의 차이는 전체집합이 포함되느냐 마느냐임 \\(\\Rightarrow\\) 그런데 이 차이로 인해 알지브라는 여집합에 닫혀있지만 링은 여집합에 닫혀있지 않게 된다."
  },
  {
    "objectID": "posts/HousePrice/2023-04-05-5wk.html#시그마링",
    "href": "posts/HousePrice/2023-04-05-5wk.html#시그마링",
    "title": "5wk: 측도론 (1)",
    "section": "시그마링",
    "text": "시그마링\n- 정의: 시그마링 (\\(\\sigma\\)-ring)\n집합 \\({\\cal A}\\subset 2^{\\Omega}\\)가 아래의 조건을 만족하면 \\({\\cal A}\\)를 \\(\\Omega\\)에 대한 링이라고 부른다.\n\n\\(\\emptyset \\in {\\cal A}\\).\n\\({\\cal A}\\)는 차집합에 닫혀있다.\n\\({\\cal A}\\)는 가산합집합에 닫혀있다. <– 링의 3번째 조건이 가산합집합으로 바뀐것이 시그마링\n\n링과 시그마링의 관계는 필드와 시그마필드의 관계와 비슷하다.\n- 여기에서 1의 조건을 생략할 수 있다."
  },
  {
    "objectID": "posts/HousePrice/2023-04-05-5wk.html#세미알지브라-starstarstar",
    "href": "posts/HousePrice/2023-04-05-5wk.html#세미알지브라-starstarstar",
    "title": "5wk: 측도론 (1)",
    "section": "세미알지브라 (\\(\\star\\star\\star\\))",
    "text": "세미알지브라 (\\(\\star\\star\\star\\))\n- 정의1: 세미알지브라 (semi-algebra) // ref : 위키북스\n집합 \\({\\cal A}\\subset 2^{\\Omega}\\)가 아래의 조건을 만족하면 \\({\\cal A}\\)를 \\(\\Omega\\)에 대한 세미알지브라 라고 부른다.\n\n\\(\\Omega \\in {\\cal A}\\). (전체집합을 포함.)\n\\({\\cal A}\\)는 교집합에 닫혀있다.\n\\(\\forall A,B \\in {\\cal A}, \\exists \\{B_i\\}_{i=1}^{n} \\subset {\\cal A}\\) such that \\[A-B = \\uplus_{i=1}^{n} B_i.\\]\n\n\n3번을 \\({\\cal A}\\)가 차집합에 반쯤 닫혀있다고 표현한다. 즉 차집합 자체가 \\({\\cal A}\\)에 들어가는건 아니지만 차집합의 disjoint한 조각들은 모두 \\({\\cal A}\\)에 들어간다.\n\n- 세미알지브라는 공집합을 포함한다. (이때 \\({\\cal A}\\neq \\emptyset\\)임을 강조함)\n\n\\({\\cal A}\\)는 공집합이 아니므로 최소한 하나의 집합 \\(A\\)는 포함해야 한다. 즉 \\(A \\in {\\cal A}\\).\n\\(A \\in {\\cal A}\\)이면 조건3에 의하여 \\(\\emptyset\\)7을 \\({\\cal A}\\)의 원소들의 countable union으로 만들 수 있어야 한다. 이 조건을 만족하기 위해서는 \\(\\emptyset \\in {\\cal A}\\)이어야만 한다.\n\n- 정의2: 세미알지브라의 또 다른 정의 // ref: 세미링의 위키에서 언급, Durret의 정의.\n집합 \\({\\cal A}\\subset 2^{\\Omega}\\)가 아래의 조건을 만족하면 \\({\\cal A}\\)를 \\(\\Omega\\)에 대한 세미알지브라 라고 부른다.\n\n\\(\\Omega \\in {\\cal A}\\)\n\\({\\cal A}\\)는 교집합에 닫혀있다.\n\\(\\forall A \\in {\\cal A}, \\exists \\{B_i\\}_{i=1}^{n} \\subset {\\cal A}\\) such that \\[A^c = \\uplus_{i=1}^{n} B_i.\\]\n\n\n3번을 \\({\\cal A}\\)가 여집합에 반쯤 닫혀있다고 표현한다. 즉 여집합 자체가 \\({\\cal A}\\)에 들어가는건 아니지만 차집합의 disjoint한 조각들은 모두 \\({\\cal A}\\)에 들어간다.\n\n- 이 정의에서도 세미알지브라는 공집합을 포함한다. (이때 \\({\\cal A}\\neq \\emptyset\\)임을 강조함)\n\n\\({\\cal A}\\)는 공집합이 아니므로 최소한 하나의 집합 \\(A\\)는 포함해야 한다. 즉 \\(A \\in {\\cal A}\\).\n3에 의하여 \\(A^c=\\uplus_{i=1}^{n}B_i\\)를 만족하는 \\(B_1,\\dots, B_n\\) 역시 \\({\\cal A}\\)에 포함되어야 한다.\n2에 의하여 \\(A \\cap B_1=\\emptyset\\) 역시 \\({\\cal A}\\)에 포함되어야 한다.\n\n- Note: 정의2의 3번조건은 정의1의 3번조건보다 강한 조건이다. (정의2의 조건3 \\(\\Rightarrow\\) 정의1의 조건3)\n\n증명은 세미링/위키 에서 스스로 확인\n\n- 교재의 정의: 정의2에서 \\(\\Omega \\in {\\cal A}\\)이 생략되어 있음.\n\n왜 생략할 수 있는지 모르겠음. (교재가 틀렸을 수도 있음)\n\n- 세미알지브라의 예시: 아래의 \\({\\cal A}\\)는 모두 \\(\\Omega\\)에 대한 세미알지브라이다.\n\n예시1: \\(\\Omega=\\{a,b,c,d\\}\\), \\({\\cal A} = \\{\\emptyset, \\{a\\},\\{b,c,d\\}, \\Omega \\}\\)\n예시2: \\(\\Omega=\\{a,b,c,d\\}\\), \\({\\cal A} = \\{\\emptyset, \\{a\\},\\{b\\},\\{c,d\\}, \\Omega \\}\\)\n예시3: \\(\\Omega=\\{a,b,c,d\\}\\), \\({\\cal A} = \\{\\emptyset, \\{a\\},\\{b,c\\},\\{d\\}, \\Omega \\}\\)\n예시4: \\(\\Omega=\\{a,b,c,d\\}\\), \\({\\cal A} = \\{\\emptyset, \\{a\\},\\{b\\},\\{c\\},\\{d\\}, \\Omega \\}\\)\n예시5: \\(\\Omega=\\{a,b,c,d\\}\\), \\({\\cal A} = \\{\\emptyset, \\{a\\},\\{b\\},\\{c\\},\\{d\\}, \\{a,b\\},\\{b,c\\},\\Omega \\}\\)\n\n\n세미알지브라는 전체집합이 몇개의 파티션으로 쪼개져서 원소로 들어가는 느낌이 있음.\n\n- 세미알지브라의 예시\\((\\star)\\): 아래의 \\({\\cal A}\\)는 모두 \\(\\Omega=\\mathbb{R}\\)에 대한 세미알지브라이다.\n\n예시1: \\({\\cal A} = \\{(a,b]: -\\infty \\leq a < b \\leq \\infty \\}\\cup \\{\\emptyset\\}\\)\n예시2: \\({\\cal A} = \\{[a,b): -\\infty \\leq a < b \\leq \\infty \\}\\cup \\{\\emptyset\\}\\)\n\n- 세미알지브라가 아닌 예시: 아래의 \\({\\cal A}\\)는 \\(\\Omega=\\mathbb{R}\\)에 대한 세미알지브라가 아니다.\n\n예시1: \\({\\cal A} = \\{(a,b): -\\infty \\leq a < b \\leq \\infty \\}\\cup \\{\\emptyset\\}\\)\n예시2: \\({\\cal A} = \\{[a,b]: -\\infty \\leq a < b \\leq \\infty \\}\\cup \\{\\emptyset\\}\\)\n\n- 교재의 언급 (p3)\n\n\n\n그림1: 교재에서의 세미알지브라 설명\n\n\n\nExample1.1.5는 우리가 했던 것8의 다차원 예제일 뿐."
  },
  {
    "objectID": "posts/HousePrice/2023-04-05-5wk.html#세미링-starstarstar",
    "href": "posts/HousePrice/2023-04-05-5wk.html#세미링-starstarstar",
    "title": "5wk: 측도론 (1)",
    "section": "세미링 \\((\\star\\star\\star)\\)",
    "text": "세미링 \\((\\star\\star\\star)\\)\n\n세미알지브라와의 차이점은 전체집합을 포함할 수 있느냐의 여부.\n\n단, 세미링은 전체집합을 포함한다는 조건이 빠져있기 때문에 2,3번째 조건 즉, 교집합/차집합에 대해서 닫혀있다는 것을 같다고 볼 수 없다.\n- 정의: 세미링\n집합 \\({\\cal A}\\subset 2^{\\Omega}\\)가 아래의 조건을 만족하면 \\({\\cal A}\\)를 \\(\\Omega\\)에 대한 세미링이라고 부른다.\n\n\\(\\emptyset \\in {\\cal A}\\).\n\\({\\cal A}\\)는 교집합에 닫혀있다.\n\\({\\cal A}\\)는 차집합에 반쯤 닫혀있다.\n\n- 세미링에서도 공집합포함 조건을 생략할 수 있다.\n- 세미링의 예시: 아래의 \\({\\cal A}\\)는 모두 \\(\\Omega\\)에 대한 세미링이다.\n\n예시1: \\(\\Omega=\\{a,b,c,d,e,f\\}\\), \\({\\cal A} = \\{\\emptyset, \\{a\\},\\{b,c,d\\}\\}\\)\n예시2: \\(\\Omega=\\{a,b,c,d,e,f\\}\\), \\({\\cal A} = \\{\\emptyset, \\{a\\},\\{b\\},\\{c,d\\}\\}\\)\n예시3: \\(\\Omega=\\{a,b,c,d,e,f\\}\\), \\({\\cal A} = \\{\\emptyset,\\{a,b,c\\},\\{b,c,d\\}, \\{a\\},\\{b,c\\},\\{d\\}\\}\\)\n\n\n전체집합이 포함될 필요가 없는 세미알지브라 느낌임.\n\n- 세미링의 예시: 아래의 \\({\\cal A}\\)는 모두 \\(\\Omega=\\mathbb{R}\\)에 대한 세미링이다.\n\n예시1: \\({\\cal A} = \\{(a,b]: -\\infty < a < b < \\infty \\}\\cup \\{\\emptyset\\}\\)\n예시2: \\({\\cal A} = \\{[a,b): -\\infty < a < b < \\infty \\}\\cup \\{\\emptyset\\}\\)\n\n세미알지브라의 예시(\\(\\star\\))와 달리 부등호에 equal이 빠져있다. a,b가 \\(-\\infty, \\infty\\)일 필요는 없다. \\(\\to\\) 전체집합을 커버할 필요가 없다는 의미이다.\n위의 두 예시는 (1)공집합을 포함하고, (2)교집합에 닫혀있으며, (3)차집합에 semi-closed 되어있기 때문에 세미링의 예시가된다고 볼 수 있다.\n- 세미링이 아닌 예시: 아래의 \\({\\cal A}\\)는 \\(\\Omega=\\mathbb{R}\\)에 대한 세미링이 아니다.\n\n예시1: \\({\\cal A} = \\{(a,b): -\\infty < a < b < \\infty \\}\\cup \\{\\emptyset\\}\\)\n예시2: \\({\\cal A} = \\{[a,b]: -\\infty < a < b < \\infty \\}\\cup \\{\\emptyset\\}\\)\n\n양쪽이 모두 open이거나 closed 이면, 교집합에 대해서는 닫혀있지만, 차집합에 semi-closed되지 않기 때문에 세미링이라고 볼 수 없다."
  },
  {
    "objectID": "posts/HousePrice/2023-04-05-5wk.html#파이시스템-starstar",
    "href": "posts/HousePrice/2023-04-05-5wk.html#파이시스템-starstar",
    "title": "5wk: 측도론 (1)",
    "section": "파이시스템 (\\(\\star\\star\\))",
    "text": "파이시스템 (\\(\\star\\star\\))\n\n교집합에 대해 닫혀있으면 파이시스템. <- 이 조건 하나만 필요함.\n\n- 정의: \\(\\pi\\)-system\n집합 \\({\\cal A}\\subset 2^{\\Omega}\\)가 아래의 조건을 만족하면 \\({\\cal A}\\)를 \\(\\Omega\\)에 대한 파이스시템 이라고 부른다.\n\n\\({\\cal A}\\)는 교집합에 닫혀있다.\n\n- 파이시스템임을 강조하기 위해서 \\({\\cal A}\\) 대신에 \\({\\cal P}\\) 라고 교재에서 표현하기도 한다.\n- 파이시스템의 예시: 아래는 모두 \\(\\Omega=\\mathbb{R}\\)에 대한 파이시스템이다.\n\n예시1: \\({\\cal A} = \\{(a,b]: -\\infty < a < b < \\infty \\}\\)\n예시2: \\({\\cal A} = \\{[a,b): -\\infty < a < b < \\infty \\}\\)\n예시3: \\({\\cal A} = \\{(a,b): -\\infty < a < b < \\infty \\}\\)\n예시4: \\({\\cal A} = \\{[a,b]: -\\infty < a < b < \\infty \\}\\)"
  },
  {
    "objectID": "posts/HousePrice/2023-04-05-5wk.html#람다시스템-starstar",
    "href": "posts/HousePrice/2023-04-05-5wk.html#람다시스템-starstar",
    "title": "5wk: 측도론 (1)",
    "section": "람다시스템 (\\(\\star\\star\\))",
    "text": "람다시스템 (\\(\\star\\star\\))\n- 정의1: \\(\\lambda\\)-system\n집합 \\({\\cal A}\\subset 2^{\\Omega}\\)가 아래의 조건을 만족하면 \\({\\cal A}\\)를 \\(\\Omega\\)에 대한 람다시스템 이라고 부른다.\n\n\\(\\Omega \\in {\\cal A}\\) (전체집합을 포함한다.)\n\\(\\forall A,B \\in {\\cal A}:~ A\\subset B \\Rightarrow B-A \\in {\\cal A}\\) (A와 B가 포함관계가 있을 때 B-A라는 집합은 람다시스템에 포함되어야 한다. // 포함관계의 차집합은 차집합에 대해서만 닫혀있다.)\n\\(\\forall B_1,B_2,\\dots \\in {\\cal A}\\) such that \\(B_1,B_2\\dots\\) are disjoint: \\[\\uplus_{i=1}^{\\infty} B_i \\in {\\cal A}\\]\n\n(\\(B_1,B_2, \\dots\\)가 disjoint하면 얘네들의 countable union도 람다시스템에 포함되어야 한다.)\n\n람다시스템은 1. 전체집합이 포함되고 2. 두 집합이 포함관계에 있는 경우 차집합에 닫혀있으며 3. 서로소인 가산합집합에 닫혀있다.\n\n- 람다시스템은 여집합에 닫혀있다. 그리고 람다시스템은 공집합을 포함한다.\n\n1번, 2번 조합하면 증명가능 (2번 B자리에 대신 \\(\\Omega\\)를 넣어보자.)\n여집합에 닫혀있고 전체집합을 포함하니까 당연히 공집합을 포함하는 것은 쉽게 유추.\n\n- 람다시스템임을 강조하기위해서 \\({\\cal A}\\) 대신에 \\({\\cal L}\\) 이라고 교재에서 표현하기도 한다.\n- 람다시스템의 느낌: 3주차 시그마필드의 motivation에서 소개한 거의 모든 예제는 사실 람다시스템이다.\n\n람다시스템의 원칙1,2,3은 사실 확률의 공리와 깊게 관련되어있음.\n내 생각: 딘킨은 확률의 공리에 착안해서 람다시스템을 만들지 않았을까?\n\n- 아래는 모두 람다시스템의 예시이다.\n\n\\(\\Omega=\\{H,T\\}\\), \\({\\cal L}=\\{\\emptyset, \\{H\\},\\{T\\},\\Omega\\}\\) – 3주차 예제1\n\\(\\Omega=\\{1,2,3,4,5,6\\}\\), \\({\\cal L}=2^\\Omega\\) – 3주차 예제4\n\\(\\Omega=\\{1,2,3,4,5,6\\}\\), \\({\\cal L}=\\{\\emptyset,\\{6\\},\\{1,2,3,4,5\\},\\Omega\\}\\) – 3주차 예제5\n\\(\\Omega=\\{1,2,3,4,5,6\\}\\), \\({\\cal L}=\\{\\emptyset,\\{1,2,3\\},\\{3,4,5\\},\\Omega\\}\\) – 3주차 예제6\n\\(\\Omega=\\{1,2,3,4,5,6\\}\\), \\({\\cal L}=\\{\\emptyset,\\Omega\\}\\) – 3주차 예제8\n\\(\\Omega=\\{1,2,3,4,5,6\\}\\), \\({\\cal L}=\\{\\emptyset,\\{1\\}, \\{2\\}, \\{2,3,4\\}, \\{1,3,4\\}, \\{3,4\\}, \\{1,2\\},\\Omega\\}\\) – 3주차 예제9,10\n\\(\\Omega=(0,2\\pi]\\), \\({\\cal L}=\\sigma({\\cal A})\\) where \\({\\cal A} = \\{\\{x\\}: x\\in \\mathbb{Q} \\cap \\Omega \\}\\) – 3주차 예제11\n\\(\\Omega=\\{1,2,3,4\\}\\), \\({\\cal L}=\\{\\emptyset, \\{1,2\\}, \\{1,3\\}, \\{1,4\\}, \\{2,3\\}, \\{2,4\\}, \\{3,4\\}, \\Omega\\}\\) – 3주차 예제12에서 교집합 안넣은 버전\n\n\n사실 3wk 측도론 \\(\\cal{F}\\)가 가져야할 조건 4가지만 가지고 \\(\\cal{F}\\)를 정의한다면 시그마필드가 아닌 “람다시스템” 이다. (교집합을 안넣은 법전)\n\n\n람다시스템에 교집합에도 closed 시키게되면 “시그마 필드”가 된다.\n\n- 정의2: \\(\\lambda\\)-system (교재의 정의)\n집합 \\({\\cal A}\\subset 2^{\\Omega}\\)가 아래의 조건을 만족하면 \\({\\cal A}\\)를 \\(\\Omega\\)에 대한 람다시스템 이라고 부른다.\n\n\\(\\Omega \\in {\\cal A}\\)\n\\(\\forall A,B \\in {\\cal A}:~ A\\subset B \\Rightarrow B-A \\in {\\cal A}\\)\n\\(\\forall A_1,A_2,\\dots \\in {\\cal A}\\) such that \\(A_1 \\subset A_2 \\subset \\dots\\): \\[\\cup_{i=1}^{\\infty} A_i \\in {\\cal A}\\]\n\n- Note: 정의1의 3번조건과 정의2의 3번조건은 서로 동치관계이다.\n- 교재에서의 파이시스템, 람다시스템 설명\n\n\n\n그림2: 교재에서의 파이시스템과 람다시스템\n\n\n\n위의 정의에서 기호 \\(A_n \\uparrow A\\)의 의미는 “\\(A_1 \\subset A_2 \\subset \\dots\\) and \\(\\cup_{i}^{\\infty}A_i=A\\)”를 뜻하는 축약표현이다."
  },
  {
    "objectID": "posts/HousePrice/2023-04-05-5wk.html#정리",
    "href": "posts/HousePrice/2023-04-05-5wk.html#정리",
    "title": "5wk: 측도론 (1)",
    "section": "정리",
    "text": "정리\n- 정리표 (hw): 물음표를 채워라\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\\(A \\cap B\\)\n\\(\\emptyset\\)\n\\(A-B\\)\n\\(\\cup_i\\to\\uplus_i\\)\n\\(\\Omega\\)\n\\(A^c\\)\n\\(A\\cup B\\)\n\\(\\cup_{i=1}^{\\infty}A_i\\)\n\\(\\uplus_{i=1}^{\\infty}B_i\\)\n\\(\\cap_{i=1}^{\\infty}A_i\\)\n\n\n\n\n\\(\\pi\\)-system\n\\(O\\)\n\\(X\\)\n\\(X\\)\n\\(X\\)\n\\(X\\)\n\\(X\\)\n\\(X\\)\n\\(X\\)\n\\(X\\)\n\\(X\\)\n\n\nsemi-ring\n\\(?\\)\n\\(?\\)\n\\(\\Delta\\)\n\\(O\\)\n\\(?\\)\n\\(?\\)\n\\(?\\)\n\\(?\\)\n\\(?\\)\n\\(?\\)\n\n\nsemi-algebra\n\\(?\\)\n\\(?\\)\n\\(\\Delta\\)\n\\(O\\)\n\\(O\\)\n\\(\\Delta\\)\n\\(?\\)\n\\(?\\)\n\\(?\\)\n\\(?\\)\n\n\nring\n\\(?\\)\n\\(?\\)\n\\(?\\)\n\\(?\\)\n\\(?\\)\n\\(?\\)\n\\(?\\)\n\\(?\\)\n\\(?\\)\n\\(?\\)\n\n\nalgebra\n\\(?\\)\n\\(?\\)\n\\(?\\)\n\\(?\\)\n\\(?\\)\n\\(?\\)\n\\(?\\)\n\\(?\\)\n\\(?\\)\n\\(?\\)\n\n\n\\(\\sigma\\)-ring\n\\(?\\)\n\\(?\\)\n\\(?\\)\n\\(?\\)\n\\(?\\)\n\\(?\\)\n\\(?\\)\n\\(?\\)\n\\(?\\)\n\\(?\\)\n\n\n\\(\\lambda\\)-system\n\\(?\\)\n\\(?\\)\n\\(\\Delta'\\)\n\\(?\\)\n\\(?\\)\n\\(?\\)\n\\(?\\)\n\\(?\\)\n\\(?\\)\n\\(?\\)\n\n\n\\(\\sigma\\)-field\n\\(O\\)\n\\(O\\)\n\\(O\\)\n\\(O\\)\n\\(O\\)\n\\(O\\)\n\\(O\\)\n\\(O\\)\n\\(O\\)\n\\(O\\)\n\n\n\nNOTE!\n\n\\(\\Delta\\) : 차집합이 반쯤 닫혀있다. / 여집합에 반쯤 닫혀있다. 등등\n차집합이 닫혀있거나 반쯤 닫혀있으면 \\(\\cup_i\\to\\uplus_i\\) 가 성립한다.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\\(A \\cap B\\)\n\\(\\emptyset\\)\n\\(A-B\\)\n\\(\\cup_iA_i\\to\\uplus B_i\\)\n\\(\\Omega\\)\n\\(A^c\\)\n\\(A\\cup B\\)\n\\(\\cup_{i=1}^{\\infty}A_i\\)\n\\(\\uplus_{i=1}^{\\infty}B_i\\)\n\\(\\cap_{i=1}^{\\infty}A_i\\)\n\n\n\n\n\\(\\pi\\)-system\n\\(O\\)\n\\(X\\)\n\\(X\\)\n\\(X\\)\n\\(X\\)\n\\(X\\)\n\\(X\\)\n\\(X\\)\n\\(X\\)\n\\(X\\)\n\n\nsemi-ring\n\\(O\\)\n\\(O\\)\n\\(\\Delta\\)\n\\(O\\)\n\\(X\\)\n\\(X\\)\n\\(X\\)\n\\(X\\)\n\\(\\Delta\\)\n\\(X\\)\n\n\nsemi-algebra\n\\(O\\)\n\\(O\\)\n\\(\\Delta\\)\n\\(O\\)\n\\(O\\)\n\\(\\Delta\\)\n\\(O\\)\n\\(X\\)\n\\(\\Delta\\)\n\\(X\\)\n\n\nring\n\\(O\\)\n\\(O\\)\n\\(O\\)\n\\(O\\)\n\\(X\\)\n\\(X\\)\n\\(O\\)\n\\(X\\)\n\\(O\\)\n\\(X\\)\n\n\nalgebra\n\\(O\\)\n\\(O\\)\n\\(O\\)\n\\(O\\)\n\\(O\\)\n\\(O\\)\n\\(O\\)\n\\(X\\)\n\\(O\\)\n\\(X\\)\n\n\n\\(\\sigma\\)-ring\n\\(O\\)\n\\(O\\)\n\\(O\\)\n\\(O\\)\n\\(X\\)\n\\(X\\)\n\\(O\\)\n\\(O\\)\n\\(O\\)\n\\(O\\)\n\n\n\\(\\lambda\\)-system\n\\(X\\)\n\\(O\\)\n\\(\\Delta'\\)\n\\(X\\)\n\\(O\\)\n\\(O\\)\n\\(X\\)\n\\(X\\)\n\\(O\\)\n\\(X\\)\n\n\n\\(\\sigma\\)-field\n\\(O\\)\n\\(O\\)\n\\(O\\)\n\\(O\\)\n\\(O\\)\n\\(O\\)\n\\(O\\)\n\\(O\\)\n\\(O\\)\n\\(O\\)\n\n\n\n- 다이어그램 (포함관계)\n\n\\(\\sigma\\)-algebra: countable union에 닫혀있다.\nalgebra: finite한 union에 닫혀있다.\n\n\n\n\n\n\n\n\nG\n\n \n\ncluster_0\n\n RING  \n\ncluster_1\n\n ALGEBRA  \n\ncluster_2\n\n LAMBDA   \n\nσ－ring\n\n σ－ring   \n\nring\n\n ring   \n\nσ－ring->ring\n\n    \n\nsemiring\n\n semiring   \n\nring->semiring\n\n    \n\nπ－system\n\n π－system   \n\nsemiring->π－system\n\n    \n\nσ－algebra\n\n σ－algebra   \n\nσ－algebra->σ－ring\n\n    \n\nalgebra\n\n algebra   \n\nσ－algebra->algebra\n\n    \n\nλ－system\n\n λ－system   \n\nσ－algebra->λ－system\n\n    \n\nalgebra->ring\n\n    \n\nsemialgebra\n\n semialgebra   \n\nalgebra->semialgebra\n\n    \n\nsemialgebra->semiring\n\n   \n\n\n\n\n\n- 다이어그램 (이해용) – 그림은 더럽지만..\n\n\n\n\n\n\n\nG\n\n \n\ncluster_1\n\n ALGEBRA  \n\ncluster_2\n\n LAMBDA  \n\ncluster_0\n\n RING   \n\nsemiring\n\n semiring   \n\nring\n\n ring   \n\nsemiring->ring\n\n  ∪－stable   \n\nsemialgebra\n\n semialgebra   \n\nsemiring->semialgebra\n\n  Ω－contained   \n\nσ－ring\n\n σ－ring   \n\nring->σ－ring\n\n  σ－∪－stable   \n\nalgebra\n\n algebra   \n\nring->algebra\n\n  Ω－contained   \n\nσ－algebra\n\n σ－algebra   \n\nσ－ring->σ－algebra\n\n  Ω－contained   \n\nsemialgebra->algebra\n\n  ∪－stable   \n\nalgebra->σ－algebra\n\n  σ－∪－stable   \n\nλ－system\n\n λ－system   \n\nλ－system->σ－algebra\n\n  ∩－stable   \n\nπ－system\n\n π－system   \n\nπ－system->semiring\n\n  ＼－semistable  \n\n\n\n\n\n\nRing 에서 algebra가 되려면 \\(\\Omega\\)를 포함시키면 된다.\n길이 \\(\\to\\) \\(\\pi\\) sys에서 시작.\n확률 \\(\\to\\) \\(\\lambda\\)-sys에서 시작."
  },
  {
    "objectID": "posts/HousePrice/2023-04-11-ts-hw4.html",
    "href": "posts/HousePrice/2023-04-11-ts-hw4.html",
    "title": "TS HW4",
    "section": "",
    "text": "– 피드백 추가 (이항정리와 일반화된 이항정리)–"
  },
  {
    "objectID": "posts/HousePrice/2023-04-11-ts-hw4.html#이항정리",
    "href": "posts/HousePrice/2023-04-11-ts-hw4.html#이항정리",
    "title": "TS HW4",
    "section": "00. 이항정리",
    "text": "00. 이항정리\n\\((x+y)^n = \\sum_{k=0}^n\\binom{n}{k}x^ky^{n-k}\\)"
  },
  {
    "objectID": "posts/HousePrice/2023-04-11-ts-hw4.html#일반화된-이항정리",
    "href": "posts/HousePrice/2023-04-11-ts-hw4.html#일반화된-이항정리",
    "title": "TS HW4",
    "section": "00. 일반화된 이항정리",
    "text": "00. 일반화된 이항정리\n사실 음이항정리라는 것은 따로 없다. 일반화된 이항정리에서 이항계수가 음수인 케이스이다.\n\\((1+x)^a = \\sum_{k=0}^\\infty \\binom{a}{k}x^k, \\quad a\\in \\mathbb{R}, -1<X<1\\)"
  },
  {
    "objectID": "posts/HousePrice/2023-04-11-ts-hw4.html#q1.-음이항분포",
    "href": "posts/HousePrice/2023-04-11-ts-hw4.html#q1.-음이항분포",
    "title": "TS HW4",
    "section": "Q1. 음이항분포",
    "text": "Q1. 음이항분포\n음이항분포 \\(NB(r,p)\\)의 확률밀도함수 \\(f(x)\\)가 \\(\\sum_{x=r}^\\infty f(x)=1\\)을 만족함을 음이항정리를 이용하여 증명하시오."
  },
  {
    "objectID": "posts/HousePrice/2023-04-11-ts-hw4.html#q2.-음이항분포의-mgf",
    "href": "posts/HousePrice/2023-04-11-ts-hw4.html#q2.-음이항분포의-mgf",
    "title": "TS HW4",
    "section": "Q2. 음이항분포의 mgf",
    "text": "Q2. 음이항분포의 mgf\n음이항분포 \\(NB(r,p)\\)의 적률생성함수를 구하시오."
  },
  {
    "objectID": "posts/HousePrice/2023-04-11-ts-hw4.html#q3.-베타분포의-k차-적률",
    "href": "posts/HousePrice/2023-04-11-ts-hw4.html#q3.-베타분포의-k차-적률",
    "title": "TS HW4",
    "section": "Q3. 베타분포의 \\(k\\)차 적률",
    "text": "Q3. 베타분포의 \\(k\\)차 적률\n베타분포 \\(BETA(a,b)\\)의 \\(k\\)차적률이 \\(E(X^k) = \\frac{\\Gamma(a+k)\\Gamma(a+b)}{\\Gamma(a)\\Gamma(a+b+k)}\\)임을 보이시오."
  },
  {
    "objectID": "posts/HousePrice/2023-04-11-ts-hw4.html#q4.-감마분포의-평균과-분산",
    "href": "posts/HousePrice/2023-04-11-ts-hw4.html#q4.-감마분포의-평균과-분산",
    "title": "TS HW4",
    "section": "Q4. 감마분포의 평균과 분산",
    "text": "Q4. 감마분포의 평균과 분산\n감마분포 \\(GAM(\\alpha, \\beta)\\)이 평균과 분산의 기댓값 정의를 이용하여 구하시오."
  },
  {
    "objectID": "posts/HousePrice/2023-04-11-ts-hw4.html#q5.-정규분포의-mgf",
    "href": "posts/HousePrice/2023-04-11-ts-hw4.html#q5.-정규분포의-mgf",
    "title": "TS HW4",
    "section": "Q5. 정규분포의 mgf",
    "text": "Q5. 정규분포의 mgf\n정규분포 \\(N(\\mu, \\sigma^2)\\)의 적률생성함수를 구하시오."
  },
  {
    "objectID": "posts/HousePrice/2023-04-11-ts-hw4.html#q6.-다변량정규분포의-pdf",
    "href": "posts/HousePrice/2023-04-11-ts-hw4.html#q6.-다변량정규분포의-pdf",
    "title": "TS HW4",
    "section": "Q6. 다변량정규분포의 pdf",
    "text": "Q6. 다변량정규분포의 pdf\n이변량정규분포 \\(BVN(\\mu_X,\\mu_Y, \\sigma_X, \\sigma_Y,\\rho)\\)를 따르는 확률벡터 \\((X,Y)\\)의 확률밀도함수를 다변량 정규분포의 확률밀도함수의 2차원형임을 이용하여 구하시오."
  },
  {
    "objectID": "posts/HousePrice/2023-04-11-ts-hw4.html#q7.-이변량정규분포-marginal-pdf",
    "href": "posts/HousePrice/2023-04-11-ts-hw4.html#q7.-이변량정규분포-marginal-pdf",
    "title": "TS HW4",
    "section": "Q7. 이변량정규분포 marginal pdf",
    "text": "Q7. 이변량정규분포 marginal pdf\n이변량정규분포 \\(BVN(\\mu_X,\\mu_Y, \\sigma_X, \\sigma_Y,\\rho)\\)의 확률밀도함수로부터 \\(X\\)의 주변확률밀도함수를 구하시오."
  },
  {
    "objectID": "posts/HousePrice/2023-04-11-ts-hw4.html#q8.-다항분포-공분산",
    "href": "posts/HousePrice/2023-04-11-ts-hw4.html#q8.-다항분포-공분산",
    "title": "TS HW4",
    "section": "Q8. 다항분포 공분산",
    "text": "Q8. 다항분포 공분산\n\\((X_1, X_2, X_3) \\sim MULT(n,p_1,p_2,p_3)\\)일 때 \\(Cov(X_1, X_2)\\)를 구하시오"
  },
  {
    "objectID": "posts/Seminar/2023-03-21-gpt3-nsmc.html",
    "href": "posts/Seminar/2023-03-21-gpt3-nsmc.html",
    "title": "Few-shot learning using GPT3",
    "section": "",
    "text": "NSMC - NAVER Sentiment Movie Corpus\n\ngpt3 백본모델로 KoAlpaca를 활용하여 인컨텍스트 퓨삿러닝을 통해 네이버 영화 리뷰 데이터(NSMC - NAVER Sentiment Movie Corpus) 분류문제를 풀어보자.\n\n참고로 KoAlpaca 는 한국어로 인스트럭션 데이터를 한국어 오픈소스 gpt3 모델인 polyglot-ko에 파인튜닝한 모델입니다.\n\n# !pip install transformers\n# !pip install accelerate\n\n\n!mkdir -p data_in/KOR/naver_movie\n!wget https://raw.githubusercontent.com/NLP-kr/tensorflow-ml-nlp-tf2/master/7.PRETRAIN_METHOD/data_in/KOR/naver_movie/ratings_train.txt \\\n              -O data_in/KOR/naver_movie/ratings_train.txt\n!wget https://raw.githubusercontent.com/NLP-kr/tensorflow-ml-nlp-tf2/master/7.PRETRAIN_METHOD/data_in/KOR/naver_movie/ratings_test.txt \\\n              -O data_in/KOR/naver_movie/ratings_test.txt\n\n--2023-04-02 21:25:32--  https://raw.githubusercontent.com/NLP-kr/tensorflow-ml-nlp-tf2/master/7.PRETRAIN_METHOD/data_in/KOR/naver_movie/ratings_train.txt\nResolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.110.133, 185.199.108.133, ...\nConnecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 14628807 (14M) [text/plain]\nSaving to: ‘data_in/KOR/naver_movie/ratings_train.txt’\n\ndata_in/KOR/naver_m 100%[===================>]  13.95M  --.-KB/s    in 0.1s    \n\n2023-04-02 21:25:34 (97.0 MB/s) - ‘data_in/KOR/naver_movie/ratings_train.txt’ saved [14628807/14628807]\n\n--2023-04-02 21:25:34--  https://raw.githubusercontent.com/NLP-kr/tensorflow-ml-nlp-tf2/master/7.PRETRAIN_METHOD/data_in/KOR/naver_movie/ratings_test.txt\nResolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.111.133, 185.199.109.133, ...\nConnecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 4893335 (4.7M) [text/plain]\nSaving to: ‘data_in/KOR/naver_movie/ratings_test.txt’\n\ndata_in/KOR/naver_m 100%[===================>]   4.67M  --.-KB/s    in 0.06s   \n\n2023-04-02 21:25:34 (78.6 MB/s) - ‘data_in/KOR/naver_movie/ratings_test.txt’ saved [4893335/4893335]\n\n\n\n\nimport os\nfrom transformers import AutoModelForCausalLM, AutoTokenizer\n\nimport torch\nimport pandas as pd\nimport numpy as np\n\nimport re\n\nimport random\nfrom random import sample\n\nfrom tqdm import tqdm\n\n\n# torch.cuda.is_available()\n# os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n\n\nSEED_NUM = 1234\nrandom.seed(SEED_NUM)\n\n\ntokenizer = AutoTokenizer.from_pretrained(\"EleutherAI/polyglot-ko-5.8b\")\n\n\ncls_model = AutoModelForCausalLM.from_pretrained(\"beomi/KoAlpaca-Polyglot\",\n                                                 torch_dtype=torch.float16,\n                                                 device_map='sequential',\n                                                 low_cpu_mem_usage=True).cuda()\n\nLoading checkpoint shards: 100%|██████████████████████████████████████████████████████████████████████████| 3/3 [00:08<00:00,  2.69s/it]\n\n\n\ncls_model.config.max_length = 2048\ncls_model.config.pad_token_id = 0\n\n\n# 데이터 전처리 준비\nDATA_IN_PATH = './data_in/KOR'\nDATA_OUT_PATH = './data_out/KOR'\n\nDATA_TRAIN_PATH = os.path.join(DATA_IN_PATH, 'naver_movie', 'ratings_train.txt')\nDATA_TEST_PATH = os.path.join(DATA_IN_PATH, 'naver_movie', 'ratings_test.txt')\n\ntrain_data = pd.read_csv(DATA_TRAIN_PATH, header = 0, delimiter = '\\t', quoting = 3)\ntrain_data = train_data.dropna()\n\n\nprint('데이터 positive 라벨: ', '긍정')\nprint('데이터 negative 라벨: ', '부정')\n\n데이터 positive 라벨:  긍정\n데이터 negative 라벨:  부정\n\n\n\nprint('학습 예시 케이스 구조: ', '문장: 오늘 기분이 좋아\\n감정: 긍정\\n')\n\n학습 예시 케이스 구조:  문장: 오늘 기분이 좋아\n감정: 긍정\n\n\n\n\nprint('gpt3 최대 토큰 길이: ', cls_model.config.max_position_embeddings)\n\ngpt3 최대 토큰 길이:  2048\n\n\n\nsent_lens = [len(tokenizer(s).input_ids) for s in tqdm(train_data['document'])]\n\nprint('Few shot 케이스 토큰 평균 길이: ', np.mean(sent_lens))\nprint('Few shot 케이스 토큰 최대 길이: ', np.max(sent_lens))\nprint('Few shot 케이스 토큰 길이 표준편차: ',np.std(sent_lens))\nprint('Few shot 케이스 토큰 길이 80 퍼센타일: ',np.percentile(sent_lens, 80))\n\n100%|████████████████████████████████████████████████████████████████████████████████████████| 149995/149995 [00:07<00:00, 21048.91it/s]\n\n\nFew shot 케이스 토큰 평균 길이:  20.22912763758792\nFew shot 케이스 토큰 최대 길이:  280\nFew shot 케이스 토큰 길이 표준편차:  16.48828728915166\nFew shot 케이스 토큰 길이 80 퍼센타일:  27.0\n\n\n\ntrain_fewshot_data = []\n\nfor train_sent, train_label in tqdm(train_data[['document', 'label']].values):\n    tokens = tokenizer(train_sent).input_ids\n\n    if len(tokens) <= 25:\n        train_fewshot_data.append((train_sent, train_label))\n\n100%|████████████████████████████████████████████████████████████████████████████████████████| 149995/149995 [00:07<00:00, 20502.42it/s]\n\n\n\ntest_data = pd.read_csv(DATA_TEST_PATH, header=0, delimiter='\\t', quoting=3)\ntest_data = test_data.dropna()\ntest_data.head()\n\n\n\n\n\n  \n    \n      \n      id\n      document\n      label\n    \n  \n  \n    \n      0\n      6270596\n      굳 ㅋ\n      1\n    \n    \n      1\n      9274899\n      GDNTOPCLASSINTHECLUB\n      0\n    \n    \n      2\n      8544678\n      뭐야 이 평점들은.... 나쁘진 않지만 10점 짜리는 더더욱 아니잖아\n      0\n    \n    \n      3\n      6825595\n      지루하지는 않은데 완전 막장임... 돈주고 보기에는....\n      0\n    \n    \n      4\n      6723715\n      3D만 아니었어도 별 다섯 개 줬을텐데.. 왜 3D로 나와서 제 심기를 불편하게 하죠??\n      0\n    \n  \n\n\n\n\n\n# 평가 데이터 수\nsample_size = 500\n\n# 평가에서 활용할 few-shot 예제를 묶음으로 저장\ntrain_fewshot_samples = []\n\nfor _ in range(sample_size):\n    # few-shot 예제를 10개씩 묶음\n    fewshot_examples = sample(train_fewshot_data, 10)\n    train_fewshot_samples.append(fewshot_examples)\n\nif sample_size < len(test_data['id']):\n    test_data = test_data.sample(sample_size, random_state=SEED_NUM)\n\n\ntrain_fewshot_samples[1]\n\n[('레전드.', 1),\n ('보고 있으면 어느새 영화에 빠져들어 있다. 마지막 장면을 생각하면 아직도 가슴이 찡하다.', 1),\n ('오즈의 영역을 넘어 마술의 경지에 이르는 허우.', 1),\n (\"'스트레스 해소용 영화' 로써만 강추..\", 0),\n ('볼만햇다 액션영화가 아닌데 아쉽다', 1),\n ('귀여운 기니피그가 나오는... 디즈니 영화. 디즈니 디즈니 디즈니', 0),\n ('햄릿! 돈은 있는데.. 정말 매너리즘에 빠진 최악의 중국 영화', 0),\n ('영화도 좋지만 책도 꼭 읽어보세요ㅎㅎ', 1),\n ('많은 생각이 떠돌게 되는 영화...', 1),\n ('개봉일을 잡았다는게 신기한 싸구려 영화.. 싼맛에 수입한거겠지?', 0)]\n\n\n\ndef build_prompt_text(sent):\n    return \"문장: \" + sent + '\\n감정:'\n\ndef clean_text(sent):\n    sent_clean = re.sub(\"[^가-힣ㄱ-ㅎㅏ-ㅣ\\\\s]\", \"\", sent)\n    return sent_clean\n\ndef generate_fewshot_example(data, with_label=True):\n    example_text, example_label = data\n    # 텍스트 전처리\n    cleaned_example_text = clean_text(example_text)\n    # Prompt 형식 구성\n    fewshot_example_text = build_prompt_text(cleaned_example_text)\n    # Label 추가\n    if with_label:\n      fewshot_example_text += ' 긍정' if example_label == 1 else ' 부정' + '\\n'\n    \n    return fewshot_example_text\n\ndef predict_by_generation(prompt_text):\n    # 토큰화 및 인덱싱\n    tokens = tokenizer(prompt_text, return_tensors=\"pt\")\n    token_ids, attn_mask = tokens.input_ids.cuda(), tokens.attention_mask.cuda()\n    # 텍스트 생성\n    gen_tokens = cls_model.generate(input_ids=token_ids, attention_mask=attn_mask,\n                                    max_new_tokens=1, pad_token_id=0)\n    # 인덱스 복호화\n    pred = tokenizer.batch_decode(gen_tokens[:, -1])[0].strip()\n    \n    return pred\n\n\ntest_data\n\n\n\n\n\n  \n    \n      \n      id\n      document\n      label\n    \n  \n  \n    \n      0\n      6270596\n      굳 ㅋ\n      1\n    \n    \n      1\n      9274899\n      GDNTOPCLASSINTHECLUB\n      0\n    \n    \n      2\n      8544678\n      뭐야 이 평점들은.... 나쁘진 않지만 10점 짜리는 더더욱 아니잖아\n      0\n    \n    \n      3\n      6825595\n      지루하지는 않은데 완전 막장임... 돈주고 보기에는....\n      0\n    \n    \n      4\n      6723715\n      3D만 아니었어도 별 다섯 개 줬을텐데.. 왜 3D로 나와서 제 심기를 불편하게 하죠??\n      0\n    \n    \n      ...\n      ...\n      ...\n      ...\n    \n    \n      49995\n      4608761\n      오랜만에 평점 로긴했네ㅋㅋ 킹왕짱 쌈뽕한 영화를 만났습니다 강렬하게 육쾌함\n      1\n    \n    \n      49996\n      5308387\n      의지 박약들이나 하는거다 탈영은 일단 주인공 김대희 닮았고 이등병 찐따 OOOO\n      0\n    \n    \n      49997\n      9072549\n      그림도 좋고 완성도도 높았지만... 보는 내내 불안하게 만든다\n      0\n    \n    \n      49998\n      5802125\n      절대 봐서는 안 될 영화.. 재미도 없고 기분만 잡치고.. 한 세트장에서 다 해먹네\n      0\n    \n    \n      49999\n      6070594\n      마무리는 또 왜이래\n      0\n    \n  \n\n49997 rows × 3 columns\n\n\n\n\nreal_labels = []\npred_tokens = []\n\ntotal_len = len(test_data[['document','label']].values)\n\nfor i, row in tqdm(enumerate(test_data[['document','label']].values), total=total_len):\n    prompt_text = ''\n\n    for ex in train_fewshot_samples[i]:\n        prompt_text += generate_fewshot_example(ex)\n\n    prompt_text += generate_fewshot_example(row, with_label=False)\n\n    pred = predict_by_generation(prompt_text)\n\n    pred_tokens.append(pred)\n    real_labels.append('긍정' if row[1] == 1 else '부정')\n\n100%|█████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [00:30<00:00, 16.16it/s]\n\n\n\naccuracy_match = [p == t for p, t in zip(pred_tokens, real_labels)]\naccuracy = len([m for m in accuracy_match if m]) / len(real_labels)\n\nprint(accuracy)\n\n0.762\n\n\n\ndef build_prompt_text(sent):\n    return '다음 문장은 긍정일까요 부정일까요?\\n' + sent + '\\n정답:'\n\nreal_labels = []\npred_tokens = []\n\ntotal_len = len(test_data[['document','label']].values)\n\nfor i, row in tqdm(enumerate(test_data[['document','label']].values), total=total_len):\n    prompt_text = ''\n\n    for ex in train_fewshot_samples[i]:\n        prompt_text += generate_fewshot_example(ex)\n\n    prompt_text += generate_fewshot_example(row, with_label=False)\n\n    pred = predict_by_generation(prompt_text)\n\n    pred_tokens.append(pred)\n    real_labels.append('긍정' if row[1] == 1 else '부정')\n\n100%|█████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [00:39<00:00, 12.80it/s]\n\n\n\naccuracy_match = [p == t for p, t in zip(pred_tokens, real_labels)]\naccuracy = len([m for m in accuracy_match if m]) / len(real_labels)\n\nprint(accuracy)\n\n0.744"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "noteda",
    "section": "",
    "text": "Date\n\n\nTitle\n\n\nAuthor\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMay 14, 2023\n\n\nPost With Code\n\n\nHarlow Malloc\n\n\n\n\nMay 8, 2023\n\n\n[SOLAR] 0508 정리중\n\n\nJiyunLim\n\n\n\n\nMay 8, 2023\n\n\nGCRN\n\n\nJiyunLim\n\n\n\n\nMay 6, 2023\n\n\n[PAPER] Ensemble patch transformation\n\n\nJiyunLim\n\n\n\n\nMay 6, 2023\n\n\n[PAPER] Spatio-Temporal Graph Convolutional Networks (+++)\n\n\nJiyunLim\n\n\n\n\nMay 6, 2023\n\n\n[SOLAR]\n\n\nJiyunLim\n\n\n\n\nMay 3, 2023\n\n\n[SOLAR] STGCN Ver2 (data2, -N +S) 시뮬레이션 (epoch, filter, lag)\n\n\nJiyunLim\n\n\n\n\nMay 3, 2023\n\n\n[SOLAR] 시뮬레이션 결과정리 1-iter (epoch, filter, lag)\n\n\nJiyunLim\n\n\n\n\nMay 2, 2023\n\n\n[SOLAR] STGCN Ver1 (data2, +N +S) 시뮬레이션(epoch, filter, lag)\n\n\nJiyunLim\n\n\n\n\nMay 2, 2023\n\n\n[SOLAR] STGCN Ver2 (data2, +N +S) 시뮬레이션 (epoch, filter, lag)\n\n\nJiyunLim\n\n\n\n\nMay 2, 2023\n\n\nTS HW6\n\n\nJiyunLim\n\n\n\n\nApr 29, 2023\n\n\n[SOLAR] STGCN Ver1 (data2, -N +S) 시뮬레이션(epoch, filter, lag)\n\n\nJiyunLim\n\n\n\n\nApr 29, 2023\n\n\n[SOLAR] STGCN Ver1 (data2, -N +S) 시뮬레이션(epoch, filter, lag)\n\n\nJiyunLim\n\n\n\n\nApr 29, 2023\n\n\n[SOLAR] STGCN Ver2 (data2, -N +S) 30회 시뮬레이션 (epoch, filter, lag)\n\n\nJiyunLim\n\n\n\n\nApr 29, 2023\n\n\n[SOLAR] 차원조사\n\n\nJiyunLim\n\n\n\n\nApr 29, 2023\n\n\n에러 모음\n\n\nJiyunLim\n\n\n\n\nApr 27, 2023\n\n\n[SOLAR] STGCN Ver1 (data2, -N +S) 30회 100epoch 64filter\n\n\nJiyunLim\n\n\n\n\nApr 27, 2023\n\n\n[SOLAR] STGCN Ver1 (data2, -N +S) 30회 50epoch 64filter\n\n\nJiyunLim\n\n\n\n\nApr 27, 2023\n\n\n[SOLAR] STGCN Ver2 (data2, -N +S) 30회 50 epoch 64filter\n\n\nJiyunLim\n\n\n\n\nApr 26, 2023\n\n\n[SOLAR] STGCN Ver1 (data2, -N +S) 30회 150epoch\n\n\nJiyunLim\n\n\n\n\nApr 26, 2023\n\n\n[SOLAR] STGCN Ver2 (data2, -N +S) 30회 150 epoch\n\n\nJiyunLim\n\n\n\n\nApr 26, 2023\n\n\n[SOLAR] To do list\n\n\njiyunLim\n\n\n\n\nApr 26, 2023\n\n\n04. 가변수(Indicator Variable) 실습\n\n\nJiyunLim\n\n\n\n\nApr 25, 2023\n\n\n[SOLAR] STGCN Ver1 (data2, -N +S) 30회 100epoch\n\n\nJiyunLim\n\n\n\n\nApr 25, 2023\n\n\n[SOLAR] STGCN Ver2 (data2, -N +S) 30회 100 epoch\n\n\nJiyunLim\n\n\n\n\nApr 25, 2023\n\n\n8wk: 측도론 (4)\n\n\n최규빈\n\n\n\n\nApr 24, 2023\n\n\n[SOLAR] Comparison of 30 simulation results (-N)\n\n\nJiyunLim\n\n\n\n\nApr 24, 2023\n\n\n[SC2022] 포아송분포, 지수분포\n\n\nJiyunLim\n\n\n\n\nApr 23, 2023\n\n\n[SOLAR] Comparison of 30 simulation results (+N)\n\n\nJiyunLim\n\n\n\n\nApr 23, 2023\n\n\n[SOLAR] STGCN Ver1 (data2, -N +S) 30회\n\n\nJiyunLim\n\n\n\n\nApr 23, 2023\n\n\n[SOLAR] STGCN Ver2 (data2, -N +S) 30회\n\n\nJiyunLim\n\n\n\n\nApr 22, 2023\n\n\n[SOLAR] STGCN Ver1 (data2, +N +S) 30회\n\n\nJiyunLim\n\n\n\n\nApr 22, 2023\n\n\n[SOLAR] STGCN Ver2 (data2, +N +S) 30회\n\n\nJiyunLim\n\n\n\n\nApr 22, 2023\n\n\n[SOLAR] 연습용 (시각화 코드 수정)\n\n\nJiyunLim\n\n\n\n\nApr 21, 2023\n\n\n[SOLAR] STGCN Ver1 (+N +S) (MSE: 0.1864) – guebin\n\n\nGuebinChoi\n\n\n\n\nApr 21, 2023\n\n\n[SOLAR] STGCN Ver2 (+N +S) (MSE: 0.1801) – guebin\n\n\nGuebinChoi\n\n\n\n\nApr 20, 2023\n\n\n[SOLAR] Create Dataset (data3: 0815/0910) 재수정\n\n\njiyunLim\n\n\n\n\nApr 20, 2023\n\n\n[SOLAR] STGCN Ver1 (Full: 08/15~09/10 data3) (MSE: 0.1523)\n\n\njiyunLim\n\n\n\n\nApr 20, 2023\n\n\n[SOLAR] STGCN Ver2 (Full: 08/15~09/10 data3) (MSE: 0.1927)\n\n\njiyunLim\n\n\n\n\nApr 20, 2023\n\n\nDiscrete Probability Distribution (추가중)\n\n\nJiyunLim\n\n\n\n\nApr 20, 2023\n\n\n학회\n\n\nJiyunLim\n\n\n\n\nApr 19, 2023\n\n\n[SOLAR] 데이터 탐색용\n\n\njiyunLim\n\n\n\n\nApr 19, 2023\n\n\nMLR_hw2\n\n\nJiyunLim\n\n\n\n\nApr 19, 2023\n\n\nTS HW5\n\n\nJiyunLim\n\n\n\n\nApr 18, 2023\n\n\n7wk: 측도론 (3)\n\n\nJiyunLim\n\n\n\n\nApr 18, 2023\n\n\nMLR prac1\n\n\nJiyunLim\n\n\n\n\nApr 17, 2023\n\n\n[SOLAR] STGCN Ver1 (data2, +N) (MSE: 0.1705)\n\n\njiyunLim\n\n\n\n\nApr 17, 2023\n\n\n[SOLAR] STGCN Ver2 (data2, +N) (MSE: 0.1834)\n\n\njiyunLim\n\n\n\n\nApr 15, 2023\n\n\n[SOLAR] STGCN Ver1 수정본 (MSE: 0.1674)\n\n\njiyunLim\n\n\n\n\nApr 15, 2023\n\n\n[SOLAR] STGCN Ver2 수정본 (MSE: 0.2000)\n\n\njiyunLim\n\n\n\n\nApr 14, 2023\n\n\n[SOLAR] Crate Dataset (data2: 22/06~22/09/15) 재수정\n\n\njiyunLim\n\n\n\n\nApr 12, 2023\n\n\n[SOLAR] Crate Dataset (22/06~22/09/15)\n\n\njiyunLim\n\n\n\n\nApr 12, 2023\n\n\n[SOLAR] STGCN Ver1 (MSE: 0.1899)\n\n\njiyunLim\n\n\n\n\nApr 12, 2023\n\n\n[SOLAR] STGCN Ver1 90% (MSE: 0.1206)\n\n\njiyunLim\n\n\n\n\nApr 12, 2023\n\n\n[SOLAR] STGCN Ver2 (MSE: 0.2019)\n\n\njiyunLim\n\n\n\n\nApr 12, 2023\n\n\n[SOLAR] STGCN Ver2 90% (MSE: 0.1635)\n\n\njiyunLim\n\n\n\n\nApr 12, 2023\n\n\nR/Python jupyter\n\n\njiyunLim\n\n\n\n\nApr 12, 2023\n\n\nWindmillOutput (Small)\n\n\nJiyunLim\n\n\n\n\nApr 11, 2023\n\n\n[SOLAR] SARIMA (MSE: 0.478)\n\n\nJiyunLim\n\n\n\n\nApr 11, 2023\n\n\n6wk: 측도론 (2)\n\n\nJiyunLim\n\n\n\n\nApr 11, 2023\n\n\nGithub remote: error: this exceeds GitHub’s file size limit of 100.00 MB\n\n\nJiyunLim\n\n\n\n\nApr 11, 2023\n\n\nTS HW4\n\n\nJiyunLim\n\n\n\n\nApr 10, 2023\n\n\n[SOLAR] LSTM\n\n\nJiyunLim\n\n\n\n\nApr 10, 2023\n\n\nARIMA (Day)\n\n\nJiyunLim\n\n\n\n\nApr 10, 2023\n\n\nLSTM for Time Series Prediction (연습)\n\n\nJiyunLim\n\n\n\n\nApr 10, 2023\n\n\n스타벅스 주가예측\n\n\nJiyunLim\n\n\n\n\nApr 10, 2023\n\n\n연습장\n\n\nJiyunLim\n\n\n\n\nApr 9, 2023\n\n\n[SOLAR] STGCN Ver1 lag1\n\n\nJiyunLim\n\n\n\n\nApr 9, 2023\n\n\n[SOLAR] STGCN Ver2 lag1\n\n\nJiyunLim\n\n\n\n\nApr 9, 2023\n\n\nARIMA (시간별 예측안됨, 에러)\n\n\nJiyunLim\n\n\n\n\nApr 9, 2023\n\n\n푸리에 변환\n\n\nJiyunLim\n\n\n\n\nApr 8, 2023\n\n\n[SOLAR] STGCN Ver2 lag4\n\n\nJiyunLim\n\n\n\n\nApr 7, 2023\n\n\n[SOLAR] Dataset for STGCN Ver2\n\n\nJiyunLim\n\n\n\n\nApr 7, 2023\n\n\n[SOLAR] STGCN Ver1 lag4\n\n\nJiyunLim\n\n\n\n\nApr 6, 2023\n\n\n[SOLAR] Correlation coefficient by region\n\n\nJiyunLim\n\n\n\n\nApr 6, 2023\n\n\n[SOLAR] Dataset for STGCN Ver1\n\n\nJiyunLim\n\n\n\n\nApr 6, 2023\n\n\n[SOLAR] EPT by region\n\n\nJiyunLim\n\n\n\n\nApr 6, 2023\n\n\n[SOLAR] WindmillOutputLargeDatasetLoader\n\n\nJiyunLim\n\n\n\n\nApr 6, 2023\n\n\n[SOLAR] yU\n\n\nJiyunLim\n\n\n\n\nApr 6, 2023\n\n\nChikenpoxDataset\n\n\nJiyunLim\n\n\n\n\nApr 6, 2023\n\n\nWindmillOutputLargeDataset 분석 (실패)\n\n\nJiyunLim\n\n\n\n\nApr 6, 2023\n\n\n[R] pivot_wider Error\n\n\nJiyunLim\n\n\n\n\nApr 6, 2023\n\n\n[R] 문자열을 변수명으로 & assign\n\n\nJiyunLim\n\n\n\n\nApr 5, 2023\n\n\nHouse Price feedback\n\n\njiyunLim\n\n\n\n\nApr 5, 2023\n\n\nppt 폰트\n\n\njiyunLim\n\n\n\n\nApr 4, 2023\n\n\n[SOLAR] EPT\n\n\n신록예찬\n\n\n\n\nApr 4, 2023\n\n\n5wk: 측도론 (1)\n\n\nJiyunLim\n\n\n\n\nApr 4, 2023\n\n\nHouse Price\n\n\njiyunLim\n\n\n\n\nApr 3, 2023\n\n\n일사량자료정리\n\n\n임지윤, 신록예찬\n\n\n\n\nApr 3, 2023\n\n\n일사량자료정리(수정 for ARIMA)\n\n\nJiyunLim\n\n\n\n\nApr 2, 2023\n\n\n[Python] 새로운 열 할당(.assign) 및 특정 열 선택\n\n\njiyunLim\n\n\n\n\nApr 2, 2023\n\n\n초록 작성법\n\n\nJiyunLim\n\n\n\n\nApr 1, 2023\n\n\n[Python] 중첩인덱스 깨는 법\n\n\njiyunLim\n\n\n\n\nApr 1, 2023\n\n\n연구참여 확약서\n\n\nJiyunLim\n\n\n\n\nMar 30, 2023\n\n\n[R]Correlation coefficient by region\n\n\njiyun Lim\n\n\n\n\nMar 30, 2023\n\n\n[R]데이터 재구조화\n\n\njiyun Lim\n\n\n\n\nMar 29, 2023\n\n\nData preprocessing\n\n\njiyun Lim\n\n\n\n\nMar 21, 2023\n\n\nFew-shot learning using GPT3\n\n\njiyunLim\n\n\n\n\nMar 21, 2023\n\n\nLibraries for DA\n\n\njiyunLim\n\n\n\n\nMar 21, 2023\n\n\nScorecard\n\n\njiyun Lim\n\n\n\n\nMar 21, 2023\n\n\ndata visualization\n\n\njiyun Lim\n\n\n\n\nMar 21, 2023\n\n\ndowncasting\n\n\njiyun Lim\n\n\n\n\n\nMar 21, 2023\n\n\nresumetable\n\n\njiyun Lim\n\n\n\n\nMar 18, 2023\n\n\nWelcome To My Blog\n\n\nTristan O’Malley\n\n\n\n\nMar 14, 2023\n\n\nLists to read\n\n\njiyun Lim\n\n\n\n\nMar 13, 2023\n\n\nHW1\n\n\njiyun Lim\n\n\n\n\nMar 5, 2023\n\n\n[PAPER] A Comprehensive Survey on Geometric Deep Learning (+++)\n\n\njiyunLim\n\n\n\n\nFeb 24, 2023\n\n\nJulia 설치 및 실행\n\n\njiyun Lim\n\n\n\n\nFeb 21, 2023\n\n\nGraph Convolutional Network (이해용)\n\n\njiyun Lim\n\n\n\n\nFeb 20, 2023\n\n\n튜토리얼 따라가기1\n\n\njiyun Lim\n\n\n\n\n\n\nNo matching items"
  }
]